strict digraph "" {
	graph [bb="0,0,1031.7,985.35"];
	node [label="\"\N\""];
	kim_amplayo_2022_beyond_opinion_mining_summarizing_opinions_of_customer_reviews	[color=blue,
		height=2,
		id=kim_amplayo_2022_beyond_opinion_mining_summarizing_opinions_of_customer_reviews,
		"k-core"=7,
		label=kim_amplayo_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="8000.0,-1.0183708125699128e-05!"];
	wang_2021_transsum_translating_aspect_and_sentiment_embeddings_for_self_supervised_opinion_summarization	[color=blue,
		height=2,
		id=wang_2021_transsum_translating_aspect_and_sentiment_embeddings_for_self_supervised_opinion_summarization,
		"k-core"=7,
		label=wang_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="7335.5011957542065,3192.2445111143966!"];
	kim_amplayo_2022_beyond_opinion_mining_summarizing_opinions_of_customer_reviews -> wang_2021_transsum_translating_aspect_and_sentiment_embeddings_for_self_supervised_opinion_summarization	[pos="e,472.09,447.15 471.7,446.68 471.77,446.76 471.83,446.83 471.9,446.91"];
	see_2017_get_to_the_point_summarization_with_pointer_generator_networks	[color=green,
		height=7.9861,
		id=see_2017_get_to_the_point_summarization_with_pointer_generator_networks,
		"k-core"=8,
		label=see_2017,
		shape=circle,
		style=filled,
		width=7.9861,
		zazaza="1812.7013827053356,4659.840445927386!"];
	kim_amplayo_2022_beyond_opinion_mining_summarizing_opinions_of_customer_reviews -> see_2017_get_to_the_point_summarization_with_pointer_generator_networks	[pos="e,498.29,399.72 497.84,399.67 497.92,399.67 497.99,399.68 498.07,399.69"];
	brazinskas_2019_unsupervised_opinion_summarization_as_copycat_review_generation	[color=blue,
		height=5.5833,
		id=brazinskas_2019_unsupervised_opinion_summarization_as_copycat_review_generation,
		"k-core"=7,
		label=brazinskas_2019,
		shape=circle,
		style=filled,
		width=5.5833,
		zazaza="-7832.113701039074,1630.3361509411368!"];
	kim_amplayo_2022_beyond_opinion_mining_summarizing_opinions_of_customer_reviews -> brazinskas_2019_unsupervised_opinion_summarization_as_copycat_review_generation	[pos="e,461.79,383.94 461.71,383.96 461.73,383.95 461.74,383.95 461.75,383.95"];
	angelidis_2018_summarizing_opinions_aspect_extraction_meets_sentiment_prediction_and_they_are_both_weakly_supervised	[color=blue,
		height=7.125,
		id=angelidis_2018_summarizing_opinions_aspect_extraction_meets_sentiment_prediction_and_they_are_both_weakly_supervised,
		"k-core"=7,
		label=angelidis_2018,
		shape=circle,
		style=filled,
		width=7.125,
		zazaza="-7919.386344851683,-1132.8359914235982!"];
	kim_amplayo_2022_beyond_opinion_mining_summarizing_opinions_of_customer_reviews -> angelidis_2018_summarizing_opinions_aspect_extraction_meets_sentiment_prediction_and_they_are_both_weakly_supervised	[pos="e,421.37,432.05 421.38,431.97 421.38,431.99 421.38,432 421.38,432.02"];
	chu_2018_meansum_a_neural_model_for_unsupervised_multi_document_abstractive_summarization	[color=blue,
		height=6.3889,
		id=chu_2018_meansum_a_neural_model_for_unsupervised_multi_document_abstractive_summarization,
		"k-core"=7,
		label=chu_2018,
		shape=circle,
		style=filled,
		width=6.3889,
		zazaza="-7832.113701039074,-1630.335694471396!"];
	kim_amplayo_2022_beyond_opinion_mining_summarizing_opinions_of_customer_reviews -> chu_2018_meansum_a_neural_model_for_unsupervised_multi_document_abstractive_summarization	[pos="e,480.55,437.82 480.43,437.72 480.46,437.74 480.48,437.76 480.5,437.78"];
	amplayo_2019_informative_and_controllable_opinion_summarization	[color=blue,
		height=5.2222,
		id=amplayo_2019_informative_and_controllable_opinion_summarization,
		"k-core"=7,
		label=amplayo_2019,
		shape=circle,
		style=filled,
		width=5.2222,
		zazaza="-6809.5478620633585,-4198.816775376452!"];
	kim_amplayo_2022_beyond_opinion_mining_summarizing_opinions_of_customer_reviews -> amplayo_2019_informative_and_controllable_opinion_summarization	[pos="e,472.85,446.09 472.56,445.75 472.61,445.81 472.66,445.87 472.71,445.92"];
	mukherjee_2020_read_what_you_need_controllable_aspect_based_opinion_summarization_of_tourist_reviews	[color=blue,
		height=6.9722,
		id=mukherjee_2020_read_what_you_need_controllable_aspect_based_opinion_summarization_of_tourist_reviews,
		"k-core"=7,
		label=mukherjee_2020,
		shape=circle,
		style=filled,
		width=6.9722,
		zazaza="-3479.193895557898,-7203.833094348925!"];
	kim_amplayo_2022_beyond_opinion_mining_summarizing_opinions_of_customer_reviews -> mukherjee_2020_read_what_you_need_controllable_aspect_based_opinion_summarization_of_tourist_reviews	[pos="e,436.94,418.85 436.91,418.79 436.92,418.8 436.92,418.82 436.93,418.83"];
	zhao_2019_weakly_supervised_opinion_summarization_by_leveraging_external_information	[color=blue,
		height=3.3889,
		id=zhao_2019_weakly_supervised_opinion_summarization_by_leveraging_external_information,
		"k-core"=7,
		label=zhao_2019,
		shape=circle,
		style=filled,
		width=3.3889,
		zazaza="5810.956483896936,-5498.43453928006!"];
	kim_amplayo_2022_beyond_opinion_mining_summarizing_opinions_of_customer_reviews -> zhao_2019_weakly_supervised_opinion_summarization_by_leveraging_external_information	[pos="e,461.22,454.42 461.01,454.04 461.04,454.1 461.08,454.16 461.11,454.23"];
	wang_2021_transsum_translating_aspect_and_sentiment_embeddings_for_self_supervised_opinion_summarization -> see_2017_get_to_the_point_summarization_with_pointer_generator_networks	[pos="e,527.75,416.61 527.61,416.97 527.63,416.91 527.66,416.85 527.68,416.79"];
	wang_2021_transsum_translating_aspect_and_sentiment_embeddings_for_self_supervised_opinion_summarization -> brazinskas_2019_unsupervised_opinion_summarization_as_copycat_review_generation	[pos="e,475.24,417.04 475.42,417.48 475.39,417.4 475.36,417.33 475.33,417.26"];
	wang_2021_transsum_translating_aspect_and_sentiment_embeddings_for_self_supervised_opinion_summarization -> chu_2018_meansum_a_neural_model_for_unsupervised_multi_document_abstractive_summarization	[pos="e,480.61,437.89 480.65,437.99 480.64,437.97 480.63,437.95 480.63,437.93"];
	wang_2021_transsum_translating_aspect_and_sentiment_embeddings_for_self_supervised_opinion_summarization -> amplayo_2019_informative_and_controllable_opinion_summarization	[pos="e,494.69,471.96 494.76,472.07 494.75,472.05 494.73,472.03 494.72,472.01"];
	wang_2021_transsum_translating_aspect_and_sentiment_embeddings_for_self_supervised_opinion_summarization -> mukherjee_2020_read_what_you_need_controllable_aspect_based_opinion_summarization_of_tourist_reviews	[pos="e,451.13,433.07 451.53,433.47 451.46,433.4 451.4,433.34 451.33,433.27"];
	devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[color=green,
		height=12.542,
		id=devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding,
		"k-core"=8,
		label=devlin_2019,
		shape=circle,
		style=filled,
		width=12.542,
		zazaza="-3349.561669245284,3712.2008042827415!"];
	wang_2021_transsum_translating_aspect_and_sentiment_embeddings_for_self_supervised_opinion_summarization -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,569.07,513.95 568.75,513.81 568.8,513.83 568.86,513.85 568.91,513.88"];
	vaswani_2017_attention_is_all_you_need	[color=green,
		height=11.194,
		id=vaswani_2017_attention_is_all_you_need,
		"k-core"=8,
		label=vaswani_2017,
		shape=circle,
		style=filled,
		width=11.194,
		zazaza="4937.822818920222,786.0702191833145!"];
	wang_2021_transsum_translating_aspect_and_sentiment_embeddings_for_self_supervised_opinion_summarization -> vaswani_2017_attention_is_all_you_need	[pos="e,572.38,505.62 571.94,505.49 572.01,505.51 572.08,505.54 572.16,505.56"];
	merity_2016_pointer_sentinel_mixture_models	[color=green,
		height=6.9722,
		id=merity_2016_pointer_sentinel_mixture_models,
		"k-core"=8,
		label=merity_2016,
		shape=circle,
		style=filled,
		width=6.9722,
		zazaza="-3891.5186885743565,3139.4395085686083!"];
	see_2017_get_to_the_point_summarization_with_pointer_generator_networks -> merity_2016_pointer_sentinel_mixture_models	[pos="e,654.37,404.17 654.3,404.17 654.31,404.17 654.33,404.17 654.34,404.17"];
	brazinskas_2019_unsupervised_opinion_summarization_as_copycat_review_generation -> see_2017_get_to_the_point_summarization_with_pointer_generator_networks	[pos="e,532.37,404.01 532.34,404 532.34,404 532.35,404 532.36,404.01"];
	brazinskas_2019_unsupervised_opinion_summarization_as_copycat_review_generation -> angelidis_2018_summarizing_opinions_aspect_extraction_meets_sentiment_prediction_and_they_are_both_weakly_supervised	[pos="e,421.4,432.05 421.49,431.95 421.47,431.97 421.45,431.99 421.44,432.01"];
	brazinskas_2019_unsupervised_opinion_summarization_as_copycat_review_generation -> chu_2018_meansum_a_neural_model_for_unsupervised_multi_document_abstractive_summarization	[pos="e,480.58,437.81 480.54,437.7 480.55,437.72 480.55,437.75 480.56,437.77"];
	holtzman_2019_the_curious_case_of_neural_text_degeneration	[color=blue,
		height=6.3889,
		id=holtzman_2019_the_curious_case_of_neural_text_degeneration,
		"k-core"=7,
		label=holtzman_2019,
		shape=circle,
		style=filled,
		width=6.3889,
		zazaza="6742.414954643893,4305.7913564722785!"];
	brazinskas_2019_unsupervised_opinion_summarization_as_copycat_review_generation -> holtzman_2019_the_curious_case_of_neural_text_degeneration	[pos="e,642.04,474.22 641.79,474.1 641.83,474.12 641.88,474.14 641.92,474.16"];
	he_2017_an_unsupervised_neural_attention_model_for_aspect_extraction	[color=blue,
		height=8.5139,
		id=he_2017_an_unsupervised_neural_attention_model_for_aspect_extraction,
		"k-core"=7,
		label=he_2017,
		shape=circle,
		style=filled,
		width=8.5139,
		zazaza="-7176.145036693861,3535.9499259328845!"];
	angelidis_2018_summarizing_opinions_aspect_extraction_meets_sentiment_prediction_and_they_are_both_weakly_supervised -> he_2017_an_unsupervised_neural_attention_model_for_aspect_extraction	[pos="e,471.03,424.45 470.92,424.47 470.94,424.47 470.97,424.46 470.98,424.46"];
	chu_2018_meansum_a_neural_model_for_unsupervised_multi_document_abstractive_summarization -> see_2017_get_to_the_point_summarization_with_pointer_generator_networks	[pos="e,532.35,404.04 532.24,404.11 532.26,404.1 532.28,404.08 532.3,404.07"];
	chu_2018_meansum_a_neural_model_for_unsupervised_multi_document_abstractive_summarization -> vaswani_2017_attention_is_all_you_need	[pos="e,587.96,510.31 587.9,510.27 587.92,510.28 587.93,510.28 587.94,510.29"];
	jang_2016_categorical_reparameterization_with_gumbel_softmax	[color=blue,
		height=7.2778,
		id=jang_2016_categorical_reparameterization_with_gumbel_softmax,
		"k-core"=7,
		label=jang_2016,
		shape=circle,
		style=filled,
		width=7.2778,
		zazaza="7746.146202757456,-1999.30453791125!"];
	chu_2018_meansum_a_neural_model_for_unsupervised_multi_document_abstractive_summarization -> jang_2016_categorical_reparameterization_with_gumbel_softmax	[pos="e,515.91,358.32 515.89,358.36 515.89,358.35 515.9,358.35 515.9,358.34"];
	amplayo_2019_informative_and_controllable_opinion_summarization -> see_2017_get_to_the_point_summarization_with_pointer_generator_networks	[pos="e,532.38,404.03 532.36,404.06 532.36,404.06 532.37,404.05 532.37,404.04"];
	amplayo_2019_informative_and_controllable_opinion_summarization -> brazinskas_2019_unsupervised_opinion_summarization_as_copycat_review_generation	[pos="e,461.82,383.95 461.84,384 461.83,383.99 461.83,383.98 461.82,383.97"];
	amplayo_2019_informative_and_controllable_opinion_summarization -> angelidis_2018_summarizing_opinions_aspect_extraction_meets_sentiment_prediction_and_they_are_both_weakly_supervised	[pos="e,421.38,432.09 421.42,432.11 421.42,432.11 421.41,432.1 421.4,432.1"];
	amplayo_2019_informative_and_controllable_opinion_summarization -> chu_2018_meansum_a_neural_model_for_unsupervised_multi_document_abstractive_summarization	[pos="e,480.6,437.88 480.63,437.95 480.62,437.93 480.62,437.92 480.61,437.91"];
	amplayo_2019_informative_and_controllable_opinion_summarization -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.17,518.85 580.12,518.82 580.13,518.83 580.14,518.83 580.15,518.83"];
	amplayo_2019_informative_and_controllable_opinion_summarization -> vaswani_2017_attention_is_all_you_need	[pos="e,587.96,510.31 587.91,510.29 587.93,510.3 587.94,510.3 587.94,510.3"];
	mukherjee_2020_read_what_you_need_controllable_aspect_based_opinion_summarization_of_tourist_reviews -> brazinskas_2019_unsupervised_opinion_summarization_as_copycat_review_generation	[pos="e,461.79,383.96 461.74,384.04 461.75,384.02 461.76,384.01 461.77,384"];
	mukherjee_2020_read_what_you_need_controllable_aspect_based_opinion_summarization_of_tourist_reviews -> angelidis_2018_summarizing_opinions_aspect_extraction_meets_sentiment_prediction_and_they_are_both_weakly_supervised	[pos="e,421.42,432.05 421.55,431.94 421.52,431.96 421.49,431.98 421.47,432"];
	mukherjee_2020_read_what_you_need_controllable_aspect_based_opinion_summarization_of_tourist_reviews -> chu_2018_meansum_a_neural_model_for_unsupervised_multi_document_abstractive_summarization	[pos="e,480.56,437.84 480.47,437.8 480.49,437.81 480.5,437.82 480.52,437.82"];
	mukherjee_2020_read_what_you_need_controllable_aspect_based_opinion_summarization_of_tourist_reviews -> amplayo_2019_informative_and_controllable_opinion_summarization	[pos="e,494.63,471.89 494.51,471.77 494.53,471.8 494.56,471.82 494.58,471.84"];
	mukherjee_2020_read_what_you_need_controllable_aspect_based_opinion_summarization_of_tourist_reviews -> zhao_2019_weakly_supervised_opinion_summarization_by_leveraging_external_information	[pos="e,477,483.01 476.98,482.97 476.99,482.98 476.99,482.99 476.99,483"];
	mukherjee_2020_read_what_you_need_controllable_aspect_based_opinion_summarization_of_tourist_reviews -> he_2017_an_unsupervised_neural_attention_model_for_aspect_extraction	[pos="e,471.04,424.44 470.97,424.43 470.98,424.43 471,424.44 471.01,424.44"];
	reimers_2019_sentence_bert_sentence_embeddings_using_siamese_bert_networks	[color=green,
		height=8.5139,
		id=reimers_2019_sentence_bert_sentence_embeddings_using_siamese_bert_networks,
		"k-core"=8,
		label=reimers_2019,
		shape=circle,
		style=filled,
		width=8.5139,
		zazaza="-4969.500873000111,-551.4175493934744!"];
	mukherjee_2020_read_what_you_need_controllable_aspect_based_opinion_summarization_of_tourist_reviews -> reimers_2019_sentence_bert_sentence_embeddings_using_siamese_bert_networks	[pos="e,606.19,490.53 606.1,490.49 606.12,490.5 606.14,490.51 606.16,490.52"];
	xu_2018_double_embeddings_and_cnn_based_sequence_labeling_for_aspect_extraction	[color=yellow,
		height=6.3889,
		id=xu_2018_double_embeddings_and_cnn_based_sequence_labeling_for_aspect_extraction,
		"k-core"=6,
		label=xu_2018,
		shape=circle,
		style=filled,
		width=6.3889,
		zazaza="-0.46310969800995394,-0.8863009799783171!"];
	mukherjee_2020_read_what_you_need_controllable_aspect_based_opinion_summarization_of_tourist_reviews -> xu_2018_double_embeddings_and_cnn_based_sequence_labeling_for_aspect_extraction	[pos="e,422.08,469.71 422.11,469.6 422.1,469.63 422.1,469.65 422.09,469.67"];
	zhao_2019_weakly_supervised_opinion_summarization_by_leveraging_external_information -> brazinskas_2019_unsupervised_opinion_summarization_as_copycat_review_generation	[pos="e,461.81,383.96 461.82,384.01 461.82,384 461.82,383.99 461.82,383.98"];
	zhao_2019_weakly_supervised_opinion_summarization_by_leveraging_external_information -> angelidis_2018_summarizing_opinions_aspect_extraction_meets_sentiment_prediction_and_they_are_both_weakly_supervised	[pos="e,421.41,432.12 421.53,432.23 421.5,432.21 421.48,432.19 421.46,432.17"];
	zhao_2019_weakly_supervised_opinion_summarization_by_leveraging_external_information -> chu_2018_meansum_a_neural_model_for_unsupervised_multi_document_abstractive_summarization	[pos="e,480.59,437.89 480.58,437.98 480.58,437.96 480.58,437.94 480.59,437.93"];
	zhao_2019_weakly_supervised_opinion_summarization_by_leveraging_external_information -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.17,518.85 580.11,518.83 580.12,518.83 580.13,518.84 580.14,518.84"];
	zhao_2019_weakly_supervised_opinion_summarization_by_leveraging_external_information -> he_2017_an_unsupervised_neural_attention_model_for_aspect_extraction	[pos="e,471.07,424.49 471.08,424.62 471.08,424.59 471.08,424.56 471.07,424.54"];
	devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding -> vaswani_2017_attention_is_all_you_need	[pos="e,587.96,510.34 587.89,510.41 587.91,510.4 587.92,510.39 587.93,510.37"];
	peters_2018_deep_contextualized_word_representations	[color=green,
		height=10.319,
		id=peters_2018_deep_contextualized_word_representations,
		"k-core"=8,
		label=peters_2018,
		shape=circle,
		style=filled,
		width=10.319,
		zazaza="4997.507929808519,-157.84176661336826!"];
	devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding -> peters_2018_deep_contextualized_word_representations	[pos="e,583.75,529.85 583.72,529.76 583.73,529.78 583.74,529.8 583.74,529.82"];
	holtzman_2019_the_curious_case_of_neural_text_degeneration -> vaswani_2017_attention_is_all_you_need	[pos="e,588,510.32 588.05,510.31 588.04,510.31 588.03,510.31 588.02,510.31"];
	radford_2019_language_models_are_unsupervised_multitask_learners	[color=green,
		height=9.4722,
		id=radford_2019_language_models_are_unsupervised_multitask_learners,
		"k-core"=8,
		label=radford_2019,
		shape=circle,
		style=filled,
		width=9.4722,
		zazaza="-4984.43124043049,394.26318560579784!"];
	holtzman_2019_the_curious_case_of_neural_text_degeneration -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,630.04,511.49 630.14,511.45 630.12,511.45 630.1,511.46 630.08,511.47"];
	reimers_2019_sentence_bert_sentence_embeddings_using_siamese_bert_networks -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.2,518.83 580.26,518.77 580.25,518.79 580.24,518.8 580.23,518.81"];
	reimers_2019_sentence_bert_sentence_embeddings_using_siamese_bert_networks -> vaswani_2017_attention_is_all_you_need	[pos="e,587.99,510.3 588.03,510.26 588.03,510.27 588.02,510.28 588.01,510.29"];
	liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[color=green,
		height=9.8194,
		id=liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach,
		"k-core"=8,
		label=liu_2019,
		shape=circle,
		style=filled,
		width=9.8194,
		zazaza="2245.3020585768713,4467.50698658093!"];
	reimers_2019_sentence_bert_sentence_embeddings_using_siamese_bert_networks -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.73,532.53 612.72,532.44 612.72,532.46 612.72,532.48 612.72,532.49"];
	zhang_2019_bertscore_evaluating_text_generation_with_bert	[color=blue,
		height=6.6111,
		id=zhang_2019_bertscore_evaluating_text_generation_with_bert,
		"k-core"=7,
		label=zhang_2019,
		shape=circle,
		style=filled,
		width=6.6111,
		zazaza="-6809.547385226202,4198.817231846192!"];
	reimers_2019_sentence_bert_sentence_embeddings_using_siamese_bert_networks -> zhang_2019_bertscore_evaluating_text_generation_with_bert	[pos="e,662.57,542.35 662.45,542.23 662.48,542.26 662.5,542.28 662.52,542.3"];
	xu_2018_double_embeddings_and_cnn_based_sequence_labeling_for_aspect_extraction -> he_2017_an_unsupervised_neural_attention_model_for_aspect_extraction	[pos="e,471.03,424.48 470.92,424.58 470.95,424.56 470.97,424.54 470.98,424.52"];
	bojanowski_2016_enriching_word_vectors_with_subword_information	[color=green,
		height=10.125,
		id=bojanowski_2016_enriching_word_vectors_with_subword_information,
		"k-core"=8,
		label=bojanowski_2016,
		shape=circle,
		style=filled,
		width=10.125,
		zazaza="-3790.471530599801,-3260.724840306416!"];
	xu_2018_double_embeddings_and_cnn_based_sequence_labeling_for_aspect_extraction -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,523.4,509.53 523.35,509.51 523.36,509.51 523.37,509.52 523.38,509.52"];
	hoyle_2022_are_neural_topic_models_broken	[color=green,
		height=2,
		id=hoyle_2022_are_neural_topic_models_broken,
		"k-core"=8,
		label=hoyle_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="4997.507929808519,157.84274108565958!"];
	hoyle_2022_are_neural_topic_models_broken -> merity_2016_pointer_sentinel_mixture_models	[pos="e,654.36,404.13 654.28,404 654.3,404.03 654.32,404.05 654.33,404.07"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey	[color=red,
		height=6.9722,
		id=zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey,
		"k-core"=9,
		label=zhao_2021,
		shape=circle,
		style=filled,
		width=6.9722,
		zazaza="47.708443462083196,51.224056854046765!"];
	hoyle_2022_are_neural_topic_models_broken -> zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey	[pos="e,595.8,371.18 595.85,371.12 595.84,371.13 595.83,371.14 595.82,371.15"];
	lau_2017_topically_driven_neural_language_model	[color=green,
		height=9.8611,
		id=lau_2017_topically_driven_neural_language_model,
		"k-core"=8,
		label=lau_2017,
		shape=circle,
		style=filled,
		width=9.8611,
		zazaza="1958.9021882219156,4600.293617814604!"];
	hoyle_2022_are_neural_topic_models_broken -> lau_2017_topically_driven_neural_language_model	[pos="e,558.72,375.37 558.85,375.3 558.82,375.32 558.8,375.33 558.78,375.34"];
	card_2017_neural_models_for_documents_with_metadata	[color=red,
		height=9.8611,
		id=card_2017_neural_models_for_documents_with_metadata,
		"k-core"=9,
		label=card_2017,
		shape=circle,
		style=filled,
		width=9.8611,
		zazaza="21.210361251866605,66.70922431653018!"];
	hoyle_2022_are_neural_topic_models_broken -> card_2017_neural_models_for_documents_with_metadata	[pos="e,615.36,384.92 615.37,384.83 615.37,384.85 615.36,384.87 615.36,384.89"];
	burkhardt_2019_decoupling_sparsity_and_smoothness_in_the_dirichlet_variational_autoencoder_topic_model	[color=green,
		height=7.5417,
		id=burkhardt_2019_decoupling_sparsity_and_smoothness_in_the_dirichlet_variational_autoencoder_topic_model,
		"k-core"=8,
		label=burkhardt_2019,
		shape=circle,
		style=filled,
		width=7.5417,
		zazaza="-1287.740154358996,4831.3274788418985!"];
	hoyle_2022_are_neural_topic_models_broken -> burkhardt_2019_decoupling_sparsity_and_smoothness_in_the_dirichlet_variational_autoencoder_topic_model	[pos="e,642.07,333.82 642.01,333.85 642.03,333.84 642.04,333.84 642.04,333.83"];
	wang_2019_topic_guided_variational_auto_encoder_for_text_generation	[color=green,
		height=7.125,
		id=wang_2019_topic_guided_variational_auto_encoder_for_text_generation,
		"k-core"=8,
		label=wang_2019,
		shape=circle,
		style=filled,
		width=7.125,
		zazaza="-1738.9137865051318,4687.875788546716!"];
	hoyle_2022_are_neural_topic_models_broken -> wang_2019_topic_guided_variational_auto_encoder_for_text_generation	[pos="e,562.49,352.01 562.61,351.99 562.58,351.99 562.56,352 562.54,352"];
	doogan_2021_topic_model_or_topic_twaddle_re_evaluating_semantic_interpretability_measures	[color=blue,
		height=7.6667,
		id=doogan_2021_topic_model_or_topic_twaddle_re_evaluating_semantic_interpretability_measures,
		"k-core"=7,
		label=doogan_2021,
		shape=circle,
		style=filled,
		width=7.6667,
		zazaza="-6064.7534952853675,5217.160200960006!"];
	hoyle_2022_are_neural_topic_models_broken -> doogan_2021_topic_model_or_topic_twaddle_re_evaluating_semantic_interpretability_measures	[pos="e,550.42,316.97 550.76,317.11 550.7,317.08 550.64,317.06 550.59,317.04"];
	card_2018_neural_models_for_documents_with_metadata	[color=red,
		height=10.056,
		id=card_2018_neural_models_for_documents_with_metadata,
		"k-core"=9,
		label=card_2018,
		shape=circle,
		style=filled,
		width=10.056,
		zazaza="-69.78204153835198,-5.519680604370938!"];
	hoyle_2022_are_neural_topic_models_broken -> card_2018_neural_models_for_documents_with_metadata	[pos="e,608.09,386.79 608.11,386.7 608.1,386.72 608.1,386.74 608.09,386.75"];
	dieng_2019_topic_modeling_in_embedding_spaces	[color=red,
		height=9.4306,
		id=dieng_2019_topic_modeling_in_embedding_spaces,
		"k-core"=9,
		label=dieng_2019,
		shape=circle,
		style=filled,
		width=9.4306,
		zazaza="-46.8938675417591,-51.97081143817327!"];
	hoyle_2022_are_neural_topic_models_broken -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,568.55,398.3 568.96,397.85 568.89,397.93 568.83,398 568.76,398.08"];
	wang_2020_friendly_topic_assistant_for_transformer_based_abstractive_summarization	[color=green,
		height=4.7778,
		id=wang_2020_friendly_topic_assistant_for_transformer_based_abstractive_summarization,
		"k-core"=8,
		label=wang_2020,
		shape=circle,
		style=filled,
		width=4.7778,
		zazaza="-3108.625390584367,-3916.1777456617488!"];
	hoyle_2022_are_neural_topic_models_broken -> wang_2020_friendly_topic_assistant_for_transformer_based_abstractive_summarization	[pos="e,608.44,416.5 608.47,416.21 608.47,416.26 608.46,416.31 608.46,416.36"];
	hoyle_2020_improving_neural_topic_models_using_knowledge_distillation	[color=red,
		height=6.6111,
		id=hoyle_2020_improving_neural_topic_models_using_knowledge_distillation,
		"k-core"=9,
		label=hoyle_2020,
		shape=circle,
		style=filled,
		width=6.6111,
		zazaza="-36.26820297801658,-59.87167649529113!"];
	hoyle_2022_are_neural_topic_models_broken -> hoyle_2020_improving_neural_topic_models_using_knowledge_distillation	[pos="e,620.75,416.95 620.74,416.67 620.74,416.72 620.74,416.77 620.75,416.81"];
	hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence	[color=red,
		height=6.3889,
		id=hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence,
		"k-core"=9,
		label=hoyle_2021,
		shape=circle,
		style=filled,
		width=6.3889,
		zazaza="39.06202562868922,-58.08750682608082!"];
	hoyle_2022_are_neural_topic_models_broken -> hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence	[pos="e,593.07,344.3 593.13,344.31 593.11,344.31 593.1,344.31 593.1,344.31"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> reimers_2019_sentence_bert_sentence_embeddings_using_siamese_bert_networks	[pos="e,606.22,490.52 606.22,490.46 606.22,490.47 606.22,490.49 606.22,490.5"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> lau_2017_topically_driven_neural_language_model	[pos="e,558.71,375.39 558.79,375.38 558.77,375.38 558.75,375.38 558.74,375.38"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> card_2017_neural_models_for_documents_with_metadata	[pos="e,615.35,384.94 615.3,384.91 615.31,384.92 615.32,384.92 615.33,384.93"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> burkhardt_2019_decoupling_sparsity_and_smoothness_in_the_dirichlet_variational_autoencoder_topic_model	[pos="e,642.05,333.84 641.95,333.92 641.97,333.91 641.99,333.89 642.01,333.88"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> wang_2019_topic_guided_variational_auto_encoder_for_text_generation	[pos="e,562.47,352.03 562.54,352.07 562.53,352.06 562.51,352.05 562.5,352.04"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> doogan_2021_topic_model_or_topic_twaddle_re_evaluating_semantic_interpretability_measures	[pos="e,525.07,306.37 525.24,306.25 525.21,306.27 525.18,306.29 525.15,306.31"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> card_2018_neural_models_for_documents_with_metadata	[pos="e,608.04,386.77 607.94,386.64 607.96,386.67 607.98,386.7 608,386.72"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,553.86,414.38 553.95,414.29 553.93,414.31 553.91,414.32 553.89,414.34"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> wang_2020_friendly_topic_assistant_for_transformer_based_abstractive_summarization	[pos="e,602.51,462.47 602.51,462.42 602.51,462.43 602.51,462.44 602.51,462.45"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> hoyle_2020_improving_neural_topic_models_using_knowledge_distillation	[pos="e,621.6,437.24 621.59,437.2 621.59,437.21 621.59,437.21 621.6,437.22"];
	guo_2019_recurrent_hierarchical_topic_guided_rnn_for_language_generation	[color=green,
		height=4.7778,
		id=guo_2019_recurrent_hierarchical_topic_guided_rnn_for_language_generation,
		"k-core"=8,
		label=guo_2019,
		shape=circle,
		style=filled,
		width=4.7778,
		zazaza="4519.4190753270395,2138.890314012625!"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> guo_2019_recurrent_hierarchical_topic_guided_rnn_for_language_generation	[pos="e,573.35,428.02 573.4,427.9 573.39,427.92 573.38,427.95 573.37,427.97"];
	nan_2019_topic_modeling_with_wasserstein_autoencoders	[color=red,
		height=8.5972,
		id=nan_2019_topic_modeling_with_wasserstein_autoencoders,
		"k-core"=9,
		label=nan_2019,
		shape=circle,
		style=filled,
		width=8.5972,
		zazaza="29.44410483813131,63.50625548915382!"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,623.26,372.37 623.2,372.36 623.22,372.36 623.23,372.36 623.24,372.36"];
	srivastava_2017_autoencoding_variational_inference_for_topic_models	[color=red,
		height=10.819,
		id=srivastava_2017_autoencoding_variational_inference_for_topic_models,
		"k-core"=9,
		label=srivastava_2017,
		shape=circle,
		style=filled,
		width=10.819,
		zazaza="-20.15462702558039,67.0357421360266!"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.69,389.49 577.73,389.45 577.72,389.46 577.71,389.46 577.71,389.47"];
	zhao_2017_metalda_a_topic_model_that_efficiently_incorporates_meta_information	[color=blue,
		height=6.1528,
		id=zhao_2017_metalda_a_topic_model_that_efficiently_incorporates_meta_information,
		"k-core"=7,
		label=zhao_2017,
		shape=circle,
		style=filled,
		width=6.1528,
		zazaza="-6938.7039743933465,-3981.756448419481!"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> zhao_2017_metalda_a_topic_model_that_efficiently_incorporates_meta_information	[pos="e,485.97,332.7 486.03,332.72 486.01,332.72 486,332.71 485.99,332.71"];
	zhao_2020_neural_topic_model_via_optimal_transport	[color=red,
		height=5.5833,
		id=zhao_2020_neural_topic_model_via_optimal_transport,
		"k-core"=9,
		label=zhao_2020,
		shape=circle,
		style=filled,
		width=5.5833,
		zazaza="-11.550303780355032,-69.04049864039368!"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> zhao_2020_neural_topic_model_via_optimal_transport	[pos="e,619.27,336.39 619.43,336.52 619.4,336.5 619.37,336.48 619.35,336.45"];
	zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling	[color=green,
		height=8.2778,
		id=zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling,
		"k-core"=8,
		label=zhang_2018,
		shape=circle,
		style=filled,
		width=8.2778,
		zazaza="2522.7516954959788,-4316.911394334684!"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling	[pos="e,538.87,376.18 538.99,376.17 538.96,376.17 538.94,376.17 538.92,376.18"];
	gui_2019_neural_topic_model_with_reinforcement_learning	[color=green,
		height=6.1528,
		id=gui_2019_neural_topic_model_with_reinforcement_learning,
		"k-core"=8,
		label=gui_2019,
		shape=circle,
		style=filled,
		width=6.1528,
		zazaza="4645.3872332396295,-1849.4264796307127!"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> gui_2019_neural_topic_model_with_reinforcement_learning	[pos="e,530.38,356.3 530.42,356.31 530.41,356.3 530.4,356.3 530.4,356.3"];
	wang_2017_topic_compositional_neural_language_model	[color=green,
		height=7.6667,
		id=wang_2017_topic_compositional_neural_language_model,
		"k-core"=8,
		label=wang_2017,
		shape=circle,
		style=filled,
		width=7.6667,
		zazaza="-2855.296412237685,4104.544205156015!"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> wang_2017_topic_compositional_neural_language_model	[pos="e,515.79,370.63 515.84,370.63 515.83,370.63 515.82,370.63 515.81,370.63"];
	miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[color=red,
		height=9.0556,
		id=miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference,
		"k-core"=9,
		label=miao_2017,
		shape=circle,
		style=filled,
		width=9.0556,
		zazaza="56.50100532756974,-41.32355926424299!"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,630.62,360.72 630.55,360.74 630.57,360.74 630.58,360.73 630.59,360.73"];
	dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency	[color=green,
		height=9.4306,
		id=dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency,
		"k-core"=8,
		label=dieng_2016,
		shape=circle,
		style=filled,
		width=9.4306,
		zazaza="4375.435115555416,-2419.8277294411937!"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency	[pos="e,585.61,373.53 585.69,373.51 585.68,373.52 585.66,373.52 585.64,373.52"];
	wu_2020_neural_mixed_counting_models_for_dispersed_topic_discovery	[color=yellow,
		height=6.6111,
		id=wu_2020_neural_mixed_counting_models_for_dispersed_topic_discovery,
		"k-core"=6,
		label=wu_2020,
		shape=circle,
		style=filled,
		width=6.6111,
		zazaza="-0.9899232931064604,0.14160455598666735!"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> wu_2020_neural_mixed_counting_models_for_dispersed_topic_discovery	[pos="e,662.67,336.81 662.64,336.83 662.64,336.82 662.65,336.82 662.66,336.82"];
	tang_2019_a_topic_augmented_text_generation_model_joint_learning_of_semantics_and_structural_features	[color=green,
		height=4.1944,
		id=tang_2019_a_topic_augmented_text_generation_model_joint_learning_of_semantics_and_structural_features,
		"k-core"=8,
		label=tang_2019,
		shape=circle,
		style=filled,
		width=4.1944,
		zazaza="276.1303385610261,4992.369393833542!"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> tang_2019_a_topic_augmented_text_generation_model_joint_learning_of_semantics_and_structural_features	[pos="e,582.09,310.41 582.09,310.44 582.09,310.43 582.09,310.42 582.09,310.42"];
	zeng_2018_topic_memory_networks_for_short_text_classification	[color=yellow,
		height=4.1944,
		id=zeng_2018_topic_memory_networks_for_short_text_classification,
		"k-core"=6,
		label=zeng_2018,
		shape=circle,
		style=filled,
		width=4.1944,
		zazaza="-0.46310939998673084,0.8863010966416794!"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> zeng_2018_topic_memory_networks_for_short_text_classification	[pos="e,666.89,354.5 666.85,354.51 666.86,354.51 666.87,354.5 666.87,354.5"];
	hu_2020_neural_topic_modeling_with_cycle_consistent_adversarial_training	[color=red,
		height=6.9722,
		id=hu_2020_neural_topic_modeling_with_cycle_consistent_adversarial_training,
		"k-core"=9,
		label=hu_2020,
		shape=circle,
		style=filled,
		width=6.9722,
		zazaza="-68.94717597048727,-12.094904092512435!"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> hu_2020_neural_topic_modeling_with_cycle_consistent_adversarial_training	[pos="e,667.6,382.26 667.56,382.25 667.57,382.25 667.57,382.25 667.58,382.26"];
	rezaee_2020_a_discrete_variational_recurrent_topic_model_without_the_reparametrization_trick	[color=green,
		height=5.2222,
		id=rezaee_2020_a_discrete_variational_recurrent_topic_model_without_the_reparametrization_trick,
		"k-core"=8,
		label=rezaee_2020,
		shape=circle,
		style=filled,
		width=5.2222,
		zazaza="-2855.296710260908,-4104.543919862427!"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> rezaee_2020_a_discrete_variational_recurrent_topic_model_without_the_reparametrization_trick	[pos="e,545.87,331.26 545.98,331.35 545.95,331.33 545.93,331.31 545.91,331.3"];
	wang_2020_neural_topic_modeling_with_bidirectional_adversarial_training	[color=red,
		height=7.2778,
		id=wang_2020_neural_topic_modeling_with_bidirectional_adversarial_training,
		"k-core"=9,
		label=wang_2020,
		shape=circle,
		style=filled,
		width=7.2778,
		zazaza="53.78064100255113,-44.806724757597294!"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> wang_2020_neural_topic_modeling_with_bidirectional_adversarial_training	[pos="e,648.31,389.45 648.19,389.41 648.22,389.42 648.24,389.43 648.26,389.44"];
	ding_2018_coherence_aware_neural_topic_modeling	[color=red,
		height=7.6667,
		id=ding_2018_coherence_aware_neural_topic_modeling,
		"k-core"=9,
		label=ding_2018,
		shape=circle,
		style=filled,
		width=7.6667,
		zazaza="68.74765158030146,-13.181828165723793!"];
	zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey -> ding_2018_coherence_aware_neural_topic_modeling	[pos="e,661.34,368.18 661.31,368.19 661.31,368.19 661.32,368.19 661.33,368.19"];
	card_2017_neural_models_for_documents_with_metadata -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.7,389.5 577.79,389.49 577.77,389.49 577.75,389.49 577.74,389.49"];
	wang_2019_topic_guided_variational_auto_encoder_for_text_generation -> see_2017_get_to_the_point_summarization_with_pointer_generator_networks	[pos="e,532.41,403.98 532.47,403.87 532.46,403.89 532.45,403.91 532.44,403.93"];
	wang_2019_topic_guided_variational_auto_encoder_for_text_generation -> lau_2017_topically_driven_neural_language_model	[pos="e,558.68,375.37 558.69,375.32 558.69,375.34 558.69,375.35 558.69,375.35"];
	wang_2019_topic_guided_variational_auto_encoder_for_text_generation -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.67,389.47 577.63,389.39 577.64,389.41 577.65,389.43 577.65,389.44"];
	wang_2019_topic_guided_variational_auto_encoder_for_text_generation -> wang_2017_topic_compositional_neural_language_model	[pos="e,515.81,370.62 515.91,370.58 515.89,370.59 515.87,370.6 515.85,370.6"];
	wang_2019_topic_guided_variational_auto_encoder_for_text_generation -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,630.64,360.71 630.6,360.71 630.61,360.71 630.61,360.71 630.62,360.71"];
	wang_2019_topic_guided_variational_auto_encoder_for_text_generation -> dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency	[pos="e,585.56,373.52 585.51,373.48 585.52,373.49 585.53,373.5 585.54,373.5"];
	yang_2017_improved_variational_autoencoders_for_text_modeling_using_dilated_convolutions	[color=blue,
		height=5.8889,
		id=yang_2017_improved_variational_autoencoders_for_text_modeling_using_dilated_convolutions,
		"k-core"=7,
		label=yang_2017,
		shape=circle,
		style=filled,
		width=5.8889,
		zazaza="7231.0705205232625,-3422.2242843690374!"];
	wang_2019_topic_guided_variational_auto_encoder_for_text_generation -> yang_2017_improved_variational_autoencoders_for_text_modeling_using_dilated_convolutions	[pos="e,519.02,331.22 519.11,331.26 519.09,331.25 519.07,331.24 519.06,331.23"];
	doogan_2021_topic_model_or_topic_twaddle_re_evaluating_semantic_interpretability_measures -> zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey	[pos="e,595.63,371.34 595.45,371.46 595.48,371.44 595.51,371.42 595.54,371.4"];
	doogan_2021_topic_model_or_topic_twaddle_re_evaluating_semantic_interpretability_measures -> zhao_2017_metalda_a_topic_model_that_efficiently_incorporates_meta_information	[pos="e,485.98,332.67 486.06,332.62 486.04,332.63 486.03,332.64 486.01,332.65"];
	card_2018_neural_models_for_documents_with_metadata -> lau_2017_topically_driven_neural_language_model	[pos="e,558.72,375.4 558.82,375.42 558.8,375.42 558.78,375.41 558.76,375.41"];
	card_2018_neural_models_for_documents_with_metadata -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.7,389.5 577.76,389.49 577.75,389.49 577.74,389.49 577.73,389.5"];
	dieng_2019_topic_modeling_in_embedding_spaces -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.66,389.52 577.61,389.57 577.62,389.56 577.63,389.55 577.64,389.54"];
	dieng_2019_topic_modeling_in_embedding_spaces -> zhao_2017_metalda_a_topic_model_that_efficiently_incorporates_meta_information	[pos="e,485.96,332.71 486,332.75 485.99,332.74 485.98,332.73 485.98,332.73"];
	dieng_2019_topic_modeling_in_embedding_spaces -> zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling	[pos="e,538.83,376.21 538.87,376.29 538.86,376.27 538.85,376.26 538.85,376.25"];
	cong_2017_deep_latent_dirichlet_allocation_with_topic_layer_adaptive_stochastic_gradient_riemannian_mcmc	[color=blue,
		height=6.3889,
		id=cong_2017_deep_latent_dirichlet_allocation_with_topic_layer_adaptive_stochastic_gradient_riemannian_mcmc,
		"k-core"=7,
		label=cong_2017,
		shape=circle,
		style=filled,
		width=6.3889,
		zazaza="6874.9828368318185,-4090.796470028029!"];
	dieng_2019_topic_modeling_in_embedding_spaces -> cong_2017_deep_latent_dirichlet_allocation_with_topic_layer_adaptive_stochastic_gradient_riemannian_mcmc	[pos="e,483.9,363.85 483.94,363.88 483.93,363.88 483.92,363.87 483.91,363.87"];
	wang_2020_friendly_topic_assistant_for_transformer_based_abstractive_summarization -> see_2017_get_to_the_point_summarization_with_pointer_generator_networks	[pos="e,532.4,404.03 532.44,404.06 532.43,404.05 532.42,404.04 532.42,404.04"];
	wang_2020_friendly_topic_assistant_for_transformer_based_abstractive_summarization -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.2,518.81 580.25,518.69 580.24,518.72 580.23,518.74 580.22,518.76"];
	wang_2020_friendly_topic_assistant_for_transformer_based_abstractive_summarization -> vaswani_2017_attention_is_all_you_need	[pos="e,587.99,510.28 588.02,510.18 588.02,510.2 588.01,510.22 588.01,510.24"];
	wang_2020_friendly_topic_assistant_for_transformer_based_abstractive_summarization -> zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling	[pos="e,538.84,376.2 538.87,376.25 538.86,376.24 538.86,376.23 538.85,376.22"];
	wang_2020_friendly_topic_assistant_for_transformer_based_abstractive_summarization -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,629.98,511.47 629.92,511.36 629.94,511.38 629.95,511.4 629.96,511.42"];
	lewis_2019_bart_denoising_sequence_to_sequence_pre_training_for_natural_language_generation_translation_and_comprehension	[color=green,
		height=8.0833,
		id=lewis_2019_bart_denoising_sequence_to_sequence_pre_training_for_natural_language_generation_translation_and_comprehension,
		"k-core"=8,
		label=lewis_2019,
		shape=circle,
		style=filled,
		width=8.0833,
		zazaza="3521.5517917556454,-3549.460765695565!"];
	wang_2020_friendly_topic_assistant_for_transformer_based_abstractive_summarization -> lewis_2019_bart_denoising_sequence_to_sequence_pre_training_for_natural_language_generation_translation_and_comprehension	[pos="e,592.4,539.79 592.41,539.75 592.41,539.76 592.41,539.77 592.4,539.78"];
	hoyle_2020_improving_neural_topic_models_using_knowledge_distillation -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.19,518.84 580.22,518.79 580.21,518.8 580.21,518.81 580.2,518.82"];
	hoyle_2020_improving_neural_topic_models_using_knowledge_distillation -> vaswani_2017_attention_is_all_you_need	[pos="e,587.99,510.31 588.01,510.27 588,510.27 588,510.28 588,510.29"];
	hoyle_2020_improving_neural_topic_models_using_knowledge_distillation -> merity_2016_pointer_sentinel_mixture_models	[pos="e,654.36,404.2 654.29,404.27 654.31,404.25 654.32,404.24 654.34,404.22"];
	hoyle_2020_improving_neural_topic_models_using_knowledge_distillation -> card_2017_neural_models_for_documents_with_metadata	[pos="e,615.36,384.99 615.38,385.1 615.37,385.08 615.37,385.05 615.37,385.04"];
	hoyle_2020_improving_neural_topic_models_using_knowledge_distillation -> burkhardt_2019_decoupling_sparsity_and_smoothness_in_the_dirichlet_variational_autoencoder_topic_model	[pos="e,642.08,333.84 642.07,333.89 642.07,333.88 642.07,333.87 642.08,333.86"];
	hoyle_2020_improving_neural_topic_models_using_knowledge_distillation -> card_2018_neural_models_for_documents_with_metadata	[pos="e,608.09,386.86 608.12,386.96 608.11,386.94 608.11,386.92 608.1,386.9"];
	hoyle_2020_improving_neural_topic_models_using_knowledge_distillation -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,553.84,414.41 553.87,414.43 553.87,414.42 553.86,414.42 553.85,414.42"];
	hoyle_2020_improving_neural_topic_models_using_knowledge_distillation -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,623.28,372.38 623.28,372.41 623.28,372.41 623.28,372.4 623.28,372.39"];
	hoyle_2020_improving_neural_topic_models_using_knowledge_distillation -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.71,389.53 577.8,389.64 577.78,389.61 577.76,389.59 577.75,389.58"];
	hoyle_2020_improving_neural_topic_models_using_knowledge_distillation -> wang_2020_neural_topic_modeling_with_bidirectional_adversarial_training	[pos="e,648.32,389.5 648.27,389.6 648.28,389.58 648.29,389.56 648.3,389.54"];
	hoyle_2020_improving_neural_topic_models_using_knowledge_distillation -> ding_2018_coherence_aware_neural_topic_modeling	[pos="e,661.35,368.2 661.32,368.23 661.33,368.23 661.33,368.22 661.34,368.21"];
	hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence -> merity_2016_pointer_sentinel_mixture_models	[pos="e,654.38,404.16 654.34,404.13 654.35,404.13 654.36,404.14 654.36,404.15"];
	hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence -> zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey	[pos="e,595.78,371.18 595.78,371.12 595.78,371.13 595.78,371.14 595.78,371.15"];
	hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence -> card_2017_neural_models_for_documents_with_metadata	[pos="e,615.34,384.92 615.3,384.83 615.31,384.85 615.32,384.87 615.32,384.88"];
	hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence -> burkhardt_2019_decoupling_sparsity_and_smoothness_in_the_dirichlet_variational_autoencoder_topic_model	[pos="e,642.05,333.82 641.94,333.85 641.97,333.84 641.99,333.84 642,333.83"];
	hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence -> doogan_2021_topic_model_or_topic_twaddle_re_evaluating_semantic_interpretability_measures	[pos="e,524.92,306.52 524.96,306.54 524.95,306.53 524.95,306.53 524.94,306.53"];
	hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence -> card_2018_neural_models_for_documents_with_metadata	[pos="e,608.07,386.79 608.04,386.7 608.04,386.72 608.05,386.74 608.05,386.75"];
	hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,553.83,414.4 553.85,414.36 553.85,414.37 553.84,414.37 553.84,414.38"];
	hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence -> hoyle_2020_improving_neural_topic_models_using_knowledge_distillation	[pos="e,621.6,437.23 621.59,437.18 621.59,437.19 621.59,437.2 621.59,437.21"];
	hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,623.26,372.35 623.19,372.29 623.21,372.3 623.22,372.31 623.23,372.32"];
	hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.69,389.47 577.72,389.37 577.71,389.39 577.71,389.41 577.7,389.43"];
	hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence -> zhao_2020_neural_topic_model_via_optimal_transport	[pos="e,619.08,336.27 619.02,336.29 619.03,336.29 619.05,336.28 619.05,336.28"];
	hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence -> zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling	[pos="e,538.86,376.16 538.98,376.09 538.95,376.11 538.93,376.12 538.91,376.13"];
	hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence -> gui_2019_neural_topic_model_with_reinforcement_learning	[pos="e,530.38,356.29 530.42,356.29 530.41,356.29 530.4,356.29 530.4,356.29"];
	hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,630.62,360.7 630.54,360.67 630.56,360.67 630.57,360.68 630.59,360.69"];
	hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence -> wu_2020_neural_mixed_counting_models_for_dispersed_topic_discovery	[pos="e,662.67,336.8 662.63,336.81 662.64,336.81 662.65,336.81 662.66,336.81"];
	hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence -> hu_2020_neural_topic_modeling_with_cycle_consistent_adversarial_training	[pos="e,667.6,382.25 667.56,382.23 667.56,382.24 667.57,382.24 667.58,382.24"];
	hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence -> rezaee_2020_a_discrete_variational_recurrent_topic_model_without_the_reparametrization_trick	[pos="e,545.87,331.24 545.97,331.27 545.95,331.27 545.93,331.26 545.91,331.26"];
	hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence -> wang_2020_neural_topic_modeling_with_bidirectional_adversarial_training	[pos="e,648.3,389.43 648.18,389.34 648.21,389.36 648.23,389.38 648.25,389.39"];
	hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence -> ding_2018_coherence_aware_neural_topic_modeling	[pos="e,661.34,368.18 661.3,368.17 661.31,368.17 661.32,368.17 661.33,368.17"];
	guo_2019_recurrent_hierarchical_topic_guided_rnn_for_language_generation -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.18,518.84 580.18,518.79 580.18,518.8 580.18,518.81 580.18,518.82"];
	guo_2019_recurrent_hierarchical_topic_guided_rnn_for_language_generation -> vaswani_2017_attention_is_all_you_need	[pos="e,587.98,510.3 587.97,510.26 587.97,510.27 587.97,510.28 587.98,510.29"];
	guo_2019_recurrent_hierarchical_topic_guided_rnn_for_language_generation -> lau_2017_topically_driven_neural_language_model	[pos="e,558.69,375.43 558.72,375.54 558.72,375.52 558.71,375.5 558.7,375.48"];
	guo_2019_recurrent_hierarchical_topic_guided_rnn_for_language_generation -> wang_2019_topic_guided_variational_auto_encoder_for_text_generation	[pos="e,562.45,352.03 562.45,352.07 562.45,352.06 562.45,352.05 562.45,352.04"];
	guo_2019_recurrent_hierarchical_topic_guided_rnn_for_language_generation -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.67,389.53 577.67,389.61 577.67,389.59 577.67,389.58 577.67,389.56"];
	guo_2019_recurrent_hierarchical_topic_guided_rnn_for_language_generation -> zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling	[pos="e,538.85,376.22 538.92,376.33 538.91,376.31 538.89,376.29 538.88,376.27"];
	guo_2019_recurrent_hierarchical_topic_guided_rnn_for_language_generation -> wang_2017_topic_compositional_neural_language_model	[pos="e,515.82,370.68 515.94,370.8 515.92,370.77 515.89,370.75 515.87,370.73"];
	guo_2019_recurrent_hierarchical_topic_guided_rnn_for_language_generation -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,630.64,360.72 630.61,360.76 630.61,360.75 630.62,360.75 630.63,360.74"];
	guo_2019_recurrent_hierarchical_topic_guided_rnn_for_language_generation -> dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency	[pos="e,585.57,373.58 585.54,373.7 585.55,373.67 585.56,373.65 585.56,373.63"];
	guo_2019_recurrent_hierarchical_topic_guided_rnn_for_language_generation -> cong_2017_deep_latent_dirichlet_allocation_with_topic_layer_adaptive_stochastic_gradient_riemannian_mcmc	[pos="e,483.9,363.86 483.95,363.89 483.94,363.88 483.93,363.88 483.92,363.87"];
	guo_2019_recurrent_hierarchical_topic_guided_rnn_for_language_generation -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,629.99,511.49 629.96,511.44 629.97,511.45 629.98,511.46 629.98,511.47"];
	nan_2019_topic_modeling_with_wasserstein_autoencoders -> merity_2016_pointer_sentinel_mixture_models	[pos="e,654.37,404.15 654.3,404.08 654.31,404.09 654.33,404.11 654.34,404.12"];
	nan_2019_topic_modeling_with_wasserstein_autoencoders -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.71,389.49 577.81,389.45 577.79,389.46 577.77,389.47 577.75,389.47"];
	nan_2019_topic_modeling_with_wasserstein_autoencoders -> ding_2018_coherence_aware_neural_topic_modeling	[pos="e,661.33,368.19 661.24,368.2 661.26,368.19 661.28,368.19 661.29,368.19"];
	arjovsky_2017_wasserstein_generative_adversarial_networks	[color=yellow,
		height=6.7917,
		id=arjovsky_2017_wasserstein_generative_adversarial_networks,
		"k-core"=6,
		label=arjovsky_2017,
		shape=circle,
		style=filled,
		width=6.7917,
		zazaza="0.9980068802886166,-0.0631054129339593!"];
	nan_2019_topic_modeling_with_wasserstein_autoencoders -> arjovsky_2017_wasserstein_generative_adversarial_networks	[pos="e,718.08,431.3 718.03,431.27 718.04,431.27 718.05,431.28 718.06,431.29"];
	gulrajani_2017_improved_training_of_wasserstein_gans	[color=yellow,
		height=5.8889,
		id=gulrajani_2017_improved_training_of_wasserstein_gans,
		"k-core"=6,
		label=gulrajani_2017,
		shape=circle,
		style=filled,
		width=5.8889,
		zazaza="-0.9988787121463905,-0.04734304289580872!"];
	nan_2019_topic_modeling_with_wasserstein_autoencoders -> gulrajani_2017_improved_training_of_wasserstein_gans	[pos="e,705.83,392.15 705.79,392.14 705.8,392.14 705.81,392.14 705.82,392.14"];
	zhao_2020_neural_topic_model_via_optimal_transport -> zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey	[pos="e,595.61,371.07 595.46,370.94 595.48,370.96 595.51,370.99 595.53,371.01"];
	zhao_2020_neural_topic_model_via_optimal_transport -> card_2017_neural_models_for_documents_with_metadata	[pos="e,615.36,384.92 615.37,384.81 615.37,384.83 615.37,384.85 615.37,384.87"];
	zhao_2020_neural_topic_model_via_optimal_transport -> burkhardt_2019_decoupling_sparsity_and_smoothness_in_the_dirichlet_variational_autoencoder_topic_model	[pos="e,642.07,333.82 642.02,333.82 642.03,333.82 642.04,333.82 642.05,333.82"];
	zhao_2020_neural_topic_model_via_optimal_transport -> card_2018_neural_models_for_documents_with_metadata	[pos="e,608.09,386.78 608.11,386.67 608.1,386.7 608.1,386.72 608.1,386.74"];
	zhao_2020_neural_topic_model_via_optimal_transport -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,553.84,414.4 553.87,414.35 553.86,414.36 553.86,414.37 553.85,414.38"];
	zhao_2020_neural_topic_model_via_optimal_transport -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,623.28,372.34 623.27,372.26 623.27,372.28 623.27,372.29 623.27,372.31"];
	zhao_2020_neural_topic_model_via_optimal_transport -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.71,389.46 577.8,389.35 577.78,389.37 577.76,389.39 577.74,389.41"];
	zhao_2020_neural_topic_model_via_optimal_transport -> zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling	[pos="e,538.84,376.18 538.88,376.15 538.87,376.16 538.86,376.16 538.86,376.17"];
	zhao_2020_neural_topic_model_via_optimal_transport -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,630.64,360.69 630.62,360.64 630.62,360.65 630.63,360.66 630.63,360.67"];
	zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.65,389.49 577.57,389.46 577.58,389.47 577.6,389.47 577.61,389.48"];
	zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling -> cong_2017_deep_latent_dirichlet_allocation_with_topic_layer_adaptive_stochastic_gradient_riemannian_mcmc	[pos="e,483.92,363.85 484.04,363.88 484.02,363.87 483.99,363.87 483.97,363.87"];
	gui_2019_neural_topic_model_with_reinforcement_learning -> he_2017_an_unsupervised_neural_attention_model_for_aspect_extraction	[pos="e,471.07,424.43 471.11,424.4 471.1,424.41 471.09,424.41 471.09,424.42"];
	gui_2019_neural_topic_model_with_reinforcement_learning -> card_2017_neural_models_for_documents_with_metadata	[pos="e,615.34,384.95 615.3,384.93 615.31,384.93 615.32,384.94 615.33,384.94"];
	gui_2019_neural_topic_model_with_reinforcement_learning -> card_2018_neural_models_for_documents_with_metadata	[pos="e,608.06,386.81 608.02,386.8 608.03,386.8 608.04,386.8 608.05,386.81"];
	gui_2019_neural_topic_model_with_reinforcement_learning -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.64,389.48 577.54,389.4 577.56,389.42 577.58,389.43 577.6,389.45"];
	wang_2017_topic_compositional_neural_language_model -> lau_2017_topically_driven_neural_language_model	[pos="e,558.65,375.39 558.56,375.38 558.58,375.38 558.6,375.38 558.61,375.38"];
	wang_2017_topic_compositional_neural_language_model -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,630.63,360.71 630.57,360.72 630.58,360.72 630.59,360.72 630.6,360.72"];
	wang_2017_topic_compositional_neural_language_model -> dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency	[pos="e,585.57,373.54 585.53,373.54 585.54,373.54 585.54,373.54 585.55,373.54"];
	wu_2020_neural_mixed_counting_models_for_dispersed_topic_discovery -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,623.31,372.34 623.39,372.26 623.38,372.28 623.36,372.3 623.35,372.31"];
	wu_2020_neural_mixed_counting_models_for_dispersed_topic_discovery -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.69,389.49 577.74,389.46 577.73,389.47 577.72,389.47 577.71,389.48"];
	wu_2020_neural_mixed_counting_models_for_dispersed_topic_discovery -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,630.67,360.7 630.74,360.64 630.73,360.66 630.71,360.67 630.7,360.67"];
	tang_2019_a_topic_augmented_text_generation_model_joint_learning_of_semantics_and_structural_features -> lau_2017_topically_driven_neural_language_model	[pos="e,558.68,375.38 558.7,375.34 558.69,375.35 558.69,375.36 558.69,375.36"];
	tang_2019_a_topic_augmented_text_generation_model_joint_learning_of_semantics_and_structural_features -> wang_2019_topic_guided_variational_auto_encoder_for_text_generation	[pos="e,562.46,351.98 562.5,351.89 562.49,351.91 562.49,351.93 562.48,351.94"];
	tang_2019_a_topic_augmented_text_generation_model_joint_learning_of_semantics_and_structural_features -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.68,389.49 577.68,389.44 577.68,389.45 577.68,389.46 577.68,389.47"];
	tang_2019_a_topic_augmented_text_generation_model_joint_learning_of_semantics_and_structural_features -> wang_2017_topic_compositional_neural_language_model	[pos="e,515.79,370.62 515.83,370.59 515.82,370.6 515.81,370.6 515.8,370.61"];
	tang_2019_a_topic_augmented_text_generation_model_joint_learning_of_semantics_and_structural_features -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,630.61,360.68 630.51,360.57 630.53,360.59 630.55,360.61 630.57,360.63"];
	tang_2019_a_topic_augmented_text_generation_model_joint_learning_of_semantics_and_structural_features -> dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency	[pos="e,585.58,373.53 585.58,373.49 585.58,373.5 585.58,373.51 585.58,373.51"];
	tang_2019_a_topic_augmented_text_generation_model_joint_learning_of_semantics_and_structural_features -> yang_2017_improved_variational_autoencoders_for_text_modeling_using_dilated_convolutions	[pos="e,519,331.2 519.03,331.19 519.02,331.19 519.02,331.19 519.01,331.19"];
	zeng_2018_topic_memory_networks_for_short_text_classification -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.69,389.49 577.74,389.47 577.73,389.48 577.72,389.48 577.71,389.49"];
	zeng_2018_topic_memory_networks_for_short_text_classification -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,630.67,360.71 630.75,360.69 630.74,360.7 630.72,360.7 630.71,360.7"];
	zeng_2018_topic_memory_networks_for_short_text_classification -> dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency	[pos="e,585.59,373.54 585.64,373.53 585.63,373.53 585.62,373.53 585.61,373.53"];
	hu_2020_neural_topic_modeling_with_cycle_consistent_adversarial_training -> card_2017_neural_models_for_documents_with_metadata	[pos="e,615.4,384.95 615.51,384.94 615.49,384.94 615.46,384.95 615.44,384.95"];
	hu_2020_neural_topic_modeling_with_cycle_consistent_adversarial_training -> card_2018_neural_models_for_documents_with_metadata	[pos="e,608.12,386.82 608.25,386.81 608.22,386.81 608.2,386.81 608.17,386.81"];
	hu_2020_neural_topic_modeling_with_cycle_consistent_adversarial_training -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.69,389.5 577.74,389.49 577.73,389.5 577.72,389.5 577.71,389.5"];
	hu_2020_neural_topic_modeling_with_cycle_consistent_adversarial_training -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,630.68,360.73 630.75,360.77 630.74,360.76 630.72,360.76 630.71,360.75"];
	hu_2020_neural_topic_modeling_with_cycle_consistent_adversarial_training -> wang_2020_neural_topic_modeling_with_bidirectional_adversarial_training	[pos="e,648.36,389.46 648.4,389.45 648.39,389.45 648.38,389.45 648.37,389.45"];
	hu_2020_neural_topic_modeling_with_cycle_consistent_adversarial_training -> arjovsky_2017_wasserstein_generative_adversarial_networks	[pos="e,718.06,431.27 717.95,431.17 717.98,431.19 718,431.21 718.02,431.23"];
	hu_2020_neural_topic_modeling_with_cycle_consistent_adversarial_training -> gulrajani_2017_improved_training_of_wasserstein_gans	[pos="e,705.82,392.14 705.74,392.12 705.76,392.13 705.77,392.13 705.79,392.13"];
	wang_2019_open_event_extraction_from_online_text_using_a_generative_adversarial_network	[color=yellow,
		height=5.5833,
		id=wang_2019_open_event_extraction_from_online_text_using_a_generative_adversarial_network,
		"k-core"=6,
		label=wang_2019,
		shape=circle,
		style=filled,
		width=5.5833,
		zazaza="-0.7977373552554335,0.6030050487482422!"];
	hu_2020_neural_topic_modeling_with_cycle_consistent_adversarial_training -> wang_2019_open_event_extraction_from_online_text_using_a_generative_adversarial_network	[pos="e,725.36,445.17 725.33,445.14 725.33,445.15 725.34,445.15 725.34,445.16"];
	rezaee_2020_a_discrete_variational_recurrent_topic_model_without_the_reparametrization_trick -> lau_2017_topically_driven_neural_language_model	[pos="e,558.67,375.36 558.64,375.26 558.65,375.29 558.65,375.3 558.66,375.32"];
	rezaee_2020_a_discrete_variational_recurrent_topic_model_without_the_reparametrization_trick -> wang_2019_topic_guided_variational_auto_encoder_for_text_generation	[pos="e,562.43,352 562.4,351.95 562.41,351.96 562.41,351.97 562.42,351.98"];
	rezaee_2020_a_discrete_variational_recurrent_topic_model_without_the_reparametrization_trick -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.65,389.46 577.59,389.33 577.6,389.36 577.61,389.38 577.63,389.41"];
	rezaee_2020_a_discrete_variational_recurrent_topic_model_without_the_reparametrization_trick -> zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling	[pos="e,538.83,376.15 538.84,376.05 538.84,376.08 538.84,376.09 538.84,376.11"];
	rezaee_2020_a_discrete_variational_recurrent_topic_model_without_the_reparametrization_trick -> wang_2017_topic_compositional_neural_language_model	[pos="e,515.8,370.61 515.86,370.52 515.85,370.54 515.84,370.56 515.83,370.57"];
	rezaee_2020_a_discrete_variational_recurrent_topic_model_without_the_reparametrization_trick -> dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency	[pos="e,585.55,373.51 585.47,373.42 585.48,373.44 585.5,373.46 585.52,373.47"];
	gururangan_2019_variational_pretraining_for_semi_supervised_text_classification	[color=green,
		height=5.2222,
		id=gururangan_2019_variational_pretraining_for_semi_supervised_text_classification,
		"k-core"=8,
		label=gururangan_2019,
		shape=circle,
		style=filled,
		width=5.2222,
		zazaza="-4336.6896859726185,2488.5983635789867!"];
	rezaee_2020_a_discrete_variational_recurrent_topic_model_without_the_reparametrization_trick -> gururangan_2019_variational_pretraining_for_semi_supervised_text_classification	[pos="e,581.9,450.77 581.88,450.7 581.89,450.71 581.89,450.73 581.89,450.74"];
	wang_2020_neural_topic_modeling_with_bidirectional_adversarial_training -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.69,389.5 577.73,389.5 577.72,389.5 577.71,389.5 577.71,389.5"];
	wang_2020_neural_topic_modeling_with_bidirectional_adversarial_training -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,630.66,360.73 630.7,360.79 630.69,360.78 630.68,360.77 630.68,360.76"];
	wang_2020_neural_topic_modeling_with_bidirectional_adversarial_training -> arjovsky_2017_wasserstein_generative_adversarial_networks	[pos="e,718.08,431.3 718.05,431.28 718.06,431.28 718.06,431.29 718.07,431.29"];
	wang_2020_neural_topic_modeling_with_bidirectional_adversarial_training -> gulrajani_2017_improved_training_of_wasserstein_gans	[pos="e,705.81,392.15 705.68,392.14 705.71,392.14 705.73,392.15 705.76,392.15"];
	wang_2020_neural_topic_modeling_with_bidirectional_adversarial_training -> wang_2019_open_event_extraction_from_online_text_using_a_generative_adversarial_network	[pos="e,725.35,445.17 725.31,445.14 725.32,445.15 725.33,445.16 725.34,445.16"];
	ding_2018_coherence_aware_neural_topic_modeling -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.69,389.5 577.74,389.48 577.73,389.49 577.72,389.49 577.71,389.49"];
	ding_2018_coherence_aware_neural_topic_modeling -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,630.67,360.72 630.74,360.73 630.72,360.73 630.71,360.73 630.7,360.72"];
	yang_2017_improved_variational_autoencoders_for_text_modeling_using_dilated_convolutions -> jang_2016_categorical_reparameterization_with_gumbel_softmax	[pos="e,515.92,358.29 515.92,358.23 515.92,358.24 515.92,358.25 515.92,358.26"];
	lewis_2019_bart_denoising_sequence_to_sequence_pre_training_for_natural_language_generation_translation_and_comprehension -> see_2017_get_to_the_point_summarization_with_pointer_generator_networks	[pos="e,532.4,404.04 532.43,404.11 532.42,404.1 532.42,404.08 532.41,404.07"];
	lewis_2019_bart_denoising_sequence_to_sequence_pre_training_for_natural_language_generation_translation_and_comprehension -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.19,518.87 580.22,518.91 580.21,518.9 580.21,518.9 580.21,518.89"];
	lewis_2019_bart_denoising_sequence_to_sequence_pre_training_for_natural_language_generation_translation_and_comprehension -> vaswani_2017_attention_is_all_you_need	[pos="e,587.98,510.34 587.99,510.4 587.99,510.39 587.99,510.38 587.99,510.37"];
	lewis_2019_bart_denoising_sequence_to_sequence_pre_training_for_natural_language_generation_translation_and_comprehension -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,629.98,511.52 629.9,511.58 629.91,511.57 629.93,511.56 629.94,511.55"];
	lewis_2019_bart_denoising_sequence_to_sequence_pre_training_for_natural_language_generation_translation_and_comprehension -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.72,532.57 612.68,532.58 612.69,532.58 612.7,532.57 612.7,532.57"];
	lewis_2019_bart_denoising_sequence_to_sequence_pre_training_for_natural_language_generation_translation_and_comprehension -> peters_2018_deep_contextualized_word_representations	[pos="e,583.79,529.91 583.86,530 583.85,529.98 583.83,529.96 583.82,529.95"];
	joshi_2019_spanbert_improving_pre_training_by_representing_and_predicting_spans	[color=green,
		height=6.1528,
		id=joshi_2019_spanbert_improving_pre_training_by_representing_and_predicting_spans,
		"k-core"=8,
		label=joshi_2019,
		shape=circle,
		style=filled,
		width=6.1528,
		zazaza="4752.83742016228,1552.590121296722!"];
	lewis_2019_bart_denoising_sequence_to_sequence_pre_training_for_natural_language_generation_translation_and_comprehension -> joshi_2019_spanbert_improving_pre_training_by_representing_and_predicting_spans	[pos="e,642.12,543.77 642.01,543.76 642.03,543.76 642.05,543.76 642.07,543.76"];
	nguyen_2022_refined_commonsense_knowledge_from_large_scale_web_contents	[color=yellow,
		height=2,
		id=nguyen_2022_refined_commonsense_knowledge_from_large_scale_web_contents,
		"k-core"=6,
		label=nguyen_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="0.9980068802886166,0.06310562645486902!"];
	nguyen_2022_refined_commonsense_knowledge_from_large_scale_web_contents -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,582.91,524.6 583.08,524.95 583.05,524.89 583.02,524.83 583,524.77"];
	nguyen_2022_refined_commonsense_knowledge_from_large_scale_web_contents -> reimers_2019_sentence_bert_sentence_embeddings_using_siamese_bert_networks	[pos="e,608.38,517.71 608.41,518.08 608.4,518.02 608.4,517.96 608.39,517.89"];
	nguyen_2022_refined_commonsense_knowledge_from_large_scale_web_contents -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,628.51,518.9 628.42,519.35 628.44,519.27 628.45,519.2 628.47,519.12"];
	nguyen_2022_refined_commonsense_knowledge_from_large_scale_web_contents -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.74,532.6 612.74,532.73 612.74,532.7 612.74,532.67 612.74,532.65"];
	liu_2020_giant_scalable_creation_of_a_web_scale_ontology	[color=yellow,
		height=4.1944,
		id=liu_2020_giant_scalable_creation_of_a_web_scale_ontology,
		"k-core"=6,
		label=liu_2020,
		shape=circle,
		style=filled,
		width=4.1944,
		zazaza="-0.22691610131665146,0.9739143213936372!"];
	nguyen_2022_refined_commonsense_knowledge_from_large_scale_web_contents -> liu_2020_giant_scalable_creation_of_a_web_scale_ontology	[pos="e,560.58,619.1 560.69,619.04 560.67,619.06 560.65,619.07 560.63,619.08"];
	wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration	[color=green,
		height=7.9861,
		id=wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration,
		"k-core"=8,
		label=wang_2021,
		shape=circle,
		style=filled,
		width=7.9861,
		zazaza="-197.2853813972373,-4996.106319757506!"];
	nguyen_2022_refined_commonsense_knowledge_from_large_scale_web_contents -> wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration	[pos="e,636.93,521.32 636.81,521.68 636.83,521.62 636.85,521.56 636.87,521.5"];
	liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.21,518.86 580.28,518.89 580.26,518.89 580.25,518.88 580.24,518.88"];
	liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach -> vaswani_2017_attention_is_all_you_need	[pos="e,588,510.34 588.05,510.38 588.04,510.37 588.03,510.36 588.02,510.36"];
	liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,629.99,511.52 629.95,511.56 629.96,511.55 629.97,511.54 629.98,511.53"];
	liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach -> peters_2018_deep_contextualized_word_representations	[pos="e,583.79,529.89 583.85,529.89 583.83,529.89 583.82,529.89 583.81,529.89"];
	liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach -> joshi_2019_spanbert_improving_pre_training_by_representing_and_predicting_spans	[pos="e,642.07,543.96 641.98,544.15 642,544.12 642.01,544.09 642.03,544.06"];
	liu_2020_giant_scalable_creation_of_a_web_scale_ontology -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.18,518.87 580.17,518.93 580.17,518.91 580.18,518.9 580.18,518.89"];
	zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[color=green,
		height=10.319,
		id=zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering,
		"k-core"=8,
		label=zhang_2018,
		shape=circle,
		style=filled,
		width=10.319,
		zazaza="3738.5252151407626,-3320.1548433157473!"];
	liu_2020_giant_scalable_creation_of_a_web_scale_ontology -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,458.06,613.85 458.11,613.85 458.1,613.85 458.09,613.85 458.08,613.85"];
	shang_2017_automated_phrase_mining_from_massive_text_corpora	[color=green,
		height=8.5972,
		id=shang_2017_automated_phrase_mining_from_massive_text_corpora,
		"k-core"=8,
		label=shang_2017,
		shape=circle,
		style=filled,
		width=8.5972,
		zazaza="-4081.8783401142855,-2887.6060234850293!"];
	liu_2020_giant_scalable_creation_of_a_web_scale_ontology -> shang_2017_automated_phrase_mining_from_massive_text_corpora	[pos="e,437.6,555.14 437.66,555.18 437.65,555.17 437.63,555.16 437.62,555.16"];
	wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.2,518.85 580.23,518.85 580.22,518.85 580.22,518.85 580.21,518.85"];
	wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration -> merity_2016_pointer_sentinel_mixture_models	[pos="e,654.39,404.19 654.38,404.25 654.38,404.23 654.38,404.22 654.38,404.21"];
	wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration -> holtzman_2019_the_curious_case_of_neural_text_degeneration	[pos="e,677.95,492.23 677.87,492.27 677.88,492.26 677.9,492.25 677.91,492.25"];
	wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration -> reimers_2019_sentence_bert_sentence_embeddings_using_siamese_bert_networks	[pos="e,606.25,490.56 606.33,490.6 606.31,490.59 606.29,490.58 606.28,490.58"];
	wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,553.84,414.43 553.89,414.48 553.88,414.47 553.87,414.46 553.86,414.45"];
	wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,630.04,511.49 630.13,511.47 630.11,511.47 630.09,511.48 630.07,511.48"];
	wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.76,532.54 612.82,532.49 612.8,532.5 612.79,532.51 612.78,532.52"];
	wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration -> joshi_2019_spanbert_improving_pre_training_by_representing_and_predicting_spans	[pos="e,642.15,543.74 642.15,543.67 642.15,543.69 642.15,543.7 642.15,543.71"];
	krishna_2020_reformulating_unsupervised_style_transfer_as_paraphrase_generation	[color=blue,
		height=4.7778,
		id=krishna_2020_reformulating_unsupervised_style_transfer_as_paraphrase_generation,
		"k-core"=7,
		label=krishna_2020,
		shape=circle,
		style=filled,
		width=4.7778,
		zazaza="6603.127006403149,4516.493298359973!"];
	wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration -> krishna_2020_reformulating_unsupervised_style_transfer_as_paraphrase_generation	[pos="e,676.29,524.64 676.21,524.61 676.23,524.61 676.24,524.62 676.26,524.63"];
	lee_2020_learning_dense_representations_of_phrases_at_scale	[color=blue,
		height=5.2222,
		id=lee_2020_learning_dense_representations_of_phrases_at_scale,
		"k-core"=7,
		label=lee_2020,
		shape=circle,
		style=filled,
		width=5.2222,
		zazaza="4671.57650872443,-6494.334213927967!"];
	wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration -> lee_2020_learning_dense_representations_of_phrases_at_scale	[pos="e,658.74,583.1 658.73,583.06 658.73,583.07 658.73,583.08 658.73,583.09"];
	wolf_2019_transfertransfo_a_transfer_learning_approach_for_neural_network_based_conversational_agents	[color=yellow,
		height=5.2222,
		id=wolf_2019_transfertransfo_a_transfer_learning_approach_for_neural_network_based_conversational_agents,
		"k-core"=6,
		label=wolf_2019,
		shape=circle,
		style=filled,
		width=5.2222,
		zazaza="-0.9553509302979348,-0.29547354628277167!"];
	wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration -> wolf_2019_transfertransfo_a_transfer_learning_approach_for_neural_network_based_conversational_agents	[pos="e,644.25,585.34 644.25,585.3 644.25,585.3 644.25,585.31 644.25,585.32"];
	devlin_2018_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[color=blue,
		height=6.3889,
		id=devlin_2018_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding,
		"k-core"=7,
		label=devlin_2018,
		shape=circle,
		style=filled,
		width=6.3889,
		zazaza="5810.957914408407,5498.433088401172!"];
	wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration -> devlin_2018_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,613.45,507.9 613.51,507.9 613.5,507.9 613.49,507.9 613.48,507.9"];
	zhang_2019_paws_paraphrase_adversaries_from_word_scrambling	[color=blue,
		height=5.2222,
		id=zhang_2019_paws_paraphrase_adversaries_from_word_scrambling,
		"k-core"=7,
		label=zhang_2019,
		shape=circle,
		style=filled,
		width=5.2222,
		zazaza="5072.094448188492,6186.586830328668!"];
	wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration -> zhang_2019_paws_paraphrase_adversaries_from_word_scrambling	[pos="e,653.32,578.16 653.31,578.13 653.32,578.14 653.32,578.14 653.32,578.15"];
	yu_2020_assessing_phrasal_representation_and_composition_in_transformers	[color=blue,
		height=4.1944,
		id=yu_2020_assessing_phrasal_representation_and_composition_in_transformers,
		"k-core"=7,
		label=yu_2020,
		shape=circle,
		style=filled,
		width=4.1944,
		zazaza="-5723.433935181652,5589.481805659626!"];
	wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration -> yu_2020_assessing_phrasal_representation_and_composition_in_transformers	[pos="e,681.51,551.77 681.43,551.68 681.45,551.7 681.46,551.72 681.48,551.73"];
	li_2020_on_the_sentence_embeddings_from_pre_trained_language_models	[color=yellow,
		height=3.3889,
		id=li_2020_on_the_sentence_embeddings_from_pre_trained_language_models,
		"k-core"=6,
		label=li_2020,
		shape=circle,
		style=filled,
		width=3.3889,
		zazaza="0.9505674840324561,-0.310518086409916!"];
	wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration -> li_2020_on_the_sentence_embeddings_from_pre_trained_language_models	[pos="e,633.72,567.02 633.74,566.9 633.73,566.93 633.73,566.95 633.73,566.97"];
	toshniwal_2020_a_cross_task_analysis_of_text_span_representations	[color=yellow,
		height=4.1944,
		id=toshniwal_2020_a_cross_task_analysis_of_text_span_representations,
		"k-core"=6,
		label=toshniwal_2020,
		shape=circle,
		style=filled,
		width=4.1944,
		zazaza="-0.4908578356491906,0.8712396585977858!"];
	wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration -> toshniwal_2020_a_cross_task_analysis_of_text_span_representations	[pos="e,682.8,540.65 682.71,540.58 682.73,540.59 682.74,540.61 682.76,540.62"];
	bommasani_2020_interpreting_pretrained_contextualized_representations_via_reductions_to_static_embeddings	[color=green,
		height=3.3889,
		id=bommasani_2020_interpreting_pretrained_contextualized_representations_via_reductions_to_static_embeddings,
		"k-core"=8,
		label=bommasani_2020,
		shape=circle,
		style=filled,
		width=3.3889,
		zazaza="-1886.0357818042842,-4630.644613606979!"];
	wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration -> bommasani_2020_interpreting_pretrained_contextualized_representations_via_reductions_to_static_embeddings	[pos="e,600.91,574.04 600.94,574.01 600.93,574.02 600.93,574.02 600.92,574.03"];
	peters_2018_deep_contextualized_word_representations -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,523.43,509.54 523.47,509.55 523.46,509.55 523.45,509.55 523.45,509.55"];
	joshi_2019_spanbert_improving_pre_training_by_representing_and_predicting_spans -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.2,518.86 580.23,518.87 580.22,518.87 580.22,518.87 580.21,518.86"];
	joshi_2019_spanbert_improving_pre_training_by_representing_and_predicting_spans -> vaswani_2017_attention_is_all_you_need	[pos="e,588.02,510.34 588.14,510.41 588.11,510.4 588.09,510.39 588.07,510.37"];
	joshi_2019_spanbert_improving_pre_training_by_representing_and_predicting_spans -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.82,532.37 612.9,532.18 612.89,532.21 612.87,532.24 612.86,532.27"];
	joshi_2019_spanbert_improving_pre_training_by_representing_and_predicting_spans -> peters_2018_deep_contextualized_word_representations	[pos="e,583.81,529.9 583.93,529.93 583.9,529.92 583.88,529.91 583.86,529.91"];
	soares_2019_matching_the_blanks_distributional_similarity_for_relation_learning	[color=yellow,
		height=5.2222,
		id=soares_2019_matching_the_blanks_distributional_similarity_for_relation_learning,
		"k-core"=6,
		label=soares_2019,
		shape=circle,
		style=filled,
		width=5.2222,
		zazaza="-0.1650043993240022,0.9862928351739826!"];
	joshi_2019_spanbert_improving_pre_training_by_representing_and_predicting_spans -> soares_2019_matching_the_blanks_distributional_similarity_for_relation_learning	[pos="e,589.62,599.25 589.73,599.13 589.7,599.15 589.68,599.18 589.66,599.2"];
	jiang_2017_metapad_meta_pattern_discovery_from_massive_text_corpora	[color=green,
		height=7.125,
		id=jiang_2017_metapad_meta_pattern_discovery_from_massive_text_corpora,
		"k-core"=8,
		label=jiang_2017,
		shape=circle,
		style=filled,
		width=7.125,
		zazaza="-3685.646034202907,-3378.759321997119!"];
	zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering -> jiang_2017_metapad_meta_pattern_discovery_from_massive_text_corpora	[pos="e,476.32,662.32 476.28,662.21 476.29,662.24 476.29,662.26 476.3,662.28"];
	zhang_2019_bertscore_evaluating_text_generation_with_bert -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.2,518.86 580.25,518.87 580.24,518.87 580.23,518.87 580.22,518.86"];
	zhang_2019_bertscore_evaluating_text_generation_with_bert -> vaswani_2017_attention_is_all_you_need	[pos="e,588,510.32 588.04,510.34 588.03,510.34 588.02,510.33 588.01,510.33"];
	zhang_2019_bertscore_evaluating_text_generation_with_bert -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.77,532.57 612.88,532.59 612.85,532.58 612.83,532.58 612.82,532.58"];
	zhang_2019_bertscore_evaluating_text_generation_with_bert -> peters_2018_deep_contextualized_word_representations	[pos="e,583.78,529.89 583.82,529.9 583.81,529.89 583.8,529.89 583.8,529.89"];
	zhang_2019_bertscore_evaluating_text_generation_with_bert -> zhang_2019_paws_paraphrase_adversaries_from_word_scrambling	[pos="e,653.33,578.15 653.35,578.07 653.35,578.09 653.34,578.11 653.34,578.12"];
	krishna_2020_reformulating_unsupervised_style_transfer_as_paraphrase_generation -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.2,518.85 580.26,518.86 580.24,518.86 580.23,518.86 580.22,518.86"];
	krishna_2020_reformulating_unsupervised_style_transfer_as_paraphrase_generation -> vaswani_2017_attention_is_all_you_need	[pos="e,588,510.32 588.05,510.33 588.04,510.33 588.03,510.33 588.02,510.32"];
	krishna_2020_reformulating_unsupervised_style_transfer_as_paraphrase_generation -> holtzman_2019_the_curious_case_of_neural_text_degeneration	[pos="e,677.97,492.24 677.97,492.31 677.97,492.3 677.97,492.28 677.97,492.27"];
	krishna_2020_reformulating_unsupervised_style_transfer_as_paraphrase_generation -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,630.04,511.51 630.14,511.54 630.11,511.53 630.1,511.53 630.08,511.52"];
	krishna_2020_reformulating_unsupervised_style_transfer_as_paraphrase_generation -> lewis_2019_bart_denoising_sequence_to_sequence_pre_training_for_natural_language_generation_translation_and_comprehension	[pos="e,592.42,539.8 592.46,539.8 592.45,539.8 592.44,539.8 592.44,539.8"];
	krishna_2020_reformulating_unsupervised_style_transfer_as_paraphrase_generation -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.75,532.56 612.78,532.55 612.77,532.56 612.77,532.56 612.76,532.56"];
	krishna_2020_reformulating_unsupervised_style_transfer_as_paraphrase_generation -> wolf_2019_transfertransfo_a_transfer_learning_approach_for_neural_network_based_conversational_agents	[pos="e,644.25,585.34 644.27,585.31 644.27,585.31 644.26,585.32 644.26,585.33"];
	keskar_2019_ctrl_a_conditional_transformer_language_model_for_controllable_generation	[color=blue,
		height=6.1528,
		id=keskar_2019_ctrl_a_conditional_transformer_language_model_for_controllable_generation,
		"k-core"=7,
		label=keskar_2019,
		shape=circle,
		style=filled,
		width=6.1528,
		zazaza="7119.431497990789,3648.793439123801!"];
	krishna_2020_reformulating_unsupervised_style_transfer_as_paraphrase_generation -> keskar_2019_ctrl_a_conditional_transformer_language_model_for_controllable_generation	[pos="e,655.6,519.18 655.65,519.19 655.64,519.19 655.63,519.18 655.62,519.18"];
	krishna_2020_reformulating_unsupervised_style_transfer_as_paraphrase_generation -> arjovsky_2017_wasserstein_generative_adversarial_networks	[pos="e,718.09,431.33 718.07,431.38 718.07,431.37 718.08,431.36 718.08,431.35"];
	lee_2020_learning_dense_representations_of_phrases_at_scale -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.2,518.87 580.24,518.9 580.23,518.89 580.22,518.89 580.22,518.88"];
	lee_2020_learning_dense_representations_of_phrases_at_scale -> peters_2018_deep_contextualized_word_representations	[pos="e,583.78,529.9 583.82,529.92 583.81,529.92 583.8,529.91 583.8,529.91"];
	lee_2020_learning_dense_representations_of_phrases_at_scale -> joshi_2019_spanbert_improving_pre_training_by_representing_and_predicting_spans	[pos="e,642.16,543.8 642.2,543.88 642.19,543.86 642.19,543.85 642.18,543.83"];
	wolf_2019_transfertransfo_a_transfer_learning_approach_for_neural_network_based_conversational_agents -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.2,518.87 580.23,518.9 580.22,518.89 580.22,518.89 580.21,518.88"];
	wolf_2019_transfertransfo_a_transfer_learning_approach_for_neural_network_based_conversational_agents -> vaswani_2017_attention_is_all_you_need	[pos="e,587.99,510.33 588.02,510.37 588.02,510.36 588.01,510.36 588,510.35"];
	wolf_2019_transfertransfo_a_transfer_learning_approach_for_neural_network_based_conversational_agents -> peters_2018_deep_contextualized_word_representations	[pos="e,583.78,529.9 583.81,529.93 583.8,529.92 583.79,529.91 583.79,529.91"];
	devlin_2018_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding -> vaswani_2017_attention_is_all_you_need	[pos="e,588,510.32 588.05,510.31 588.04,510.31 588.03,510.31 588.02,510.32"];
	devlin_2018_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding -> peters_2018_deep_contextualized_word_representations	[pos="e,583.79,529.87 583.85,529.82 583.84,529.83 583.82,529.84 583.81,529.85"];
	zhang_2019_paws_paraphrase_adversaries_from_word_scrambling -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.2,518.86 580.24,518.9 580.23,518.89 580.22,518.88 580.22,518.88"];
	zhang_2019_paws_paraphrase_adversaries_from_word_scrambling -> vaswani_2017_attention_is_all_you_need	[pos="e,587.99,510.33 588.03,510.37 588.02,510.36 588.01,510.35 588.01,510.35"];
	zhang_2019_paws_paraphrase_adversaries_from_word_scrambling -> peters_2018_deep_contextualized_word_representations	[pos="e,583.78,529.89 583.81,529.92 583.81,529.92 583.8,529.91 583.79,529.91"];
	yu_2020_assessing_phrasal_representation_and_composition_in_transformers -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.2,518.86 580.26,518.88 580.25,518.87 580.24,518.87 580.23,518.87"];
	yu_2020_assessing_phrasal_representation_and_composition_in_transformers -> vaswani_2017_attention_is_all_you_need	[pos="e,588,510.33 588.05,510.35 588.04,510.34 588.03,510.34 588.02,510.34"];
	yu_2020_assessing_phrasal_representation_and_composition_in_transformers -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,630.04,511.53 630.15,511.62 630.13,511.6 630.11,511.58 630.09,511.57"];
	yu_2020_assessing_phrasal_representation_and_composition_in_transformers -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.75,532.56 612.79,532.57 612.78,532.57 612.77,532.57 612.76,532.57"];
	yu_2020_assessing_phrasal_representation_and_composition_in_transformers -> zhang_2019_paws_paraphrase_adversaries_from_word_scrambling	[pos="e,653.34,578.16 653.4,578.1 653.39,578.11 653.38,578.13 653.37,578.13"];
	li_2020_on_the_sentence_embeddings_from_pre_trained_language_models -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.22,518.89 580.34,518.99 580.31,518.97 580.29,518.95 580.27,518.93"];
	li_2020_on_the_sentence_embeddings_from_pre_trained_language_models -> vaswani_2017_attention_is_all_you_need	[pos="e,588.01,510.36 588.11,510.48 588.09,510.45 588.07,510.43 588.06,510.41"];
	li_2020_on_the_sentence_embeddings_from_pre_trained_language_models -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,630.01,511.54 630.01,511.66 630.01,511.63 630.01,511.61 630.01,511.59"];
	li_2020_on_the_sentence_embeddings_from_pre_trained_language_models -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.75,532.59 612.8,532.66 612.79,532.64 612.78,532.63 612.77,532.62"];
	toshniwal_2020_a_cross_task_analysis_of_text_span_representations -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.2,518.86 580.26,518.87 580.25,518.87 580.24,518.86 580.23,518.86"];
	toshniwal_2020_a_cross_task_analysis_of_text_span_representations -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.75,532.56 612.79,532.57 612.78,532.57 612.77,532.56 612.76,532.56"];
	toshniwal_2020_a_cross_task_analysis_of_text_span_representations -> peters_2018_deep_contextualized_word_representations	[pos="e,583.78,529.89 583.84,529.89 583.82,529.89 583.81,529.89 583.8,529.89"];
	toshniwal_2020_a_cross_task_analysis_of_text_span_representations -> joshi_2019_spanbert_improving_pre_training_by_representing_and_predicting_spans	[pos="e,642.18,543.77 642.27,543.76 642.25,543.76 642.23,543.76 642.22,543.76"];
	bommasani_2020_interpreting_pretrained_contextualized_representations_via_reductions_to_static_embeddings -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.2,518.89 580.24,519.01 580.24,518.99 580.23,518.96 580.22,518.94"];
	bommasani_2020_interpreting_pretrained_contextualized_representations_via_reductions_to_static_embeddings -> vaswani_2017_attention_is_all_you_need	[pos="e,587.98,510.33 587.99,510.37 587.99,510.36 587.99,510.35 587.99,510.34"];
	bommasani_2020_interpreting_pretrained_contextualized_representations_via_reductions_to_static_embeddings -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,630,511.51 629.98,511.55 629.99,511.54 629.99,511.53 629.99,511.53"];
	bommasani_2020_interpreting_pretrained_contextualized_representations_via_reductions_to_static_embeddings -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.73,532.59 612.7,532.68 612.71,532.66 612.71,532.64 612.72,532.63"];
	bommasani_2020_interpreting_pretrained_contextualized_representations_via_reductions_to_static_embeddings -> peters_2018_deep_contextualized_word_representations	[pos="e,583.78,529.92 583.81,530.01 583.81,529.99 583.8,529.97 583.79,529.96"];
	bommasani_2020_interpreting_pretrained_contextualized_representations_via_reductions_to_static_embeddings -> zhang_2019_bertscore_evaluating_text_generation_with_bert	[pos="e,662.6,542.39 662.57,542.41 662.57,542.4 662.58,542.4 662.59,542.4"];
	bommasani_2020_interpreting_pretrained_contextualized_representations_via_reductions_to_static_embeddings -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,523.44,509.55 523.48,509.59 523.47,509.58 523.46,509.57 523.45,509.57"];
	ge_2021_fine_grained_opinion_summarization_with_minimal_supervision	[color=blue,
		height=2,
		id=ge_2021_fine_grained_opinion_summarization_with_minimal_supervision,
		"k-core"=7,
		label=ge_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="7964.138031100518,756.6384551309832!"];
	ge_2021_fine_grained_opinion_summarization_with_minimal_supervision -> angelidis_2018_summarizing_opinions_aspect_extraction_meets_sentiment_prediction_and_they_are_both_weakly_supervised	[pos="e,455.02,459.48 455.45,459.83 455.38,459.77 455.31,459.71 455.24,459.65"];
	ge_2021_fine_grained_opinion_summarization_with_minimal_supervision -> chu_2018_meansum_a_neural_model_for_unsupervised_multi_document_abstractive_summarization	[pos="e,481.28,439.36 481.48,439.8 481.45,439.73 481.41,439.65 481.38,439.58"];
	ge_2021_fine_grained_opinion_summarization_with_minimal_supervision -> amplayo_2019_informative_and_controllable_opinion_summarization	[pos="e,494.68,471.95 494.72,472.02 494.71,472.01 494.71,471.99 494.7,471.98"];
	ge_2021_fine_grained_opinion_summarization_with_minimal_supervision -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.17,518.85 580.14,518.84 580.14,518.85 580.15,518.85 580.16,518.85"];
	ge_2021_fine_grained_opinion_summarization_with_minimal_supervision -> holtzman_2019_the_curious_case_of_neural_text_degeneration	[pos="e,583.82,499.71 583.56,499.73 583.6,499.73 583.65,499.73 583.69,499.72"];
	meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding	[color=green,
		height=8.6667,
		id=meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding,
		"k-core"=8,
		label=meng_2020,
		shape=circle,
		style=filled,
		width=8.6667,
		zazaza="4375.435115555416,2419.82786572317!"];
	ge_2021_fine_grained_opinion_summarization_with_minimal_supervision -> meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding	[pos="e,476.13,507.79 476.2,507.78 476.19,507.78 476.17,507.78 476.16,507.78"];
	pablos_2018_w2vlda_almost_unsupervised_system_for_aspect_based_sentiment_analysis	[color=blue,
		height=11.597,
		id=pablos_2018_w2vlda_almost_unsupervised_system_for_aspect_based_sentiment_analysis,
		"k-core"=7,
		label=pablos_2018,
		shape=circle,
		style=filled,
		width=11.597,
		zazaza="-7999.002891272393,126.28913364131158!"];
	ge_2021_fine_grained_opinion_summarization_with_minimal_supervision -> pablos_2018_w2vlda_almost_unsupervised_system_for_aspect_based_sentiment_analysis	[pos="e,450.75,465.07 451.18,465.35 451.11,465.31 451.03,465.26 450.96,465.21"];
	meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,553.81,414.43 553.77,414.48 553.78,414.47 553.79,414.46 553.79,414.45"];
	meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding -> shang_2017_automated_phrase_mining_from_massive_text_corpora	[pos="e,437.6,555.1 437.68,555 437.67,555.02 437.65,555.04 437.64,555.06"];
	meng_2019_spherical_text_embedding	[color=green,
		height=7.7778,
		id=meng_2019_spherical_text_embedding,
		"k-core"=8,
		label=meng_2019,
		shape=circle,
		style=filled,
		width=7.7778,
		zazaza="4035.785498779964,2951.6833879055957!"];
	meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding -> meng_2019_spherical_text_embedding	[pos="e,500,530.09 499.95,530.05 499.96,530.06 499.97,530.07 499.98,530.07"];
	meng_2018_weakly_supervised_neural_text_classification	[color=green,
		height=7.8889,
		id=meng_2018_weakly_supervised_neural_text_classification,
		"k-core"=8,
		label=meng_2018,
		shape=circle,
		style=filled,
		width=7.8889,
		zazaza="3046.4157513685445,3964.7635649228578!"];
	meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding -> meng_2018_weakly_supervised_neural_text_classification	[pos="e,474.35,580.68 474.35,580.64 474.35,580.65 474.35,580.66 474.35,580.66"];
	nickel_2017_poincare_embeddings_for_learning_hierarchical_representations	[color=green,
		height=8.5972,
		id=nickel_2017_poincare_embeddings_for_learning_hierarchical_representations,
		"k-core"=8,
		label=nickel_2017,
		shape=circle,
		style=filled,
		width=8.5972,
		zazaza="-980.2898606758907,4902.961532836779!"];
	meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding -> nickel_2017_poincare_embeddings_for_learning_hierarchical_representations	[pos="e,445,526.36 445.07,526.32 445.05,526.33 445.04,526.34 445.03,526.35"];
	tifrea_2018_poincare_glove_hyperbolic_word_embeddings	[color=green,
		height=6.7917,
		id=tifrea_2018_poincare_glove_hyperbolic_word_embeddings,
		"k-core"=8,
		label=tifrea_2018,
		shape=circle,
		style=filled,
		width=6.7917,
		zazaza="-4081.878638137509,2887.605712732171!"];
	meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding -> tifrea_2018_poincare_glove_hyperbolic_word_embeddings	[pos="e,445.2,495.67 445.27,495.69 445.25,495.69 445.24,495.68 445.23,495.68"];
	meng_2018_weakly_supervised_hierarchical_text_classification	[color=green,
		height=7.8889,
		id=meng_2018_weakly_supervised_hierarchical_text_classification,
		"k-core"=8,
		label=meng_2018,
		shape=circle,
		style=filled,
		width=7.8889,
		zazaza="-4776.754949512898,1477.3669736261654!"];
	meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding -> meng_2018_weakly_supervised_hierarchical_text_classification	[pos="e,466.39,568.66 466.39,568.62 466.39,568.63 466.39,568.64 466.39,568.64"];
	meng_2020_unsupervised_word_embedding_learning_by_incorporating_local_and_global_contexts	[color=yellow,
		height=3.3889,
		id=meng_2020_unsupervised_word_embedding_learning_by_incorporating_local_and_global_contexts,
		"k-core"=6,
		label=meng_2020,
		shape=circle,
		style=filled,
		width=3.3889,
		zazaza="-0.9998753614090491,-0.015786319339734546!"];
	meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding -> meng_2020_unsupervised_word_embedding_learning_by_incorporating_local_and_global_contexts	[pos="e,472.81,623.66 472.81,623.6 472.81,623.62 472.81,623.63 472.81,623.64"];
	meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding	[color=green,
		height=7.2778,
		id=meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding,
		"k-core"=8,
		label=meng_2019,
		shape=circle,
		style=filled,
		width=7.2778,
		zazaza="747.0686100921912,-4943.873875609029!"];
	meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding -> meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding	[pos="e,511.58,523.24 511.5,523.21 511.52,523.22 511.54,523.23 511.55,523.23"];
	huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring	[color=green,
		height=7.7778,
		id=huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring,
		"k-core"=8,
		label=huang_2020,
		shape=circle,
		style=filled,
		width=7.7778,
		zazaza="2103.1504945924194,-4536.161119097765!"];
	meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding -> huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring	[pos="e,502.99,557.07 502.79,557.14 502.82,557.13 502.86,557.12 502.89,557.11"];
	huang_2020_guiding_corpus_based_set_expansion_by_auxiliary_sets_generation_and_co_expansion	[color=green,
		height=6.1528,
		id=huang_2020_guiding_corpus_based_set_expansion_by_auxiliary_sets_generation_and_co_expansion,
		"k-core"=8,
		label=huang_2020,
		shape=circle,
		style=filled,
		width=6.1528,
		zazaza="4126.954677025191,-2822.8077281581714!"];
	meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding -> huang_2020_guiding_corpus_based_set_expansion_by_auxiliary_sets_generation_and_co_expansion	[pos="e,557.82,596.76 557.78,596.71 557.79,596.72 557.8,596.73 557.8,596.74"];
	nickel_2018_learning_continuous_hierarchies_in_the_lorentz_model_of_hyperbolic_geometry	[color=green,
		height=6.9722,
		id=nickel_2018_learning_continuous_hierarchies_in_the_lorentz_model_of_hyperbolic_geometry,
		"k-core"=8,
		label=nickel_2018,
		shape=circle,
		style=filled,
		width=6.9722,
		zazaza="-3465.081430979551,-3604.6096651052044!"];
	meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding -> nickel_2018_learning_continuous_hierarchies_in_the_lorentz_model_of_hyperbolic_geometry	[pos="e,420.07,486.96 420.19,487.01 420.16,487 420.14,486.99 420.12,486.98"];
	ganea_2018_hyperbolic_entailment_cones_for_learning_hierarchical_embeddings	[color=green,
		height=7.4167,
		id=ganea_2018_hyperbolic_entailment_cones_for_learning_hierarchical_embeddings,
		"k-core"=8,
		label=ganea_2018,
		shape=circle,
		style=filled,
		width=7.4167,
		zazaza="-1287.7400053473846,-4831.327491571534!"];
	meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding -> ganea_2018_hyperbolic_entailment_cones_for_learning_hierarchical_embeddings	[pos="e,421.44,508.87 421.56,508.87 421.53,508.87 421.51,508.87 421.49,508.87"];
	zhang_2019_higitclass_keyword_driven_hierarchical_classification_of_github_repositories	[color=yellow,
		height=5.2222,
		id=zhang_2019_higitclass_keyword_driven_hierarchical_classification_of_github_repositories,
		"k-core"=6,
		label=zhang_2019,
		shape=circle,
		style=filled,
		width=5.2222,
		zazaza="-0.03945701294951255,0.9992212614055742!"];
	meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding -> zhang_2019_higitclass_keyword_driven_hierarchical_classification_of_github_repositories	[pos="e,411.1,565.49 411.14,565.46 411.13,565.47 411.12,565.47 411.12,565.48"];
	meng_2019_spherical_text_embedding -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.17,518.86 580.13,518.86 580.14,518.86 580.15,518.86 580.15,518.86"];
	meng_2019_spherical_text_embedding -> meng_2018_weakly_supervised_neural_text_classification	[pos="e,474.37,580.66 474.43,580.55 474.41,580.57 474.4,580.59 474.4,580.61"];
	meng_2019_spherical_text_embedding -> nickel_2017_poincare_embeddings_for_learning_hierarchical_representations	[pos="e,445.02,526.38 445.13,526.39 445.11,526.39 445.09,526.38 445.07,526.38"];
	meng_2019_spherical_text_embedding -> tifrea_2018_poincare_glove_hyperbolic_word_embeddings	[pos="e,445.22,495.68 445.33,495.76 445.31,495.74 445.29,495.73 445.27,495.71"];
	meng_2019_spherical_text_embedding -> meng_2018_weakly_supervised_hierarchical_text_classification	[pos="e,466.41,568.64 466.48,568.56 466.46,568.57 466.45,568.59 466.44,568.6"];
	meng_2019_spherical_text_embedding -> nickel_2018_learning_continuous_hierarchies_in_the_lorentz_model_of_hyperbolic_geometry	[pos="e,420.04,486.95 420.08,486.98 420.07,486.97 420.06,486.97 420.06,486.96"];
	meng_2019_spherical_text_embedding -> ganea_2018_hyperbolic_entailment_cones_for_learning_hierarchical_embeddings	[pos="e,421.42,508.87 421.46,508.89 421.45,508.88 421.44,508.88 421.44,508.88"];
	meng_2019_spherical_text_embedding -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,523.41,509.55 523.36,509.6 523.37,509.59 523.38,509.58 523.38,509.57"];
	nickel_2017_poincare_embeddings_for_learning_hierarchical_representations -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,523.41,509.54 523.37,509.55 523.38,509.55 523.38,509.55 523.39,509.55"];
	tifrea_2018_poincare_glove_hyperbolic_word_embeddings -> nickel_2017_poincare_embeddings_for_learning_hierarchical_representations	[pos="e,444.98,526.35 444.98,526.29 444.98,526.3 444.98,526.32 444.98,526.33"];
	tifrea_2018_poincare_glove_hyperbolic_word_embeddings -> nickel_2018_learning_continuous_hierarchies_in_the_lorentz_model_of_hyperbolic_geometry	[pos="e,420.04,486.95 420.1,486.97 420.09,486.97 420.07,486.96 420.07,486.96"];
	tifrea_2018_poincare_glove_hyperbolic_word_embeddings -> ganea_2018_hyperbolic_entailment_cones_for_learning_hierarchical_embeddings	[pos="e,421.42,508.86 421.47,508.83 421.46,508.84 421.45,508.84 421.44,508.85"];
	tifrea_2018_poincare_glove_hyperbolic_word_embeddings -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,523.41,509.54 523.37,509.53 523.38,509.53 523.38,509.53 523.39,509.53"];
	meng_2018_weakly_supervised_hierarchical_text_classification -> meng_2018_weakly_supervised_neural_text_classification	[pos="e,474.33,580.66 474.26,580.56 474.28,580.58 474.29,580.6 474.3,580.62"];
	meng_2020_unsupervised_word_embedding_learning_by_incorporating_local_and_global_contexts -> meng_2019_spherical_text_embedding	[pos="e,500.01,530.13 499.99,530.18 500,530.17 500,530.16 500,530.15"];
	meng_2020_unsupervised_word_embedding_learning_by_incorporating_local_and_global_contexts -> meng_2018_weakly_supervised_neural_text_classification	[pos="e,474.35,580.72 474.35,580.82 474.35,580.8 474.35,580.78 474.35,580.76"];
	meng_2020_unsupervised_word_embedding_learning_by_incorporating_local_and_global_contexts -> meng_2018_weakly_supervised_hierarchical_text_classification	[pos="e,466.39,568.71 466.4,568.82 466.4,568.8 466.4,568.78 466.39,568.76"];
	meng_2020_unsupervised_word_embedding_learning_by_incorporating_local_and_global_contexts -> meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding	[pos="e,511.6,523.27 511.58,523.33 511.58,523.32 511.59,523.31 511.59,523.3"];
	meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.17,518.85 580.14,518.86 580.14,518.86 580.15,518.86 580.16,518.86"];
	meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding -> vaswani_2017_attention_is_all_you_need	[pos="e,587.97,510.32 587.93,510.33 587.94,510.33 587.94,510.33 587.95,510.32"];
	meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,553.82,414.43 553.79,414.49 553.8,414.48 553.8,414.46 553.81,414.45"];
	meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding -> peters_2018_deep_contextualized_word_representations	[pos="e,583.75,529.88 583.71,529.88 583.72,529.88 583.73,529.88 583.73,529.88"];
	meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,458.05,613.83 458.08,613.78 458.07,613.79 458.06,613.8 458.06,613.81"];
	meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding -> shang_2017_automated_phrase_mining_from_massive_text_corpora	[pos="e,437.59,555.13 437.63,555.11 437.62,555.11 437.61,555.12 437.6,555.12"];
	meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding -> meng_2019_spherical_text_embedding	[pos="e,500.05,530.09 500.14,530.03 500.12,530.05 500.1,530.06 500.09,530.07"];
	meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding -> meng_2018_weakly_supervised_neural_text_classification	[pos="e,474.38,580.65 474.46,580.53 474.44,580.55 474.43,580.58 474.41,580.6"];
	meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding -> nickel_2017_poincare_embeddings_for_learning_hierarchical_representations	[pos="e,444.99,526.38 445.02,526.37 445.02,526.38 445.01,526.38 445,526.38"];
	meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding -> tifrea_2018_poincare_glove_hyperbolic_word_embeddings	[pos="e,445.19,495.66 445.22,495.68 445.22,495.67 445.21,495.67 445.2,495.67"];
	meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding -> meng_2018_weakly_supervised_hierarchical_text_classification	[pos="e,466.42,568.63 466.51,568.54 466.49,568.56 466.47,568.58 466.46,568.59"];
	meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding -> huang_2020_guiding_corpus_based_set_expansion_by_auxiliary_sets_generation_and_co_expansion	[pos="e,557.65,596.87 557.45,596.94 557.49,596.94 557.52,596.92 557.55,596.91"];
	meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding -> nickel_2018_learning_continuous_hierarchies_in_the_lorentz_model_of_hyperbolic_geometry	[pos="e,420.04,486.95 420.09,486.97 420.08,486.97 420.07,486.96 420.06,486.96"];
	meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding -> ganea_2018_hyperbolic_entailment_cones_for_learning_hierarchical_embeddings	[pos="e,421.42,508.87 421.47,508.88 421.46,508.88 421.45,508.88 421.44,508.88"];
	meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding -> zhang_2019_higitclass_keyword_driven_hierarchical_classification_of_github_repositories	[pos="e,411.11,565.49 411.17,565.47 411.15,565.48 411.14,565.48 411.13,565.48"];
	meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,523.39,509.58 523.29,509.69 523.31,509.67 523.33,509.65 523.35,509.63"];
	huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.17,518.86 580.13,518.88 580.14,518.88 580.15,518.87 580.15,518.87"];
	huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,458.07,613.8 458.17,613.68 458.15,613.71 458.13,613.73 458.11,613.75"];
	huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring -> shang_2017_automated_phrase_mining_from_massive_text_corpora	[pos="e,437.58,555.13 437.62,555.13 437.61,555.13 437.61,555.13 437.6,555.13"];
	huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring -> devlin_2018_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,613.41,507.91 613.35,507.94 613.37,507.93 613.38,507.93 613.39,507.92"];
	huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring -> meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding	[pos="e,476.29,507.7 476.49,507.62 476.45,507.63 476.42,507.65 476.39,507.66"];
	huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring -> meng_2019_spherical_text_embedding	[pos="e,500.02,530.13 500.02,530.19 500.02,530.18 500.02,530.16 500.02,530.15"];
	huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring -> nickel_2017_poincare_embeddings_for_learning_hierarchical_representations	[pos="e,445.02,526.4 445.14,526.46 445.12,526.45 445.09,526.44 445.07,526.43"];
	huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring -> meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding	[pos="e,511.6,523.28 511.58,523.35 511.59,523.34 511.59,523.32 511.59,523.31"];
	huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring -> huang_2020_guiding_corpus_based_set_expansion_by_auxiliary_sets_generation_and_co_expansion	[pos="e,557.8,596.75 557.68,596.66 557.71,596.68 557.73,596.7 557.75,596.71"];
	le_2019_inferring_concept_hierarchies_from_text_corpora_via_hyperbolic_embeddings	[color=blue,
		height=5.5833,
		id=le_2019_inferring_concept_hierarchies_from_text_corpora_via_hyperbolic_embeddings,
		"k-core"=7,
		label=le_2019,
		shape=circle,
		style=filled,
		width=5.5833,
		zazaza="7900.516033435199,-1257.7138015721903!"];
	huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring -> le_2019_inferring_concept_hierarchies_from_text_corpora_via_hyperbolic_embeddings	[pos="e,399.36,502.17 399.42,502.2 399.41,502.19 399.4,502.19 399.39,502.18"];
	huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring -> soares_2019_matching_the_blanks_distributional_similarity_for_relation_learning	[pos="e,589.56,599.28 589.52,599.26 589.53,599.26 589.54,599.27 589.54,599.27"];
	huang_2020_guiding_corpus_based_set_expansion_by_auxiliary_sets_generation_and_co_expansion -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.18,518.87 580.17,518.91 580.17,518.9 580.17,518.89 580.18,518.89"];
	huang_2020_guiding_corpus_based_set_expansion_by_auxiliary_sets_generation_and_co_expansion -> meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding	[pos="e,511.79,523.16 511.99,523.09 511.96,523.1 511.92,523.11 511.89,523.12"];
	nickel_2018_learning_continuous_hierarchies_in_the_lorentz_model_of_hyperbolic_geometry -> nickel_2017_poincare_embeddings_for_learning_hierarchical_representations	[pos="e,444.96,526.35 444.91,526.26 444.92,526.28 444.93,526.3 444.94,526.31"];
	nickel_2018_learning_continuous_hierarchies_in_the_lorentz_model_of_hyperbolic_geometry -> ganea_2018_hyperbolic_entailment_cones_for_learning_hierarchical_embeddings	[pos="e,421.4,508.86 421.4,508.81 421.4,508.82 421.4,508.83 421.4,508.84"];
	ganea_2018_hyperbolic_entailment_cones_for_learning_hierarchical_embeddings -> nickel_2017_poincare_embeddings_for_learning_hierarchical_representations	[pos="e,444.96,526.36 444.91,526.33 444.92,526.34 444.93,526.34 444.94,526.35"];
	zhang_2019_higitclass_keyword_driven_hierarchical_classification_of_github_repositories -> meng_2018_weakly_supervised_neural_text_classification	[pos="e,474.34,580.69 474.31,580.68 474.32,580.68 474.32,580.68 474.33,580.69"];
	zhang_2019_higitclass_keyword_driven_hierarchical_classification_of_github_repositories -> meng_2018_weakly_supervised_hierarchical_text_classification	[pos="e,466.34,568.66 466.23,568.66 466.25,568.66 466.27,568.66 466.29,568.66"];
	liu_2020_multilingual_denoising_pre_training_for_neural_machine_translation	[color=blue,
		height=3.3889,
		id=liu_2020_multilingual_denoising_pre_training_for_neural_machine_translation,
		"k-core"=7,
		label=liu_2020,
		shape=circle,
		style=filled,
		width=3.3889,
		zazaza="7936.282634903291,1007.6776614500174!"];
	liu_2020_multilingual_denoising_pre_training_for_neural_machine_translation -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.19,518.87 580.22,518.9 580.22,518.9 580.21,518.89 580.21,518.88"];
	liu_2020_multilingual_denoising_pre_training_for_neural_machine_translation -> vaswani_2017_attention_is_all_you_need	[pos="e,587.99,510.33 588.01,510.38 588.01,510.37 588,510.36 588,510.35"];
	liu_2020_multilingual_denoising_pre_training_for_neural_machine_translation -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,630,511.51 630,511.56 630,511.55 630,511.54 630,511.53"];
	liu_2020_multilingual_denoising_pre_training_for_neural_machine_translation -> lewis_2019_bart_denoising_sequence_to_sequence_pre_training_for_natural_language_generation_translation_and_comprehension	[pos="e,592.43,539.84 592.51,539.95 592.49,539.92 592.47,539.9 592.46,539.89"];
	liu_2020_multilingual_denoising_pre_training_for_neural_machine_translation -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.75,532.6 612.78,532.72 612.78,532.69 612.77,532.67 612.76,532.65"];
	liu_2020_multilingual_denoising_pre_training_for_neural_machine_translation -> peters_2018_deep_contextualized_word_representations	[pos="e,583.8,529.93 583.9,530.05 583.87,530.03 583.85,530 583.84,529.98"];
	liu_2020_multilingual_denoising_pre_training_for_neural_machine_translation -> keskar_2019_ctrl_a_conditional_transformer_language_model_for_controllable_generation	[pos="e,655.58,519.18 655.57,519.22 655.57,519.21 655.57,519.21 655.58,519.2"];
	keskar_2019_ctrl_a_conditional_transformer_language_model_for_controllable_generation -> see_2017_get_to_the_point_summarization_with_pointer_generator_networks	[pos="e,532.41,404.04 532.48,404.1 532.46,404.08 532.45,404.07 532.44,404.06"];
	keskar_2019_ctrl_a_conditional_transformer_language_model_for_controllable_generation -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.2,518.85 580.24,518.85 580.23,518.85 580.22,518.85 580.22,518.85"];
	keskar_2019_ctrl_a_conditional_transformer_language_model_for_controllable_generation -> vaswani_2017_attention_is_all_you_need	[pos="e,587.99,510.32 588.03,510.33 588.02,510.32 588.02,510.32 588.01,510.32"];
	keskar_2019_ctrl_a_conditional_transformer_language_model_for_controllable_generation -> holtzman_2019_the_curious_case_of_neural_text_degeneration	[pos="e,677.96,492.24 677.91,492.3 677.92,492.29 677.93,492.27 677.94,492.26"];
	keskar_2019_ctrl_a_conditional_transformer_language_model_for_controllable_generation -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,630.02,511.51 630.08,511.52 630.06,511.52 630.05,511.52 630.04,511.51"];
	keskar_2019_ctrl_a_conditional_transformer_language_model_for_controllable_generation -> peters_2018_deep_contextualized_word_representations	[pos="e,583.78,529.88 583.82,529.88 583.81,529.88 583.8,529.88 583.79,529.88"];
	keskar_2019_ctrl_a_conditional_transformer_language_model_for_controllable_generation -> arjovsky_2017_wasserstein_generative_adversarial_networks	[pos="e,718.09,431.33 718.05,431.37 718.06,431.36 718.07,431.35 718.07,431.35"];
	wang_2022_representing_mixtures_of_word_embeddings_with_mixtures_of_topic_embeddings	[color=green,
		height=2,
		id=wang_2022_representing_mixtures_of_word_embeddings_with_mixtures_of_topic_embeddings,
		"k-core"=8,
		label=wang_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="4910.546541450104,941.5583224010579!"];
	wang_2022_representing_mixtures_of_word_embeddings_with_mixtures_of_topic_embeddings -> zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey	[pos="e,595.74,371.18 595.63,371.13 595.65,371.14 595.68,371.15 595.7,371.16"];
	wang_2022_representing_mixtures_of_word_embeddings_with_mixtures_of_topic_embeddings -> card_2017_neural_models_for_documents_with_metadata	[pos="e,606.53,380.69 606.27,380.57 606.31,380.59 606.36,380.61 606.4,380.63"];
	wang_2022_representing_mixtures_of_word_embeddings_with_mixtures_of_topic_embeddings -> burkhardt_2019_decoupling_sparsity_and_smoothness_in_the_dirichlet_variational_autoencoder_topic_model	[pos="e,613.03,338.24 612.64,338.3 612.7,338.29 612.77,338.28 612.83,338.27"];
	wang_2022_representing_mixtures_of_word_embeddings_with_mixtures_of_topic_embeddings -> card_2018_neural_models_for_documents_with_metadata	[pos="e,604.55,384.84 604.1,384.58 604.17,384.62 604.25,384.67 604.33,384.71"];
	wang_2022_representing_mixtures_of_word_embeddings_with_mixtures_of_topic_embeddings -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,553.82,414.4 553.82,414.36 553.82,414.37 553.82,414.38 553.82,414.38"];
	wang_2022_representing_mixtures_of_word_embeddings_with_mixtures_of_topic_embeddings -> guo_2019_recurrent_hierarchical_topic_guided_rnn_for_language_generation	[pos="e,568.6,416.42 568.46,416.08 568.48,416.14 568.5,416.19 568.53,416.25"];
	wang_2022_representing_mixtures_of_word_embeddings_with_mixtures_of_topic_embeddings -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,611.17,368.94 610.82,368.85 610.88,368.86 610.94,368.88 610.99,368.9"];
	wang_2022_representing_mixtures_of_word_embeddings_with_mixtures_of_topic_embeddings -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.65,389.47 577.57,389.38 577.59,389.4 577.61,389.42 577.62,389.43"];
	wang_2022_representing_mixtures_of_word_embeddings_with_mixtures_of_topic_embeddings -> zhao_2017_metalda_a_topic_model_that_efficiently_incorporates_meta_information	[pos="e,485.99,332.7 486.11,332.74 486.08,332.73 486.06,332.73 486.04,332.72"];
	wang_2022_representing_mixtures_of_word_embeddings_with_mixtures_of_topic_embeddings -> zhao_2020_neural_topic_model_via_optimal_transport	[pos="e,613.09,337.26 612.72,337.32 612.79,337.31 612.85,337.3 612.91,337.29"];
	wang_2022_representing_mixtures_of_word_embeddings_with_mixtures_of_topic_embeddings -> zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling	[pos="e,538.83,376.16 538.83,376.11 538.83,376.12 538.83,376.13 538.83,376.14"];
	gulrajani_2017_improved_training_of_wasserstein_gans -> jang_2016_categorical_reparameterization_with_gumbel_softmax	[pos="e,515.95,358.31 516.05,358.33 516.03,358.33 516.01,358.32 515.99,358.32"];
	meng_2020_embedding_driven_multi_dimensional_topic_mining_and_text_analysis	[color=green,
		height=2,
		id=meng_2020_embedding_driven_multi_dimensional_topic_mining_and_text_analysis,
		"k-core"=8,
		label=meng_2020,
		shape=circle,
		style=filled,
		width=2,
		zazaza="4878.375530563951,1096.1078759834843!"];
	meng_2020_embedding_driven_multi_dimensional_topic_mining_and_text_analysis -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,574.26,523.45 573.9,523.73 573.96,523.68 574.02,523.64 574.08,523.59"];
	meng_2020_embedding_driven_multi_dimensional_topic_mining_and_text_analysis -> peters_2018_deep_contextualized_word_representations	[pos="e,580.25,531.89 579.79,532.15 579.87,532.1 579.95,532.06 580.02,532.02"];
	meng_2020_embedding_driven_multi_dimensional_topic_mining_and_text_analysis -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,459.56,612.66 460,612.31 459.92,612.38 459.85,612.44 459.77,612.49"];
	meng_2020_embedding_driven_multi_dimensional_topic_mining_and_text_analysis -> meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding	[pos="e,476.13,507.83 476.22,507.96 476.2,507.93 476.18,507.91 476.17,507.89"];
	meng_2020_embedding_driven_multi_dimensional_topic_mining_and_text_analysis -> meng_2019_spherical_text_embedding	[pos="e,500.03,530.14 500.06,530.22 500.05,530.2 500.05,530.19 500.04,530.17"];
	meng_2020_embedding_driven_multi_dimensional_topic_mining_and_text_analysis -> meng_2018_weakly_supervised_neural_text_classification	[pos="e,474.38,580.68 474.48,580.66 474.46,580.66 474.44,580.67 474.42,580.67"];
	meng_2020_embedding_driven_multi_dimensional_topic_mining_and_text_analysis -> nickel_2017_poincare_embeddings_for_learning_hierarchical_representations	[pos="e,454.14,531.65 454.4,531.8 454.36,531.77 454.31,531.75 454.27,531.72"];
	meng_2020_embedding_driven_multi_dimensional_topic_mining_and_text_analysis -> tifrea_2018_poincare_glove_hyperbolic_word_embeddings	[pos="e,465.7,516.26 465.97,516.54 465.93,516.49 465.88,516.45 465.84,516.4"];
	meng_2020_embedding_driven_multi_dimensional_topic_mining_and_text_analysis -> meng_2018_weakly_supervised_hierarchical_text_classification	[pos="e,466.42,568.67 466.53,568.66 466.51,568.66 466.48,568.66 466.47,568.66"];
	meng_2020_embedding_driven_multi_dimensional_topic_mining_and_text_analysis -> meng_2020_unsupervised_word_embedding_learning_by_incorporating_local_and_global_contexts	[pos="e,472.84,623.64 472.94,623.53 472.92,623.55 472.9,623.57 472.88,623.59"];
	meng_2020_embedding_driven_multi_dimensional_topic_mining_and_text_analysis -> meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding	[pos="e,511.61,523.29 511.62,523.38 511.62,523.36 511.62,523.34 511.61,523.33"];
	meng_2020_embedding_driven_multi_dimensional_topic_mining_and_text_analysis -> huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring	[pos="e,503.21,557.01 503.33,557.1 503.31,557.08 503.28,557.06 503.26,557.05"];
	meng_2020_embedding_driven_multi_dimensional_topic_mining_and_text_analysis -> huang_2020_guiding_corpus_based_set_expansion_by_auxiliary_sets_generation_and_co_expansion	[pos="e,557.81,596.76 557.72,596.69 557.74,596.71 557.76,596.72 557.77,596.73"];
	meng_2020_embedding_driven_multi_dimensional_topic_mining_and_text_analysis -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,523.42,509.58 523.4,509.71 523.41,509.68 523.41,509.65 523.41,509.63"];
	le_2019_inferring_concept_hierarchies_from_text_corpora_via_hyperbolic_embeddings -> nickel_2017_poincare_embeddings_for_learning_hierarchical_representations	[pos="e,444.94,526.36 444.85,526.31 444.87,526.32 444.89,526.33 444.9,526.34"];
	le_2019_inferring_concept_hierarchies_from_text_corpora_via_hyperbolic_embeddings -> tifrea_2018_poincare_glove_hyperbolic_word_embeddings	[pos="e,445.14,495.66 445.05,495.68 445.07,495.67 445.09,495.67 445.1,495.67"];
	le_2019_inferring_concept_hierarchies_from_text_corpora_via_hyperbolic_embeddings -> nickel_2018_learning_continuous_hierarchies_in_the_lorentz_model_of_hyperbolic_geometry	[pos="e,420.01,486.96 419.97,486.99 419.98,486.98 419.98,486.98 419.99,486.97"];
	le_2019_inferring_concept_hierarchies_from_text_corpora_via_hyperbolic_embeddings -> ganea_2018_hyperbolic_entailment_cones_for_learning_hierarchical_embeddings	[pos="e,421.39,508.87 421.34,508.85 421.35,508.86 421.36,508.86 421.37,508.86"];
	soares_2019_matching_the_blanks_distributional_similarity_for_relation_learning -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.19,518.87 580.19,518.91 580.19,518.9 580.19,518.89 580.19,518.89"];
	soares_2019_matching_the_blanks_distributional_similarity_for_relation_learning -> vaswani_2017_attention_is_all_you_need	[pos="e,587.98,510.34 587.98,510.38 587.98,510.37 587.98,510.36 587.98,510.36"];
	soares_2019_matching_the_blanks_distributional_similarity_for_relation_learning -> peters_2018_deep_contextualized_word_representations	[pos="e,583.77,529.9 583.77,529.94 583.77,529.93 583.77,529.92 583.77,529.91"];
	jiang_2017_metapad_meta_pattern_discovery_from_massive_text_corpora -> shang_2017_automated_phrase_mining_from_massive_text_corpora	[pos="e,437.58,555.15 437.6,555.21 437.6,555.2 437.59,555.19 437.59,555.18"];
	lees_2020_embedding_semantic_taxonomies	[color=yellow,
		height=2,
		id=lees_2020_embedding_semantic_taxonomies,
		"k-core"=6,
		label=lees_2020,
		shape=circle,
		style=filled,
		width=2,
		zazaza="0.9682683349493266,0.24991296038485114!"];
	lees_2020_embedding_semantic_taxonomies -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,422.95,591.12 422.5,590.83 422.58,590.88 422.65,590.92 422.73,590.97"];
	lees_2020_embedding_semantic_taxonomies -> nickel_2017_poincare_embeddings_for_learning_hierarchical_representations	[pos="e,431.64,530.42 431.25,530.53 431.32,530.51 431.38,530.5 431.45,530.48"];
	lees_2020_embedding_semantic_taxonomies -> tifrea_2018_poincare_glove_hyperbolic_word_embeddings	[pos="e,422.28,511.02 421.97,511.23 422.02,511.19 422.08,511.16 422.13,511.12"];
	lees_2020_embedding_semantic_taxonomies -> nickel_2018_learning_continuous_hierarchies_in_the_lorentz_model_of_hyperbolic_geometry	[pos="e,410.43,497.6 410.16,497.91 410.21,497.85 410.25,497.8 410.3,497.75"];
	lees_2020_embedding_semantic_taxonomies -> ganea_2018_hyperbolic_entailment_cones_for_learning_hierarchical_embeddings	[pos="e,421.23,508.99 420.74,509.35 420.84,509.27 420.94,509.2 421.02,509.14"];
	lees_2020_embedding_semantic_taxonomies -> le_2019_inferring_concept_hierarchies_from_text_corpora_via_hyperbolic_embeddings	[pos="e,399.32,502.2 399.24,502.3 399.25,502.28 399.27,502.26 399.28,502.24"];
	li_2022_uctopic_unsupervised_contrastive_learning_for_phrase_representations_and_topic_mining	[color=blue,
		height=3.3889,
		id=li_2022_uctopic_unsupervised_contrastive_learning_for_phrase_representations_and_topic_mining,
		"k-core"=7,
		label=li_2022,
		shape=circle,
		style=filled,
		width=3.3889,
		zazaza="7679.170609367346,2242.841942895883!"];
	li_2022_uctopic_unsupervised_contrastive_learning_for_phrase_representations_and_topic_mining -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.2,518.87 580.26,518.9 580.24,518.89 580.23,518.89 580.23,518.88"];
	li_2022_uctopic_unsupervised_contrastive_learning_for_phrase_representations_and_topic_mining -> he_2017_an_unsupervised_neural_attention_model_for_aspect_extraction	[pos="e,510.13,456.79 510.39,457.01 510.35,456.97 510.31,456.94 510.26,456.9"];
	li_2022_uctopic_unsupervised_contrastive_learning_for_phrase_representations_and_topic_mining -> wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration	[pos="e,641.13,508.56 641.05,508.62 641.07,508.61 641.08,508.6 641.09,508.59"];
	li_2022_uctopic_unsupervised_contrastive_learning_for_phrase_representations_and_topic_mining -> krishna_2020_reformulating_unsupervised_style_transfer_as_paraphrase_generation	[pos="e,676.3,524.65 676.26,524.66 676.27,524.66 676.28,524.66 676.28,524.66"];
	li_2022_uctopic_unsupervised_contrastive_learning_for_phrase_representations_and_topic_mining -> lee_2020_learning_dense_representations_of_phrases_at_scale	[pos="e,658.7,583.08 658.58,582.98 658.61,583 658.63,583.02 658.65,583.04"];
	li_2022_uctopic_unsupervised_contrastive_learning_for_phrase_representations_and_topic_mining -> soares_2019_matching_the_blanks_distributional_similarity_for_relation_learning	[pos="e,589.58,599.28 589.59,599.24 589.59,599.25 589.59,599.26 589.59,599.26"];
	zhang_2021_supporting_clustering_with_contrastive_learning	[color=yellow,
		height=4.7778,
		id=zhang_2021_supporting_clustering_with_contrastive_learning,
		"k-core"=6,
		label=zhang_2021,
		shape=circle,
		style=filled,
		width=4.7778,
		zazaza="0.5580289971573477,0.8298214639362973!"];
	li_2022_uctopic_unsupervised_contrastive_learning_for_phrase_representations_and_topic_mining -> zhang_2021_supporting_clustering_with_contrastive_learning	[pos="e,665.52,507.65 665.48,507.66 665.49,507.66 665.5,507.66 665.5,507.66"];
	tulkens_2020_embarrassingly_simple_unsupervised_aspect_extraction	[color=blue,
		height=6.1528,
		id=tulkens_2020_embarrassingly_simple_unsupervised_aspect_extraction,
		"k-core"=7,
		label=tulkens_2020,
		shape=circle,
		style=filled,
		width=6.1528,
		zazaza="-7713.619667538364,2121.3366827490704!"];
	li_2022_uctopic_unsupervised_contrastive_learning_for_phrase_representations_and_topic_mining -> tulkens_2020_embarrassingly_simple_unsupervised_aspect_extraction	[pos="e,497.19,475.3 497.54,475.5 497.48,475.46 497.42,475.43 497.36,475.4"];
	chen_2020_a_simple_framework_for_contrastive_learning_of_visual_representations	[color=yellow,
		height=7.125,
		id=chen_2020_a_simple_framework_for_contrastive_learning_of_visual_representations,
		"k-core"=6,
		label=chen_2020,
		shape=circle,
		style=filled,
		width=7.125,
		zazaza="-0.3180114294071965,-0.9480868565661777!"];
	li_2022_uctopic_unsupervised_contrastive_learning_for_phrase_representations_and_topic_mining -> chen_2020_a_simple_framework_for_contrastive_learning_of_visual_representations	[pos="e,700.75,458.48 700.32,458.81 700.4,458.76 700.47,458.7 700.54,458.64"];
	zhang_2021_supporting_clustering_with_contrastive_learning -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.2,518.85 580.25,518.85 580.24,518.85 580.23,518.85 580.22,518.85"];
	zhang_2021_supporting_clustering_with_contrastive_learning -> lewis_2019_bart_denoising_sequence_to_sequence_pre_training_for_natural_language_generation_translation_and_comprehension	[pos="e,592.41,539.8 592.45,539.78 592.45,539.79 592.44,539.79 592.43,539.79"];
	zhang_2021_supporting_clustering_with_contrastive_learning -> peters_2018_deep_contextualized_word_representations	[pos="e,583.78,529.88 583.82,529.87 583.81,529.87 583.81,529.88 583.8,529.88"];
	zhang_2021_supporting_clustering_with_contrastive_learning -> chen_2020_a_simple_framework_for_contrastive_learning_of_visual_representations	[pos="e,715.25,446.95 715.22,446.99 715.22,446.98 715.23,446.97 715.23,446.97"];
	tulkens_2020_embarrassingly_simple_unsupervised_aspect_extraction -> he_2017_an_unsupervised_neural_attention_model_for_aspect_extraction	[pos="e,471.04,424.46 470.98,424.51 470.99,424.5 471.01,424.49 471.02,424.48"];
	tulkens_2020_embarrassingly_simple_unsupervised_aspect_extraction -> pablos_2018_w2vlda_almost_unsupervised_system_for_aspect_based_sentiment_analysis	[pos="e,417.52,442.97 417.57,442.97 417.56,442.97 417.55,442.97 417.54,442.97"];
	song_2021_who_should_go_first_a_self_supervised_concept_sorting_model_for_improving_taxonomy_expansion	[color=green,
		height=3.3889,
		id=song_2021_who_should_go_first_a_self_supervised_concept_sorting_model_for_improving_taxonomy_expansion,
		"k-core"=8,
		label=song_2021,
		shape=circle,
		style=filled,
		width=3.3889,
		zazaza="4701.455534292502,1701.8565426976206!"];
	song_2021_who_should_go_first_a_self_supervised_concept_sorting_model_for_improving_taxonomy_expansion -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,458.04,613.88 458.04,613.99 458.04,613.96 458.04,613.94 458.04,613.92"];
	song_2021_who_should_go_first_a_self_supervised_concept_sorting_model_for_improving_taxonomy_expansion -> jiang_2017_metapad_meta_pattern_discovery_from_massive_text_corpora	[pos="e,476.32,662.35 476.28,662.36 476.29,662.36 476.29,662.35 476.3,662.35"];
	mao_2020_octet_online_catalog_taxonomy_enrichment_with_self_supervision	[color=green,
		height=5.8889,
		id=mao_2020_octet_online_catalog_taxonomy_enrichment_with_self_supervision,
		"k-core"=8,
		label=mao_2020,
		shape=circle,
		style=filled,
		width=5.8889,
		zazaza="-1886.0365268623418,4630.644302854121!"];
	song_2021_who_should_go_first_a_self_supervised_concept_sorting_model_for_improving_taxonomy_expansion -> mao_2020_octet_online_catalog_taxonomy_enrichment_with_self_supervision	[pos="e,442.27,595.04 442.28,595.08 442.27,595.07 442.27,595.06 442.27,595.05"];
	yang_2020_co_embedding_network_nodes_and_hierarchical_labels_with_taxonomy_based_generative_adversarial_networks	[color=yellow,
		height=5.5833,
		id=yang_2020_co_embedding_network_nodes_and_hierarchical_labels_with_taxonomy_based_generative_adversarial_networks,
		"k-core"=6,
		label=yang_2020,
		shape=circle,
		style=filled,
		width=5.5833,
		zazaza="0.02367801104398754,-0.9997196183851529!"];
	song_2021_who_should_go_first_a_self_supervised_concept_sorting_model_for_improving_taxonomy_expansion -> yang_2020_co_embedding_network_nodes_and_hierarchical_labels_with_taxonomy_based_generative_adversarial_networks	[pos="e,422.5,624.88 422.58,624.96 422.56,624.95 422.55,624.93 422.54,624.92"];
	manzoor_2020_expanding_taxonomies_with_implicit_edge_semantics	[color=green,
		height=5.8889,
		id=manzoor_2020_expanding_taxonomies_with_implicit_edge_semantics,
		"k-core"=8,
		label=manzoor_2020,
		shape=circle,
		style=filled,
		width=5.8889,
		zazaza="1211.3123487101757,-4851.053648707882!"];
	song_2021_who_should_go_first_a_self_supervised_concept_sorting_model_for_improving_taxonomy_expansion -> manzoor_2020_expanding_taxonomies_with_implicit_edge_semantics	[pos="e,449.83,591.48 449.84,591.52 449.84,591.51 449.84,591.5 449.83,591.49"];
	yu_2020_steam_self_supervised_taxonomy_expansion_with_mini_paths	[color=green,
		height=6.3889,
		id=yu_2020_steam_self_supervised_taxonomy_expansion_with_mini_paths,
		"k-core"=8,
		label=yu_2020,
		shape=circle,
		style=filled,
		width=6.3889,
		zazaza="3046.415155322098,-3964.764173698939!"];
	song_2021_who_should_go_first_a_self_supervised_concept_sorting_model_for_improving_taxonomy_expansion -> yu_2020_steam_self_supervised_taxonomy_expansion_with_mini_paths	[pos="e,508.42,598.97 508.39,599.01 508.4,599 508.4,598.99 508.41,598.99"];
	shen_2020_taxoexpan_self_supervised_taxonomy_expansion_with_position_enhanced_graph_neural_network	[color=green,
		height=7.125,
		id=shen_2020_taxoexpan_self_supervised_taxonomy_expansion_with_position_enhanced_graph_neural_network,
		"k-core"=8,
		label=shen_2020,
		shape=circle,
		style=filled,
		width=7.125,
		zazaza="3940.5941991159107,-3077.6154977378274!"];
	song_2021_who_should_go_first_a_self_supervised_concept_sorting_model_for_improving_taxonomy_expansion -> shen_2020_taxoexpan_self_supervised_taxonomy_expansion_with_position_enhanced_graph_neural_network	[pos="e,501.66,584.15 501.64,584.19 501.64,584.18 501.65,584.18 501.65,584.17"];
	mao_2020_octet_online_catalog_taxonomy_enrichment_with_self_supervision -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,458.03,613.83 457.99,613.79 458,613.8 458.01,613.81 458.01,613.81"];
	mao_2020_octet_online_catalog_taxonomy_enrichment_with_self_supervision -> shang_2017_automated_phrase_mining_from_massive_text_corpora	[pos="e,437.58,555.16 437.59,555.25 437.58,555.23 437.58,555.21 437.58,555.2"];
	mao_2020_octet_online_catalog_taxonomy_enrichment_with_self_supervision -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,523.41,509.55 523.36,509.6 523.37,509.59 523.38,509.58 523.39,509.57"];
	mao_2020_octet_online_catalog_taxonomy_enrichment_with_self_supervision -> shen_2020_taxoexpan_self_supervised_taxonomy_expansion_with_position_enhanced_graph_neural_network	[pos="e,501.63,584.14 501.5,584.17 501.53,584.16 501.55,584.16 501.57,584.15"];
	yang_2020_co_embedding_network_nodes_and_hierarchical_labels_with_taxonomy_based_generative_adversarial_networks -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,458.01,613.85 457.94,613.88 457.95,613.87 457.97,613.87 457.98,613.86"];
	yang_2020_co_embedding_network_nodes_and_hierarchical_labels_with_taxonomy_based_generative_adversarial_networks -> nickel_2017_poincare_embeddings_for_learning_hierarchical_representations	[pos="e,444.97,526.4 444.96,526.45 444.96,526.44 444.97,526.43 444.97,526.42"];
	yang_2020_co_embedding_network_nodes_and_hierarchical_labels_with_taxonomy_based_generative_adversarial_networks -> jiang_2017_metapad_meta_pattern_discovery_from_massive_text_corpora	[pos="e,476.29,662.33 476.18,662.25 476.2,662.26 476.22,662.28 476.24,662.29"];
	manzoor_2020_expanding_taxonomies_with_implicit_edge_semantics -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,458.03,613.83 458.01,613.78 458.02,613.79 458.02,613.8 458.02,613.81"];
	manzoor_2020_expanding_taxonomies_with_implicit_edge_semantics -> nickel_2017_poincare_embeddings_for_learning_hierarchical_representations	[pos="e,444.98,526.39 444.98,526.42 444.98,526.42 444.98,526.41 444.98,526.4"];
	manzoor_2020_expanding_taxonomies_with_implicit_edge_semantics -> nickel_2018_learning_continuous_hierarchies_in_the_lorentz_model_of_hyperbolic_geometry	[pos="e,420.03,486.97 420.05,487.02 420.04,487.01 420.04,487 420.04,486.99"];
	manzoor_2020_expanding_taxonomies_with_implicit_edge_semantics -> ganea_2018_hyperbolic_entailment_cones_for_learning_hierarchical_embeddings	[pos="e,421.41,508.89 421.42,508.93 421.42,508.92 421.42,508.91 421.42,508.9"];
	manzoor_2020_expanding_taxonomies_with_implicit_edge_semantics -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,523.41,509.55 523.37,509.6 523.38,509.59 523.39,509.58 523.39,509.57"];
	aly_2019_every_child_should_have_parents_a_taxonomy_refinement_algorithm_based_on_hyperbolic_term_embeddings	[color=blue,
		height=5.2222,
		id=aly_2019_every_child_should_have_parents_a_taxonomy_refinement_algorithm_based_on_hyperbolic_term_embeddings,
		"k-core"=7,
		label=aly_2019,
		shape=circle,
		style=filled,
		width=5.2222,
		zazaza="-819.4789653682055,-7957.917679455667!"];
	manzoor_2020_expanding_taxonomies_with_implicit_edge_semantics -> aly_2019_every_child_should_have_parents_a_taxonomy_refinement_algorithm_based_on_hyperbolic_term_embeddings	[pos="e,412.8,541.79 412.88,541.9 412.87,541.87 412.85,541.85 412.84,541.84"];
	yu_2020_steam_self_supervised_taxonomy_expansion_with_mini_paths -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.17,518.87 580.13,518.91 580.14,518.9 580.15,518.89 580.16,518.89"];
	yu_2020_steam_self_supervised_taxonomy_expansion_with_mini_paths -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,458.07,613.83 458.18,613.8 458.16,613.81 458.14,613.82 458.12,613.82"];
	yu_2020_steam_self_supervised_taxonomy_expansion_with_mini_paths -> nickel_2017_poincare_embeddings_for_learning_hierarchical_representations	[pos="e,444.99,526.39 445.02,526.43 445.01,526.42 445.01,526.41 445,526.41"];
	yu_2020_steam_self_supervised_taxonomy_expansion_with_mini_paths -> manzoor_2020_expanding_taxonomies_with_implicit_edge_semantics	[pos="e,449.87,591.47 450,591.49 449.97,591.48 449.95,591.48 449.93,591.48"];
	yu_2020_steam_self_supervised_taxonomy_expansion_with_mini_paths -> shen_2020_taxoexpan_self_supervised_taxonomy_expansion_with_position_enhanced_graph_neural_network	[pos="e,501.69,584.18 501.75,584.3 501.73,584.28 501.72,584.25 501.71,584.23"];
	yu_2020_steam_self_supervised_taxonomy_expansion_with_mini_paths -> aly_2019_every_child_should_have_parents_a_taxonomy_refinement_algorithm_based_on_hyperbolic_term_embeddings	[pos="e,412.8,541.77 412.85,541.8 412.84,541.79 412.83,541.78 412.82,541.78"];
	shen_2020_taxoexpan_self_supervised_taxonomy_expansion_with_position_enhanced_graph_neural_network -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.17,518.87 580.13,518.9 580.14,518.89 580.15,518.89 580.15,518.88"];
	shen_2020_taxoexpan_self_supervised_taxonomy_expansion_with_position_enhanced_graph_neural_network -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,458.07,613.82 458.16,613.76 458.14,613.77 458.12,613.79 458.11,613.8"];
	shen_2020_taxoexpan_self_supervised_taxonomy_expansion_with_position_enhanced_graph_neural_network -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,523.42,509.55 523.41,509.59 523.41,509.58 523.41,509.58 523.41,509.57"];
	shen_2020_taxoexpan_self_supervised_taxonomy_expansion_with_position_enhanced_graph_neural_network -> jiang_2017_metapad_meta_pattern_discovery_from_massive_text_corpora	[pos="e,476.33,662.34 476.35,662.3 476.35,662.31 476.34,662.31 476.34,662.32"];
	shen_2020_taxoexpan_self_supervised_taxonomy_expansion_with_position_enhanced_graph_neural_network -> aly_2019_every_child_should_have_parents_a_taxonomy_refinement_algorithm_based_on_hyperbolic_term_embeddings	[pos="e,412.79,541.76 412.84,541.79 412.83,541.78 412.82,541.78 412.81,541.77"];
	aly_2019_every_child_should_have_parents_a_taxonomy_refinement_algorithm_based_on_hyperbolic_term_embeddings -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,458.03,613.83 458,613.79 458.01,613.8 458.02,613.81 458.02,613.82"];
	aly_2019_every_child_should_have_parents_a_taxonomy_refinement_algorithm_based_on_hyperbolic_term_embeddings -> nickel_2017_poincare_embeddings_for_learning_hierarchical_representations	[pos="e,444.95,526.39 444.88,526.42 444.9,526.41 444.91,526.41 444.92,526.4"];
	aly_2019_every_child_should_have_parents_a_taxonomy_refinement_algorithm_based_on_hyperbolic_term_embeddings -> le_2019_inferring_concept_hierarchies_from_text_corpora_via_hyperbolic_embeddings	[pos="e,399.35,502.19 399.38,502.27 399.38,502.25 399.37,502.24 399.37,502.22"];
	silva_2022_no_pattern_no_recognition_a_survey_about_reproducibility_and_distortion_issues_of_text_clustering_and_topic_modeling	[color=green,
		height=2,
		id=silva_2022_no_pattern_no_recognition_a_survey_about_reproducibility_and_distortion_issues_of_text_clustering_and_topic_modeling,
		"k-core"=8,
		label=silva_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="4645.3872332396295,1849.426317889466!"];
	silva_2022_no_pattern_no_recognition_a_survey_about_reproducibility_and_distortion_issues_of_text_clustering_and_topic_modeling -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,578.07,511.3 577.94,510.85 577.96,510.92 577.98,511 578,511.08"];
	silva_2022_no_pattern_no_recognition_a_survey_about_reproducibility_and_distortion_issues_of_text_clustering_and_topic_modeling -> vaswani_2017_attention_is_all_you_need	[pos="e,586.99,508 586.86,507.7 586.88,507.75 586.9,507.8 586.93,507.85"];
	silva_2022_no_pattern_no_recognition_a_survey_about_reproducibility_and_distortion_issues_of_text_clustering_and_topic_modeling -> reimers_2019_sentence_bert_sentence_embeddings_using_siamese_bert_networks	[pos="e,606.19,490.51 606.09,490.41 606.11,490.43 606.13,490.45 606.15,490.47"];
	silva_2022_no_pattern_no_recognition_a_survey_about_reproducibility_and_distortion_issues_of_text_clustering_and_topic_modeling -> zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey	[pos="e,592.53,377.29 592.34,377.67 592.37,377.6 592.4,377.54 592.44,377.48"];
	silva_2022_no_pattern_no_recognition_a_survey_about_reproducibility_and_distortion_issues_of_text_clustering_and_topic_modeling -> doogan_2021_topic_model_or_topic_twaddle_re_evaluating_semantic_interpretability_measures	[pos="e,540.89,370.75 540.98,371.14 540.97,371.07 540.95,371.01 540.93,370.95"];
	silva_2022_no_pattern_no_recognition_a_survey_about_reproducibility_and_distortion_issues_of_text_clustering_and_topic_modeling -> hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence	[pos="e,582.89,372.76 582.76,373.14 582.78,373.08 582.8,373.02 582.83,372.95"];
	silva_2022_no_pattern_no_recognition_a_survey_about_reproducibility_and_distortion_issues_of_text_clustering_and_topic_modeling -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.66,389.54 577.62,389.65 577.63,389.62 577.64,389.6 577.65,389.58"];
	silva_2022_no_pattern_no_recognition_a_survey_about_reproducibility_and_distortion_issues_of_text_clustering_and_topic_modeling -> gui_2019_neural_topic_model_with_reinforcement_learning	[pos="e,535.63,372.23 535.78,372.68 535.76,372.61 535.73,372.53 535.71,372.46"];
	silva_2022_no_pattern_no_recognition_a_survey_about_reproducibility_and_distortion_issues_of_text_clustering_and_topic_modeling -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,525.27,505.94 525.51,505.47 525.47,505.55 525.43,505.63 525.39,505.71"];
	wang_2021_enquire_ones_parent_and_child_before_decision_fully_exploit_hierarchical_structure_for_self_supervised_taxonomy_expansion	[color=green,
		height=3.3889,
		id=wang_2021_enquire_ones_parent_and_child_before_decision_fully_exploit_hierarchical_structure_for_self_supervised_taxonomy_expansion,
		"k-core"=8,
		label=wang_2021,
		shape=circle,
		style=filled,
		width=3.3889,
		zazaza="4296.86367697344,2556.748079061106!"];
	wang_2021_enquire_ones_parent_and_child_before_decision_fully_exploit_hierarchical_structure_for_self_supervised_taxonomy_expansion -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.18,518.87 580.15,518.91 580.15,518.9 580.16,518.89 580.16,518.88"];
	wang_2021_enquire_ones_parent_and_child_before_decision_fully_exploit_hierarchical_structure_for_self_supervised_taxonomy_expansion -> vaswani_2017_attention_is_all_you_need	[pos="e,587.97,510.33 587.94,510.38 587.95,510.37 587.95,510.36 587.96,510.35"];
	wang_2021_enquire_ones_parent_and_child_before_decision_fully_exploit_hierarchical_structure_for_self_supervised_taxonomy_expansion -> liu_2020_giant_scalable_creation_of_a_web_scale_ontology	[pos="e,560.52,619.1 560.45,619.04 560.46,619.06 560.48,619.07 560.49,619.08"];
	wang_2021_enquire_ones_parent_and_child_before_decision_fully_exploit_hierarchical_structure_for_self_supervised_taxonomy_expansion -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,458.05,613.84 458.09,613.83 458.08,613.83 458.07,613.83 458.07,613.84"];
	wang_2021_enquire_ones_parent_and_child_before_decision_fully_exploit_hierarchical_structure_for_self_supervised_taxonomy_expansion -> le_2019_inferring_concept_hierarchies_from_text_corpora_via_hyperbolic_embeddings	[pos="e,426.47,520.81 426.85,521.07 426.78,521.02 426.72,520.98 426.66,520.94"];
	wang_2021_enquire_ones_parent_and_child_before_decision_fully_exploit_hierarchical_structure_for_self_supervised_taxonomy_expansion -> jiang_2017_metapad_meta_pattern_discovery_from_massive_text_corpora	[pos="e,476.34,662.34 476.37,662.3 476.36,662.31 476.36,662.32 476.35,662.32"];
	wang_2021_enquire_ones_parent_and_child_before_decision_fully_exploit_hierarchical_structure_for_self_supervised_taxonomy_expansion -> manzoor_2020_expanding_taxonomies_with_implicit_edge_semantics	[pos="e,449.85,591.46 449.89,591.46 449.88,591.46 449.87,591.46 449.86,591.46"];
	wang_2021_enquire_ones_parent_and_child_before_decision_fully_exploit_hierarchical_structure_for_self_supervised_taxonomy_expansion -> yu_2020_steam_self_supervised_taxonomy_expansion_with_mini_paths	[pos="e,508.44,598.95 508.48,598.94 508.47,598.94 508.46,598.94 508.46,598.95"];
	wang_2021_enquire_ones_parent_and_child_before_decision_fully_exploit_hierarchical_structure_for_self_supervised_taxonomy_expansion -> shen_2020_taxoexpan_self_supervised_taxonomy_expansion_with_position_enhanced_graph_neural_network	[pos="e,501.69,584.14 501.74,584.15 501.73,584.15 501.72,584.15 501.71,584.15"];
	shang_2020_nettaxo_automated_topic_taxonomy_construction_from_text_rich_network	[color=green,
		height=7.6667,
		id=shang_2020_nettaxo_automated_topic_taxonomy_construction_from_text_rich_network,
		"k-core"=8,
		label=shang_2020,
		shape=circle,
		style=filled,
		width=7.6667,
		zazaza="-2983.4478882826356,-4012.360568589024!"];
	wang_2021_enquire_ones_parent_and_child_before_decision_fully_exploit_hierarchical_structure_for_self_supervised_taxonomy_expansion -> shang_2020_nettaxo_automated_topic_taxonomy_construction_from_text_rich_network	[pos="e,451.11,638.11 451.16,638.09 451.15,638.09 451.14,638.1 451.13,638.1"];
	shang_2020_nettaxo_automated_topic_taxonomy_construction_from_text_rich_network -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,458.03,613.86 458.02,613.91 458.02,613.9 458.02,613.89 458.03,613.88"];
	shang_2020_nettaxo_automated_topic_taxonomy_construction_from_text_rich_network -> shang_2017_automated_phrase_mining_from_massive_text_corpora	[pos="e,437.58,555.15 437.58,555.19 437.58,555.18 437.58,555.17 437.58,555.17"];
	shang_2020_nettaxo_automated_topic_taxonomy_construction_from_text_rich_network -> jiang_2017_metapad_meta_pattern_discovery_from_massive_text_corpora	[pos="e,476.31,662.34 476.26,662.28 476.27,662.3 476.28,662.31 476.29,662.31"];
	zhu_2021_self_supervised_euphemism_detection_and_identification_for_content_moderation	[color=green,
		height=2,
		id=zhu_2021_self_supervised_euphemism_detection_and_identification_for_content_moderation,
		"k-core"=8,
		label=zhu_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="3940.5936030694643,3077.616081054639!"];
	zhu_2021_self_supervised_euphemism_detection_and_identification_for_content_moderation -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,573.41,530.49 573.21,530.82 573.25,530.76 573.28,530.71 573.31,530.65"];
	zhu_2021_self_supervised_euphemism_detection_and_identification_for_content_moderation -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,593.44,548 593.18,548.21 593.22,548.18 593.27,548.14 593.31,548.11"];
	zhu_2021_self_supervised_euphemism_detection_and_identification_for_content_moderation -> huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring	[pos="e,503.2,557.01 503.27,557.08 503.26,557.07 503.24,557.05 503.23,557.04"];
	zhu_2021_self_supervised_euphemism_detection_and_identification_for_content_moderation -> huang_2020_guiding_corpus_based_set_expansion_by_auxiliary_sets_generation_and_co_expansion	[pos="e,557.82,596.77 557.78,596.77 557.79,596.77 557.8,596.77 557.8,596.77"];
	zhu_2021_self_supervised_euphemism_detection_and_identification_for_content_moderation -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,525.34,521.56 525.4,521.9 525.39,521.85 525.38,521.79 525.37,521.73"];
	zhu_2021_self_supervised_euphemism_detection_and_identification_for_content_moderation -> mao_2020_octet_online_catalog_taxonomy_enrichment_with_self_supervision	[pos="e,464.37,594.63 464.67,594.63 464.62,594.63 464.57,594.63 464.52,594.63"];
	zhu_2021_self_supervised_euphemism_detection_and_identification_for_content_moderation -> yang_2020_co_embedding_network_nodes_and_hierarchical_labels_with_taxonomy_based_generative_adversarial_networks	[pos="e,466.73,612.66 467.01,612.58 466.96,612.59 466.91,612.61 466.87,612.62"];
	zhu_2021_self_supervised_euphemism_detection_and_identification_for_content_moderation -> shen_2020_taxoexpan_self_supervised_taxonomy_expansion_with_position_enhanced_graph_neural_network	[pos="e,501.7,584.14 501.77,584.16 501.75,584.16 501.74,584.15 501.73,584.15"];
	zhu_2021_self_supervised_euphemism_detection_and_identification_for_content_moderation -> shang_2020_nettaxo_automated_topic_taxonomy_construction_from_text_rich_network	[pos="e,472.44,626.97 472.73,626.82 472.68,626.85 472.63,626.87 472.58,626.9"];
	chen_2021_hierarchical_neural_topic_modeling_with_manifold_regularization	[color=yellow,
		height=2,
		id=chen_2021_hierarchical_neural_topic_modeling_with_manifold_regularization,
		"k-core"=6,
		label=chen_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="0.7682947522557269,0.6400962442336825!"];
	chen_2021_hierarchical_neural_topic_modeling_with_manifold_regularization -> merity_2016_pointer_sentinel_mixture_models	[pos="e,654.08,380.12 654.07,379.8 654.07,379.85 654.08,379.91 654.08,379.96"];
	chen_2021_hierarchical_neural_topic_modeling_with_manifold_regularization -> burkhardt_2019_decoupling_sparsity_and_smoothness_in_the_dirichlet_variational_autoencoder_topic_model	[pos="e,642.09,333.8 642.12,333.74 642.11,333.75 642.11,333.76 642.1,333.77"];
	chen_2021_hierarchical_neural_topic_modeling_with_manifold_regularization -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,623.29,372.35 623.3,372.32 623.3,372.33 623.3,372.33 623.29,372.34"];
	chen_2021_hierarchical_neural_topic_modeling_with_manifold_regularization -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,603.73,361.21 604.07,360.85 604.01,360.91 603.96,360.97 603.9,361.03"];
	chen_2021_hierarchical_neural_topic_modeling_with_manifold_regularization -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,630.67,360.67 630.71,360.56 630.7,360.59 630.69,360.61 630.69,360.63"];
	chen_2021_hierarchical_neural_topic_modeling_with_manifold_regularization -> wu_2020_neural_mixed_counting_models_for_dispersed_topic_discovery	[pos="e,662.68,336.78 662.66,336.72 662.66,336.73 662.67,336.75 662.67,336.76"];
	shi_2021_a_simple_and_effective_self_supervised_contrastive_learning_framework_for_aspect_detection	[color=blue,
		height=2,
		id=shi_2021_a_simple_and_effective_self_supervised_contrastive_learning_framework_for_aspect_detection,
		"k-core"=7,
		label=shi_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="5981.639390550907,5312.24915944925!"];
	shi_2021_a_simple_and_effective_self_supervised_contrastive_learning_framework_for_aspect_detection -> angelidis_2018_summarizing_opinions_aspect_extraction_meets_sentiment_prediction_and_they_are_both_weakly_supervised	[pos="e,465.83,437.69 466.11,437.73 466.06,437.72 466.02,437.72 465.97,437.71"];
	shi_2021_a_simple_and_effective_self_supervised_contrastive_learning_framework_for_aspect_detection -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,574.65,509.41 574.49,509.13 574.52,509.18 574.54,509.23 574.57,509.27"];
	shi_2021_a_simple_and_effective_self_supervised_contrastive_learning_framework_for_aspect_detection -> vaswani_2017_attention_is_all_you_need	[pos="e,582.93,503.91 582.63,503.52 582.68,503.59 582.73,503.65 582.78,503.71"];
	shi_2021_a_simple_and_effective_self_supervised_contrastive_learning_framework_for_aspect_detection -> he_2017_an_unsupervised_neural_attention_model_for_aspect_extraction	[pos="e,471.08,424.45 471.11,424.46 471.1,424.46 471.1,424.46 471.09,424.46"];
	shi_2021_a_simple_and_effective_self_supervised_contrastive_learning_framework_for_aspect_detection -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.65,389.54 577.56,389.66 577.58,389.64 577.6,389.61 577.61,389.59"];
	shi_2021_a_simple_and_effective_self_supervised_contrastive_learning_framework_for_aspect_detection -> pablos_2018_w2vlda_almost_unsupervised_system_for_aspect_based_sentiment_analysis	[pos="e,465.5,444.49 465.8,444.5 465.75,444.5 465.7,444.5 465.65,444.49"];
	shi_2021_a_simple_and_effective_self_supervised_contrastive_learning_framework_for_aspect_detection -> tulkens_2020_embarrassingly_simple_unsupervised_aspect_extraction	[pos="e,465.46,445.19 465.78,445.2 465.73,445.2 465.67,445.2 465.62,445.2"];
	shi_2021_a_simple_and_effective_self_supervised_contrastive_learning_framework_for_aspect_detection -> chen_2020_a_simple_framework_for_contrastive_learning_of_visual_representations	[pos="e,610.61,446.85 610.32,446.85 610.37,446.85 610.42,446.85 610.46,446.85"];
	dieng_2019_the_dynamic_embedded_topic_model	[color=blue,
		height=5.5833,
		id=dieng_2019_the_dynamic_embedded_topic_model,
		"k-core"=7,
		label=dieng_2019,
		shape=circle,
		style=filled,
		width=5.5833,
		zazaza="5634.483820483347,5679.136727908331!"];
	dieng_2019_the_dynamic_embedded_topic_model -> card_2017_neural_models_for_documents_with_metadata	[pos="e,615.34,384.94 615.3,384.91 615.31,384.91 615.32,384.92 615.32,384.93"];
	dieng_2019_the_dynamic_embedded_topic_model -> card_2018_neural_models_for_documents_with_metadata	[pos="e,608.06,386.81 608.02,386.77 608.03,386.78 608.04,386.79 608.04,386.79"];
	dieng_2019_the_dynamic_embedded_topic_model -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,553.82,414.39 553.8,414.34 553.81,414.35 553.81,414.36 553.81,414.37"];
	dieng_2019_the_dynamic_embedded_topic_model -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.67,389.49 577.64,389.45 577.65,389.46 577.65,389.47 577.66,389.47"];
	dieng_2019_the_dynamic_embedded_topic_model -> zhao_2017_metalda_a_topic_model_that_efficiently_incorporates_meta_information	[pos="e,485.98,332.69 486.06,332.66 486.04,332.67 486.03,332.67 486.01,332.68"];
	dieng_2019_the_dynamic_embedded_topic_model -> zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling	[pos="e,538.81,376.14 538.79,376.03 538.79,376.05 538.8,376.08 538.8,376.1"];
	dieng_2019_the_dynamic_embedded_topic_model -> cong_2017_deep_latent_dirichlet_allocation_with_topic_layer_adaptive_stochastic_gradient_riemannian_mcmc	[pos="e,483.91,363.81 484,363.73 483.99,363.75 483.97,363.76 483.95,363.78"];
	wang_2019_open_event_extraction_from_online_text_using_a_generative_adversarial_network -> gulrajani_2017_improved_training_of_wasserstein_gans	[pos="e,705.86,392.19 705.9,392.3 705.9,392.28 705.89,392.26 705.88,392.24"];
	gururangan_2019_variational_pretraining_for_semi_supervised_text_classification -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.19,518.84 580.19,518.8 580.19,518.81 580.19,518.82 580.19,518.83"];
	gururangan_2019_variational_pretraining_for_semi_supervised_text_classification -> card_2017_neural_models_for_documents_with_metadata	[pos="e,615.35,384.96 615.34,385 615.34,384.99 615.34,384.98 615.35,384.98"];
	gururangan_2019_variational_pretraining_for_semi_supervised_text_classification -> card_2018_neural_models_for_documents_with_metadata	[pos="e,608.07,386.83 608.06,386.87 608.06,386.86 608.07,386.85 608.07,386.85"];
	gururangan_2019_variational_pretraining_for_semi_supervised_text_classification -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.68,389.51 577.68,389.54 577.68,389.54 577.68,389.53 577.68,389.53"];
	gururangan_2019_variational_pretraining_for_semi_supervised_text_classification -> ding_2018_coherence_aware_neural_topic_modeling	[pos="e,661.34,368.2 661.3,368.24 661.31,368.23 661.31,368.23 661.32,368.22"];
	gururangan_2019_variational_pretraining_for_semi_supervised_text_classification -> yang_2017_improved_variational_autoencoders_for_text_modeling_using_dilated_convolutions	[pos="e,519,331.22 519.03,331.29 519.02,331.27 519.02,331.26 519.01,331.25"];
	gururangan_2019_variational_pretraining_for_semi_supervised_text_classification -> peters_2018_deep_contextualized_word_representations	[pos="e,583.76,529.87 583.76,529.83 583.76,529.84 583.76,529.85 583.76,529.85"];
	goldberg_2020_text_mining_approaches_for_postmarket_food_safety_surveillance_using_online_media	[color=yellow,
		height=4.1944,
		id=goldberg_2020_text_mining_approaches_for_postmarket_food_safety_surveillance_using_online_media,
		"k-core"=6,
		label=goldberg_2020,
		shape=circle,
		style=filled,
		width=4.1944,
		zazaza="0.6581085333311733,0.7529230681241055!"];
	zaman_2020_facebook_hospital_reviews_automated_service_quality_detection_and_relationships_with_patient_satisfaction	[color=yellow,
		height=4.7778,
		id=zaman_2020_facebook_hospital_reviews_automated_service_quality_detection_and_relationships_with_patient_satisfaction,
		"k-core"=6,
		label=zaman_2020,
		shape=circle,
		style=filled,
		width=4.7778,
		zazaza="0.5839470635905537,0.8117917145904242!"];
	goldberg_2020_text_mining_approaches_for_postmarket_food_safety_surveillance_using_online_media -> zaman_2020_facebook_hospital_reviews_automated_service_quality_detection_and_relationships_with_patient_satisfaction	[pos="e,618.65,702.28 618.72,702.26 618.71,702.26 618.69,702.27 618.68,702.27"];
	mummalaneni_2018_social_media_analytics_for_quality_surveillance_and_safety_hazard_detection_in_baby_cribs	[color=yellow,
		height=5.8889,
		id=mummalaneni_2018_social_media_analytics_for_quality_surveillance_and_safety_hazard_detection_in_baby_cribs,
		"k-core"=6,
		label=mummalaneni_2018,
		shape=circle,
		style=filled,
		width=5.8889,
		zazaza="-0.1337862282867135,0.9910101851676346!"];
	goldberg_2020_text_mining_approaches_for_postmarket_food_safety_surveillance_using_online_media -> mummalaneni_2018_social_media_analytics_for_quality_surveillance_and_safety_hazard_detection_in_baby_cribs	[pos="e,591.8,706.77 591.92,706.74 591.89,706.75 591.87,706.75 591.85,706.76"];
	law_2017_automated_defect_discovery_for_dishwasher_appliances_from_online_consumer_reviews	[color=yellow,
		height=6.7917,
		id=law_2017_automated_defect_discovery_for_dishwasher_appliances_from_online_consumer_reviews,
		"k-core"=6,
		label=law_2017,
		shape=circle,
		style=filled,
		width=6.7917,
		zazaza="-0.007893465592952181,-0.999968825404301!"];
	goldberg_2020_text_mining_approaches_for_postmarket_food_safety_surveillance_using_online_media -> law_2017_automated_defect_discovery_for_dishwasher_appliances_from_online_consumer_reviews	[pos="e,629.26,700.02 629.31,700.01 629.3,700.01 629.29,700.01 629.28,700.01"];
	goldberg_2018_a_tabu_search_heuristic_for_smoke_term_curation_in_safety_defect_discovery	[color=yellow,
		height=5.5833,
		id=goldberg_2018_a_tabu_search_heuristic_for_smoke_term_curation_in_safety_defect_discovery,
		"k-core"=6,
		label=goldberg_2018,
		shape=circle,
		style=filled,
		width=5.5833,
		zazaza="0.08671871068737955,-0.9962328062796408!"];
	goldberg_2020_text_mining_approaches_for_postmarket_food_safety_surveillance_using_online_media -> goldberg_2018_a_tabu_search_heuristic_for_smoke_term_curation_in_safety_defect_discovery	[pos="e,700.74,661.87 700.63,661.94 700.66,661.92 700.68,661.91 700.7,661.9"];
	zaman_2020_facebook_hospital_reviews_automated_service_quality_detection_and_relationships_with_patient_satisfaction -> mummalaneni_2018_social_media_analytics_for_quality_surveillance_and_safety_hazard_detection_in_baby_cribs	[pos="e,591.78,706.78 591.83,706.77 591.82,706.77 591.81,706.77 591.8,706.77"];
	zaman_2020_facebook_hospital_reviews_automated_service_quality_detection_and_relationships_with_patient_satisfaction -> goldberg_2018_a_tabu_search_heuristic_for_smoke_term_curation_in_safety_defect_discovery	[pos="e,700.77,661.85 700.72,661.88 700.73,661.87 700.74,661.87 700.75,661.86"];
	mummalaneni_2018_social_media_analytics_for_quality_surveillance_and_safety_hazard_detection_in_baby_cribs -> law_2017_automated_defect_discovery_for_dishwasher_appliances_from_online_consumer_reviews	[pos="e,629.22,700.03 629.14,700.04 629.16,700.04 629.17,700.04 629.19,700.03"];
	goldberg_2018_a_tabu_search_heuristic_for_smoke_term_curation_in_safety_defect_discovery -> law_2017_automated_defect_discovery_for_dishwasher_appliances_from_online_consumer_reviews	[pos="e,629.26,700.02 629.3,700 629.29,700 629.28,700 629.28,700.01"];
	chiu_2022_a_joint_learning_approach_for_semi_supervised_neural_topic_modeling	[color=yellow,
		height=2,
		id=chiu_2022_a_joint_learning_approach_for_semi_supervised_neural_topic_modeling,
		"k-core"=6,
		label=chiu_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="0.5315545809712767,0.8470240200241609!"];
	chiu_2022_a_joint_learning_approach_for_semi_supervised_neural_topic_modeling -> doogan_2021_topic_model_or_topic_twaddle_re_evaluating_semantic_interpretability_measures	[pos="e,524.92,306.51 524.96,306.51 524.95,306.51 524.94,306.51 524.94,306.51"];
	chiu_2022_a_joint_learning_approach_for_semi_supervised_neural_topic_modeling -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,566.17,373 566.25,372.73 566.24,372.78 566.23,372.82 566.21,372.87"];
	chiu_2022_a_joint_learning_approach_for_semi_supervised_neural_topic_modeling -> hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence	[pos="e,593.05,344.28 593.04,344.19 593.04,344.21 593.04,344.22 593.05,344.24"];
	chiu_2022_a_joint_learning_approach_for_semi_supervised_neural_topic_modeling -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,620.82,367.69 620.67,367.4 620.69,367.45 620.72,367.5 620.74,367.55"];
	chiu_2022_a_joint_learning_approach_for_semi_supervised_neural_topic_modeling -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,579.17,375.67 579.21,375.27 579.2,375.34 579.19,375.4 579.19,375.47"];
	chiu_2022_a_joint_learning_approach_for_semi_supervised_neural_topic_modeling -> dieng_2019_the_dynamic_embedded_topic_model	[pos="e,525.92,322.31 525.96,322.3 525.95,322.3 525.94,322.3 525.94,322.3"];
	maheshwari_2022_dynamictoc_persona_based_table_of_contents_for_consumption_of_long_documents	[color=yellow,
		height=2,
		id=maheshwari_2022_dynamictoc_persona_based_table_of_contents_for_consumption_of_long_documents,
		"k-core"=6,
		label=maheshwari_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="0.5045503390991958,0.8633822763210097!"];
	maheshwari_2022_dynamictoc_persona_based_table_of_contents_for_consumption_of_long_documents -> see_2017_get_to_the_point_summarization_with_pointer_generator_networks	[pos="e,532.36,404.03 532.28,404.07 532.3,404.06 532.31,404.05 532.33,404.04"];
	maheshwari_2022_dynamictoc_persona_based_table_of_contents_for_consumption_of_long_documents -> he_2017_an_unsupervised_neural_attention_model_for_aspect_extraction	[pos="e,471.08,424.44 471.13,424.44 471.12,424.44 471.11,424.44 471.1,424.44"];
	maheshwari_2022_dynamictoc_persona_based_table_of_contents_for_consumption_of_long_documents -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,563.42,395.09 563.02,395.25 563.09,395.22 563.15,395.19 563.22,395.17"];
	maheshwari_2022_dynamictoc_persona_based_table_of_contents_for_consumption_of_long_documents -> lewis_2019_bart_denoising_sequence_to_sequence_pre_training_for_natural_language_generation_translation_and_comprehension	[pos="e,541.78,477.97 541.49,477.61 541.54,477.67 541.59,477.73 541.63,477.79"];
	maheshwari_2022_dynamictoc_persona_based_table_of_contents_for_consumption_of_long_documents -> shang_2017_automated_phrase_mining_from_massive_text_corpora	[pos="e,466.62,488.39 466.79,488 466.77,488.06 466.74,488.13 466.71,488.19"];
	maheshwari_2022_dynamictoc_persona_based_table_of_contents_for_consumption_of_long_documents -> pablos_2018_w2vlda_almost_unsupervised_system_for_aspect_based_sentiment_analysis	[pos="e,425.39,440.81 425.87,440.68 425.79,440.71 425.71,440.73 425.63,440.75"];
	lee_2022_taxocom_topic_taxonomy_completion_with_hierarchical_discovery_of_novel_topic_clusters	[color=green,
		height=2,
		id=lee_2022_taxocom_topic_taxonomy_completion_with_hierarchical_discovery_of_novel_topic_clusters,
		"k-core"=8,
		label=lee_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="2385.215617167527,4394.399505771092!"];
	lee_2022_taxocom_topic_taxonomy_completion_with_hierarchical_discovery_of_novel_topic_clusters -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,458.03,613.8 458.02,613.68 458.03,613.71 458.03,613.73 458.03,613.75"];
	lee_2022_taxocom_topic_taxonomy_completion_with_hierarchical_discovery_of_novel_topic_clusters -> shang_2017_automated_phrase_mining_from_massive_text_corpora	[pos="e,437.62,555.14 437.75,555.15 437.72,555.15 437.69,555.15 437.67,555.14"];
	lee_2022_taxocom_topic_taxonomy_completion_with_hierarchical_discovery_of_novel_topic_clusters -> meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding	[pos="e,476.09,507.82 476.04,507.93 476.05,507.91 476.06,507.89 476.06,507.87"];
	lee_2022_taxocom_topic_taxonomy_completion_with_hierarchical_discovery_of_novel_topic_clusters -> meng_2019_spherical_text_embedding	[pos="e,499.98,530.13 499.88,530.19 499.9,530.18 499.92,530.16 499.94,530.15"];
	lee_2022_taxocom_topic_taxonomy_completion_with_hierarchical_discovery_of_novel_topic_clusters -> meng_2018_weakly_supervised_neural_text_classification	[pos="e,474.34,580.67 474.29,580.62 474.3,580.64 474.31,580.65 474.32,580.65"];
	lee_2022_taxocom_topic_taxonomy_completion_with_hierarchical_discovery_of_novel_topic_clusters -> meng_2018_weakly_supervised_hierarchical_text_classification	[pos="e,466.35,568.63 466.24,568.54 466.26,568.56 466.28,568.58 466.3,568.59"];
	lee_2022_taxocom_topic_taxonomy_completion_with_hierarchical_discovery_of_novel_topic_clusters -> meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding	[pos="e,511.56,523.28 511.44,523.35 511.47,523.34 511.49,523.32 511.51,523.31"];
	lee_2022_taxocom_topic_taxonomy_completion_with_hierarchical_discovery_of_novel_topic_clusters -> huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring	[pos="e,503.14,556.98 503.03,556.98 503.05,556.98 503.08,556.98 503.09,556.98"];
	lee_2022_taxocom_topic_taxonomy_completion_with_hierarchical_discovery_of_novel_topic_clusters -> ganea_2018_hyperbolic_entailment_cones_for_learning_hierarchical_embeddings	[pos="e,421.43,508.91 421.49,509.01 421.48,508.99 421.47,508.97 421.46,508.95"];
	lee_2022_taxocom_topic_taxonomy_completion_with_hierarchical_discovery_of_novel_topic_clusters -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,513.34,516.34 513.05,516.54 513.1,516.51 513.15,516.48 513.19,516.44"];
	lee_2022_taxocom_topic_taxonomy_completion_with_hierarchical_discovery_of_novel_topic_clusters -> mao_2020_octet_online_catalog_taxonomy_enrichment_with_self_supervision	[pos="e,442.27,595 442.3,594.92 442.29,594.93 442.29,594.95 442.28,594.96"];
	lee_2022_taxocom_topic_taxonomy_completion_with_hierarchical_discovery_of_novel_topic_clusters -> yu_2020_steam_self_supervised_taxonomy_expansion_with_mini_paths	[pos="e,508.39,598.93 508.27,598.84 508.29,598.86 508.32,598.88 508.34,598.89"];
	lee_2022_taxocom_topic_taxonomy_completion_with_hierarchical_discovery_of_novel_topic_clusters -> shen_2020_taxoexpan_self_supervised_taxonomy_expansion_with_position_enhanced_graph_neural_network	[pos="e,501.63,584.12 501.53,584.06 501.55,584.07 501.57,584.08 501.59,584.09"];
	lee_2022_taxocom_topic_taxonomy_completion_with_hierarchical_discovery_of_novel_topic_clusters -> shang_2020_nettaxo_automated_topic_taxonomy_construction_from_text_rich_network	[pos="e,451.3,629.94 451.31,629.44 451.31,629.52 451.31,629.61 451.31,629.69"];
	lee_2021_out_of_category_document_identification_using_target_category_names_as_weak_supervision	[color=blue,
		height=2,
		id=lee_2021_out_of_category_document_identification_using_target_category_names_as_weak_supervision,
		"k-core"=7,
		label=lee_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="2182.1575318358464,7696.634738940512!"];
	lee_2022_taxocom_topic_taxonomy_completion_with_hierarchical_discovery_of_novel_topic_clusters -> lee_2021_out_of_category_document_identification_using_target_category_names_as_weak_supervision	[pos="e,398.56,529.97 398.67,530.03 398.65,530.02 398.63,530.01 398.61,530"];
	zeng_2021_enhancing_taxonomy_completion_with_concept_generation_via_fusing_relational_representations	[color=green,
		height=5.2222,
		id=zeng_2021_enhancing_taxonomy_completion_with_concept_generation_via_fusing_relational_representations,
		"k-core"=8,
		label=zeng_2021,
		shape=circle,
		style=filled,
		width=5.2222,
		zazaza="-1590.0577430824287,4740.434270101254!"];
	lee_2022_taxocom_topic_taxonomy_completion_with_hierarchical_discovery_of_novel_topic_clusters -> zeng_2021_enhancing_taxonomy_completion_with_concept_generation_via_fusing_relational_representations	[pos="e,515.96,593.42 515.7,593.27 515.75,593.29 515.79,593.32 515.83,593.34"];
	huang_2020_weakly_supervised_aspect_based_sentiment_analysis_via_joint_aspect_sentiment_topic_embedding	[color=green,
		height=6.3889,
		id=huang_2020_weakly_supervised_aspect_based_sentiment_analysis_via_joint_aspect_sentiment_topic_embedding,
		"k-core"=8,
		label=huang_2020,
		shape=circle,
		style=filled,
		width=6.3889,
		zazaza="-4821.012292211478,-1325.8351414245808!"];
	lee_2022_taxocom_topic_taxonomy_completion_with_hierarchical_discovery_of_novel_topic_clusters -> huang_2020_weakly_supervised_aspect_based_sentiment_analysis_via_joint_aspect_sentiment_topic_embedding	[pos="e,480.37,502.73 480.31,502.85 480.32,502.83 480.34,502.8 480.35,502.78"];
	meng_2020_text_classification_using_label_names_only_a_language_model_self_training_approach	[color=green,
		height=6.6111,
		id=meng_2020_text_classification_using_label_names_only_a_language_model_self_training_approach,
		"k-core"=8,
		label=meng_2020,
		shape=circle,
		style=filled,
		width=6.6111,
		zazaza="276.12942586490544,-4992.369406563177!"];
	lee_2022_taxocom_topic_taxonomy_completion_with_hierarchical_discovery_of_novel_topic_clusters -> meng_2020_text_classification_using_label_names_only_a_language_model_self_training_approach	[pos="e,525.34,548.46 524.83,548.52 524.92,548.51 525,548.5 525.09,548.49"];
	shen_2021_taxoclass_hierarchical_multi_label_text_classification_using_only_class_names	[color=green,
		height=5.5833,
		id=shen_2021_taxoclass_hierarchical_multi_label_text_classification_using_only_class_names,
		"k-core"=8,
		label=shen_2021,
		shape=circle,
		style=filled,
		width=5.5833,
		zazaza="1664.6936623871588,-4714.742296814719!"];
	lee_2022_taxocom_topic_taxonomy_completion_with_hierarchical_discovery_of_novel_topic_clusters -> shen_2021_taxoclass_hierarchical_multi_label_text_classification_using_only_class_names	[pos="e,523.65,574.5 523.26,574.41 523.32,574.42 523.39,574.44 523.45,574.46"];
	lee_2021_out_of_category_document_identification_using_target_category_names_as_weak_supervision -> shang_2017_automated_phrase_mining_from_massive_text_corpora	[pos="e,437.54,555.11 437.46,555.06 437.48,555.07 437.5,555.08 437.51,555.09"];
	lee_2021_out_of_category_document_identification_using_target_category_names_as_weak_supervision -> meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding	[pos="e,468.55,509.95 468.09,510.08 468.17,510.05 468.25,510.03 468.32,510.01"];
	lee_2021_out_of_category_document_identification_using_target_category_names_as_weak_supervision -> meng_2019_spherical_text_embedding	[pos="e,471.31,530.07 470.93,530.07 470.99,530.07 471.06,530.07 471.12,530.07"];
	lee_2021_out_of_category_document_identification_using_target_category_names_as_weak_supervision -> meng_2018_weakly_supervised_neural_text_classification	[pos="e,459.07,570.47 458.64,570.18 458.71,570.23 458.78,570.27 458.86,570.32"];
	lee_2021_out_of_category_document_identification_using_target_category_names_as_weak_supervision -> ganea_2018_hyperbolic_entailment_cones_for_learning_hierarchical_embeddings	[pos="e,421.39,508.89 421.34,508.93 421.35,508.92 421.36,508.91 421.37,508.91"];
	lee_2021_out_of_category_document_identification_using_target_category_names_as_weak_supervision -> huang_2020_weakly_supervised_aspect_based_sentiment_analysis_via_joint_aspect_sentiment_topic_embedding	[pos="e,467.6,506.95 467.24,507.07 467.3,507.05 467.36,507.03 467.42,507.01"];
	zeng_2021_enhancing_taxonomy_completion_with_concept_generation_via_fusing_relational_representations -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.18,518.87 580.15,518.92 580.16,518.91 580.16,518.9 580.17,518.89"];
	zeng_2021_enhancing_taxonomy_completion_with_concept_generation_via_fusing_relational_representations -> vaswani_2017_attention_is_all_you_need	[pos="e,587.97,510.34 587.94,510.39 587.95,510.38 587.96,510.37 587.96,510.36"];
	zeng_2021_enhancing_taxonomy_completion_with_concept_generation_via_fusing_relational_representations -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,458.05,613.84 458.09,613.84 458.08,613.84 458.08,613.84 458.07,613.84"];
	zeng_2021_enhancing_taxonomy_completion_with_concept_generation_via_fusing_relational_representations -> manzoor_2020_expanding_taxonomies_with_implicit_edge_semantics	[pos="e,449.85,591.47 449.89,591.47 449.88,591.47 449.87,591.47 449.87,591.47"];
	zeng_2021_enhancing_taxonomy_completion_with_concept_generation_via_fusing_relational_representations -> yu_2020_steam_self_supervised_taxonomy_expansion_with_mini_paths	[pos="e,508.45,598.96 508.5,598.98 508.49,598.97 508.48,598.97 508.47,598.97"];
	zeng_2021_enhancing_taxonomy_completion_with_concept_generation_via_fusing_relational_representations -> shen_2020_taxoexpan_self_supervised_taxonomy_expansion_with_position_enhanced_graph_neural_network	[pos="e,501.69,584.15 501.76,584.19 501.75,584.18 501.73,584.18 501.72,584.17"];
	zeng_2021_enhancing_taxonomy_completion_with_concept_generation_via_fusing_relational_representations -> aly_2019_every_child_should_have_parents_a_taxonomy_refinement_algorithm_based_on_hyperbolic_term_embeddings	[pos="e,412.8,541.77 412.87,541.8 412.85,541.79 412.84,541.79 412.83,541.78"];
	zeng_2021_enhancing_taxonomy_completion_with_concept_generation_via_fusing_relational_representations -> wang_2021_enquire_ones_parent_and_child_before_decision_fully_exploit_hierarchical_structure_for_self_supervised_taxonomy_expansion	[pos="e,527.57,590.33 527.62,590.45 527.61,590.42 527.6,590.4 527.59,590.38"];
	zeng_2021_enhancing_taxonomy_completion_with_concept_generation_via_fusing_relational_representations -> shang_2020_nettaxo_automated_topic_taxonomy_construction_from_text_rich_network	[pos="e,451.12,638.12 451.16,638.1 451.15,638.1 451.14,638.11 451.13,638.11"];
	huang_2020_weakly_supervised_aspect_based_sentiment_analysis_via_joint_aspect_sentiment_topic_embedding -> angelidis_2018_summarizing_opinions_aspect_extraction_meets_sentiment_prediction_and_they_are_both_weakly_supervised	[pos="e,421.38,432.1 421.41,432.14 421.41,432.13 421.4,432.12 421.4,432.11"];
	huang_2020_weakly_supervised_aspect_based_sentiment_analysis_via_joint_aspect_sentiment_topic_embedding -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.17,518.85 580.11,518.84 580.13,518.84 580.14,518.85 580.14,518.85"];
	huang_2020_weakly_supervised_aspect_based_sentiment_analysis_via_joint_aspect_sentiment_topic_embedding -> he_2017_an_unsupervised_neural_attention_model_for_aspect_extraction	[pos="e,471.07,424.46 471.07,424.5 471.07,424.49 471.07,424.49 471.07,424.48"];
	huang_2020_weakly_supervised_aspect_based_sentiment_analysis_via_joint_aspect_sentiment_topic_embedding -> xu_2018_double_embeddings_and_cnn_based_sequence_labeling_for_aspect_extraction	[pos="e,422.11,469.77 422.23,469.85 422.21,469.83 422.18,469.82 422.16,469.8"];
	huang_2020_weakly_supervised_aspect_based_sentiment_analysis_via_joint_aspect_sentiment_topic_embedding -> shang_2017_automated_phrase_mining_from_massive_text_corpora	[pos="e,437.6,555.09 437.7,554.98 437.68,555.01 437.66,555.03 437.64,555.05"];
	huang_2020_weakly_supervised_aspect_based_sentiment_analysis_via_joint_aspect_sentiment_topic_embedding -> pablos_2018_w2vlda_almost_unsupervised_system_for_aspect_based_sentiment_analysis	[pos="e,417.51,442.98 417.55,443.01 417.54,443 417.53,443 417.53,442.99"];
	huang_2020_weakly_supervised_aspect_based_sentiment_analysis_via_joint_aspect_sentiment_topic_embedding -> meng_2019_spherical_text_embedding	[pos="e,500,530.09 499.96,530.03 499.97,530.05 499.97,530.06 499.98,530.07"];
	huang_2020_weakly_supervised_aspect_based_sentiment_analysis_via_joint_aspect_sentiment_topic_embedding -> meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding	[pos="e,511.58,523.24 511.52,523.2 511.53,523.21 511.54,523.22 511.56,523.22"];
	huang_2020_weakly_supervised_aspect_based_sentiment_analysis_via_joint_aspect_sentiment_topic_embedding -> huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring	[pos="e,503.16,556.94 503.11,556.82 503.12,556.85 503.13,556.87 503.14,556.89"];
	huang_2020_weakly_supervised_aspect_based_sentiment_analysis_via_joint_aspect_sentiment_topic_embedding -> tulkens_2020_embarrassingly_simple_unsupervised_aspect_extraction	[pos="e,442.11,444.72 442.19,444.85 442.18,444.82 442.16,444.79 442.15,444.77"];
	huang_2020_weakly_supervised_aspect_based_sentiment_analysis_via_joint_aspect_sentiment_topic_embedding -> meng_2020_text_classification_using_label_names_only_a_language_model_self_training_approach	[pos="e,533.63,547.61 533.47,547.75 533.49,547.73 533.52,547.7 533.55,547.68"];
	meng_2020_text_classification_using_label_names_only_a_language_model_self_training_approach -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.15,518.87 580.05,518.94 580.07,518.92 580.09,518.91 580.11,518.9"];
	meng_2020_text_classification_using_label_names_only_a_language_model_self_training_approach -> vaswani_2017_attention_is_all_you_need	[pos="e,587.94,510.35 587.83,510.43 587.85,510.41 587.87,510.39 587.89,510.38"];
	meng_2020_text_classification_using_label_names_only_a_language_model_self_training_approach -> lewis_2019_bart_denoising_sequence_to_sequence_pre_training_for_natural_language_generation_translation_and_comprehension	[pos="e,592.36,539.81 592.23,539.83 592.26,539.83 592.28,539.82 592.31,539.82"];
	meng_2020_text_classification_using_label_names_only_a_language_model_self_training_approach -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.72,532.56 612.68,532.57 612.69,532.57 612.7,532.57 612.7,532.57"];
	meng_2020_text_classification_using_label_names_only_a_language_model_self_training_approach -> peters_2018_deep_contextualized_word_representations	[pos="e,583.73,529.9 583.62,529.94 583.64,529.93 583.67,529.92 583.68,529.91"];
	meng_2020_text_classification_using_label_names_only_a_language_model_self_training_approach -> meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding	[pos="e,476.14,507.82 476.27,507.9 476.24,507.88 476.22,507.87 476.2,507.85"];
	meng_2020_text_classification_using_label_names_only_a_language_model_self_training_approach -> meng_2018_weakly_supervised_neural_text_classification	[pos="e,474.4,580.67 474.52,580.6 474.5,580.61 474.47,580.63 474.45,580.64"];
	meng_2020_text_classification_using_label_names_only_a_language_model_self_training_approach -> meng_2018_weakly_supervised_hierarchical_text_classification	[pos="e,466.4,568.66 466.43,568.65 466.42,568.65 466.42,568.66 466.41,568.66"];
	meng_2020_text_classification_using_label_names_only_a_language_model_self_training_approach -> meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding	[pos="e,511.62,523.27 511.67,523.33 511.66,523.31 511.65,523.3 511.64,523.3"];
	meng_2020_text_classification_using_label_names_only_a_language_model_self_training_approach -> huang_2020_weakly_supervised_aspect_based_sentiment_analysis_via_joint_aspect_sentiment_topic_embedding	[pos="e,480.53,502.54 480.7,502.41 480.67,502.43 480.64,502.45 480.61,502.47"];
	shen_2021_taxoclass_hierarchical_multi_label_text_classification_using_only_class_names -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.18,518.87 580.17,518.9 580.17,518.89 580.17,518.88 580.17,518.88"];
	shen_2021_taxoclass_hierarchical_multi_label_text_classification_using_only_class_names -> meng_2018_weakly_supervised_neural_text_classification	[pos="e,474.37,580.69 474.41,580.69 474.4,580.69 474.39,580.69 474.39,580.69"];
	shen_2021_taxoclass_hierarchical_multi_label_text_classification_using_only_class_names -> meng_2018_weakly_supervised_hierarchical_text_classification	[pos="e,466.4,568.67 466.45,568.68 466.44,568.67 466.43,568.67 466.42,568.67"];
	shen_2021_taxoclass_hierarchical_multi_label_text_classification_using_only_class_names -> shen_2020_taxoexpan_self_supervised_taxonomy_expansion_with_position_enhanced_graph_neural_network	[pos="e,501.71,584.13 501.82,584.13 501.79,584.13 501.77,584.13 501.75,584.13"];
	shen_2021_taxoclass_hierarchical_multi_label_text_classification_using_only_class_names -> gururangan_2019_variational_pretraining_for_semi_supervised_text_classification	[pos="e,581.9,450.81 581.89,450.88 581.89,450.87 581.89,450.85 581.9,450.84"];
	shen_2021_taxoclass_hierarchical_multi_label_text_classification_using_only_class_names -> meng_2020_text_classification_using_label_names_only_a_language_model_self_training_approach	[pos="e,533.78,547.49 533.83,547.56 533.82,547.54 533.81,547.53 533.8,547.52"];
	xu_2022_hyperminer_topic_taxonomy_mining_with_hyperbolic_embedding	[color=green,
		height=2,
		id=xu_2022_hyperminer_topic_taxonomy_mining_with_hyperbolic_embedding,
		"k-core"=8,
		label=xu_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="1664.693066340713,4714.742582108307!"];
	xu_2022_hyperminer_topic_taxonomy_mining_with_hyperbolic_embedding -> merity_2016_pointer_sentinel_mixture_models	[pos="e,560.05,412.1 559.79,412.12 559.83,412.12 559.88,412.11 559.92,412.11"];
	xu_2022_hyperminer_topic_taxonomy_mining_with_hyperbolic_embedding -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,553.81,414.41 553.78,414.41 553.78,414.41 553.79,414.41 553.8,414.41"];
	xu_2022_hyperminer_topic_taxonomy_mining_with_hyperbolic_embedding -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,556.63,394.87 556.24,395.01 556.3,394.98 556.37,394.96 556.43,394.94"];
	xu_2022_hyperminer_topic_taxonomy_mining_with_hyperbolic_embedding -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,556.62,396.21 556.33,396.3 556.38,396.28 556.43,396.27 556.48,396.25"];
	xu_2022_hyperminer_topic_taxonomy_mining_with_hyperbolic_embedding -> zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling	[pos="e,538.79,376.21 538.68,376.3 538.7,376.28 538.72,376.27 538.74,376.25"];
	xu_2022_hyperminer_topic_taxonomy_mining_with_hyperbolic_embedding -> wang_2017_topic_compositional_neural_language_model	[pos="e,515.76,370.67 515.7,370.77 515.71,370.75 515.72,370.73 515.73,370.71"];
	xu_2022_hyperminer_topic_taxonomy_mining_with_hyperbolic_embedding -> meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding	[pos="e,478.31,490.57 478.37,490.09 478.36,490.17 478.35,490.25 478.34,490.33"];
	xu_2022_hyperminer_topic_taxonomy_mining_with_hyperbolic_embedding -> nickel_2017_poincare_embeddings_for_learning_hierarchical_representations	[pos="e,460.99,485.73 461.09,485.47 461.07,485.52 461.06,485.56 461.04,485.6"];
	xu_2022_hyperminer_topic_taxonomy_mining_with_hyperbolic_embedding -> tifrea_2018_poincare_glove_hyperbolic_word_embeddings	[pos="e,452.74,481.84 452.96,481.45 452.92,481.51 452.89,481.58 452.85,481.64"];
	xu_2022_hyperminer_topic_taxonomy_mining_with_hyperbolic_embedding -> nickel_2018_learning_continuous_hierarchies_in_the_lorentz_model_of_hyperbolic_geometry	[pos="e,436.62,470.06 437.08,469.59 437,469.67 436.92,469.75 436.85,469.83"];
	xu_2022_hyperminer_topic_taxonomy_mining_with_hyperbolic_embedding -> ganea_2018_hyperbolic_entailment_cones_for_learning_hierarchical_embeddings	[pos="e,444.63,477.05 444.93,476.64 444.88,476.71 444.83,476.78 444.78,476.85"];
	xu_2022_hyperminer_topic_taxonomy_mining_with_hyperbolic_embedding -> wang_2022_representing_mixtures_of_word_embeddings_with_mixtures_of_topic_embeddings	[pos="e,532.14,360.87 531.88,361.21 531.93,361.15 531.97,361.09 532.01,361.04"];
	duan_2021_topicnet_semantic_graph_guided_topic_discovery	[color=blue,
		height=3.3889,
		id=duan_2021_topicnet_semantic_graph_guided_topic_discovery,
		"k-core"=7,
		label=duan_2021,
		shape=circle,
		style=filled,
		width=3.3889,
		zazaza="-7176.145036693861,-3535.949469463144!"];
	xu_2022_hyperminer_topic_taxonomy_mining_with_hyperbolic_embedding -> duan_2021_topicnet_semantic_graph_guided_topic_discovery	[pos="e,546.86,457.38 546.73,457.3 546.76,457.32 546.78,457.33 546.8,457.35"];
	wang_2022_knowledge_aware_bayesian_deep_topic_model	[color=blue,
		height=2,
		id=wang_2022_knowledge_aware_bayesian_deep_topic_model,
		"k-core"=7,
		label=wang_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="2182.158723928739,-7696.634759307928!"];
	xu_2022_hyperminer_topic_taxonomy_mining_with_hyperbolic_embedding -> wang_2022_knowledge_aware_bayesian_deep_topic_model	[pos="e,530.61,475.11 530.52,474.99 530.54,475.02 530.56,475.04 530.57,475.06"];
	duan_2021_topicnet_semantic_graph_guided_topic_discovery -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.18,518.84 580.16,518.81 580.17,518.82 580.17,518.82 580.17,518.83"];
	duan_2021_topicnet_semantic_graph_guided_topic_discovery -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,553.82,414.44 553.8,414.53 553.81,414.51 553.81,414.5 553.81,414.48"];
	duan_2021_topicnet_semantic_graph_guided_topic_discovery -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.67,389.51 577.66,389.55 577.66,389.54 577.66,389.53 577.67,389.53"];
	duan_2021_topicnet_semantic_graph_guided_topic_discovery -> zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling	[pos="e,538.83,376.2 538.83,376.24 538.83,376.23 538.83,376.22 538.83,376.22"];
	duan_2021_topicnet_semantic_graph_guided_topic_discovery -> cong_2017_deep_latent_dirichlet_allocation_with_topic_layer_adaptive_stochastic_gradient_riemannian_mcmc	[pos="e,483.9,363.86 483.93,363.91 483.92,363.9 483.92,363.89 483.91,363.88"];
	duan_2021_topicnet_semantic_graph_guided_topic_discovery -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,629.99,511.49 629.94,511.46 629.95,511.47 629.96,511.47 629.97,511.48"];
	duan_2021_topicnet_semantic_graph_guided_topic_discovery -> meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding	[pos="e,476.12,507.78 476.15,507.75 476.14,507.76 476.14,507.76 476.13,507.77"];
	wang_2022_knowledge_aware_bayesian_deep_topic_model -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.15,518.82 580.04,518.73 580.07,518.75 580.09,518.77 580.11,518.78"];
	wang_2022_knowledge_aware_bayesian_deep_topic_model -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,553.82,414.42 553.81,414.45 553.81,414.45 553.81,414.44 553.82,414.43"];
	wang_2022_knowledge_aware_bayesian_deep_topic_model -> hoyle_2020_improving_neural_topic_models_using_knowledge_distillation	[pos="e,597.55,447.27 597.23,447.41 597.28,447.38 597.34,447.36 597.39,447.34"];
	wang_2022_knowledge_aware_bayesian_deep_topic_model -> zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling	[pos="e,536.64,402.61 536.61,402.97 536.62,402.91 536.62,402.85 536.62,402.79"];
	wang_2022_knowledge_aware_bayesian_deep_topic_model -> meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding	[pos="e,476.14,507.76 476.26,507.69 476.23,507.71 476.21,507.72 476.19,507.74"];
	wang_2022_knowledge_aware_bayesian_deep_topic_model -> duan_2021_topicnet_semantic_graph_guided_topic_discovery	[pos="e,546.89,457.42 546.85,457.46 546.86,457.45 546.87,457.44 546.87,457.44"];
	popa_2021_bart_tl_weakly_supervised_topic_label_generation	[color=blue,
		height=5.5833,
		id=popa_2021_bart_tl_weakly_supervised_topic_label_generation,
		"k-core"=7,
		label=popa_2021,
		shape=circle,
		style=filled,
		width=5.5833,
		zazaza="1938.0983274248103,7761.686294402351!"];
	popa_2021_bart_tl_weakly_supervised_topic_label_generation -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.22,518.89 580.31,519 580.29,518.97 580.27,518.95 580.26,518.93"];
	popa_2021_bart_tl_weakly_supervised_topic_label_generation -> vaswani_2017_attention_is_all_you_need	[pos="e,588.01,510.36 588.09,510.49 588.07,510.46 588.06,510.43 588.04,510.41"];
	popa_2021_bart_tl_weakly_supervised_topic_label_generation -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,630,511.54 629.99,511.67 629.99,511.64 629.99,511.61 630,511.59"];
	popa_2021_bart_tl_weakly_supervised_topic_label_generation -> lewis_2019_bart_denoising_sequence_to_sequence_pre_training_for_natural_language_generation_translation_and_comprehension	[pos="e,592.42,539.83 592.49,539.89 592.48,539.88 592.47,539.86 592.45,539.85"];
	popa_2021_bart_tl_weakly_supervised_topic_label_generation -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.74,532.59 612.77,532.66 612.77,532.65 612.76,532.63 612.76,532.62"];
	popa_2021_bart_tl_weakly_supervised_topic_label_generation -> zhang_2019_bertscore_evaluating_text_generation_with_bert	[pos="e,662.58,542.4 662.5,542.46 662.52,542.45 662.54,542.44 662.55,542.43"];
	popa_2021_bart_tl_weakly_supervised_topic_label_generation -> devlin_2018_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,613.44,507.91 613.44,507.95 613.44,507.94 613.44,507.93 613.44,507.93"];
	popa_2021_bart_tl_weakly_supervised_topic_label_generation -> keskar_2019_ctrl_a_conditional_transformer_language_model_for_controllable_generation	[pos="e,655.56,519.21 655.5,519.31 655.51,519.29 655.53,519.27 655.54,519.25"];
	pham_2022_pic_a_phrase_in_context_dataset_for_phrase_understanding_and_semantic_search	[color=blue,
		height=2,
		id=pham_2022_pic_a_phrase_in_context_dataset_for_phrase_understanding_and_semantic_search,
		"k-core"=7,
		label=pham_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="1692.1074556909923,7819.00069015561!"];
	pham_2022_pic_a_phrase_in_context_dataset_for_phrase_understanding_and_semantic_search -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,593.47,537.42 593.65,537.68 593.62,537.63 593.59,537.59 593.56,537.55"];
	pham_2022_pic_a_phrase_in_context_dataset_for_phrase_understanding_and_semantic_search -> reimers_2019_sentence_bert_sentence_embeddings_using_siamese_bert_networks	[pos="e,616.28,526.58 616.41,527.05 616.38,526.97 616.36,526.89 616.34,526.81"];
	pham_2022_pic_a_phrase_in_context_dataset_for_phrase_understanding_and_semantic_search -> wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration	[pos="e,640.23,523.85 640.2,524.29 640.2,524.22 640.21,524.14 640.21,524.07"];
	pham_2022_pic_a_phrase_in_context_dataset_for_phrase_understanding_and_semantic_search -> joshi_2019_spanbert_improving_pre_training_by_representing_and_predicting_spans	[pos="e,642.15,543.81 642.13,543.92 642.14,543.9 642.14,543.87 642.14,543.86"];
	pham_2022_pic_a_phrase_in_context_dataset_for_phrase_understanding_and_semantic_search -> lee_2020_learning_dense_representations_of_phrases_at_scale	[pos="e,658.72,583.13 658.67,583.16 658.68,583.15 658.69,583.15 658.7,583.14"];
	pham_2022_pic_a_phrase_in_context_dataset_for_phrase_understanding_and_semantic_search -> zhang_2019_paws_paraphrase_adversaries_from_word_scrambling	[pos="e,653.31,578.19 653.27,578.23 653.28,578.22 653.29,578.21 653.3,578.21"];
	pham_2022_pic_a_phrase_in_context_dataset_for_phrase_understanding_and_semantic_search -> yu_2020_assessing_phrasal_representation_and_composition_in_transformers	[pos="e,681.51,551.83 681.41,551.93 681.43,551.91 681.45,551.89 681.47,551.87"];
	ning_2020_nonparametric_topic_modeling_with_neural_inference	[color=blue,
		height=2,
		id=ning_2020_nonparametric_topic_modeling_with_neural_inference,
		"k-core"=7,
		label=ning_2020,
		shape=circle,
		style=filled,
		width=2,
		zazaza="1444.428818840169,7868.521182578609!"];
	ning_2020_nonparametric_topic_modeling_with_neural_inference -> jang_2016_categorical_reparameterization_with_gumbel_softmax	[pos="e,529.06,345.51 529.43,345.15 529.37,345.21 529.3,345.27 529.24,345.33"];
	ning_2020_nonparametric_topic_modeling_with_neural_inference -> card_2017_neural_models_for_documents_with_metadata	[pos="e,606.84,362.51 606.72,362.2 606.74,362.26 606.76,362.31 606.78,362.36"];
	ning_2020_nonparametric_topic_modeling_with_neural_inference -> burkhardt_2019_decoupling_sparsity_and_smoothness_in_the_dirichlet_variational_autoencoder_topic_model	[pos="e,642.07,333.81 642.04,333.79 642.05,333.79 642.05,333.8 642.06,333.8"];
	ning_2020_nonparametric_topic_modeling_with_neural_inference -> card_2018_neural_models_for_documents_with_metadata	[pos="e,601.51,364.38 601.42,364.08 601.43,364.13 601.45,364.18 601.46,364.23"];
	ning_2020_nonparametric_topic_modeling_with_neural_inference -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,578.48,367.36 578.5,367.06 578.49,367.11 578.49,367.16 578.49,367.21"];
	ning_2020_nonparametric_topic_modeling_with_neural_inference -> zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling	[pos="e,547.55,359.4 547.8,358.93 547.76,359 547.71,359.08 547.67,359.16"];
	ning_2020_nonparametric_topic_modeling_with_neural_inference -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,624.92,353.09 624.58,352.63 624.63,352.71 624.69,352.79 624.75,352.86"];
	duan_2021_enslm_ensemble_language_model_for_data_diversity_by_semantic_clustering	[color=green,
		height=2,
		id=duan_2021_enslm_ensemble_language_model_for_data_diversity_by_semantic_clustering,
		"k-core"=8,
		label=duan_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="747.0695041618606,4943.873564856171!"];
	duan_2021_enslm_ensemble_language_model_for_data_diversity_by_semantic_clustering -> see_2017_get_to_the_point_summarization_with_pointer_generator_networks	[pos="e,532.42,404.04 532.51,404.12 532.49,404.11 532.47,404.09 532.46,404.08"];
	duan_2021_enslm_ensemble_language_model_for_data_diversity_by_semantic_clustering -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,579.96,514.82 579.93,514.29 579.94,514.38 579.94,514.47 579.95,514.56"];
	duan_2021_enslm_ensemble_language_model_for_data_diversity_by_semantic_clustering -> vaswani_2017_attention_is_all_you_need	[pos="e,587.98,510.31 587.97,510.27 587.97,510.28 587.98,510.28 587.98,510.29"];
	duan_2021_enslm_ensemble_language_model_for_data_diversity_by_semantic_clustering -> jang_2016_categorical_reparameterization_with_gumbel_softmax	[pos="e,533.69,383.16 533.93,383.49 533.89,383.44 533.85,383.38 533.81,383.33"];
	duan_2021_enslm_ensemble_language_model_for_data_diversity_by_semantic_clustering -> lau_2017_topically_driven_neural_language_model	[pos="e,558.68,375.4 558.69,375.44 558.69,375.43 558.69,375.42 558.69,375.42"];
	duan_2021_enslm_ensemble_language_model_for_data_diversity_by_semantic_clustering -> wang_2019_topic_guided_variational_auto_encoder_for_text_generation	[pos="e,565.21,370.45 565.25,370.71 565.24,370.67 565.23,370.62 565.23,370.58"];
	duan_2021_enslm_ensemble_language_model_for_data_diversity_by_semantic_clustering -> wang_2020_friendly_topic_assistant_for_transformer_based_abstractive_summarization	[pos="e,602.5,462.47 602.44,462.42 602.45,462.43 602.46,462.44 602.47,462.45"];
	duan_2021_enslm_ensemble_language_model_for_data_diversity_by_semantic_clustering -> guo_2019_recurrent_hierarchical_topic_guided_rnn_for_language_generation	[pos="e,573.34,428.1 573.37,428.22 573.36,428.19 573.36,428.17 573.35,428.15"];
	duan_2021_enslm_ensemble_language_model_for_data_diversity_by_semantic_clustering -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.68,389.54 577.67,389.65 577.67,389.63 577.67,389.6 577.67,389.59"];
	duan_2021_enslm_ensemble_language_model_for_data_diversity_by_semantic_clustering -> zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling	[pos="e,540.41,379 540.62,379.37 540.58,379.31 540.54,379.24 540.51,379.18"];
	duan_2021_enslm_ensemble_language_model_for_data_diversity_by_semantic_clustering -> dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency	[pos="e,585.58,373.55 585.57,373.59 585.57,373.58 585.57,373.57 585.58,373.57"];
	duan_2021_enslm_ensemble_language_model_for_data_diversity_by_semantic_clustering -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,620.61,499.46 620.34,499.12 620.39,499.18 620.43,499.24 620.47,499.29"];
	meng_2022_topic_discovery_via_latent_space_clustering_of_pretrained_language_model_representations	[color=green,
		height=3.3889,
		id=meng_2022_topic_discovery_via_latent_space_clustering_of_pretrained_language_model_representations,
		"k-core"=8,
		label=meng_2022,
		shape=circle,
		style=filled,
		width=3.3889,
		zazaza="590.6263482728212,4964.993576606912!"];
	meng_2022_topic_discovery_via_latent_space_clustering_of_pretrained_language_model_representations -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.17,518.83 580.11,518.77 580.12,518.79 580.14,518.8 580.14,518.81"];
	meng_2022_topic_discovery_via_latent_space_clustering_of_pretrained_language_model_representations -> vaswani_2017_attention_is_all_you_need	[pos="e,587.96,510.31 587.89,510.26 587.9,510.27 587.92,510.28 587.93,510.29"];
	meng_2022_topic_discovery_via_latent_space_clustering_of_pretrained_language_model_representations -> reimers_2019_sentence_bert_sentence_embeddings_using_siamese_bert_networks	[pos="e,606.19,490.55 606.08,490.55 606.1,490.55 606.12,490.55 606.14,490.55"];
	meng_2022_topic_discovery_via_latent_space_clustering_of_pretrained_language_model_representations -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,553.82,414.42 553.83,414.47 553.83,414.46 553.83,414.45 553.83,414.44"];
	meng_2022_topic_discovery_via_latent_space_clustering_of_pretrained_language_model_representations -> hoyle_2020_improving_neural_topic_models_using_knowledge_distillation	[pos="e,621.59,437.26 621.56,437.29 621.57,437.28 621.57,437.27 621.58,437.27"];
	meng_2022_topic_discovery_via_latent_space_clustering_of_pretrained_language_model_representations -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.67,389.52 577.66,389.57 577.66,389.56 577.67,389.55 577.67,389.54"];
	meng_2022_topic_discovery_via_latent_space_clustering_of_pretrained_language_model_representations -> wang_2020_neural_topic_modeling_with_bidirectional_adversarial_training	[pos="e,637.92,400.82 637.61,401.15 637.66,401.09 637.71,401.04 637.77,400.98"];
	meng_2022_topic_discovery_via_latent_space_clustering_of_pretrained_language_model_representations -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.69,532.53 612.57,532.44 612.6,532.46 612.62,532.48 612.64,532.49"];
	meng_2022_topic_discovery_via_latent_space_clustering_of_pretrained_language_model_representations -> li_2020_on_the_sentence_embeddings_from_pre_trained_language_models	[pos="e,633.7,567.05 633.66,567.01 633.67,567.02 633.68,567.03 633.68,567.04"];
	meng_2022_topic_discovery_via_latent_space_clustering_of_pretrained_language_model_representations -> meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding	[pos="e,476.12,507.79 476.16,507.78 476.15,507.78 476.14,507.78 476.13,507.78"];
	meng_2022_topic_discovery_via_latent_space_clustering_of_pretrained_language_model_representations -> meng_2019_spherical_text_embedding	[pos="e,500.05,530.08 500.17,530 500.15,530.02 500.12,530.03 500.1,530.05"];
	meng_2022_topic_discovery_via_latent_space_clustering_of_pretrained_language_model_representations -> meng_2018_weakly_supervised_neural_text_classification	[pos="e,474.37,580.68 474.41,580.63 474.4,580.64 474.39,580.65 474.39,580.66"];
	meng_2022_topic_discovery_via_latent_space_clustering_of_pretrained_language_model_representations -> meng_2018_weakly_supervised_hierarchical_text_classification	[pos="e,466.4,568.65 466.45,568.61 466.44,568.62 466.43,568.63 466.42,568.63"];
	meng_2022_topic_discovery_via_latent_space_clustering_of_pretrained_language_model_representations -> meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding	[pos="e,511.64,523.23 511.73,523.16 511.71,523.18 511.69,523.19 511.68,523.2"];
	meng_2022_topic_discovery_via_latent_space_clustering_of_pretrained_language_model_representations -> huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring	[pos="e,503.18,556.97 503.21,556.93 503.21,556.94 503.2,556.95 503.2,556.95"];
	meng_2022_topic_discovery_via_latent_space_clustering_of_pretrained_language_model_representations -> huang_2020_weakly_supervised_aspect_based_sentiment_analysis_via_joint_aspect_sentiment_topic_embedding	[pos="e,480.4,502.69 480.44,502.69 480.43,502.69 480.43,502.69 480.42,502.69"];
	meng_2022_topic_discovery_via_latent_space_clustering_of_pretrained_language_model_representations -> meng_2020_text_classification_using_label_names_only_a_language_model_self_training_approach	[pos="e,533.79,547.42 533.83,547.3 533.82,547.33 533.81,547.35 533.8,547.37"];
	wang_2022_qen_applicable_taxonomy_completion_via_evaluating_full_taxonomic_relations	[color=green,
		height=2,
		id=wang_2022_qen_applicable_taxonomy_completion_via_evaluating_full_taxonomic_relations,
		"k-core"=8,
		label=wang_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="433.594447506567,4981.164018668569!"];
	wang_2022_qen_applicable_taxonomy_completion_via_evaluating_full_taxonomic_relations -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,570.97,544.87 570.84,545.22 570.87,545.17 570.89,545.11 570.91,545.05"];
	wang_2022_qen_applicable_taxonomy_completion_via_evaluating_full_taxonomic_relations -> vaswani_2017_attention_is_all_you_need	[pos="e,573.71,545.95 573.53,546.41 573.56,546.34 573.59,546.26 573.62,546.18"];
	wang_2022_qen_applicable_taxonomy_completion_via_evaluating_full_taxonomic_relations -> liu_2020_giant_scalable_creation_of_a_web_scale_ontology	[pos="e,560.5,619.11 560.38,619.06 560.41,619.07 560.43,619.08 560.45,619.09"];
	wang_2022_qen_applicable_taxonomy_completion_via_evaluating_full_taxonomic_relations -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,473.84,613.79 474.29,613.79 474.22,613.79 474.14,613.79 474.07,613.79"];
	wang_2022_qen_applicable_taxonomy_completion_via_evaluating_full_taxonomic_relations -> jiang_2017_metapad_meta_pattern_discovery_from_massive_text_corpora	[pos="e,487.01,654.94 487.32,654.72 487.27,654.76 487.22,654.8 487.16,654.83"];
	wang_2022_qen_applicable_taxonomy_completion_via_evaluating_full_taxonomic_relations -> song_2021_who_should_go_first_a_self_supervised_concept_sorting_model_for_improving_taxonomy_expansion	[pos="e,483.4,648.78 483.73,648.59 483.68,648.63 483.62,648.66 483.57,648.69"];
	wang_2022_qen_applicable_taxonomy_completion_via_evaluating_full_taxonomic_relations -> manzoor_2020_expanding_taxonomies_with_implicit_edge_semantics	[pos="e,475.68,597.35 476.03,597.43 475.97,597.42 475.92,597.41 475.86,597.39"];
	wang_2022_qen_applicable_taxonomy_completion_via_evaluating_full_taxonomic_relations -> yu_2020_steam_self_supervised_taxonomy_expansion_with_mini_paths	[pos="e,508.45,598.97 508.54,599 508.52,599 508.5,598.99 508.49,598.98"];
	wang_2022_qen_applicable_taxonomy_completion_via_evaluating_full_taxonomic_relations -> shen_2020_taxoexpan_self_supervised_taxonomy_expansion_with_position_enhanced_graph_neural_network	[pos="e,501.7,584.16 501.8,584.22 501.78,584.21 501.76,584.19 501.74,584.18"];
	wang_2022_qen_applicable_taxonomy_completion_via_evaluating_full_taxonomic_relations -> wang_2021_enquire_ones_parent_and_child_before_decision_fully_exploit_hierarchical_structure_for_self_supervised_taxonomy_expansion	[pos="e,527.56,590.31 527.6,590.36 527.59,590.35 527.58,590.34 527.58,590.33"];
	wang_2022_qen_applicable_taxonomy_completion_via_evaluating_full_taxonomic_relations -> shang_2020_nettaxo_automated_topic_taxonomy_construction_from_text_rich_network	[pos="e,476.12,631.68 476.46,631.6 476.4,631.61 476.34,631.62 476.29,631.64"];
	wang_2022_qen_applicable_taxonomy_completion_via_evaluating_full_taxonomic_relations -> zeng_2021_enhancing_taxonomy_completion_with_concept_generation_via_fusing_relational_representations	[pos="e,534.64,604.25 534.74,604.33 534.72,604.31 534.7,604.29 534.68,604.28"];
	li_2021_a_deep_decomposable_model_for_disentangling_syntax_and_semantics_in_sentence_representation	[color=blue,
		height=2,
		id=li_2021_a_deep_decomposable_model_for_disentangling_syntax_and_semantics_in_sentence_representation,
		"k-core"=7,
		label=li_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="189.42556356685463,7997.756926713807!"];
	li_2021_a_deep_decomposable_model_for_disentangling_syntax_and_semantics_in_sentence_representation -> vaswani_2017_attention_is_all_you_need	[pos="e,618.02,475.18 618.4,474.74 618.34,474.81 618.27,474.88 618.21,474.96"];
	li_2021_a_deep_decomposable_model_for_disentangling_syntax_and_semantics_in_sentence_representation -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,623.31,372.4 623.4,372.5 623.38,372.48 623.36,372.46 623.35,372.44"];
	li_2021_a_deep_decomposable_model_for_disentangling_syntax_and_semantics_in_sentence_representation -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,596.91,396.1 597.17,396.19 597.13,396.17 597.08,396.16 597.04,396.14"];
	li_2021_a_deep_decomposable_model_for_disentangling_syntax_and_semantics_in_sentence_representation -> dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency	[pos="e,602.45,383.27 602.92,383.54 602.84,383.49 602.77,383.45 602.69,383.4"];
	li_2021_a_deep_decomposable_model_for_disentangling_syntax_and_semantics_in_sentence_representation -> ding_2018_coherence_aware_neural_topic_modeling	[pos="e,661.36,368.22 661.37,368.33 661.36,368.31 661.36,368.29 661.36,368.27"];
	li_2021_a_deep_decomposable_model_for_disentangling_syntax_and_semantics_in_sentence_representation -> yang_2017_improved_variational_autoencoders_for_text_modeling_using_dilated_convolutions	[pos="e,603.33,382.1 603.79,382.38 603.72,382.34 603.64,382.29 603.56,382.24"];
	pergola_2021_a_disentangled_adversarial_neural_topic_model_for_separating_opinions_from_plots_in_user_reviews	[color=green,
		height=5.5833,
		id=pergola_2021_a_disentangled_adversarial_neural_topic_model_for_separating_opinions_from_plots_in_user_reviews,
		"k-core"=8,
		label=pergola_2021,
		shape=circle,
		style=filled,
		width=5.5833,
		zazaza="-354.9064554490896,4987.38823368281!"];
	li_2021_a_deep_decomposable_model_for_disentangling_syntax_and_semantics_in_sentence_representation -> pergola_2021_a_disentangled_adversarial_neural_topic_model_for_separating_opinions_from_plots_in_user_reviews	[pos="e,616.85,435.5 616.95,435.46 616.93,435.47 616.91,435.48 616.89,435.48"];
	john_2018_disentangled_representation_learning_for_non_parallel_text_style_transfer	[color=yellow,
		height=5.8889,
		id=john_2018_disentangled_representation_learning_for_non_parallel_text_style_transfer,
		"k-core"=6,
		label=john_2018,
		shape=circle,
		style=filled,
		width=5.8889,
		zazaza="-0.9455470987465113,-0.3254853193129908!"];
	li_2021_a_deep_decomposable_model_for_disentangling_syntax_and_semantics_in_sentence_representation -> john_2018_disentangled_representation_learning_for_non_parallel_text_style_transfer	[pos="e,735.47,407.47 735.43,407.48 735.44,407.48 735.44,407.48 735.45,407.47"];
	pergola_2021_a_disentangled_adversarial_neural_topic_model_for_separating_opinions_from_plots_in_user_reviews -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.19,518.84 580.21,518.79 580.21,518.8 580.2,518.81 580.2,518.82"];
	pergola_2021_a_disentangled_adversarial_neural_topic_model_for_separating_opinions_from_plots_in_user_reviews -> reimers_2019_sentence_bert_sentence_embeddings_using_siamese_bert_networks	[pos="e,606.23,490.51 606.26,490.39 606.25,490.41 606.25,490.44 606.24,490.46"];
	pergola_2021_a_disentangled_adversarial_neural_topic_model_for_separating_opinions_from_plots_in_user_reviews -> card_2017_neural_models_for_documents_with_metadata	[pos="e,615.36,384.99 615.36,385.1 615.36,385.07 615.36,385.05 615.36,385.03"];
	pergola_2021_a_disentangled_adversarial_neural_topic_model_for_separating_opinions_from_plots_in_user_reviews -> card_2018_neural_models_for_documents_with_metadata	[pos="e,608.08,386.86 608.1,386.96 608.1,386.94 608.1,386.92 608.09,386.9"];
	pergola_2021_a_disentangled_adversarial_neural_topic_model_for_separating_opinions_from_plots_in_user_reviews -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,623.28,372.38 623.28,372.41 623.28,372.4 623.28,372.4 623.28,372.39"];
	pergola_2021_a_disentangled_adversarial_neural_topic_model_for_separating_opinions_from_plots_in_user_reviews -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.71,389.53 577.79,389.63 577.77,389.61 577.76,389.59 577.74,389.57"];
	pergola_2021_a_disentangled_adversarial_neural_topic_model_for_separating_opinions_from_plots_in_user_reviews -> gui_2019_neural_topic_model_with_reinforcement_learning	[pos="e,530.39,356.31 530.43,356.35 530.42,356.34 530.41,356.33 530.41,356.33"];
	pergola_2021_a_disentangled_adversarial_neural_topic_model_for_separating_opinions_from_plots_in_user_reviews -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,630.65,360.73 630.64,360.77 630.64,360.76 630.64,360.75 630.64,360.74"];
	pergola_2021_a_disentangled_adversarial_neural_topic_model_for_separating_opinions_from_plots_in_user_reviews -> dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency	[pos="e,585.59,373.55 585.6,373.58 585.6,373.58 585.6,373.57 585.59,373.57"];
	pergola_2021_a_disentangled_adversarial_neural_topic_model_for_separating_opinions_from_plots_in_user_reviews -> ding_2018_coherence_aware_neural_topic_modeling	[pos="e,661.35,368.2 661.32,368.23 661.33,368.22 661.33,368.22 661.34,368.21"];
	pergola_2021_a_disentangled_adversarial_neural_topic_model_for_separating_opinions_from_plots_in_user_reviews -> yang_2017_improved_variational_autoencoders_for_text_modeling_using_dilated_convolutions	[pos="e,519,331.22 519.06,331.28 519.04,331.26 519.03,331.25 519.03,331.24"];
	pergola_2021_a_disentangled_adversarial_neural_topic_model_for_separating_opinions_from_plots_in_user_reviews -> devlin_2018_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,613.44,507.89 613.44,507.85 613.44,507.86 613.44,507.87 613.44,507.87"];
	pergola_2021_a_disentangled_adversarial_neural_topic_model_for_separating_opinions_from_plots_in_user_reviews -> john_2018_disentangled_representation_learning_for_non_parallel_text_style_transfer	[pos="e,735.46,407.47 735.39,407.49 735.41,407.49 735.42,407.48 735.43,407.48"];
	wang_2018_atmadversarial_neural_topic_model	[color=yellow,
		height=3.3889,
		id=wang_2018_atmadversarial_neural_topic_model,
		"k-core"=6,
		label=wang_2018,
		shape=circle,
		style=filled,
		width=3.3889,
		zazaza="-0.007893402263017274,0.999968822858374!"];
	pergola_2021_a_disentangled_adversarial_neural_topic_model_for_separating_opinions_from_plots_in_user_reviews -> wang_2018_atmadversarial_neural_topic_model	[pos="e,644.22,416.17 644.16,416.21 644.17,416.2 644.18,416.19 644.19,416.19"];
	pergola_2019_tdam_a_topic_dependent_attention_model_for_sentiment_analysis	[color=green,
		height=5.2222,
		id=pergola_2019_tdam_a_topic_dependent_attention_model_for_sentiment_analysis,
		"k-core"=8,
		label=pergola_2019,
		shape=circle,
		style=filled,
		width=5.2222,
		zazaza="-4552.620922146589,-2067.279220535558!"];
	pergola_2021_a_disentangled_adversarial_neural_topic_model_for_separating_opinions_from_plots_in_user_reviews -> pergola_2019_tdam_a_topic_dependent_attention_model_for_sentiment_analysis	[pos="e,639.47,472.56 639.42,472.48 639.43,472.5 639.44,472.52 639.45,472.53"];
	john_2018_disentangled_representation_learning_for_non_parallel_text_style_transfer -> arjovsky_2017_wasserstein_generative_adversarial_networks	[pos="e,718.11,431.29 718.15,431.24 718.14,431.25 718.13,431.26 718.13,431.27"];
	wang_2018_atmadversarial_neural_topic_model -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.69,389.5 577.73,389.52 577.72,389.52 577.71,389.51 577.7,389.51"];
	wang_2018_atmadversarial_neural_topic_model -> arjovsky_2017_wasserstein_generative_adversarial_networks	[pos="e,718.08,431.31 718.04,431.3 718.05,431.3 718.06,431.3 718.07,431.3"];
	wang_2018_atmadversarial_neural_topic_model -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,547.25,491.12 547.58,490.87 547.53,490.91 547.47,490.95 547.42,490.99"];
	wang_2018_atmadversarial_neural_topic_model -> gulrajani_2017_improved_training_of_wasserstein_gans	[pos="e,705.84,392.15 705.8,392.17 705.81,392.16 705.82,392.16 705.82,392.16"];
	pergola_2019_tdam_a_topic_dependent_attention_model_for_sentiment_analysis -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.23,518.82 580.36,518.72 580.33,518.74 580.3,518.76 580.28,518.78"];
	pergola_2019_tdam_a_topic_dependent_attention_model_for_sentiment_analysis -> vaswani_2017_attention_is_all_you_need	[pos="e,588.02,510.29 588.13,510.21 588.11,510.23 588.08,510.24 588.07,510.26"];
	pergola_2019_tdam_a_topic_dependent_attention_model_for_sentiment_analysis -> card_2017_neural_models_for_documents_with_metadata	[pos="e,615.36,384.97 615.38,385.01 615.37,385 615.37,384.99 615.37,384.99"];
	pergola_2019_tdam_a_topic_dependent_attention_model_for_sentiment_analysis -> card_2018_neural_models_for_documents_with_metadata	[pos="e,608.08,386.84 608.1,386.88 608.1,386.87 608.09,386.86 608.09,386.85"];
	pergola_2019_tdam_a_topic_dependent_attention_model_for_sentiment_analysis -> dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency	[pos="e,585.59,373.56 585.62,373.61 585.61,373.6 585.61,373.59 585.6,373.58"];
	pergola_2019_tdam_a_topic_dependent_attention_model_for_sentiment_analysis -> peters_2018_deep_contextualized_word_representations	[pos="e,583.8,529.84 583.92,529.72 583.9,529.75 583.87,529.77 583.85,529.79"];
	university_of_helsinki_2021_not_all_comments_are_equal_insights_into_comment_moderation_from_a_topic_aware_model	[color=yellow,
		height=2.4167,
		id=university_of_helsinki_2021_not_all_comments_are_equal_insights_into_comment_moderation_from_a_topic_aware_model,
		"k-core"=6,
		label=university_of_helsinki_2021,
		shape=circle,
		style=filled,
		width=2.4167,
		zazaza="-0.10243481106638107,0.9947397073860313!"];
	university_of_helsinki_2021_not_all_comments_are_equal_insights_into_comment_moderation_from_a_topic_aware_model -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.18,518.82 580.16,518.73 580.17,518.75 580.17,518.77 580.17,518.78"];
	university_of_helsinki_2021_not_all_comments_are_equal_insights_into_comment_moderation_from_a_topic_aware_model -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,553.83,414.42 553.84,414.45 553.84,414.45 553.83,414.44 553.83,414.43"];
	university_of_helsinki_2021_not_all_comments_are_equal_insights_into_comment_moderation_from_a_topic_aware_model -> wang_2017_topic_compositional_neural_language_model	[pos="e,530.58,398.45 530.78,398.82 530.75,398.76 530.71,398.7 530.68,398.63"];
	university_of_helsinki_2021_not_all_comments_are_equal_insights_into_comment_moderation_from_a_topic_aware_model -> dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency	[pos="e,583.48,389.07 583.42,389.52 583.43,389.45 583.44,389.37 583.45,389.3"];
	university_of_helsinki_2021_not_all_comments_are_equal_insights_into_comment_moderation_from_a_topic_aware_model -> popa_2021_bart_tl_weakly_supervised_topic_label_generation	[pos="e,615.36,551.76 615.08,551.28 615.13,551.36 615.17,551.44 615.22,551.52"];
	chaudhary_2020_explainable_and_discourse_topic_aware_neural_language_understanding	[color=yellow,
		height=2,
		id=chaudhary_2020_explainable_and_discourse_topic_aware_neural_language_understanding,
		"k-core"=6,
		label=chaudhary_2020,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-0.9231225201390146,-0.38450586821611865!"];
	university_of_helsinki_2021_not_all_comments_are_equal_insights_into_comment_moderation_from_a_topic_aware_model -> chaudhary_2020_explainable_and_discourse_topic_aware_neural_language_understanding	[pos="e,490.83,443.6 490.88,443.62 490.87,443.62 490.86,443.61 490.85,443.61"];
	chaudhary_2020_explainable_and_discourse_topic_aware_neural_language_understanding -> lau_2017_topically_driven_neural_language_model	[pos="e,542.36,391.8 541.91,392.25 541.98,392.18 542.06,392.1 542.13,392.02"];
	chaudhary_2020_explainable_and_discourse_topic_aware_neural_language_understanding -> wang_2017_topic_compositional_neural_language_model	[pos="e,514.23,375.14 514.14,375.42 514.16,375.37 514.17,375.33 514.19,375.28"];
	chaudhary_2020_explainable_and_discourse_topic_aware_neural_language_understanding -> dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency	[pos="e,549.4,400.29 548.94,400.63 549.02,400.57 549.1,400.51 549.17,400.46"];
	chaudhary_2020_explainable_and_discourse_topic_aware_neural_language_understanding -> peters_2018_deep_contextualized_word_representations	[pos="e,544.3,493.24 543.81,492.79 543.89,492.87 543.97,492.94 544.05,493.02"];
	chaudhary_2020_explainable_and_discourse_topic_aware_neural_language_understanding -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,523.28,509.24 522.86,508.39 522.95,508.58 523.03,508.74 523.1,508.89"];
	ettaleb_2022_evaluation_of_weakly_supervised_methods_for_aspect_extraction	[color=yellow,
		height=2,
		id=ettaleb_2022_evaluation_of_weakly_supervised_methods_for_aspect_extraction,
		"k-core"=6,
		label=ettaleb_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-0.406255807741015,0.9137594066964607!"];
	ettaleb_2022_evaluation_of_weakly_supervised_methods_for_aspect_extraction -> he_2017_an_unsupervised_neural_attention_model_for_aspect_extraction	[pos="e,461.57,437.69 461.3,438.07 461.35,438.01 461.39,437.94 461.44,437.88"];
	ettaleb_2022_evaluation_of_weakly_supervised_methods_for_aspect_extraction -> pablos_2018_w2vlda_almost_unsupervised_system_for_aspect_based_sentiment_analysis	[pos="e,417.5,443.01 417.5,443.12 417.5,443.1 417.5,443.07 417.5,443.05"];
	ettaleb_2022_evaluation_of_weakly_supervised_methods_for_aspect_extraction -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,491.43,505.65 491.01,505.6 491.08,505.61 491.15,505.62 491.22,505.63"];
	ettaleb_2022_evaluation_of_weakly_supervised_methods_for_aspect_extraction -> tulkens_2020_embarrassingly_simple_unsupervised_aspect_extraction	[pos="e,442.07,444.72 442.02,444.83 442.03,444.8 442.04,444.78 442.05,444.76"];
	ettaleb_2022_evaluation_of_weakly_supervised_methods_for_aspect_extraction -> huang_2020_weakly_supervised_aspect_based_sentiment_analysis_via_joint_aspect_sentiment_topic_embedding	[pos="e,480.38,502.69 480.35,502.69 480.35,502.69 480.36,502.69 480.36,502.69"];
	ettaleb_2022_evaluation_of_weakly_supervised_methods_for_aspect_extraction -> meng_2020_text_classification_using_label_names_only_a_language_model_self_training_approach	[pos="e,485.47,526.14 485.17,526 485.22,526.03 485.27,526.05 485.32,526.07"];
	mohamed_2022_self_supervised_speech_representation_learning_a_review	[color=yellow,
		height=2,
		id=mohamed_2022_self_supervised_speech_representation_learning_a_review,
		"k-core"=6,
		label=mohamed_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-0.43489935615402653,0.9004790746430441!"];
	mohamed_2022_self_supervised_speech_representation_learning_a_review -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,599.06,513.02 599.32,512.94 599.28,512.95 599.23,512.96 599.19,512.98"];
	mohamed_2022_self_supervised_speech_representation_learning_a_review -> jang_2016_categorical_reparameterization_with_gumbel_softmax	[pos="e,613.93,443.99 614.19,444.22 614.14,444.18 614.1,444.14 614.06,444.11"];
	mohamed_2022_self_supervised_speech_representation_learning_a_review -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,630.03,511.49 630.11,511.44 630.1,511.45 630.08,511.46 630.07,511.47"];
	mohamed_2022_self_supervised_speech_representation_learning_a_review -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.78,532.53 612.89,532.44 612.87,532.46 612.85,532.48 612.83,532.49"];
	mohamed_2022_self_supervised_speech_representation_learning_a_review -> wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration	[pos="e,641.17,508.53 641.23,508.5 641.22,508.5 641.21,508.51 641.2,508.52"];
	mohamed_2022_self_supervised_speech_representation_learning_a_review -> peters_2018_deep_contextualized_word_representations	[pos="e,602.28,521.5 602.54,521.39 602.5,521.4 602.45,521.42 602.41,521.44"];
	mohamed_2022_self_supervised_speech_representation_learning_a_review -> toshniwal_2020_a_cross_task_analysis_of_text_span_representations	[pos="e,682.82,540.64 682.79,540.53 682.79,540.55 682.8,540.57 682.8,540.59"];
	mohamed_2022_self_supervised_speech_representation_learning_a_review -> gulrajani_2017_improved_training_of_wasserstein_gans	[pos="e,694.04,423.47 693.89,423.88 693.91,423.82 693.94,423.75 693.96,423.68"];
	mohamed_2022_self_supervised_speech_representation_learning_a_review -> chen_2020_a_simple_framework_for_contrastive_learning_of_visual_representations	[pos="e,715.22,446.97 715.12,447.07 715.14,447.05 715.16,447.03 715.18,447.01"];
	hourrane_2022_topic_transformer_for_document_level_language_understanding	[color=yellow,
		height=2,
		id=hourrane_2022_topic_transformer_for_document_level_language_understanding,
		"k-core"=6,
		label=hourrane_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-0.5181169469816584,0.855309780881807!"];
	hourrane_2022_topic_transformer_for_document_level_language_understanding -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.16,518.81 580.09,518.69 580.1,518.72 580.12,518.74 580.13,518.76"];
	hourrane_2022_topic_transformer_for_document_level_language_understanding -> vaswani_2017_attention_is_all_you_need	[pos="e,587.95,510.28 587.86,510.18 587.88,510.2 587.9,510.22 587.91,510.24"];
	hourrane_2022_topic_transformer_for_document_level_language_understanding -> lau_2017_topically_driven_neural_language_model	[pos="e,556.53,390.09 556.47,390.51 556.48,390.44 556.49,390.37 556.5,390.3"];
	hourrane_2022_topic_transformer_for_document_level_language_understanding -> wang_2019_topic_guided_variational_auto_encoder_for_text_generation	[pos="e,556.77,390.05 556.69,390.54 556.71,390.46 556.72,390.38 556.73,390.29"];
	hourrane_2022_topic_transformer_for_document_level_language_understanding -> wang_2017_topic_compositional_neural_language_model	[pos="e,523.3,393.42 523.4,393.73 523.39,393.68 523.37,393.63 523.35,393.58"];
	hourrane_2022_topic_transformer_for_document_level_language_understanding -> dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency	[pos="e,575.52,396.06 575.39,396.36 575.41,396.31 575.43,396.26 575.45,396.21"];
	chang_2021_ta_bilstm_an_interpretable_topic_aware_model_for_misleading_information_detection_in_mobile_social_networks	[color=yellow,
		height=2,
		id=chang_2021_ta_bilstm_an_interpretable_topic_aware_model_for_misleading_information_detection_in_mobile_social_networks,
		"k-core"=6,
		label=chang_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-0.5448597628824445,0.8385271395152777!"];
	chang_2021_ta_bilstm_an_interpretable_topic_aware_model_for_misleading_information_detection_in_mobile_social_networks -> vaswani_2017_attention_is_all_you_need	[pos="e,587.99,510.31 588,510.27 588,510.28 588,510.29 587.99,510.29"];
	chang_2021_ta_bilstm_an_interpretable_topic_aware_model_for_misleading_information_detection_in_mobile_social_networks -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,622.8,377.11 622.77,377.4 622.77,377.36 622.78,377.31 622.78,377.26"];
	chang_2021_ta_bilstm_an_interpretable_topic_aware_model_for_misleading_information_detection_in_mobile_social_networks -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.7,389.54 577.79,389.67 577.77,389.64 577.75,389.62 577.74,389.6"];
	chang_2021_ta_bilstm_an_interpretable_topic_aware_model_for_misleading_information_detection_in_mobile_social_networks -> hu_2020_neural_topic_modeling_with_cycle_consistent_adversarial_training	[pos="e,660.13,391.85 659.91,392.13 659.95,392.08 659.98,392.04 660.02,391.99"];
	chang_2021_ta_bilstm_an_interpretable_topic_aware_model_for_misleading_information_detection_in_mobile_social_networks -> wang_2020_neural_topic_modeling_with_bidirectional_adversarial_training	[pos="e,648.32,389.51 648.25,389.64 648.26,389.61 648.28,389.58 648.29,389.56"];
	chang_2021_ta_bilstm_an_interpretable_topic_aware_model_for_misleading_information_detection_in_mobile_social_networks -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,554.42,489.19 554.83,488.93 554.76,488.97 554.69,489.02 554.63,489.06"];
	chang_2021_ta_bilstm_an_interpretable_topic_aware_model_for_misleading_information_detection_in_mobile_social_networks -> wang_2019_open_event_extraction_from_online_text_using_a_generative_adversarial_network	[pos="e,688.32,446.52 687.84,446.54 687.92,446.54 688,446.53 688.08,446.53"];
	zhao_2021_adversarial_learning_of_poisson_factorisation_model_for_gauging_brand_sentiment_in_user_reviews	[color=blue,
		height=2,
		id=zhao_2021_adversarial_learning_of_poisson_factorisation_model_for_gauging_brand_sentiment_in_user_reviews,
		"k-core"=7,
		label=zhao_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-4773.516144415059,6419.777366212179!"];
	zhao_2021_adversarial_learning_of_poisson_factorisation_model_for_gauging_brand_sentiment_in_user_reviews -> he_2017_an_unsupervised_neural_attention_model_for_aspect_extraction	[pos="e,537.43,374.85 537.82,374.56 537.75,374.61 537.69,374.66 537.63,374.7"];
	zhao_2021_adversarial_learning_of_poisson_factorisation_model_for_gauging_brand_sentiment_in_user_reviews -> jang_2016_categorical_reparameterization_with_gumbel_softmax	[pos="e,527.04,354.53 527.36,354.43 527.31,354.44 527.25,354.46 527.2,354.48"];
	zhao_2021_adversarial_learning_of_poisson_factorisation_model_for_gauging_brand_sentiment_in_user_reviews -> card_2017_neural_models_for_documents_with_metadata	[pos="e,615.35,384.91 615.3,384.8 615.31,384.82 615.32,384.84 615.33,384.86"];
	zhao_2021_adversarial_learning_of_poisson_factorisation_model_for_gauging_brand_sentiment_in_user_reviews -> card_2018_neural_models_for_documents_with_metadata	[pos="e,608.07,386.78 608.04,386.66 608.05,386.69 608.05,386.71 608.06,386.73"];
	zhao_2021_adversarial_learning_of_poisson_factorisation_model_for_gauging_brand_sentiment_in_user_reviews -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,623.26,372.34 623.2,372.25 623.22,372.27 623.23,372.28 623.24,372.3"];
	zhao_2021_adversarial_learning_of_poisson_factorisation_model_for_gauging_brand_sentiment_in_user_reviews -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.69,389.46 577.73,389.33 577.72,389.36 577.71,389.38 577.71,389.41"];
	zhao_2021_adversarial_learning_of_poisson_factorisation_model_for_gauging_brand_sentiment_in_user_reviews -> hu_2020_neural_topic_modeling_with_cycle_consistent_adversarial_training	[pos="e,655.13,373.39 654.77,373.14 654.83,373.18 654.89,373.22 654.95,373.26"];
	zhao_2021_adversarial_learning_of_poisson_factorisation_model_for_gauging_brand_sentiment_in_user_reviews -> wang_2020_neural_topic_modeling_with_bidirectional_adversarial_training	[pos="e,644.69,385.42 644.22,384.9 644.3,384.99 644.38,385.07 644.46,385.16"];
	zhao_2021_adversarial_learning_of_poisson_factorisation_model_for_gauging_brand_sentiment_in_user_reviews -> john_2018_disentangled_representation_learning_for_non_parallel_text_style_transfer	[pos="e,659.54,366.02 659.1,365.78 659.18,365.82 659.25,365.86 659.32,365.9"];
	zhao_2021_adversarial_learning_of_poisson_factorisation_model_for_gauging_brand_sentiment_in_user_reviews -> wang_2018_atmadversarial_neural_topic_model	[pos="e,631.68,394.14 631.51,393.84 631.54,393.89 631.57,393.94 631.6,393.99"];
	huang_2022_few_shot_fine_grained_entity_typing_with_automatic_label_interpretation_and_instance_generation	[color=yellow,
		height=2,
		id=huang_2022_few_shot_fine_grained_entity_typing_with_automatic_label_interpretation_and_instance_generation,
		"k-core"=6,
		label=huang_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-0.6217250185122287,0.7832356061910674!"];
	huang_2022_few_shot_fine_grained_entity_typing_with_automatic_label_interpretation_and_instance_generation -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.09,520.51 580.06,521 580.06,520.91 580.07,520.83 580.07,520.75"];
	huang_2022_few_shot_fine_grained_entity_typing_with_automatic_label_interpretation_and_instance_generation -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,615.93,532.69 615.74,532.97 615.77,532.93 615.8,532.88 615.83,532.83"];
	huang_2022_few_shot_fine_grained_entity_typing_with_automatic_label_interpretation_and_instance_generation -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.73,532.57 612.71,532.6 612.71,532.6 612.72,532.59 612.72,532.59"];
	huang_2022_few_shot_fine_grained_entity_typing_with_automatic_label_interpretation_and_instance_generation -> meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding	[pos="e,520.68,546.03 520.95,546.26 520.91,546.22 520.86,546.18 520.82,546.14"];
	huang_2022_few_shot_fine_grained_entity_typing_with_automatic_label_interpretation_and_instance_generation -> meng_2020_text_classification_using_label_names_only_a_language_model_self_training_approach	[pos="e,533.8,547.49 533.89,547.59 533.87,547.57 533.85,547.55 533.84,547.53"];
	sircar_2022_distantly_supervised_aspect_clustering_and_naming_for_e_commerce_reviews	[color=yellow,
		height=2,
		id=sircar_2022_distantly_supervised_aspect_clustering_and_naming_for_e_commerce_reviews,
		"k-core"=6,
		label=sircar_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-0.6461407498778364,0.7632182803657603!"];
	sircar_2022_distantly_supervised_aspect_clustering_and_naming_for_e_commerce_reviews -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,562.89,519.92 562.4,519.95 562.49,519.95 562.57,519.94 562.65,519.94"];
	sircar_2022_distantly_supervised_aspect_clustering_and_naming_for_e_commerce_reviews -> he_2017_an_unsupervised_neural_attention_model_for_aspect_extraction	[pos="e,476.52,452.98 476.59,453.36 476.58,453.3 476.57,453.24 476.56,453.17"];
	sircar_2022_distantly_supervised_aspect_clustering_and_naming_for_e_commerce_reviews -> xu_2018_double_embeddings_and_cnn_based_sequence_labeling_for_aspect_extraction	[pos="e,433.6,479.01 433.93,479.27 433.88,479.23 433.82,479.18 433.77,479.14"];
	sircar_2022_distantly_supervised_aspect_clustering_and_naming_for_e_commerce_reviews -> lewis_2019_bart_denoising_sequence_to_sequence_pre_training_for_natural_language_generation_translation_and_comprehension	[pos="e,562.14,535.25 561.73,535.19 561.8,535.2 561.87,535.21 561.93,535.22"];
	sircar_2022_distantly_supervised_aspect_clustering_and_naming_for_e_commerce_reviews -> peters_2018_deep_contextualized_word_representations	[pos="e,562.82,528.66 562.53,528.65 562.58,528.65 562.63,528.65 562.67,528.65"];
	sircar_2022_distantly_supervised_aspect_clustering_and_naming_for_e_commerce_reviews -> pablos_2018_w2vlda_almost_unsupervised_system_for_aspect_based_sentiment_analysis	[pos="e,441.79,470.19 442.11,470.54 442.06,470.48 442,470.42 441.95,470.37"];
	meng_2021_on_the_power_of_pre_trained_text_representations_models_and_applications_in_text_mining	[color=green,
		height=2,
		id=meng_2021_on_the_power_of_pre_trained_text_representations_models_and_applications_in_text_mining,
		"k-core"=8,
		label=meng_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-3465.081132956328,3604.609950398792!"];
	meng_2021_on_the_power_of_pre_trained_text_representations_models_and_applications_in_text_mining -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.17,518.86 580.14,518.88 580.15,518.87 580.15,518.87 580.16,518.87"];
	meng_2021_on_the_power_of_pre_trained_text_representations_models_and_applications_in_text_mining -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,590.35,536.96 590.04,537.02 590.09,537.01 590.14,537 590.2,536.99"];
	meng_2021_on_the_power_of_pre_trained_text_representations_models_and_applications_in_text_mining -> peters_2018_deep_contextualized_word_representations	[pos="e,583.75,529.89 583.72,529.9 583.73,529.9 583.73,529.9 583.74,529.89"];
	meng_2021_on_the_power_of_pre_trained_text_representations_models_and_applications_in_text_mining -> meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding	[pos="e,476.13,507.82 476.23,507.91 476.2,507.89 476.19,507.87 476.17,507.86"];
	meng_2021_on_the_power_of_pre_trained_text_representations_models_and_applications_in_text_mining -> meng_2019_spherical_text_embedding	[pos="e,500.03,530.13 500.07,530.17 500.06,530.16 500.05,530.15 500.04,530.14"];
	meng_2021_on_the_power_of_pre_trained_text_representations_models_and_applications_in_text_mining -> meng_2018_weakly_supervised_neural_text_classification	[pos="e,474.39,580.67 474.48,580.61 474.46,580.62 474.44,580.63 474.43,580.64"];
	meng_2021_on_the_power_of_pre_trained_text_representations_models_and_applications_in_text_mining -> nickel_2017_poincare_embeddings_for_learning_hierarchical_representations	[pos="e,449.99,528.05 450.3,528.15 450.25,528.13 450.2,528.11 450.14,528.1"];
	meng_2021_on_the_power_of_pre_trained_text_representations_models_and_applications_in_text_mining -> tifrea_2018_poincare_glove_hyperbolic_word_embeddings	[pos="e,460.76,507.34 461.19,507.67 461.12,507.61 461.05,507.56 460.98,507.5"];
	meng_2021_on_the_power_of_pre_trained_text_representations_models_and_applications_in_text_mining -> meng_2018_weakly_supervised_hierarchical_text_classification	[pos="e,466.42,568.65 466.54,568.62 466.51,568.62 466.49,568.63 466.47,568.64"];
	meng_2021_on_the_power_of_pre_trained_text_representations_models_and_applications_in_text_mining -> meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding	[pos="e,511.61,523.28 511.63,523.34 511.62,523.32 511.62,523.31 511.62,523.3"];
	meng_2021_on_the_power_of_pre_trained_text_representations_models_and_applications_in_text_mining -> huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring	[pos="e,503.19,556.98 503.22,556.96 503.21,556.97 503.21,556.97 503.2,556.97"];
	meng_2021_on_the_power_of_pre_trained_text_representations_models_and_applications_in_text_mining -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,523.42,509.57 523.41,509.66 523.41,509.64 523.41,509.62 523.42,509.61"];
	meng_2021_on_the_power_of_pre_trained_text_representations_models_and_applications_in_text_mining -> huang_2020_weakly_supervised_aspect_based_sentiment_analysis_via_joint_aspect_sentiment_topic_embedding	[pos="e,480.42,502.73 480.5,502.83 480.48,502.81 480.47,502.79 480.45,502.77"];
	meng_2021_on_the_power_of_pre_trained_text_representations_models_and_applications_in_text_mining -> meng_2020_text_classification_using_label_names_only_a_language_model_self_training_approach	[pos="e,533.73,547.47 533.6,547.5 533.63,547.49 533.66,547.49 533.68,547.48"];
	meng_2021_on_the_power_of_pre_trained_text_representations_models_and_applications_in_text_mining -> shen_2021_taxoclass_hierarchical_multi_label_text_classification_using_only_class_names	[pos="e,552.91,581.75 552.84,581.69 552.86,581.7 552.87,581.71 552.88,581.72"];
	meng_2022_adapting_pretrained_representations_for_text_mining	[color=green,
		height=2,
		id=meng_2022_adapting_pretrained_representations_for_text_mining,
		"k-core"=8,
		label=meng_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-3685.645438156461,3378.7596072907068!"];
	meng_2022_adapting_pretrained_representations_for_text_mining -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.16,518.88 580.09,518.97 580.1,518.95 580.12,518.94 580.13,518.92"];
	meng_2022_adapting_pretrained_representations_for_text_mining -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,608.11,524.33 607.82,524.5 607.87,524.47 607.92,524.44 607.97,524.41"];
	meng_2022_adapting_pretrained_representations_for_text_mining -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.63,532.61 612.31,532.74 612.38,532.71 612.44,532.69 612.49,532.66"];
	meng_2022_adapting_pretrained_representations_for_text_mining -> meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding	[pos="e,487.87,516.8 488.2,517.05 488.15,517.01 488.09,516.97 488.03,516.92"];
	meng_2022_adapting_pretrained_representations_for_text_mining -> meng_2019_spherical_text_embedding	[pos="e,500.05,530.13 500.14,530.2 500.12,530.18 500.1,530.17 500.09,530.16"];
	meng_2022_adapting_pretrained_representations_for_text_mining -> meng_2018_weakly_supervised_neural_text_classification	[pos="e,474.74,580.59 475.84,580.28 475.6,580.35 475.39,580.41 475.2,580.46"];
	meng_2022_adapting_pretrained_representations_for_text_mining -> tifrea_2018_poincare_glove_hyperbolic_word_embeddings	[pos="e,484.36,521.15 484.85,521.47 484.77,521.42 484.69,521.37 484.61,521.31"];
	meng_2022_adapting_pretrained_representations_for_text_mining -> meng_2018_weakly_supervised_hierarchical_text_classification	[pos="e,473.01,568.02 473.41,567.98 473.34,567.99 473.28,568 473.21,568"];
	meng_2022_adapting_pretrained_representations_for_text_mining -> meng_2019_discriminative_topic_mining_via_category_name_guided_text_embedding	[pos="e,511.63,523.28 511.7,523.36 511.69,523.35 511.67,523.33 511.66,523.32"];
	meng_2022_adapting_pretrained_representations_for_text_mining -> huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring	[pos="e,503.21,556.98 503.3,556.99 503.28,556.99 503.26,556.99 503.24,556.99"];
	meng_2022_adapting_pretrained_representations_for_text_mining -> meng_2020_text_classification_using_label_names_only_a_language_model_self_training_approach	[pos="e,533.8,547.5 533.9,547.61 533.88,547.59 533.86,547.57 533.85,547.55"];
	meng_2022_adapting_pretrained_representations_for_text_mining -> shen_2021_taxoclass_hierarchical_multi_label_text_classification_using_only_class_names	[pos="e,552.93,581.76 552.92,581.71 552.92,581.72 552.92,581.73 552.93,581.74"];
	meng_2022_adapting_pretrained_representations_for_text_mining -> meng_2022_topic_discovery_via_latent_space_clustering_of_pretrained_language_model_representations	[pos="e,554.79,491.33 554.79,491.37 554.79,491.36 554.79,491.35 554.79,491.34"];
	meng_2022_adapting_pretrained_representations_for_text_mining -> huang_2022_few_shot_fine_grained_entity_typing_with_automatic_label_interpretation_and_instance_generation	[pos="e,575.69,593.2 575.62,593.13 575.64,593.15 575.65,593.16 575.66,593.17"];
	song_2021_classification_aware_neural_topic_model_for_covid_19_disinformation_categorisation	[color=green,
		height=2,
		id=song_2021_classification_aware_neural_topic_model_for_covid_19_disinformation_categorisation,
		"k-core"=8,
		label=song_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-4171.001588932998,2757.3075754113015!"];
	song_2021_classification_aware_neural_topic_model_for_covid_19_disinformation_categorisation -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,593.47,505.37 593.84,504.99 593.78,505.06 593.72,505.12 593.65,505.18"];
	song_2021_classification_aware_neural_topic_model_for_covid_19_disinformation_categorisation -> vaswani_2017_attention_is_all_you_need	[pos="e,593.29,504.99 593.62,504.66 593.56,504.72 593.51,504.77 593.45,504.83"];
	song_2021_classification_aware_neural_topic_model_for_covid_19_disinformation_categorisation -> card_2017_neural_models_for_documents_with_metadata	[pos="e,616.01,386.48 616.2,386.93 616.17,386.85 616.14,386.77 616.1,386.7"];
	song_2021_classification_aware_neural_topic_model_for_covid_19_disinformation_categorisation -> card_2018_neural_models_for_documents_with_metadata	[pos="e,609.63,389.66 609.84,390.04 609.8,389.97 609.77,389.91 609.74,389.85"];
	song_2021_classification_aware_neural_topic_model_for_covid_19_disinformation_categorisation -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,591.8,403.01 592.19,403.39 592.13,403.32 592.06,403.26 592,403.2"];
	song_2021_classification_aware_neural_topic_model_for_covid_19_disinformation_categorisation -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,633.84,381.94 633.88,382.23 633.87,382.18 633.86,382.14 633.86,382.09"];
	song_2021_classification_aware_neural_topic_model_for_covid_19_disinformation_categorisation -> zeng_2018_topic_memory_networks_for_short_text_classification	[pos="e,660.59,382.49 660.5,382.87 660.52,382.8 660.53,382.74 660.55,382.68"];
	song_2021_classification_aware_neural_topic_model_for_covid_19_disinformation_categorisation -> ding_2018_coherence_aware_neural_topic_modeling	[pos="e,658.59,382.25 658.51,382.66 658.52,382.59 658.53,382.52 658.55,382.45"];
	song_2021_classification_aware_neural_topic_model_for_covid_19_disinformation_categorisation -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,617.44,520.89 617.57,520.55 617.55,520.61 617.53,520.67 617.5,520.72"];
	song_2021_classification_aware_neural_topic_model_for_covid_19_disinformation_categorisation -> gururangan_2019_variational_pretraining_for_semi_supervised_text_classification	[pos="e,581.92,450.79 581.95,450.79 581.95,450.79 581.94,450.79 581.93,450.79"];
	avron_2022_automated_category_tree_construction_in_e_commerce	[color=yellow,
		height=2,
		id=avron_2022_automated_category_tree_construction_in_e_commerce,
		"k-core"=6,
		label=avron_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-0.8826179454702318,0.4700909827843753!"];
	avron_2022_automated_category_tree_construction_in_e_commerce -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,458.01,613.84 457.91,613.81 457.93,613.82 457.95,613.82 457.97,613.83"];
	avron_2022_automated_category_tree_construction_in_e_commerce -> nickel_2017_poincare_embeddings_for_learning_hierarchical_representations	[pos="e,441.5,534.89 441.29,535.4 441.33,535.31 441.36,535.23 441.4,535.14"];
	avron_2022_automated_category_tree_construction_in_e_commerce -> huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring	[pos="e,478.64,569.47 478.32,569.64 478.37,569.61 478.43,569.58 478.48,569.55"];
	avron_2022_automated_category_tree_construction_in_e_commerce -> yu_2020_steam_self_supervised_taxonomy_expansion_with_mini_paths	[pos="e,486.34,599.77 486.03,599.78 486.08,599.78 486.13,599.78 486.18,599.78"];
	avron_2022_automated_category_tree_construction_in_e_commerce -> shen_2020_taxoexpan_self_supervised_taxonomy_expansion_with_position_enhanced_graph_neural_network	[pos="e,485.22,587.57 484.75,587.66 484.83,587.65 484.91,587.63 484.99,587.61"];
	avron_2022_automated_category_tree_construction_in_e_commerce -> shang_2020_nettaxo_automated_topic_taxonomy_construction_from_text_rich_network	[pos="e,451.07,638.1 450.99,638.02 451.01,638.04 451.03,638.05 451.04,638.07"];
	jiang_2022_taxoenrich_self_supervised_taxonomy_completion_via_structure_semantic_representations	[color=green,
		height=2,
		id=jiang_2022_taxoenrich_self_supervised_taxonomy_completion_via_structure_semantic_representations,
		"k-core"=8,
		label=jiang_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-4552.620624123366,2067.279505829146!"];
	jiang_2022_taxoenrich_self_supervised_taxonomy_completion_via_structure_semantic_representations -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,458.07,613.88 458.15,613.99 458.13,613.97 458.12,613.95 458.1,613.93"];
	jiang_2022_taxoenrich_self_supervised_taxonomy_completion_via_structure_semantic_representations -> huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring	[pos="e,501.48,591.66 501.46,592.11 501.46,592.04 501.46,591.96 501.47,591.89"];
	jiang_2022_taxoenrich_self_supervised_taxonomy_completion_via_structure_semantic_representations -> jiang_2017_metapad_meta_pattern_discovery_from_massive_text_corpora	[pos="e,476.35,662.36 476.39,662.36 476.38,662.36 476.37,662.36 476.37,662.36"];
	jiang_2022_taxoenrich_self_supervised_taxonomy_completion_via_structure_semantic_representations -> song_2021_who_should_go_first_a_self_supervised_concept_sorting_model_for_improving_taxonomy_expansion	[pos="e,458.16,662.87 458.24,662.87 458.22,662.87 458.21,662.87 458.19,662.87"];
	jiang_2022_taxoenrich_self_supervised_taxonomy_completion_via_structure_semantic_representations -> yang_2020_co_embedding_network_nodes_and_hierarchical_labels_with_taxonomy_based_generative_adversarial_networks	[pos="e,433.62,630.67 433.94,630.84 433.88,630.81 433.83,630.79 433.78,630.76"];
	jiang_2022_taxoenrich_self_supervised_taxonomy_completion_via_structure_semantic_representations -> manzoor_2020_expanding_taxonomies_with_implicit_edge_semantics	[pos="e,457.76,603.47 457.99,603.82 457.95,603.76 457.91,603.7 457.88,603.64"];
	jiang_2022_taxoenrich_self_supervised_taxonomy_completion_via_structure_semantic_representations -> yu_2020_steam_self_supervised_taxonomy_expansion_with_mini_paths	[pos="e,508.42,598.97 508.42,599.01 508.42,599 508.42,598.99 508.42,598.99"];
	jiang_2022_taxoenrich_self_supervised_taxonomy_completion_via_structure_semantic_representations -> shen_2020_taxoexpan_self_supervised_taxonomy_expansion_with_position_enhanced_graph_neural_network	[pos="e,501.32,591.66 501.3,592.11 501.3,592.04 501.3,591.96 501.31,591.88"];
	jiang_2022_taxoenrich_self_supervised_taxonomy_completion_via_structure_semantic_representations -> zeng_2021_enhancing_taxonomy_completion_with_concept_generation_via_fusing_relational_representations	[pos="e,534.6,604.23 534.58,604.27 534.58,604.26 534.59,604.25 534.59,604.25"];
	wang_2021_neural_labeled_lda_a_topic_model_for_semi_supervised_document_classification	[color=blue,
		height=2,
		id=wang_2021_neural_labeled_lda_a_topic_model_for_semi_supervised_document_classification,
		"k-core"=7,
		label=wang_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-7384.9801611121175,3076.0474021986897!"];
	wang_2021_neural_labeled_lda_a_topic_model_for_semi_supervised_document_classification -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,590.82,505.82 591.12,505.45 591.07,505.51 591.02,505.57 590.97,505.63"];
	wang_2021_neural_labeled_lda_a_topic_model_for_semi_supervised_document_classification -> card_2017_neural_models_for_documents_with_metadata	[pos="e,615.36,384.96 615.38,385 615.37,384.99 615.37,384.98 615.37,384.98"];
	wang_2021_neural_labeled_lda_a_topic_model_for_semi_supervised_document_classification -> burkhardt_2019_decoupling_sparsity_and_smoothness_in_the_dirichlet_variational_autoencoder_topic_model	[pos="e,640.16,376.89 640.14,377.16 640.15,377.12 640.15,377.07 640.15,377.02"];
	wang_2021_neural_labeled_lda_a_topic_model_for_semi_supervised_document_classification -> card_2018_neural_models_for_documents_with_metadata	[pos="e,608.08,386.83 608.1,386.87 608.1,386.86 608.09,386.85 608.09,386.85"];
	wang_2021_neural_labeled_lda_a_topic_model_for_semi_supervised_document_classification -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,585.45,397.35 585.91,397.82 585.84,397.74 585.76,397.66 585.68,397.59"];
	wang_2021_neural_labeled_lda_a_topic_model_for_semi_supervised_document_classification -> zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling	[pos="e,578.51,405.78 579,406.15 578.92,406.09 578.84,406.02 578.75,405.96"];
	wang_2021_neural_labeled_lda_a_topic_model_for_semi_supervised_document_classification -> wang_2020_neural_topic_modeling_with_bidirectional_adversarial_training	[pos="e,648.34,389.48 648.34,389.51 648.34,389.5 648.34,389.5 648.34,389.49"];
	su_2022_tacl_improving_bert_pre_training_with_token_aware_contrastive_learning	[color=yellow,
		height=2,
		id=su_2022_tacl_improving_bert_pre_training_with_token_aware_contrastive_learning,
		"k-core"=6,
		label=su_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-0.934800798554387,0.35517245310037066!"];
	su_2022_tacl_improving_bert_pre_training_with_token_aware_contrastive_learning -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,617.79,523.37 618.28,523.43 618.2,523.42 618.12,523.41 618.04,523.4"];
	su_2022_tacl_improving_bert_pre_training_with_token_aware_contrastive_learning -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,630.01,511.5 630.05,511.52 630.04,511.51 630.03,511.51 630.03,511.51"];
	su_2022_tacl_improving_bert_pre_training_with_token_aware_contrastive_learning -> lewis_2019_bart_denoising_sequence_to_sequence_pre_training_for_natural_language_generation_translation_and_comprehension	[pos="e,617.45,537.81 617.79,537.79 617.73,537.79 617.67,537.79 617.62,537.8"];
	su_2022_tacl_improving_bert_pre_training_with_token_aware_contrastive_learning -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,617.51,532.53 617.8,532.53 617.75,532.53 617.71,532.53 617.66,532.53"];
	su_2022_tacl_improving_bert_pre_training_with_token_aware_contrastive_learning -> wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration	[pos="e,641.19,508.56 641.29,508.61 641.27,508.6 641.25,508.59 641.23,508.58"];
	su_2022_tacl_improving_bert_pre_training_with_token_aware_contrastive_learning -> chen_2020_a_simple_framework_for_contrastive_learning_of_visual_representations	[pos="e,710.75,462.12 710.62,462.55 710.64,462.48 710.66,462.41 710.69,462.33"];
	wang_2021_hierarchical_concept_driven_language_model	[color=green,
		height=2,
		id=wang_2021_hierarchical_concept_driven_language_model,
		"k-core"=8,
		label=wang_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-4727.73579175578,1627.4256897656496!"];
	wang_2021_hierarchical_concept_driven_language_model -> see_2017_get_to_the_point_summarization_with_pointer_generator_networks	[pos="e,532.4,404.04 532.45,404.1 532.44,404.09 532.43,404.07 532.42,404.06"];
	wang_2021_hierarchical_concept_driven_language_model -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,575.5,503.3 575.37,502.86 575.39,502.93 575.41,503 575.43,503.08"];
	wang_2021_hierarchical_concept_driven_language_model -> vaswani_2017_attention_is_all_you_need	[pos="e,583.6,500.29 583.48,500 583.5,500.05 583.52,500.1 583.54,500.15"];
	wang_2021_hierarchical_concept_driven_language_model -> lau_2017_topically_driven_neural_language_model	[pos="e,558.68,375.43 558.67,375.56 558.67,375.53 558.67,375.51 558.67,375.49"];
	wang_2021_hierarchical_concept_driven_language_model -> wang_2019_topic_guided_variational_auto_encoder_for_text_generation	[pos="e,561.54,361.44 561.51,361.72 561.52,361.67 561.52,361.62 561.53,361.58"];
	wang_2021_hierarchical_concept_driven_language_model -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.66,389.53 577.61,389.63 577.62,389.61 577.63,389.59 577.64,389.57"];
	wang_2021_hierarchical_concept_driven_language_model -> zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling	[pos="e,538.84,376.22 538.87,376.35 538.86,376.32 538.86,376.3 538.85,376.28"];
	wang_2021_hierarchical_concept_driven_language_model -> wang_2017_topic_compositional_neural_language_model	[pos="e,516.03,371.04 516.74,372.2 516.58,371.94 516.44,371.72 516.33,371.53"];
	wang_2021_hierarchical_concept_driven_language_model -> dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency	[pos="e,585.57,373.55 585.56,373.58 585.56,373.58 585.56,373.57 585.57,373.56"];
	wang_2021_hierarchical_concept_driven_language_model -> cong_2017_deep_latent_dirichlet_allocation_with_topic_layer_adaptive_stochastic_gradient_riemannian_mcmc	[pos="e,502.94,382.71 503.2,382.96 503.16,382.92 503.11,382.88 503.07,382.83"];
	shen_2022_automated_taxonomy_discovery_and_exploration	[color=green,
		height=2,
		id=shen_2022_automated_taxonomy_discovery_and_exploration,
		"k-core"=8,
		label=shen_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-4860.464308460951,1172.9823703331842!"];
	shen_2022_automated_taxonomy_discovery_and_exploration -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,458.06,613.87 458.13,613.94 458.12,613.92 458.1,613.91 458.09,613.9"];
	shen_2022_automated_taxonomy_discovery_and_exploration -> shang_2017_automated_phrase_mining_from_massive_text_corpora	[pos="e,454.77,584.34 454.99,584.73 454.96,584.66 454.92,584.6 454.88,584.53"];
	shen_2022_automated_taxonomy_discovery_and_exploration -> meng_2018_weakly_supervised_hierarchical_text_classification	[pos="e,469.4,578.01 469.49,578.28 469.47,578.23 469.46,578.19 469.44,578.14"];
	shen_2022_automated_taxonomy_discovery_and_exploration -> manzoor_2020_expanding_taxonomies_with_implicit_edge_semantics	[pos="e,449.86,591.5 449.95,591.62 449.93,591.6 449.91,591.57 449.9,591.55"];
	shen_2022_automated_taxonomy_discovery_and_exploration -> yu_2020_steam_self_supervised_taxonomy_expansion_with_mini_paths	[pos="e,508.41,599 508.38,599.1 508.39,599.08 508.39,599.06 508.4,599.04"];
	shen_2022_automated_taxonomy_discovery_and_exploration -> shen_2020_taxoexpan_self_supervised_taxonomy_expansion_with_position_enhanced_graph_neural_network	[pos="e,501.67,584.15 501.66,584.18 501.66,584.17 501.66,584.17 501.67,584.16"];
	shen_2022_automated_taxonomy_discovery_and_exploration -> shang_2020_nettaxo_automated_topic_taxonomy_construction_from_text_rich_network	[pos="e,451.13,638.13 451.22,638.15 451.2,638.15 451.18,638.14 451.17,638.14"];
	shen_2022_automated_taxonomy_discovery_and_exploration -> zeng_2021_enhancing_taxonomy_completion_with_concept_generation_via_fusing_relational_representations	[pos="e,534.58,604.25 534.48,604.34 534.5,604.32 534.52,604.31 534.54,604.29"];
	shen_2022_automated_taxonomy_discovery_and_exploration -> meng_2020_text_classification_using_label_names_only_a_language_model_self_training_approach	[pos="e,520.06,579.92 519.88,580.35 519.91,580.28 519.94,580.21 519.97,580.14"];
	shen_2022_automated_taxonomy_discovery_and_exploration -> shen_2021_taxoclass_hierarchical_multi_label_text_classification_using_only_class_names	[pos="e,541.45,594.02 541.13,594.36 541.18,594.3 541.24,594.25 541.29,594.19"];
	yin_2022_improving_deep_embedded_clustering_via_learning_cluster_level_representations	[color=green,
		height=2,
		id=yin_2022_improving_deep_embedded_clustering_via_learning_cluster_level_representations,
		"k-core"=8,
		label=yin_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-4924.798283606233,863.9220061873334!"];
	yin_2022_improving_deep_embedded_clustering_via_learning_cluster_level_representations -> see_2017_get_to_the_point_summarization_with_pointer_generator_networks	[pos="e,538.45,404.4 538.82,404.42 538.75,404.42 538.69,404.41 538.63,404.41"];
	yin_2022_improving_deep_embedded_clustering_via_learning_cluster_level_representations -> reimers_2019_sentence_bert_sentence_embeddings_using_siamese_bert_networks	[pos="e,606.75,481.46 606.77,481.19 606.77,481.23 606.76,481.28 606.76,481.32"];
	yin_2022_improving_deep_embedded_clustering_via_learning_cluster_level_representations -> wang_2019_topic_guided_variational_auto_encoder_for_text_generation	[pos="e,562.87,352.5 564.06,353.91 563.93,353.75 563.81,353.61 563.7,353.48"];
	yin_2022_improving_deep_embedded_clustering_via_learning_cluster_level_representations -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,553.87,414.41 553.99,414.39 553.96,414.4 553.94,414.4 553.92,414.4"];
	yin_2022_improving_deep_embedded_clustering_via_learning_cluster_level_representations -> wang_2020_friendly_topic_assistant_for_transformer_based_abstractive_summarization	[pos="e,602.52,462.44 602.54,462.33 602.54,462.35 602.53,462.38 602.53,462.4"];
	yin_2022_improving_deep_embedded_clustering_via_learning_cluster_level_representations -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.7,389.51 577.77,389.56 577.76,389.55 577.74,389.54 577.73,389.53"];
	yin_2022_improving_deep_embedded_clustering_via_learning_cluster_level_representations -> zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling	[pos="e,544.62,378.82 544.98,378.98 544.92,378.95 544.86,378.92 544.8,378.9"];
	yin_2022_improving_deep_embedded_clustering_via_learning_cluster_level_representations -> dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency	[pos="e,585.6,373.57 585.65,373.64 585.64,373.62 585.63,373.61 585.62,373.6"];
	yin_2022_improving_deep_embedded_clustering_via_learning_cluster_level_representations -> tang_2019_a_topic_augmented_text_generation_model_joint_learning_of_semantics_and_structural_features	[pos="e,590.48,339.05 590.6,339.44 590.58,339.37 590.56,339.31 590.54,339.24"];
	yin_2022_improving_deep_embedded_clustering_via_learning_cluster_level_representations -> zeng_2018_topic_memory_networks_for_short_text_classification	[pos="e,663.34,357.97 662.88,358.41 662.96,358.34 663.04,358.26 663.11,358.19"];
	yin_2022_improving_deep_embedded_clustering_via_learning_cluster_level_representations -> cong_2017_deep_latent_dirichlet_allocation_with_topic_layer_adaptive_stochastic_gradient_riemannian_mcmc	[pos="e,542.61,384.69 542.96,384.82 542.91,384.8 542.85,384.78 542.79,384.76"];
	yin_2022_improving_deep_embedded_clustering_via_learning_cluster_level_representations -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.01,481.54 612,481.22 612,481.27 612,481.32 612.01,481.38"];
	yin_2022_improving_deep_embedded_clustering_via_learning_cluster_level_representations -> devlin_2018_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,612.78,481.74 612.77,481.39 612.78,481.45 612.78,481.51 612.78,481.57"];
	yin_2022_improving_deep_embedded_clustering_via_learning_cluster_level_representations -> zhang_2021_supporting_clustering_with_contrastive_learning	[pos="e,646.24,472.75 645.99,472.3 646.03,472.37 646.07,472.45 646.11,472.52"];
	yin_2022_improving_deep_embedded_clustering_via_learning_cluster_level_representations -> chen_2020_a_simple_framework_for_contrastive_learning_of_visual_representations	[pos="e,679.54,433.93 679.07,433.77 679.15,433.79 679.23,433.82 679.31,433.85"];
	wang_2019_topic_guided_variational_autoencoders_for_text_generation	[color=blue,
		height=2,
		id=wang_2019_topic_guided_variational_autoencoders_for_text_generation,
		"k-core"=7,
		label=wang_2019,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-7951.2013968001775,882.2685354992998!"];
	yin_2022_improving_deep_embedded_clustering_via_learning_cluster_level_representations -> wang_2019_topic_guided_variational_autoencoders_for_text_generation	[pos="e,573.74,346.62 573.96,346.99 573.92,346.93 573.89,346.87 573.85,346.81"];
	wang_2019_topic_guided_variational_autoencoders_for_text_generation -> see_2017_get_to_the_point_summarization_with_pointer_generator_networks	[pos="e,536.86,388.34 536.98,387.89 536.96,387.97 536.94,388.04 536.92,388.12"];
	wang_2019_topic_guided_variational_autoencoders_for_text_generation -> lau_2017_topically_driven_neural_language_model	[pos="e,558.68,375.35 558.67,375.23 558.68,375.25 558.68,375.28 558.68,375.3"];
	wang_2019_topic_guided_variational_autoencoders_for_text_generation -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.54,389.05 577.16,387.74 577.2,387.88 577.24,388.02 577.28,388.14"];
	wang_2019_topic_guided_variational_autoencoders_for_text_generation -> wang_2017_topic_compositional_neural_language_model	[pos="e,515.81,370.6 515.9,370.48 515.88,370.51 515.86,370.53 515.84,370.55"];
	wang_2019_topic_guided_variational_autoencoders_for_text_generation -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,619.75,354.45 619.44,354.27 619.49,354.3 619.54,354.33 619.6,354.36"];
	wang_2019_topic_guided_variational_autoencoders_for_text_generation -> dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency	[pos="e,585.56,373.5 585.5,373.38 585.51,373.41 585.52,373.43 585.53,373.45"];
	wang_2019_topic_guided_variational_autoencoders_for_text_generation -> yang_2017_improved_variational_autoencoders_for_text_modeling_using_dilated_convolutions	[pos="e,519.01,331.19 519.09,331.16 519.08,331.17 519.06,331.18 519.05,331.18"];
	tan_2022_enhancing_recommendation_with_automated_tag_taxonomy_construction_in_hyperbolic_space	[color=yellow,
		height=2,
		id=tan_2022_enhancing_recommendation_with_automated_tag_taxonomy_construction_in_hyperbolic_space,
		"k-core"=6,
		label=tan_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-0.9988786525417459,0.04734310740510689!"];
	tan_2022_enhancing_recommendation_with_automated_tag_taxonomy_construction_in_hyperbolic_space -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,438.92,607.07 438.65,606.98 438.7,606.99 438.74,607.01 438.79,607.03"];
	tan_2022_enhancing_recommendation_with_automated_tag_taxonomy_construction_in_hyperbolic_space -> nickel_2017_poincare_embeddings_for_learning_hierarchical_representations	[pos="e,428.58,538.86 428.12,539.2 428.2,539.15 428.27,539.09 428.35,539.03"];
	tan_2022_enhancing_recommendation_with_automated_tag_taxonomy_construction_in_hyperbolic_space -> nickel_2018_learning_continuous_hierarchies_in_the_lorentz_model_of_hyperbolic_geometry	[pos="e,403.95,518.22 403.74,518.63 403.77,518.56 403.81,518.5 403.84,518.43"];
	tan_2022_enhancing_recommendation_with_automated_tag_taxonomy_construction_in_hyperbolic_space -> ganea_2018_hyperbolic_entailment_cones_for_learning_hierarchical_embeddings	[pos="e,411.9,522.75 411.63,523.15 411.67,523.08 411.72,523.01 411.76,522.95"];
	tan_2022_enhancing_recommendation_with_automated_tag_taxonomy_construction_in_hyperbolic_space -> yang_2020_co_embedding_network_nodes_and_hierarchical_labels_with_taxonomy_based_generative_adversarial_networks	[pos="e,422.44,624.83 422.33,624.74 422.36,624.76 422.38,624.77 422.4,624.79"];
	tan_2022_enhancing_recommendation_with_automated_tag_taxonomy_construction_in_hyperbolic_space -> shang_2020_nettaxo_automated_topic_taxonomy_construction_from_text_rich_network	[pos="e,430.67,624.09 430.39,623.9 430.44,623.93 430.49,623.97 430.53,624"];
	li_2019_a_review_of_text_corpus_based_tourism_big_data_mining	[color=yellow,
		height=4.7778,
		id=li_2019_a_review_of_text_corpus_based_tourism_big_data_mining,
		"k-core"=6,
		label=li_2019,
		shape=circle,
		style=filled,
		width=4.7778,
		zazaza="-0.9720928616921901,-0.23459641700791925!"];
	li_2019_a_review_of_text_corpus_based_tourism_big_data_mining -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.16,518.83 580.08,518.76 580.1,518.78 580.11,518.79 580.13,518.8"];
	li_2019_a_review_of_text_corpus_based_tourism_big_data_mining -> vaswani_2017_attention_is_all_you_need	[pos="e,587.95,510.3 587.86,510.25 587.88,510.26 587.9,510.27 587.91,510.28"];
	li_2019_a_review_of_text_corpus_based_tourism_big_data_mining -> he_2017_an_unsupervised_neural_attention_model_for_aspect_extraction	[pos="e,471.08,424.46 471.12,424.49 471.11,424.49 471.1,424.48 471.09,424.47"];
	li_2019_a_review_of_text_corpus_based_tourism_big_data_mining -> lau_2017_topically_driven_neural_language_model	[pos="e,558.68,375.41 558.67,375.47 558.67,375.46 558.67,375.45 558.67,375.44"];
	li_2019_a_review_of_text_corpus_based_tourism_big_data_mining -> dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency	[pos="e,585.57,373.56 585.55,373.62 585.55,373.61 585.56,373.6 585.56,373.59"];
	li_2019_a_review_of_text_corpus_based_tourism_big_data_mining -> peters_2018_deep_contextualized_word_representations	[pos="e,583.74,529.86 583.65,529.76 583.67,529.78 583.69,529.8 583.7,529.82"];
	zhang_2022_pre_training_and_fine_tuning_neural_topic_model_a_simple_yet_effective_approach_to_incorporating_external_knowledge	[color=red,
		height=2,
		id=zhang_2022_pre_training_and_fine_tuning_neural_topic_model_a_simple_yet_effective_approach_to_incorporating_external_knowledge,
		"k-core"=9,
		label=zhang_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-65.43605172648196,-24.862082326053645!"];
	zhang_2022_pre_training_and_fine_tuning_neural_topic_model_a_simple_yet_effective_approach_to_incorporating_external_knowledge -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.19,518.84 580.19,518.81 580.19,518.82 580.19,518.82 580.19,518.83"];
	zhang_2022_pre_training_and_fine_tuning_neural_topic_model_a_simple_yet_effective_approach_to_incorporating_external_knowledge -> vaswani_2017_attention_is_all_you_need	[pos="e,587.98,510.28 587.98,510.17 587.98,510.19 587.98,510.21 587.98,510.23"];
	zhang_2022_pre_training_and_fine_tuning_neural_topic_model_a_simple_yet_effective_approach_to_incorporating_external_knowledge -> card_2017_neural_models_for_documents_with_metadata	[pos="e,613.46,389.86 613.34,390.16 613.36,390.11 613.38,390.06 613.4,390.01"];
	zhang_2022_pre_training_and_fine_tuning_neural_topic_model_a_simple_yet_effective_approach_to_incorporating_external_knowledge -> card_2018_neural_models_for_documents_with_metadata	[pos="e,607.99,387.13 607.72,388.04 607.78,387.85 607.83,387.67 607.87,387.52"];
	zhang_2022_pre_training_and_fine_tuning_neural_topic_model_a_simple_yet_effective_approach_to_incorporating_external_knowledge -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,553.85,414.44 553.92,414.53 553.9,414.51 553.89,414.49 553.88,414.48"];
	zhang_2022_pre_training_and_fine_tuning_neural_topic_model_a_simple_yet_effective_approach_to_incorporating_external_knowledge -> hoyle_2020_improving_neural_topic_models_using_knowledge_distillation	[pos="e,621.58,437.26 621.51,437.31 621.52,437.3 621.54,437.29 621.55,437.28"];
	zhang_2022_pre_training_and_fine_tuning_neural_topic_model_a_simple_yet_effective_approach_to_incorporating_external_knowledge -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,615.69,390.31 615.47,390.81 615.51,390.73 615.54,390.65 615.58,390.56"];
	zhang_2022_pre_training_and_fine_tuning_neural_topic_model_a_simple_yet_effective_approach_to_incorporating_external_knowledge -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.68,389.51 577.68,389.55 577.68,389.54 577.68,389.53 577.68,389.53"];
	zhang_2022_pre_training_and_fine_tuning_neural_topic_model_a_simple_yet_effective_approach_to_incorporating_external_knowledge -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,617.11,390.9 616.93,391.3 616.96,391.23 616.99,391.17 617.02,391.1"];
	zhang_2022_pre_training_and_fine_tuning_neural_topic_model_a_simple_yet_effective_approach_to_incorporating_external_knowledge -> hu_2020_neural_topic_modeling_with_cycle_consistent_adversarial_training	[pos="e,640.32,407.78 639.97,408.11 640.03,408.06 640.09,408 640.15,407.95"];
	zhang_2022_pre_training_and_fine_tuning_neural_topic_model_a_simple_yet_effective_approach_to_incorporating_external_knowledge -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,629.97,511.46 629.88,511.35 629.9,511.37 629.92,511.39 629.93,511.41"];
	zhang_2022_pre_training_and_fine_tuning_neural_topic_model_a_simple_yet_effective_approach_to_incorporating_external_knowledge -> peters_2018_deep_contextualized_word_representations	[pos="e,583.77,529.83 583.77,529.68 583.77,529.71 583.77,529.74 583.77,529.77"];
	zhang_2022_pre_training_and_fine_tuning_neural_topic_model_a_simple_yet_effective_approach_to_incorporating_external_knowledge -> meng_2019_spherical_text_embedding	[pos="e,531.61,503.78 532.02,503.44 531.95,503.5 531.88,503.56 531.82,503.61"];
	wang_2020_knowledge_efficient_deep_learning_for_natural_language_processing	[color=yellow,
		height=2,
		id=wang_2020_knowledge_efficient_deep_learning_for_natural_language_processing,
		"k-core"=6,
		label=wang_2020,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-0.8826180050748763,-0.47009092572565764!"];
	wang_2020_knowledge_efficient_deep_learning_for_natural_language_processing -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.17,518.86 580.12,518.88 580.13,518.87 580.14,518.87 580.15,518.87"];
	wang_2020_knowledge_efficient_deep_learning_for_natural_language_processing -> vaswani_2017_attention_is_all_you_need	[pos="e,587.96,510.33 587.89,510.37 587.91,510.36 587.92,510.35 587.93,510.35"];
	wang_2020_knowledge_efficient_deep_learning_for_natural_language_processing -> lau_2017_topically_driven_neural_language_model	[pos="e,557.48,453.53 557.47,453.99 557.47,453.91 557.47,453.84 557.47,453.76"];
	wang_2020_knowledge_efficient_deep_learning_for_natural_language_processing -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,627.53,512 627.21,512.07 627.26,512.06 627.32,512.04 627.37,512.03"];
	wang_2020_knowledge_efficient_deep_learning_for_natural_language_processing -> peters_2018_deep_contextualized_word_representations	[pos="e,583.74,529.88 583.69,529.88 583.7,529.88 583.71,529.88 583.72,529.88"];
	wang_2020_knowledge_efficient_deep_learning_for_natural_language_processing -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,523.45,509.55 523.52,509.59 523.5,509.58 523.49,509.57 523.48,509.57"];
	zhang_2022_lifelong_topic_modeling_with_knowledge_enhanced_adversarial_network	[color=yellow,
		height=2,
		id=zhang_2022_lifelong_topic_modeling_with_knowledge_enhanced_adversarial_network,
		"k-core"=6,
		label=zhang_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-0.8342004369958887,-0.5514613984188981!"];
	zhang_2022_lifelong_topic_modeling_with_knowledge_enhanced_adversarial_network -> hoyle_2020_improving_neural_topic_models_using_knowledge_distillation	[pos="e,640.93,417.65 641.19,417.39 641.14,417.43 641.1,417.48 641.06,417.52"];
	zhang_2022_lifelong_topic_modeling_with_knowledge_enhanced_adversarial_network -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,623.29,372.37 623.33,372.36 623.32,372.36 623.32,372.36 623.31,372.36"];
	zhang_2022_lifelong_topic_modeling_with_knowledge_enhanced_adversarial_network -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,620.91,380.59 621.19,380.53 621.14,380.54 621.1,380.55 621.05,380.56"];
	zhang_2022_lifelong_topic_modeling_with_knowledge_enhanced_adversarial_network -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,630.66,360.71 630.69,360.72 630.69,360.72 630.68,360.72 630.67,360.71"];
	zhang_2022_lifelong_topic_modeling_with_knowledge_enhanced_adversarial_network -> hu_2020_neural_topic_modeling_with_cycle_consistent_adversarial_training	[pos="e,667.63,382.25 667.68,382.21 667.67,382.22 667.66,382.23 667.65,382.23"];
	zhang_2022_lifelong_topic_modeling_with_knowledge_enhanced_adversarial_network -> wang_2020_neural_topic_modeling_with_bidirectional_adversarial_training	[pos="e,648.37,389.45 648.47,389.4 648.45,389.41 648.43,389.42 648.41,389.43"];
	zhang_2022_lifelong_topic_modeling_with_knowledge_enhanced_adversarial_network -> wang_2019_open_event_extraction_from_online_text_using_a_generative_adversarial_network	[pos="e,720.14,432.81 719.99,432.46 720.02,432.51 720.04,432.57 720.07,432.63"];
	zandie_2022_topical_language_generation_using_transformers	[color=yellow,
		height=2,
		id=zandie_2022_topical_language_generation_using_transformers,
		"k-core"=6,
		label=zandie_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-0.797737295650789,-0.6030051705034585!"];
	zandie_2022_topical_language_generation_using_transformers -> vaswani_2017_attention_is_all_you_need	[pos="e,624.05,496.92 624.52,496.74 624.44,496.77 624.36,496.8 624.29,496.83"];
	zandie_2022_topical_language_generation_using_transformers -> holtzman_2019_the_curious_case_of_neural_text_degeneration	[pos="e,677.98,492.21 678.01,492.16 678.01,492.17 678,492.18 678,492.19"];
	zandie_2022_topical_language_generation_using_transformers -> reimers_2019_sentence_bert_sentence_embeddings_using_siamese_bert_networks	[pos="e,621.6,487.15 622.04,487.05 621.97,487.07 621.89,487.09 621.82,487.1"];
	zandie_2022_topical_language_generation_using_transformers -> lau_2017_topically_driven_neural_language_model	[pos="e,633.35,429.04 633.78,429.35 633.7,429.3 633.63,429.25 633.56,429.2"];
	zandie_2022_topical_language_generation_using_transformers -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,630.4,511.25 631.55,510.51 631.3,510.67 631.08,510.81 630.89,510.94"];
	zandie_2022_topical_language_generation_using_transformers -> keskar_2019_ctrl_a_conditional_transformer_language_model_for_controllable_generation	[pos="e,655.61,519.14 655.69,519.04 655.67,519.06 655.66,519.08 655.65,519.09"];
	"terragni_2022_one_configuration_to_rule_them_all_towards_hyperparameter_transfer_in_topic_models_using_multi_objective_bayesian_\
optimization"	[color=blue,
		height=2,
		id="\"terragni_2022_one_configuration_to_rule_them_all_towards_hyperparameter_transfer_in_topic_models_using_multi_objective_bayesian_\
optimization\"",
		"k-core"=7,
		label=terragni_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-6226.429424881813,-5023.104187751504!"];
	"terragni_2022_one_configuration_to_rule_them_all_towards_hyperparameter_transfer_in_topic_models_using_multi_objective_bayesian_\
optimization" -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,604.89,495.67 605.21,495.36 605.16,495.42 605.1,495.47 605.05,495.52"];
	"terragni_2022_one_configuration_to_rule_them_all_towards_hyperparameter_transfer_in_topic_models_using_multi_objective_bayesian_\
optimization" -> zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey	[pos="e,611.57,390.17 611.79,390.43 611.75,390.39 611.72,390.34 611.68,390.3"];
	"terragni_2022_one_configuration_to_rule_them_all_towards_hyperparameter_transfer_in_topic_models_using_multi_objective_bayesian_\
optimization" -> burkhardt_2019_decoupling_sparsity_and_smoothness_in_the_dirichlet_variational_autoencoder_topic_model	[pos="e,647.77,374.02 647.8,374.28 647.8,374.23 647.79,374.19 647.79,374.15"];
	"terragni_2022_one_configuration_to_rule_them_all_towards_hyperparameter_transfer_in_topic_models_using_multi_objective_bayesian_\
optimization" -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,588.33,424.84 588.78,424.98 588.7,424.96 588.63,424.93 588.55,424.91"];
	"terragni_2022_one_configuration_to_rule_them_all_towards_hyperparameter_transfer_in_topic_models_using_multi_objective_bayesian_\
optimization" -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,626.9,380.05 627.12,380.52 627.08,380.44 627.05,380.36 627.01,380.28"];
	"terragni_2022_one_configuration_to_rule_them_all_towards_hyperparameter_transfer_in_topic_models_using_multi_objective_bayesian_\
optimization" -> ding_2018_coherence_aware_neural_topic_modeling	[pos="e,661.13,373.22 661.12,373.52 661.12,373.47 661.12,373.42 661.13,373.37"];
	doan_2021_benchmarking_neural_topic_models_an_empirical_study	[color=blue,
		height=4.1944,
		id=doan_2021_benchmarking_neural_topic_models_an_empirical_study,
		"k-core"=7,
		label=doan_2021,
		shape=circle,
		style=filled,
		width=4.1944,
		zazaza="-5169.125999022692,-6105.745786456341!"];
	"terragni_2022_one_configuration_to_rule_them_all_towards_hyperparameter_transfer_in_topic_models_using_multi_objective_bayesian_\
optimization" -> doan_2021_benchmarking_neural_topic_models_an_empirical_study	[pos="e,650.72,458.22 650.78,458.12 650.76,458.14 650.75,458.16 650.74,458.18"];
	doan_2021_benchmarking_neural_topic_models_an_empirical_study -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.2,518.84 580.24,518.81 580.23,518.82 580.22,518.82 580.21,518.83"];
	doan_2021_benchmarking_neural_topic_models_an_empirical_study -> card_2017_neural_models_for_documents_with_metadata	[pos="e,615.37,384.96 615.39,385 615.38,385 615.38,384.99 615.37,384.98"];
	doan_2021_benchmarking_neural_topic_models_an_empirical_study -> card_2018_neural_models_for_documents_with_metadata	[pos="e,608.09,386.83 608.11,386.87 608.1,386.86 608.1,386.86 608.1,386.85"];
	doan_2021_benchmarking_neural_topic_models_an_empirical_study -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.69,389.51 577.73,389.55 577.72,389.54 577.71,389.53 577.71,389.53"];
	doan_2021_benchmarking_neural_topic_models_an_empirical_study -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,630.65,360.73 630.66,360.78 630.66,360.77 630.66,360.76 630.66,360.75"];
	doan_2021_benchmarking_neural_topic_models_an_empirical_study -> dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency	[pos="e,585.59,373.56 585.63,373.6 585.62,373.59 585.61,373.58 585.61,373.57"];
	kashyap_2022_so_different_yet_so_alike_constrained_unsupervised_text_style_transfer	[color=yellow,
		height=2,
		id=kashyap_2022_so_different_yet_so_alike_constrained_unsupervised_text_style_transfer,
		"k-core"=6,
		label=kashyap_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-0.7154293015023511,-0.6986851090440911!"];
	kashyap_2022_so_different_yet_so_alike_constrained_unsupervised_text_style_transfer -> vaswani_2017_attention_is_all_you_need	[pos="e,641.74,499.36 642.07,499.3 642.02,499.31 641.96,499.32 641.91,499.33"];
	kashyap_2022_so_different_yet_so_alike_constrained_unsupervised_text_style_transfer -> holtzman_2019_the_curious_case_of_neural_text_degeneration	[pos="e,678,492.22 678.07,492.2 678.06,492.2 678.04,492.21 678.03,492.21"];
	kashyap_2022_so_different_yet_so_alike_constrained_unsupervised_text_style_transfer -> hu_2020_neural_topic_modeling_with_cycle_consistent_adversarial_training	[pos="e,683.52,418.25 683.73,418.72 683.69,418.64 683.66,418.56 683.62,418.49"];
	kashyap_2022_so_different_yet_so_alike_constrained_unsupervised_text_style_transfer -> krishna_2020_reformulating_unsupervised_style_transfer_as_paraphrase_generation	[pos="e,676.34,524.62 676.42,524.54 676.4,524.56 676.39,524.57 676.37,524.59"];
	kashyap_2022_so_different_yet_so_alike_constrained_unsupervised_text_style_transfer -> chen_2020_a_simple_framework_for_contrastive_learning_of_visual_representations	[pos="e,715.25,446.97 715.25,447.05 715.25,447.03 715.25,447.02 715.25,447"];
	kashyap_2022_so_different_yet_so_alike_constrained_unsupervised_text_style_transfer -> john_2018_disentangled_representation_learning_for_non_parallel_text_style_transfer	[pos="e,733.29,415 733.15,415.46 733.18,415.38 733.2,415.31 733.22,415.23"];
	yang_2021_topnet_learning_from_neural_topic_model_to_generate_long_stories	[color=green,
		height=2,
		id=yang_2021_topnet_learning_from_neural_topic_model_to_generate_long_stories,
		"k-core"=8,
		label=yang_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-2724.299112435446,-4192.635710306023!"];
	yang_2021_topnet_learning_from_neural_topic_model_to_generate_long_stories -> see_2017_get_to_the_point_summarization_with_pointer_generator_networks	[pos="e,537.74,407.39 538.06,407.59 538.01,407.56 537.95,407.52 537.9,407.49"];
	yang_2021_topnet_learning_from_neural_topic_model_to_generate_long_stories -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.82,516.41 580.9,516.09 580.88,516.14 580.87,516.2 580.86,516.25"];
	yang_2021_topnet_learning_from_neural_topic_model_to_generate_long_stories -> vaswani_2017_attention_is_all_you_need	[pos="e,587.98,510.31 587.99,510.27 587.99,510.28 587.99,510.29 587.99,510.29"];
	yang_2021_topnet_learning_from_neural_topic_model_to_generate_long_stories -> lau_2017_topically_driven_neural_language_model	[pos="e,562.89,382.77 563.15,383.22 563.1,383.14 563.06,383.07 563.02,382.99"];
	yang_2021_topnet_learning_from_neural_topic_model_to_generate_long_stories -> wang_2019_topic_guided_variational_auto_encoder_for_text_generation	[pos="e,572.58,378.09 572.72,378.44 572.7,378.38 572.67,378.32 572.65,378.26"];
	yang_2021_topnet_learning_from_neural_topic_model_to_generate_long_stories -> wang_2017_topic_compositional_neural_language_model	[pos="e,544.97,397.07 545.34,397.41 545.28,397.35 545.22,397.3 545.15,397.24"];
	yang_2021_topnet_learning_from_neural_topic_model_to_generate_long_stories -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,624.26,377.9 624.09,378.38 624.12,378.3 624.15,378.22 624.18,378.14"];
	yang_2021_topnet_learning_from_neural_topic_model_to_generate_long_stories -> dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency	[pos="e,585.64,373.86 585.81,374.8 585.77,374.59 585.74,374.41 585.71,374.26"];
	yang_2021_topnet_learning_from_neural_topic_model_to_generate_long_stories -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,630,511.49 629.98,511.45 629.98,511.46 629.99,511.47 629.99,511.47"];
	yang_2021_topnet_learning_from_neural_topic_model_to_generate_long_stories -> joshi_2019_spanbert_improving_pre_training_by_representing_and_predicting_spans	[pos="e,628.43,512.7 628.25,512.29 628.28,512.36 628.31,512.43 628.34,512.5"];
	kumar_2021_bert_based_semi_supervised_hybrid_approach_for_aspect_and_sentiment_classification	[color=blue,
		height=2,
		id=kumar_2021_bert_based_semi_supervised_hybrid_approach_for_aspect_and_sentiment_classification,
		"k-core"=7,
		label=kumar_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-3926.864830960731,-6969.916335475388!"];
	kumar_2021_bert_based_semi_supervised_hybrid_approach_for_aspect_and_sentiment_classification -> angelidis_2018_summarizing_opinions_aspect_extraction_meets_sentiment_prediction_and_they_are_both_weakly_supervised	[pos="e,440.17,435.67 440.43,435.72 440.39,435.71 440.34,435.7 440.3,435.7"];
	kumar_2021_bert_based_semi_supervised_hybrid_approach_for_aspect_and_sentiment_classification -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,562.55,501.05 562.07,500.56 562.15,500.64 562.23,500.72 562.31,500.8"];
	kumar_2021_bert_based_semi_supervised_hybrid_approach_for_aspect_and_sentiment_classification -> he_2017_an_unsupervised_neural_attention_model_for_aspect_extraction	[pos="e,471.09,424.46 471.18,424.52 471.16,424.51 471.14,424.5 471.13,424.49"];
	kumar_2021_bert_based_semi_supervised_hybrid_approach_for_aspect_and_sentiment_classification -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,565.22,400.7 564.87,401.02 564.93,400.96 564.99,400.91 565.04,400.86"];
	kumar_2021_bert_based_semi_supervised_hybrid_approach_for_aspect_and_sentiment_classification -> pablos_2018_w2vlda_almost_unsupervised_system_for_aspect_based_sentiment_analysis	[pos="e,438.95,444.4 439.24,444.42 439.19,444.42 439.14,444.41 439.09,444.41"];
	kumar_2021_bert_based_semi_supervised_hybrid_approach_for_aspect_and_sentiment_classification -> tulkens_2020_embarrassingly_simple_unsupervised_aspect_extraction	[pos="e,442.1,444.68 442.13,444.68 442.13,444.68 442.12,444.68 442.11,444.68"];
	kumar_2021_bert_based_semi_supervised_hybrid_approach_for_aspect_and_sentiment_classification -> huang_2020_weakly_supervised_aspect_based_sentiment_analysis_via_joint_aspect_sentiment_topic_embedding	[pos="e,480.41,502.66 480.48,502.54 480.46,502.57 480.45,502.59 480.44,502.61"];
	meng_2022_general_to_specific_transfer_labeling_for_domain_adaptable_keyphrase_generation	[color=yellow,
		height=2,
		id=meng_2022_general_to_specific_transfer_labeling_for_domain_adaptable_keyphrase_generation,
		"k-core"=6,
		label=meng_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-0.4062556885317258,-0.9137594688470324!"];
	meng_2022_general_to_specific_transfer_labeling_for_domain_adaptable_keyphrase_generation -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,587.07,523.23 587.49,523.5 587.42,523.45 587.35,523.41 587.28,523.37"];
	meng_2022_general_to_specific_transfer_labeling_for_domain_adaptable_keyphrase_generation -> vaswani_2017_attention_is_all_you_need	[pos="e,593.24,514.84 593.56,515.11 593.5,515.07 593.45,515.02 593.4,514.97"];
	meng_2022_general_to_specific_transfer_labeling_for_domain_adaptable_keyphrase_generation -> lewis_2019_bart_denoising_sequence_to_sequence_pre_training_for_natural_language_generation_translation_and_comprehension	[pos="e,592.44,539.82 592.56,539.87 592.53,539.86 592.51,539.85 592.49,539.84"];
	meng_2022_general_to_specific_transfer_labeling_for_domain_adaptable_keyphrase_generation -> wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration	[pos="e,641.16,508.58 641.17,508.7 641.17,508.67 641.17,508.65 641.17,508.63"];
	meng_2022_general_to_specific_transfer_labeling_for_domain_adaptable_keyphrase_generation -> lee_2020_learning_dense_representations_of_phrases_at_scale	[pos="e,658.73,583.1 658.71,583.06 658.71,583.07 658.72,583.08 658.72,583.08"];
	meng_2022_general_to_specific_transfer_labeling_for_domain_adaptable_keyphrase_generation -> li_2022_uctopic_unsupervised_contrastive_learning_for_phrase_representations_and_topic_mining	[pos="e,604.58,534.98 604.68,535.04 604.66,535.03 604.64,535.02 604.62,535.01"];
	sanaullah_2022_applications_of_machine_learning_for_covid_19_misinformation_a_systematic_review	[color=yellow,
		height=2,
		id=sanaullah_2022_applications_of_machine_learning_for_covid_19_misinformation_a_systematic_review,
		"k-core"=6,
		label=sanaullah_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-0.34778263809173715,-0.9375752198599147!"];
	sanaullah_2022_applications_of_machine_learning_for_covid_19_misinformation_a_systematic_review -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,587.79,515.87 588.25,515.69 588.17,515.72 588.09,515.75 588.02,515.78"];
	sanaullah_2022_applications_of_machine_learning_for_covid_19_misinformation_a_systematic_review -> vaswani_2017_attention_is_all_you_need	[pos="e,587.99,510.32 588.03,510.3 588.02,510.31 588.02,510.31 588.01,510.31"];
	sanaullah_2022_applications_of_machine_learning_for_covid_19_misinformation_a_systematic_review -> card_2017_neural_models_for_documents_with_metadata	[pos="e,629.34,421.27 629.52,421.74 629.49,421.66 629.46,421.58 629.43,421.5"];
	sanaullah_2022_applications_of_machine_learning_for_covid_19_misinformation_a_systematic_review -> card_2018_neural_models_for_documents_with_metadata	[pos="e,624.86,423.06 625.07,423.52 625.04,423.45 625,423.37 624.97,423.29"];
	sanaullah_2022_applications_of_machine_learning_for_covid_19_misinformation_a_systematic_review -> peters_2018_deep_contextualized_word_representations	[pos="e,592.07,525.19 592.56,524.91 592.48,524.96 592.4,525 592.31,525.05"];
	sanaullah_2022_applications_of_machine_learning_for_covid_19_misinformation_a_systematic_review -> zhang_2019_bertscore_evaluating_text_generation_with_bert	[pos="e,662.61,542.35 662.59,542.23 662.59,542.26 662.6,542.28 662.6,542.3"];
	jin_2021_neural_attention_aware_hierarchical_topic_model	[color=red,
		height=2,
		id=jin_2021_neural_attention_aware_hierarchical_topic_model,
		"k-core"=9,
		label=jin_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-20.15462493941783,-67.03574648656662!"];
	jin_2021_neural_attention_aware_hierarchical_topic_model -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,596.25,496.53 596.46,496.23 596.43,496.28 596.39,496.33 596.35,496.38"];
	jin_2021_neural_attention_aware_hierarchical_topic_model -> zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey	[pos="e,599.23,376.54 599.44,376.86 599.4,376.81 599.37,376.75 599.33,376.7"];
	jin_2021_neural_attention_aware_hierarchical_topic_model -> card_2017_neural_models_for_documents_with_metadata	[pos="e,615.38,384.99 615.43,385.1 615.42,385.08 615.41,385.06 615.4,385.04"];
	jin_2021_neural_attention_aware_hierarchical_topic_model -> card_2018_neural_models_for_documents_with_metadata	[pos="e,608.1,386.86 608.17,386.97 608.15,386.94 608.14,386.92 608.13,386.9"];
	jin_2021_neural_attention_aware_hierarchical_topic_model -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,568.56,418.45 568.98,418.56 568.91,418.54 568.84,418.52 568.77,418.5"];
	jin_2021_neural_attention_aware_hierarchical_topic_model -> hoyle_2020_improving_neural_topic_models_using_knowledge_distillation	[pos="e,621.62,437.25 621.65,437.25 621.65,437.25 621.64,437.25 621.63,437.25"];
	jin_2021_neural_attention_aware_hierarchical_topic_model -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,623.28,372.38 623.29,372.41 623.29,372.41 623.29,372.4 623.29,372.39"];
	jin_2021_neural_attention_aware_hierarchical_topic_model -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,581.56,392.57 582.06,392.96 581.97,392.89 581.89,392.83 581.81,392.76"];
	jin_2021_neural_attention_aware_hierarchical_topic_model -> zhao_2020_neural_topic_model_via_optimal_transport	[pos="e,624.88,366.28 624.95,366.68 624.94,366.61 624.93,366.55 624.92,366.48"];
	jin_2021_neural_attention_aware_hierarchical_topic_model -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,631.14,365.47 631.17,365.76 631.17,365.71 631.16,365.66 631.16,365.61"];
	jin_2021_neural_attention_aware_hierarchical_topic_model -> ding_2018_coherence_aware_neural_topic_modeling	[pos="e,661.29,368.38 661.1,368.96 661.14,368.84 661.18,368.72 661.21,368.63"];
	yan_2022_clip_also_understands_text_prompting_clip_for_phrase_understanding	[color=blue,
		height=2,
		id=yan_2022_clip_also_understands_text_prompting_clip_for_phrase_understanding,
		"k-core"=7,
		label=yan_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-1815.3283336960549,-7791.314591516514!"];
	yan_2022_clip_also_understands_text_prompting_clip_for_phrase_understanding -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,609.48,531.35 609.87,531.52 609.8,531.49 609.74,531.46 609.67,531.44"];
	yan_2022_clip_also_understands_text_prompting_clip_for_phrase_understanding -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,630.04,511.54 630.14,511.64 630.11,511.62 630.1,511.6 630.08,511.58"];
	yan_2022_clip_also_understands_text_prompting_clip_for_phrase_understanding -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.75,532.57 612.78,532.58 612.77,532.58 612.77,532.57 612.76,532.57"];
	yan_2022_clip_also_understands_text_prompting_clip_for_phrase_understanding -> wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration	[pos="e,641.18,508.58 641.26,508.69 641.24,508.67 641.22,508.65 641.21,508.63"];
	yan_2022_clip_also_understands_text_prompting_clip_for_phrase_understanding -> krishna_2020_reformulating_unsupervised_style_transfer_as_paraphrase_generation	[pos="e,676.31,524.68 676.31,524.75 676.31,524.74 676.31,524.72 676.31,524.71"];
	yan_2022_clip_also_understands_text_prompting_clip_for_phrase_understanding -> lee_2020_learning_dense_representations_of_phrases_at_scale	[pos="e,658.75,583.1 658.79,583.05 658.78,583.06 658.77,583.07 658.77,583.08"];
	yan_2022_clip_also_understands_text_prompting_clip_for_phrase_understanding -> li_2022_uctopic_unsupervised_contrastive_learning_for_phrase_representations_and_topic_mining	[pos="e,607.62,536.03 608.02,536.17 607.95,536.14 607.89,536.12 607.82,536.1"];
	zosa_2022_multilingual_topic_labelling_of_news_topics_using_ontological_mapping	[color=yellow,
		height=2,
		id=zosa_2022_multilingual_topic_labelling_of_news_topics_using_ontological_mapping,
		"k-core"=6,
		label=zosa_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-0.19605791253053353,-0.9805923091132828!"];
	zosa_2022_multilingual_topic_labelling_of_news_topics_using_ontological_mapping -> vaswani_2017_attention_is_all_you_need	[pos="e,624.68,535.51 625.15,535.83 625.07,535.77 624.99,535.72 624.92,535.67"];
	zosa_2022_multilingual_topic_labelling_of_news_topics_using_ontological_mapping -> reimers_2019_sentence_bert_sentence_embeddings_using_siamese_bert_networks	[pos="e,636.01,523.23 636.39,523.64 636.33,523.57 636.26,523.51 636.2,523.44"];
	zosa_2022_multilingual_topic_labelling_of_news_topics_using_ontological_mapping -> lewis_2019_bart_denoising_sequence_to_sequence_pre_training_for_natural_language_generation_translation_and_comprehension	[pos="e,617.32,549.78 617.66,549.91 617.6,549.89 617.55,549.87 617.49,549.85"];
	zosa_2022_multilingual_topic_labelling_of_news_topics_using_ontological_mapping -> zhang_2019_bertscore_evaluating_text_generation_with_bert	[pos="e,662.63,542.41 662.67,542.48 662.66,542.47 662.65,542.45 662.65,542.44"];
	zosa_2022_multilingual_topic_labelling_of_news_topics_using_ontological_mapping -> liu_2020_multilingual_denoising_pre_training_for_neural_machine_translation	[pos="e,629.39,588.49 629.51,588.47 629.49,588.48 629.46,588.48 629.44,588.48"];
	zosa_2022_multilingual_topic_labelling_of_news_topics_using_ontological_mapping -> popa_2021_bart_tl_weakly_supervised_topic_label_generation	[pos="e,625.16,568.77 625.29,568.79 625.26,568.78 625.23,568.78 625.21,568.78"];
	panwar_2021_tan_ntm_topic_attention_networks_for_neural_topic_modeling	[color=red,
		height=2,
		id=panwar_2021_tan_ntm_topic_attention_networks_for_neural_topic_modeling,
		"k-core"=9,
		label=panwar_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-9.365040152395068,-69.3707131399493!"];
	panwar_2021_tan_ntm_topic_attention_networks_for_neural_topic_modeling -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,586.64,492.45 586.73,492.1 586.71,492.16 586.7,492.22 586.68,492.28"];
	panwar_2021_tan_ntm_topic_attention_networks_for_neural_topic_modeling -> card_2017_neural_models_for_documents_with_metadata	[pos="e,615.35,384.98 615.33,385.06 615.33,385.04 615.34,385.02 615.34,385.01"];
	panwar_2021_tan_ntm_topic_attention_networks_for_neural_topic_modeling -> burkhardt_2019_decoupling_sparsity_and_smoothness_in_the_dirichlet_variational_autoencoder_topic_model	[pos="e,632.77,355.29 632.64,355.59 632.67,355.54 632.69,355.49 632.71,355.44"];
	panwar_2021_tan_ntm_topic_attention_networks_for_neural_topic_modeling -> card_2018_neural_models_for_documents_with_metadata	[pos="e,608.08,386.85 608.07,386.92 608.07,386.9 608.07,386.89 608.07,386.88"];
	panwar_2021_tan_ntm_topic_attention_networks_for_neural_topic_modeling -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,553.86,414.42 553.97,414.43 553.94,414.43 553.92,414.42 553.91,414.42"];
	panwar_2021_tan_ntm_topic_attention_networks_for_neural_topic_modeling -> hoyle_2020_improving_neural_topic_models_using_knowledge_distillation	[pos="e,621.59,437.24 621.55,437.2 621.56,437.21 621.57,437.22 621.58,437.22"];
	panwar_2021_tan_ntm_topic_attention_networks_for_neural_topic_modeling -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,623.27,372.4 623.23,372.51 623.23,372.48 623.24,372.46 623.25,372.45"];
	panwar_2021_tan_ntm_topic_attention_networks_for_neural_topic_modeling -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.7,389.52 577.75,389.59 577.74,389.58 577.73,389.56 577.72,389.55"];
	panwar_2021_tan_ntm_topic_attention_networks_for_neural_topic_modeling -> zhao_2020_neural_topic_model_via_optimal_transport	[pos="e,616.59,350.39 616.52,350.79 616.53,350.72 616.54,350.66 616.55,350.59"];
	panwar_2021_tan_ntm_topic_attention_networks_for_neural_topic_modeling -> zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling	[pos="e,544.48,380.16 544.83,380.4 544.77,380.36 544.71,380.32 544.66,380.28"];
	panwar_2021_tan_ntm_topic_attention_networks_for_neural_topic_modeling -> gui_2019_neural_topic_model_with_reinforcement_learning	[pos="e,549.81,373.64 550.07,373.87 550.03,373.83 549.99,373.79 549.94,373.75"];
	panwar_2021_tan_ntm_topic_attention_networks_for_neural_topic_modeling -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,630.64,360.72 630.63,360.76 630.63,360.75 630.64,360.74 630.64,360.74"];
	panwar_2021_tan_ntm_topic_attention_networks_for_neural_topic_modeling -> dieng_2016_topicrnn_a_recurrent_neural_network_with_long_range_semantic_dependency	[pos="e,585.59,373.57 585.63,373.68 585.62,373.66 585.62,373.64 585.61,373.62"];
	panwar_2021_tan_ntm_topic_attention_networks_for_neural_topic_modeling -> wu_2020_neural_mixed_counting_models_for_dispersed_topic_discovery	[pos="e,645.28,362 645.04,362.33 645.08,362.27 645.12,362.22 645.16,362.16"];
	panwar_2021_tan_ntm_topic_attention_networks_for_neural_topic_modeling -> hu_2020_neural_topic_modeling_with_cycle_consistent_adversarial_training	[pos="e,665.74,383.42 665.19,383.76 665.29,383.7 665.38,383.65 665.47,383.59"];
	panwar_2021_tan_ntm_topic_attention_networks_for_neural_topic_modeling -> rezaee_2020_a_discrete_variational_recurrent_topic_model_without_the_reparametrization_trick	[pos="e,564.6,360.53 564.84,360.92 564.8,360.85 564.76,360.79 564.72,360.72"];
	panwar_2021_tan_ntm_topic_attention_networks_for_neural_topic_modeling -> wang_2020_neural_topic_modeling_with_bidirectional_adversarial_training	[pos="e,648.31,389.49 648.22,389.56 648.24,389.54 648.26,389.53 648.27,389.52"];
	panwar_2021_tan_ntm_topic_attention_networks_for_neural_topic_modeling -> ding_2018_coherence_aware_neural_topic_modeling	[pos="e,657.36,371.92 656.84,372.4 656.93,372.32 657.02,372.23 657.11,372.15"];
	panwar_2021_tan_ntm_topic_attention_networks_for_neural_topic_modeling -> pergola_2019_tdam_a_topic_dependent_attention_model_for_sentiment_analysis	[pos="e,639.46,472.55 639.38,472.44 639.4,472.47 639.41,472.49 639.43,472.51"];
	zhao_2019_structured_bayesian_latent_factor_models_with_meta_data	[color=blue,
		height=2,
		id=zhao_2019_structured_bayesian_latent_factor_models_with_meta_data,
		"k-core"=7,
		label=zhao_2019,
		shape=circle,
		style=filled,
		width=2,
		zazaza="-567.8508055557004,-7979.821194259913!"];
	zhao_2019_structured_bayesian_latent_factor_models_with_meta_data -> card_2017_neural_models_for_documents_with_metadata	[pos="e,569.46,386.07 569.17,386.08 569.21,386.08 569.26,386.08 569.31,386.08"];
	zhao_2019_structured_bayesian_latent_factor_models_with_meta_data -> card_2018_neural_models_for_documents_with_metadata	[pos="e,569.64,387.17 569.14,387.18 569.23,387.18 569.31,387.18 569.39,387.18"];
	zhao_2019_structured_bayesian_latent_factor_models_with_meta_data -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,569.51,389.33 569.02,389.32 569.1,389.32 569.18,389.33 569.27,389.33"];
	zhao_2019_structured_bayesian_latent_factor_models_with_meta_data -> zhao_2017_metalda_a_topic_model_that_efficiently_incorporates_meta_information	[pos="e,485.96,332.73 485.98,332.85 485.97,332.82 485.97,332.8 485.97,332.78"];
	zhao_2019_structured_bayesian_latent_factor_models_with_meta_data -> zhang_2018_whai_weibull_hybrid_autoencoding_inference_for_deep_topic_modeling	[pos="e,538.79,376.19 538.7,376.22 538.72,376.21 538.74,376.21 538.76,376.2"];
	zhao_2019_structured_bayesian_latent_factor_models_with_meta_data -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,568,373.41 567.62,373.48 567.69,373.47 567.75,373.46 567.81,373.45"];
	zhao_2019_structured_bayesian_latent_factor_models_with_meta_data -> cong_2017_deep_latent_dirichlet_allocation_with_topic_layer_adaptive_stochastic_gradient_riemannian_mcmc	[pos="e,483.89,363.86 483.92,363.91 483.92,363.9 483.91,363.89 483.91,363.88"];
	zhao_2019_structured_bayesian_latent_factor_models_with_meta_data -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,512.34,458.95 512.27,458.64 512.28,458.69 512.29,458.74 512.3,458.79"];
	kumar_2022_barlat_a_nearly_unsupervised_approach_for_aspect_category_detection	[color=blue,
		height=2,
		id=kumar_2022_barlat_a_nearly_unsupervised_approach_for_aspect_category_detection,
		"k-core"=7,
		label=kumar_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="945.0007863296877,-7943.9897429384755!"];
	kumar_2022_barlat_a_nearly_unsupervised_approach_for_aspect_category_detection -> angelidis_2018_summarizing_opinions_aspect_extraction_meets_sentiment_prediction_and_they_are_both_weakly_supervised	[pos="e,451.64,437.02 452.04,437.09 451.97,437.08 451.9,437.06 451.84,437.05"];
	kumar_2022_barlat_a_nearly_unsupervised_approach_for_aspect_category_detection -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,569.31,505.38 569,505 569.05,505.07 569.1,505.13 569.16,505.19"];
	kumar_2022_barlat_a_nearly_unsupervised_approach_for_aspect_category_detection -> vaswani_2017_attention_is_all_you_need	[pos="e,576.2,499.06 575.87,498.74 575.92,498.79 575.98,498.85 576.04,498.9"];
	kumar_2022_barlat_a_nearly_unsupervised_approach_for_aspect_category_detection -> he_2017_an_unsupervised_neural_attention_model_for_aspect_extraction	[pos="e,471.1,424.46 471.21,424.52 471.19,424.51 471.17,424.5 471.15,424.49"];
	kumar_2022_barlat_a_nearly_unsupervised_approach_for_aspect_category_detection -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,572.6,395.06 572.29,395.4 572.34,395.34 572.4,395.28 572.45,395.23"];
	kumar_2022_barlat_a_nearly_unsupervised_approach_for_aspect_category_detection -> pablos_2018_w2vlda_almost_unsupervised_system_for_aspect_based_sentiment_analysis	[pos="e,450.92,444.79 451.36,444.81 451.28,444.81 451.21,444.81 451.14,444.8"];
	kumar_2022_barlat_a_nearly_unsupervised_approach_for_aspect_category_detection -> tulkens_2020_embarrassingly_simple_unsupervised_aspect_extraction	[pos="e,451.17,445.13 451.43,445.15 451.39,445.14 451.34,445.14 451.3,445.14"];
	xu_2022_neural_topic_modeling_with_deep_mutual_information_estimation	[color=red,
		height=2,
		id=xu_2022_neural_topic_modeling_with_deep_mutual_information_estimation,
		"k-core"=9,
		label=xu_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="12.638771983395815,-68.84955635345261!"];
	xu_2022_neural_topic_modeling_with_deep_mutual_information_estimation -> jang_2016_categorical_reparameterization_with_gumbel_softmax	[pos="e,515.93,358.3 515.96,358.3 515.96,358.3 515.95,358.3 515.94,358.3"];
	xu_2022_neural_topic_modeling_with_deep_mutual_information_estimation -> card_2017_neural_models_for_documents_with_metadata	[pos="e,615.34,384.92 615.27,384.84 615.28,384.86 615.29,384.88 615.31,384.89"];
	xu_2022_neural_topic_modeling_with_deep_mutual_information_estimation -> burkhardt_2019_decoupling_sparsity_and_smoothness_in_the_dirichlet_variational_autoencoder_topic_model	[pos="e,642.04,333.83 641.91,333.86 641.94,333.85 641.97,333.84 641.99,333.84"];
	xu_2022_neural_topic_modeling_with_deep_mutual_information_estimation -> card_2018_neural_models_for_documents_with_metadata	[pos="e,608.06,386.79 608,386.71 608.02,386.73 608.03,386.74 608.04,386.76"];
	xu_2022_neural_topic_modeling_with_deep_mutual_information_estimation -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,553.87,414.3 554.01,413.98 553.98,414.05 553.95,414.11 553.93,414.17"];
	xu_2022_neural_topic_modeling_with_deep_mutual_information_estimation -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,623.25,372.35 623.16,372.29 623.18,372.31 623.2,372.32 623.21,372.33"];
	xu_2022_neural_topic_modeling_with_deep_mutual_information_estimation -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,577.68,389.47 577.69,389.38 577.69,389.4 577.69,389.42 577.69,389.43"];
	xu_2022_neural_topic_modeling_with_deep_mutual_information_estimation -> zhao_2020_neural_topic_model_via_optimal_transport	[pos="e,619.07,336.27 618.99,336.3 619.01,336.29 619.02,336.29 619.04,336.28"];
	xu_2022_neural_topic_modeling_with_deep_mutual_information_estimation -> gui_2019_neural_topic_model_with_reinforcement_learning	[pos="e,530.41,356.29 530.52,356.27 530.49,356.27 530.47,356.28 530.45,356.28"];
	xu_2022_neural_topic_modeling_with_deep_mutual_information_estimation -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,630.61,360.7 630.51,360.67 630.53,360.68 630.55,360.69 630.57,360.69"];
	xu_2022_neural_topic_modeling_with_deep_mutual_information_estimation -> wang_2020_neural_topic_modeling_with_bidirectional_adversarial_training	[pos="e,643.46,386.35 643.16,386.16 643.21,386.19 643.26,386.22 643.31,386.25"];
	xu_2022_neural_topic_modeling_with_deep_mutual_information_estimation -> ding_2018_coherence_aware_neural_topic_modeling	[pos="e,652.54,365.86 652.28,365.79 652.33,365.8 652.37,365.81 652.41,365.82"];
	xu_2022_neural_topic_modeling_with_deep_mutual_information_estimation -> zhang_2022_pre_training_and_fine_tuning_neural_topic_model_a_simple_yet_effective_approach_to_incorporating_external_knowledge	[pos="e,585.6,419.99 585.57,419.5 585.58,419.58 585.58,419.66 585.59,419.74"];
	xu_2022_neural_topic_modeling_with_deep_mutual_information_estimation -> yang_2021_topnet_learning_from_neural_topic_model_to_generate_long_stories	[pos="e,594.43,419.12 594.37,418.76 594.38,418.82 594.39,418.88 594.4,418.94"];
	"martin_michalowski_2020_artificial_intelligence_in_medicine_18th_international_conference_on_artificial_intelligence_in_medicine_\
aime_2020_minneapolis_mn_usa_august_25__28_2020_proceedings"	[color=yellow,
		height=2.2917,
		id="\"martin_michalowski_2020_artificial_intelligence_in_medicine_18th_international_conference_on_artificial_intelligence_in_medicine_\
aime_2020_minneapolis_mn_usa_august_25__28_2020_proceedings\"",
		"k-core"=6,
		label=martin_michalowski_2020,
		shape=circle,
		style=filled,
		width=2.2917,
		zazaza="0.21151359587414673,-0.9773750292107336!"];
	"martin_michalowski_2020_artificial_intelligence_in_medicine_18th_international_conference_on_artificial_intelligence_in_medicine_\
aime_2020_minneapolis_mn_usa_august_25__28_2020_proceedings" -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.21,518.83 580.28,518.74 580.26,518.76 580.25,518.78 580.24,518.79"];
	"martin_michalowski_2020_artificial_intelligence_in_medicine_18th_international_conference_on_artificial_intelligence_in_medicine_\
aime_2020_minneapolis_mn_usa_august_25__28_2020_proceedings" -> card_2017_neural_models_for_documents_with_metadata	[pos="e,614.89,396.59 614.87,396.93 614.87,396.87 614.88,396.81 614.88,396.76"];
	"martin_michalowski_2020_artificial_intelligence_in_medicine_18th_international_conference_on_artificial_intelligence_in_medicine_\
aime_2020_minneapolis_mn_usa_august_25__28_2020_proceedings" -> card_2018_neural_models_for_documents_with_metadata	[pos="e,608.43,396.46 608.44,396.74 608.44,396.69 608.44,396.65 608.44,396.6"];
	"martin_michalowski_2020_artificial_intelligence_in_medicine_18th_international_conference_on_artificial_intelligence_in_medicine_\
aime_2020_minneapolis_mn_usa_august_25__28_2020_proceedings" -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,556.28,417.19 556.61,417.55 556.55,417.49 556.5,417.43 556.44,417.37"];
	"martin_michalowski_2020_artificial_intelligence_in_medicine_18th_international_conference_on_artificial_intelligence_in_medicine_\
aime_2020_minneapolis_mn_usa_august_25__28_2020_proceedings" -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.73,532.52 612.73,532.41 612.73,532.43 612.73,532.46 612.73,532.47"];
	"martin_michalowski_2020_artificial_intelligence_in_medicine_18th_international_conference_on_artificial_intelligence_in_medicine_\
aime_2020_minneapolis_mn_usa_august_25__28_2020_proceedings" -> arjovsky_2017_wasserstein_generative_adversarial_networks	[pos="e,687.39,445.2 686.98,445.39 687.05,445.35 687.12,445.32 687.18,445.29"];
	"martin_michalowski_2020_artificial_intelligence_in_medicine_18th_international_conference_on_artificial_intelligence_in_medicine_\
aime_2020_minneapolis_mn_usa_august_25__28_2020_proceedings" -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,532.91,506.31 533.19,506.21 533.14,506.23 533.09,506.24 533.05,506.26"];
	zaman_2021_cross_category_defect_discovery_from_online_reviews_supplementing_sentiment_with_category_specific_semantics	[color=yellow,
		height=3.3889,
		id=zaman_2021_cross_category_defect_discovery_from_online_reviews_supplementing_sentiment_with_category_specific_semantics,
		"k-core"=6,
		label=zaman_2021,
		shape=circle,
		style=filled,
		width=3.3889,
		zazaza="0.30300530975256307,-0.9529888617488564!"];
	zaman_2021_cross_category_defect_discovery_from_online_reviews_supplementing_sentiment_with_category_specific_semantics -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.19,518.87 580.2,518.93 580.2,518.91 580.2,518.9 580.19,518.89"];
	zaman_2021_cross_category_defect_discovery_from_online_reviews_supplementing_sentiment_with_category_specific_semantics -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,531.06,520.21 531.29,520.53 531.25,520.47 531.21,520.42 531.17,520.37"];
	zaman_2021_cross_category_defect_discovery_from_online_reviews_supplementing_sentiment_with_category_specific_semantics -> goldberg_2020_text_mining_approaches_for_postmarket_food_safety_surveillance_using_online_media	[pos="e,649.45,693.67 649.42,693.63 649.43,693.64 649.43,693.65 649.44,693.66"];
	zaman_2021_cross_category_defect_discovery_from_online_reviews_supplementing_sentiment_with_category_specific_semantics -> zaman_2020_facebook_hospital_reviews_automated_service_quality_detection_and_relationships_with_patient_satisfaction	[pos="e,618.63,702.27 618.62,702.22 618.62,702.23 618.62,702.24 618.63,702.25"];
	zaman_2021_cross_category_defect_discovery_from_online_reviews_supplementing_sentiment_with_category_specific_semantics -> mummalaneni_2018_social_media_analytics_for_quality_surveillance_and_safety_hazard_detection_in_baby_cribs	[pos="e,591.76,706.76 591.76,706.72 591.76,706.73 591.76,706.74 591.76,706.74"];
	zaman_2021_cross_category_defect_discovery_from_online_reviews_supplementing_sentiment_with_category_specific_semantics -> law_2017_automated_defect_discovery_for_dishwasher_appliances_from_online_consumer_reviews	[pos="e,629.24,700.01 629.23,699.97 629.23,699.98 629.23,699.98 629.24,699.99"];
	zaman_2021_cross_category_defect_discovery_from_online_reviews_supplementing_sentiment_with_category_specific_semantics -> goldberg_2018_a_tabu_search_heuristic_for_smoke_term_curation_in_safety_defect_discovery	[pos="e,700.76,661.84 700.71,661.82 700.72,661.82 700.73,661.82 700.74,661.83"];
	goldberg_2022_fumeus_a_family_of_python_tools_for_text_mining_with_smoke_terms	[color=yellow,
		height=2,
		id=goldberg_2022_fumeus_a_family_of_python_tools_for_text_mining_with_smoke_terms,
		"k-core"=6,
		label=goldberg_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="0.3625403063433894,-0.9319680917314043!"];
	goldberg_2022_fumeus_a_family_of_python_tools_for_text_mining_with_smoke_terms -> goldberg_2020_text_mining_approaches_for_postmarket_food_safety_surveillance_using_online_media	[pos="e,649.48,693.67 649.55,693.64 649.53,693.64 649.52,693.65 649.51,693.66"];
	goldberg_2022_fumeus_a_family_of_python_tools_for_text_mining_with_smoke_terms -> zaman_2020_facebook_hospital_reviews_automated_service_quality_detection_and_relationships_with_patient_satisfaction	[pos="e,618.64,702.28 618.68,702.26 618.67,702.27 618.66,702.27 618.66,702.27"];
	goldberg_2022_fumeus_a_family_of_python_tools_for_text_mining_with_smoke_terms -> mummalaneni_2018_social_media_analytics_for_quality_surveillance_and_safety_hazard_detection_in_baby_cribs	[pos="e,612.11,699.79 612.39,699.69 612.34,699.71 612.3,699.72 612.25,699.74"];
	goldberg_2022_fumeus_a_family_of_python_tools_for_text_mining_with_smoke_terms -> law_2017_automated_defect_discovery_for_dishwasher_appliances_from_online_consumer_reviews	[pos="e,629.28,700.01 629.39,699.96 629.37,699.97 629.35,699.98 629.33,699.98"];
	goldberg_2022_fumeus_a_family_of_python_tools_for_text_mining_with_smoke_terms -> goldberg_2018_a_tabu_search_heuristic_for_smoke_term_curation_in_safety_defect_discovery	[pos="e,700.77,661.86 700.72,661.89 700.73,661.88 700.74,661.87 700.75,661.87"];
	goldberg_2022_fumeus_a_family_of_python_tools_for_text_mining_with_smoke_terms -> zaman_2021_cross_category_defect_discovery_from_online_reviews_supplementing_sentiment_with_category_specific_semantics	[pos="e,621.92,633.94 622.18,634.13 622.14,634.1 622.09,634.07 622.05,634.04"];
	goldberg_2022_sourcing_product_innovation_intelligence_from_online_reviews	[color=yellow,
		height=4.7778,
		id=goldberg_2022_sourcing_product_innovation_intelligence_from_online_reviews,
		"k-core"=6,
		label=goldberg_2022,
		shape=circle,
		style=filled,
		width=4.7778,
		zazaza="0.6815490731061848,-0.7317724221319576!"];
	goldberg_2022_fumeus_a_family_of_python_tools_for_text_mining_with_smoke_terms -> goldberg_2022_sourcing_product_innovation_intelligence_from_online_reviews	[pos="e,665.59,685.88 665.72,685.8 665.69,685.81 665.66,685.83 665.64,685.84"];
	goldberg_2022_sourcing_product_innovation_intelligence_from_online_reviews -> goldberg_2020_text_mining_approaches_for_postmarket_food_safety_surveillance_using_online_media	[pos="e,649.47,693.68 649.5,693.66 649.5,693.67 649.49,693.67 649.48,693.67"];
	goldberg_2022_sourcing_product_innovation_intelligence_from_online_reviews -> zaman_2020_facebook_hospital_reviews_automated_service_quality_detection_and_relationships_with_patient_satisfaction	[pos="e,618.67,702.27 618.77,702.24 618.74,702.24 618.73,702.25 618.71,702.26"];
	goldberg_2022_sourcing_product_innovation_intelligence_from_online_reviews -> mummalaneni_2018_social_media_analytics_for_quality_surveillance_and_safety_hazard_detection_in_baby_cribs	[pos="e,591.77,706.77 591.81,706.76 591.8,706.77 591.79,706.77 591.79,706.77"];
	goldberg_2022_sourcing_product_innovation_intelligence_from_online_reviews -> law_2017_automated_defect_discovery_for_dishwasher_appliances_from_online_consumer_reviews	[pos="e,629.27,700.01 629.35,699.98 629.33,699.99 629.32,700 629.31,700"];
	goldberg_2022_sourcing_product_innovation_intelligence_from_online_reviews -> goldberg_2018_a_tabu_search_heuristic_for_smoke_term_curation_in_safety_defect_discovery	[pos="e,700.76,661.86 700.68,661.91 700.7,661.9 700.71,661.89 700.72,661.88"];
	goldberg_2022_sourcing_product_innovation_intelligence_from_online_reviews -> zaman_2021_cross_category_defect_discovery_from_online_reviews_supplementing_sentiment_with_category_specific_semantics	[pos="e,602.43,619.94 602.47,619.98 602.46,619.97 602.45,619.96 602.45,619.96"];
	gan_2022_semglove_semantic_co_occurrences_for_glove_from_bert	[color=green,
		height=2,
		id=gan_2022_semglove_semantic_co_occurrences_for_glove_from_bert,
		"k-core"=8,
		label=gan_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="1958.902337233527,-4600.293630544239!"];
	gan_2022_semglove_semantic_co_occurrences_for_glove_from_bert -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.19,518.89 580.2,519 580.2,518.97 580.19,518.95 580.19,518.93"];
	gan_2022_semglove_semantic_co_occurrences_for_glove_from_bert -> vaswani_2017_attention_is_all_you_need	[pos="e,587.98,510.36 587.97,510.49 587.97,510.46 587.97,510.43 587.98,510.41"];
	gan_2022_semglove_semantic_co_occurrences_for_glove_from_bert -> reimers_2019_sentence_bert_sentence_embeddings_using_siamese_bert_networks	[pos="e,603.92,498.73 603.78,499.22 603.8,499.14 603.83,499.05 603.85,498.97"];
	gan_2022_semglove_semantic_co_occurrences_for_glove_from_bert -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.71,532.59 612.65,532.66 612.67,532.65 612.68,532.63 612.69,532.62"];
	gan_2022_semglove_semantic_co_occurrences_for_glove_from_bert -> wang_2021_phrase_bert_improved_phrase_embeddings_from_bert_with_an_application_to_corpus_exploration	[pos="e,634.34,515.74 633.93,516.17 634,516.1 634.07,516.03 634.14,515.96"];
	gan_2022_semglove_semantic_co_occurrences_for_glove_from_bert -> peters_2018_deep_contextualized_word_representations	[pos="e,583.76,529.91 583.77,530 583.77,529.98 583.77,529.96 583.77,529.95"];
	gan_2022_semglove_semantic_co_occurrences_for_glove_from_bert -> bommasani_2020_interpreting_pretrained_contextualized_representations_via_reductions_to_static_embeddings	[pos="e,600.89,574.05 600.86,574.04 600.87,574.04 600.87,574.04 600.88,574.05"];
	gan_2022_semglove_semantic_co_occurrences_for_glove_from_bert -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,531.88,517.79 532.38,518.28 532.3,518.2 532.22,518.12 532.13,518.04"];
	meng_2020_discriminative_topic_mining_via_category_name_guided_text_embedding	[color=green,
		height=2,
		id=meng_2020_discriminative_topic_mining_via_category_name_guided_text_embedding,
		"k-core"=8,
		label=meng_2020,
		shape=circle,
		style=filled,
		width=2,
		zazaza="2245.302207588483,-4467.506999310564!"];
	meng_2020_discriminative_topic_mining_via_category_name_guided_text_embedding -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,579.92,518.85 579.15,518.83 579.32,518.84 579.46,518.84 579.59,518.84"];
	meng_2020_discriminative_topic_mining_via_category_name_guided_text_embedding -> vaswani_2017_attention_is_all_you_need	[pos="e,578.92,511.1 578.65,511.12 578.7,511.12 578.74,511.12 578.79,511.11"];
	meng_2020_discriminative_topic_mining_via_category_name_guided_text_embedding -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,537.02,451.1 536.8,451.57 536.84,451.49 536.87,451.41 536.91,451.34"];
	meng_2020_discriminative_topic_mining_via_category_name_guided_text_embedding -> peters_2018_deep_contextualized_word_representations	[pos="e,578.54,529.04 578.22,528.98 578.27,528.99 578.33,529 578.38,529.01"];
	meng_2020_discriminative_topic_mining_via_category_name_guided_text_embedding -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,473.89,582.39 474.09,581.98 474.06,582.05 474.03,582.12 473.99,582.19"];
	meng_2020_discriminative_topic_mining_via_category_name_guided_text_embedding -> shang_2017_automated_phrase_mining_from_massive_text_corpora	[pos="e,443.12,552.1 443.46,551.91 443.41,551.94 443.35,551.97 443.29,552"];
	meng_2020_discriminative_topic_mining_via_category_name_guided_text_embedding -> meng_2019_spherical_text_embedding	[pos="e,500.03,530.07 500.09,529.97 500.08,529.99 500.07,530.01 500.06,530.03"];
	meng_2020_discriminative_topic_mining_via_category_name_guided_text_embedding -> meng_2018_weakly_supervised_neural_text_classification	[pos="e,474.36,580.68 474.38,580.65 474.37,580.65 474.37,580.66 474.37,580.67"];
	meng_2020_discriminative_topic_mining_via_category_name_guided_text_embedding -> nickel_2017_poincare_embeddings_for_learning_hierarchical_representations	[pos="e,444.99,526.38 445.02,526.37 445.01,526.37 445.01,526.37 445,526.37"];
	meng_2020_discriminative_topic_mining_via_category_name_guided_text_embedding -> tifrea_2018_poincare_glove_hyperbolic_word_embeddings	[pos="e,445.19,495.66 445.22,495.67 445.21,495.67 445.21,495.67 445.2,495.67"];
	meng_2020_discriminative_topic_mining_via_category_name_guided_text_embedding -> meng_2018_weakly_supervised_hierarchical_text_classification	[pos="e,466.41,568.63 466.5,568.52 466.48,568.54 466.46,568.56 466.45,568.58"];
	meng_2020_discriminative_topic_mining_via_category_name_guided_text_embedding -> huang_2020_guiding_corpus_based_set_expansion_by_auxiliary_sets_generation_and_co_expansion	[pos="e,545.87,578.21 545.71,577.95 545.74,578 545.76,578.04 545.79,578.08"];
	meng_2020_discriminative_topic_mining_via_category_name_guided_text_embedding -> nickel_2018_learning_continuous_hierarchies_in_the_lorentz_model_of_hyperbolic_geometry	[pos="e,437.9,493.22 438.4,493.39 438.32,493.36 438.23,493.33 438.15,493.3"];
	meng_2020_discriminative_topic_mining_via_category_name_guided_text_embedding -> ganea_2018_hyperbolic_entailment_cones_for_learning_hierarchical_embeddings	[pos="e,434.35,510.16 434.73,510.2 434.66,510.19 434.6,510.18 434.54,510.18"];
	meng_2020_discriminative_topic_mining_via_category_name_guided_text_embedding -> zhang_2019_higitclass_keyword_driven_hierarchical_classification_of_github_repositories	[pos="e,441.72,550.07 442.12,549.87 442.06,549.9 441.99,549.93 441.92,549.97"];
	meng_2020_discriminative_topic_mining_via_category_name_guided_text_embedding -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,523.41,509.54 523.37,509.56 523.38,509.56 523.39,509.55 523.4,509.55"];
	shen_2021_corpus_based_open_domain_event_type_induction	[color=blue,
		height=2,
		id=shen_2021_corpus_based_open_domain_event_type_induction,
		"k-core"=7,
		label=shen_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="3816.3449874680427,-7031.039229601163!"];
	shen_2021_corpus_based_open_domain_event_type_induction -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,580.18,518.88 580.16,518.96 580.16,518.95 580.16,518.93 580.17,518.92"];
	shen_2021_corpus_based_open_domain_event_type_induction -> meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding	[pos="e,505.29,523.22 505.67,523.43 505.61,523.39 505.54,523.36 505.48,523.33"];
	shen_2021_corpus_based_open_domain_event_type_induction -> meng_2019_spherical_text_embedding	[pos="e,501.56,530.71 502.02,530.89 501.94,530.86 501.86,530.83 501.79,530.8"];
	shen_2021_corpus_based_open_domain_event_type_induction -> meng_2018_weakly_supervised_neural_text_classification	[pos="e,499.03,574.61 499.37,574.52 499.31,574.54 499.26,574.55 499.2,574.56"];
	shen_2021_corpus_based_open_domain_event_type_induction -> meng_2018_weakly_supervised_hierarchical_text_classification	[pos="e,497.21,565.24 497.62,565.2 497.55,565.21 497.48,565.21 497.41,565.22"];
	shen_2021_corpus_based_open_domain_event_type_induction -> huang_2020_guiding_corpus_based_set_expansion_by_auxiliary_sets_generation_and_co_expansion	[pos="e,557.85,596.75 557.87,596.66 557.86,596.68 557.86,596.7 557.86,596.71"];
	shen_2021_corpus_based_open_domain_event_type_induction -> wang_2019_open_event_extraction_from_online_text_using_a_generative_adversarial_network	[pos="e,628.28,514.99 628.02,515.18 628.06,515.15 628.1,515.12 628.15,515.09"];
	shen_2021_corpus_based_open_domain_event_type_induction -> meng_2022_topic_discovery_via_latent_space_clustering_of_pretrained_language_model_representations	[pos="e,554.8,491.33 554.8,491.36 554.8,491.36 554.8,491.35 554.8,491.34"];
	wolf_2020_transformers_state_of_the_art_natural_language_processing	[color=blue,
		height=2,
		id=wolf_2020_transformers_state_of_the_art_natural_language_processing,
		"k-core"=7,
		label=wolf_2020,
		shape=circle,
		style=filled,
		width=2,
		zazaza="4252.436647770214,-6776.192657397861!"];
	wolf_2020_transformers_state_of_the_art_natural_language_processing -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,586.21,532.36 586.38,532.75 586.35,532.69 586.33,532.62 586.3,532.56"];
	wolf_2020_transformers_state_of_the_art_natural_language_processing -> vaswani_2017_attention_is_all_you_need	[pos="e,593.93,529.22 594.01,529.48 594,529.44 593.98,529.39 593.97,529.35"];
	wolf_2020_transformers_state_of_the_art_natural_language_processing -> radford_2019_language_models_are_unsupervised_multitask_learners	[pos="e,627.46,527.04 627.39,527.48 627.4,527.41 627.42,527.33 627.43,527.26"];
	wolf_2020_transformers_state_of_the_art_natural_language_processing -> lewis_2019_bart_denoising_sequence_to_sequence_pre_training_for_natural_language_generation_translation_and_comprehension	[pos="e,592.42,539.85 592.47,539.98 592.46,539.95 592.45,539.92 592.44,539.9"];
	wolf_2020_transformers_state_of_the_art_natural_language_processing -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.74,532.57 612.74,532.61 612.74,532.6 612.74,532.59 612.74,532.59"];
	wolf_2020_transformers_state_of_the_art_natural_language_processing -> peters_2018_deep_contextualized_word_representations	[pos="e,585.13,532.82 585.31,533.2 585.28,533.14 585.25,533.07 585.22,533.01"];
	wolf_2020_transformers_state_of_the_art_natural_language_processing -> joshi_2019_spanbert_improving_pre_training_by_representing_and_predicting_spans	[pos="e,642.13,543.81 642.08,543.93 642.09,543.9 642.1,543.88 642.11,543.86"];
	qin_2021_lifelong_learning_of_topics_and_domain_specific_word_embeddings	[color=yellow,
		height=2,
		id=qin_2021_lifelong_learning_of_topics_and_domain_specific_word_embeddings,
		"k-core"=6,
		label=qin_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="0.6340117464189168,-0.7733234159416552!"];
	qin_2021_lifelong_learning_of_topics_and_domain_specific_word_embeddings -> card_2017_neural_models_for_documents_with_metadata	[pos="e,587.86,386.99 587.5,387.02 587.56,387.01 587.62,387.01 587.68,387"];
	qin_2021_lifelong_learning_of_topics_and_domain_specific_word_embeddings -> burkhardt_2019_decoupling_sparsity_and_smoothness_in_the_dirichlet_variational_autoencoder_topic_model	[pos="e,581.3,361.9 580.93,362.06 580.99,362.04 581.05,362.01 581.12,361.98"];
	qin_2021_lifelong_learning_of_topics_and_domain_specific_word_embeddings -> card_2018_neural_models_for_documents_with_metadata	[pos="e,587.77,388.03 587.49,388.05 587.54,388.05 587.59,388.05 587.63,388.04"];
	qin_2021_lifelong_learning_of_topics_and_domain_specific_word_embeddings -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,553.8,414.39 553.71,414.35 553.73,414.36 553.75,414.37 553.76,414.37"];
	qin_2021_lifelong_learning_of_topics_and_domain_specific_word_embeddings -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,586.9,379.11 586.43,379.19 586.51,379.18 586.59,379.17 586.67,379.15"];
	qin_2021_lifelong_learning_of_topics_and_domain_specific_word_embeddings -> bojanowski_2016_enriching_word_vectors_with_subword_information	[pos="e,520.34,464.86 520.32,464.57 520.32,464.62 520.32,464.67 520.33,464.71"];
	lee_2022_topic_taxonomy_expansion_via_hierarchy_aware_topic_phrase_generation	[color=green,
		height=2,
		id=lee_2022_topic_taxonomy_expansion_via_hierarchy_aware_topic_phrase_generation,
		"k-core"=8,
		label=lee_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="3290.54207060942,-3764.615949396609!"];
	lee_2022_topic_taxonomy_expansion_via_hierarchy_aware_topic_phrase_generation -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,575.03,524.35 574.71,524.68 574.77,524.63 574.82,524.57 574.87,524.52"];
	lee_2022_topic_taxonomy_expansion_via_hierarchy_aware_topic_phrase_generation -> vaswani_2017_attention_is_all_you_need	[pos="e,575.03,524.16 574.67,524.55 574.73,524.48 574.79,524.42 574.85,524.35"];
	lee_2022_topic_taxonomy_expansion_via_hierarchy_aware_topic_phrase_generation -> zhang_2018_taxogen_unsupervised_topic_taxonomy_construction_by_adaptive_term_embedding_and_clustering	[pos="e,461.23,612.11 461.65,611.89 461.58,611.93 461.51,611.96 461.44,612"];
	lee_2022_topic_taxonomy_expansion_via_hierarchy_aware_topic_phrase_generation -> shang_2017_automated_phrase_mining_from_massive_text_corpora	[pos="e,454.82,559.52 455.31,559.64 455.23,559.62 455.15,559.6 455.07,559.58"];
	lee_2022_topic_taxonomy_expansion_via_hierarchy_aware_topic_phrase_generation -> meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding	[pos="e,483.35,518.07 483.56,518.36 483.53,518.31 483.49,518.26 483.46,518.22"];
	lee_2022_topic_taxonomy_expansion_via_hierarchy_aware_topic_phrase_generation -> meng_2018_weakly_supervised_hierarchical_text_classification	[pos="e,466.43,568.67 466.55,568.69 466.53,568.69 466.5,568.68 466.48,568.68"];
	lee_2022_topic_taxonomy_expansion_via_hierarchy_aware_topic_phrase_generation -> huang_2020_corel_seed_guided_topical_taxonomy_construction_by_concept_learning_and_relation_transferring	[pos="e,503.19,556.99 503.24,557.04 503.23,557.03 503.22,557.02 503.21,557.01"];
	lee_2022_topic_taxonomy_expansion_via_hierarchy_aware_topic_phrase_generation -> mao_2020_octet_online_catalog_taxonomy_enrichment_with_self_supervision	[pos="e,454.16,592.5 454.5,592.43 454.45,592.44 454.39,592.45 454.33,592.46"];
	lee_2022_topic_taxonomy_expansion_via_hierarchy_aware_topic_phrase_generation -> shen_2020_taxoexpan_self_supervised_taxonomy_expansion_with_position_enhanced_graph_neural_network	[pos="e,501.69,584.13 501.74,584.12 501.73,584.12 501.72,584.12 501.71,584.13"];
	lee_2022_topic_taxonomy_expansion_via_hierarchy_aware_topic_phrase_generation -> shang_2020_nettaxo_automated_topic_taxonomy_construction_from_text_rich_network	[pos="e,468.93,623.52 469.42,623.12 469.34,623.18 469.26,623.25 469.17,623.32"];
	lee_2022_topic_taxonomy_expansion_via_hierarchy_aware_topic_phrase_generation -> lee_2022_taxocom_topic_taxonomy_completion_with_hierarchical_discovery_of_novel_topic_clusters	[pos="e,454.96,557.52 455.51,557.68 455.41,557.65 455.32,557.62 455.23,557.6"];
	lee_2022_topic_taxonomy_expansion_via_hierarchy_aware_topic_phrase_generation -> zeng_2021_enhancing_taxonomy_completion_with_concept_generation_via_fusing_relational_representations	[pos="e,534.6,604.2 534.58,604.14 534.58,604.16 534.59,604.17 534.59,604.18"];
	lee_2022_topic_taxonomy_expansion_via_hierarchy_aware_topic_phrase_generation -> shen_2021_taxoclass_hierarchical_multi_label_text_classification_using_only_class_names	[pos="e,552.92,581.77 552.86,581.76 552.87,581.76 552.88,581.77 552.89,581.77"];
	saha_2021_proto_a_neural_cocktail_for_generating_appealing_conversations	[color=yellow,
		height=2,
		id=saha_2021_proto_a_neural_cocktail_for_generating_appealing_conversations,
		"k-core"=6,
		label=saha_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="0.8428019289351312,-0.5382238028956726!"];
	saha_2021_proto_a_neural_cocktail_for_generating_appealing_conversations -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,601.22,529.06 601.5,529.2 601.46,529.18 601.41,529.15 601.36,529.13"];
	saha_2021_proto_a_neural_cocktail_for_generating_appealing_conversations -> vaswani_2017_attention_is_all_you_need	[pos="e,605.3,521.44 605.78,521.75 605.7,521.7 605.62,521.65 605.54,521.6"];
	saha_2021_proto_a_neural_cocktail_for_generating_appealing_conversations -> holtzman_2019_the_curious_case_of_neural_text_degeneration	[pos="e,677.97,492.23 677.96,492.27 677.97,492.26 677.97,492.25 677.97,492.25"];
	saha_2021_proto_a_neural_cocktail_for_generating_appealing_conversations -> reimers_2019_sentence_bert_sentence_embeddings_using_siamese_bert_networks	[pos="e,618.93,505.36 619.29,505.77 619.23,505.7 619.17,505.63 619.11,505.56"];
	saha_2021_proto_a_neural_cocktail_for_generating_appealing_conversations -> liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach	[pos="e,612.77,532.58 612.89,532.64 612.86,532.63 612.84,532.62 612.82,532.61"];
	saha_2021_proto_a_neural_cocktail_for_generating_appealing_conversations -> wolf_2019_transfertransfo_a_transfer_learning_approach_for_neural_network_based_conversational_agents	[pos="e,644.26,585.33 644.31,585.28 644.3,585.29 644.29,585.3 644.28,585.31"];
	zhu_2022_disentangled_learning_of_stance_and_aspect_topics_for_vaccine_attitude_detection_in_social_media	[color=yellow,
		height=2,
		id=zhu_2022_disentangled_learning_of_stance_and_aspect_topics_for_vaccine_attitude_detection_in_social_media,
		"k-core"=6,
		label=zhu_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="0.8899289968534931,-0.4560991228317575!"];
	zhu_2022_disentangled_learning_of_stance_and_aspect_topics_for_vaccine_attitude_detection_in_social_media -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,609.36,505.16 609.75,504.98 609.68,505.01 609.62,505.04 609.55,505.07"];
	zhu_2022_disentangled_learning_of_stance_and_aspect_topics_for_vaccine_attitude_detection_in_social_media -> card_2017_neural_models_for_documents_with_metadata	[pos="e,634.72,413.81 634.97,414.19 634.93,414.12 634.89,414.06 634.85,414"];
	zhu_2022_disentangled_learning_of_stance_and_aspect_topics_for_vaccine_attitude_detection_in_social_media -> card_2018_neural_models_for_documents_with_metadata	[pos="e,630.9,416.52 631.2,416.9 631.15,416.84 631.1,416.78 631.05,416.71"];
	zhu_2022_disentangled_learning_of_stance_and_aspect_topics_for_vaccine_attitude_detection_in_social_media -> zhang_2019_bertscore_evaluating_text_generation_with_bert	[pos="e,662.61,542.37 662.62,542.33 662.62,542.34 662.62,542.35 662.62,542.36"];
	zhu_2022_disentangled_learning_of_stance_and_aspect_topics_for_vaccine_attitude_detection_in_social_media -> zhang_2021_supporting_clustering_with_contrastive_learning	[pos="e,665.54,507.62 665.56,507.55 665.55,507.56 665.55,507.58 665.54,507.59"];
	zhu_2022_disentangled_learning_of_stance_and_aspect_topics_for_vaccine_attitude_detection_in_social_media -> pergola_2021_a_disentangled_adversarial_neural_topic_model_for_separating_opinions_from_plots_in_user_reviews	[pos="e,616.86,435.54 616.98,435.62 616.95,435.6 616.93,435.59 616.91,435.57"];
	zhu_2022_disentangled_learning_of_stance_and_aspect_topics_for_vaccine_attitude_detection_in_social_media -> john_2018_disentangled_representation_learning_for_non_parallel_text_style_transfer	[pos="e,723.91,420.3 723.58,420.66 723.64,420.6 723.69,420.54 723.75,420.48"];
	zhu_2022_disentangled_learning_of_stance_and_aspect_topics_for_vaccine_attitude_detection_in_social_media -> pergola_2019_tdam_a_topic_dependent_attention_model_for_sentiment_analysis	[pos="e,639.51,472.59 639.59,472.59 639.57,472.59 639.55,472.59 639.54,472.59"];
	austin_2022_community_topic_topic_model_inference_by_consecutive_word_community_discovery	[color=blue,
		height=2,
		id=austin_2022_community_topic_topic_model_inference_by_consecutive_word_community_discovery,
		"k-core"=7,
		label=austin_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="7335.5011957542065,-3192.244531481813!"];
	austin_2022_community_topic_topic_model_inference_by_consecutive_word_community_discovery -> burkhardt_2019_decoupling_sparsity_and_smoothness_in_the_dirichlet_variational_autoencoder_topic_model	[pos="e,626.14,328.54 625.69,328.39 625.77,328.42 625.84,328.44 625.92,328.47"];
	austin_2022_community_topic_topic_model_inference_by_consecutive_word_community_discovery -> doogan_2021_topic_model_or_topic_twaddle_re_evaluating_semantic_interpretability_measures	[pos="e,524.93,306.51 525,306.51 524.99,306.51 524.97,306.51 524.96,306.51"];
	austin_2022_community_topic_topic_model_inference_by_consecutive_word_community_discovery -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,554.9,378.37 554.91,377.9 554.91,377.98 554.91,378.06 554.91,378.14"];
	austin_2022_community_topic_topic_model_inference_by_consecutive_word_community_discovery -> hoyle_2021_is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence	[pos="e,593.03,344.28 592.95,344.19 592.97,344.21 592.98,344.23 593,344.24"];
	austin_2022_community_topic_topic_model_inference_by_consecutive_word_community_discovery -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,608.34,357.32 607.92,356.9 607.99,356.97 608.06,357.04 608.13,357.11"];
	austin_2022_community_topic_topic_model_inference_by_consecutive_word_community_discovery -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,574.46,376.41 574.37,376.03 574.38,376.1 574.4,376.16 574.41,376.22"];
	austin_2022_community_topic_topic_model_inference_by_consecutive_word_community_discovery -> zhao_2017_metalda_a_topic_model_that_efficiently_incorporates_meta_information	[pos="e,488.98,331.54 489.38,331.39 489.31,331.42 489.24,331.44 489.18,331.47"];
	zhang_2021_hierarchical_metadata_aware_document_categorization_under_weak_supervision	[color=green,
		height=2,
		id=zhang_2021_hierarchical_metadata_aware_document_categorization_under_weak_supervision,
		"k-core"=8,
		label=zhang_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="4701.455534292502,-1701.8567044388672!"];
	zhang_2021_hierarchical_metadata_aware_document_categorization_under_weak_supervision -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,558.06,528.31 557.76,528.44 557.81,528.41 557.86,528.39 557.91,528.37"];
	zhang_2021_hierarchical_metadata_aware_document_categorization_under_weak_supervision -> meng_2020_hierarchical_topic_mining_via_joint_spherical_tree_and_text_embedding	[pos="e,476.11,507.82 476.15,507.93 476.14,507.91 476.13,507.89 476.13,507.87"];
	zhang_2021_hierarchical_metadata_aware_document_categorization_under_weak_supervision -> meng_2019_spherical_text_embedding	[pos="e,500.01,530.13 499.99,530.19 499.99,530.17 500,530.16 500,530.15"];
	zhang_2021_hierarchical_metadata_aware_document_categorization_under_weak_supervision -> nickel_2017_poincare_embeddings_for_learning_hierarchical_representations	[pos="e,445.01,526.4 445.11,526.46 445.09,526.45 445.07,526.44 445.05,526.43"];
	zhang_2021_hierarchical_metadata_aware_document_categorization_under_weak_supervision -> meng_2018_weakly_supervised_hierarchical_text_classification	[pos="e,466.4,568.66 466.46,568.63 466.44,568.64 466.43,568.64 466.42,568.65"];
	zhang_2021_hierarchical_metadata_aware_document_categorization_under_weak_supervision -> nickel_2018_learning_continuous_hierarchies_in_the_lorentz_model_of_hyperbolic_geometry	[pos="e,439.62,506.15 439.88,506.41 439.84,506.37 439.79,506.33 439.75,506.28"];
	zhang_2021_hierarchical_metadata_aware_document_categorization_under_weak_supervision -> ganea_2018_hyperbolic_entailment_cones_for_learning_hierarchical_embeddings	[pos="e,431.43,515.75 431.72,515.95 431.67,515.91 431.62,515.88 431.57,515.85"];
	zhang_2021_hierarchical_metadata_aware_document_categorization_under_weak_supervision -> zhang_2019_higitclass_keyword_driven_hierarchical_classification_of_github_repositories	[pos="e,418.9,564.66 419.37,564.61 419.29,564.61 419.22,564.62 419.14,564.63"];
	zhang_2021_hierarchical_metadata_aware_document_categorization_under_weak_supervision -> mao_2020_octet_online_catalog_taxonomy_enrichment_with_self_supervision	[pos="e,442.3,595 442.41,594.92 442.38,594.93 442.36,594.95 442.34,594.96"];
	nguyen_2021_contrastive_learning_for_neural_topic_model	[color=red,
		height=2,
		id=nguyen_2021_contrastive_learning_for_neural_topic_model,
		"k-core"=9,
		label=nguyen_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="67.19273865963915,-19.624871350878994!"];
	nguyen_2021_contrastive_learning_for_neural_topic_model -> merity_2016_pointer_sentinel_mixture_models	[pos="e,654.42,404.16 654.49,404.11 654.48,404.12 654.46,404.13 654.45,404.14"];
	nguyen_2021_contrastive_learning_for_neural_topic_model -> card_2017_neural_models_for_documents_with_metadata	[pos="e,618.6,384.91 619.02,384.91 618.95,384.91 618.88,384.91 618.81,384.91"];
	nguyen_2021_contrastive_learning_for_neural_topic_model -> card_2018_neural_models_for_documents_with_metadata	[pos="e,618.64,386.47 618.95,386.46 618.9,386.46 618.85,386.46 618.8,386.46"];
	nguyen_2021_contrastive_learning_for_neural_topic_model -> hoyle_2020_improving_neural_topic_models_using_knowledge_distillation	[pos="e,633.4,428.24 633.74,427.98 633.68,428.02 633.62,428.06 633.57,428.11"];
	nguyen_2021_contrastive_learning_for_neural_topic_model -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,623.29,372.37 623.33,372.37 623.32,372.37 623.32,372.37 623.31,372.37"];
	nguyen_2021_contrastive_learning_for_neural_topic_model -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,618.74,387.52 619,387.51 618.96,387.51 618.91,387.52 618.87,387.52"];
	nguyen_2021_contrastive_learning_for_neural_topic_model -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,630.66,360.72 630.69,360.73 630.69,360.73 630.68,360.72 630.67,360.72"];
	nguyen_2021_contrastive_learning_for_neural_topic_model -> hu_2020_neural_topic_modeling_with_cycle_consistent_adversarial_training	[pos="e,667.63,382.26 667.68,382.26 667.67,382.26 667.66,382.26 667.65,382.26"];
	nguyen_2021_contrastive_learning_for_neural_topic_model -> wang_2020_neural_topic_modeling_with_bidirectional_adversarial_training	[pos="e,648.37,389.46 648.47,389.45 648.45,389.45 648.43,389.46 648.41,389.46"];
	nguyen_2021_contrastive_learning_for_neural_topic_model -> ding_2018_coherence_aware_neural_topic_modeling	[pos="e,661.38,368.2 661.44,368.23 661.43,368.22 661.41,368.22 661.4,368.21"];
	nguyen_2021_contrastive_learning_for_neural_topic_model -> chen_2020_a_simple_framework_for_contrastive_learning_of_visual_representations	[pos="e,715.25,446.93 715.24,446.9 715.24,446.9 715.24,446.91 715.24,446.92"];
	nguyen_2021_contrastive_learning_for_neural_topic_model -> wang_2019_open_event_extraction_from_online_text_using_a_generative_adversarial_network	[pos="e,725.36,445.17 725.34,445.14 725.35,445.15 725.35,445.15 725.35,445.16"];
	"shao_2022_towards_better_understanding_with_uniformity_and_explicit_regularization_of_embeddings_in_embedding_based_neural_topic_\
models"	[color=blue,
		height=2,
		id="\"shao_2022_towards_better_understanding_with_uniformity_and_explicit_regularization_of_embeddings_in_embedding_based_neural_topic_\
models\"",
		"k-core"=7,
		label=shao_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="7805.400372065165,-1753.773694824594!"];
	"shao_2022_towards_better_understanding_with_uniformity_and_explicit_regularization_of_embeddings_in_embedding_based_neural_topic_\
models" -> dieng_2019_topic_modeling_in_embedding_spaces	[pos="e,583.4,374.49 583.77,373.99 583.7,374.07 583.64,374.16 583.58,374.24"];
	"shao_2022_towards_better_understanding_with_uniformity_and_explicit_regularization_of_embeddings_in_embedding_based_neural_topic_\
models" -> nan_2019_topic_modeling_with_wasserstein_autoencoders	[pos="e,623.28,372.33 623.29,372.2 623.29,372.23 623.29,372.25 623.29,372.27"];
	"shao_2022_towards_better_understanding_with_uniformity_and_explicit_regularization_of_embeddings_in_embedding_based_neural_topic_\
models" -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,586.46,376.34 586.71,375.97 586.67,376.03 586.63,376.1 586.58,376.16"];
	"shao_2022_towards_better_understanding_with_uniformity_and_explicit_regularization_of_embeddings_in_embedding_based_neural_topic_\
models" -> miao_2017_discovering_discrete_latent_topics_with_neural_variational_inference	[pos="e,630.65,360.68 630.64,360.58 630.64,360.6 630.64,360.62 630.64,360.64"];
	"shao_2022_towards_better_understanding_with_uniformity_and_explicit_regularization_of_embeddings_in_embedding_based_neural_topic_\
models" -> hu_2020_neural_topic_modeling_with_cycle_consistent_adversarial_training	[pos="e,664.85,377.75 664.68,377.48 664.71,377.52 664.74,377.57 664.77,377.61"];
	"shao_2022_towards_better_understanding_with_uniformity_and_explicit_regularization_of_embeddings_in_embedding_based_neural_topic_\
models" -> wang_2020_neural_topic_modeling_with_bidirectional_adversarial_training	[pos="e,647.21,385.58 647.07,385.07 647.09,385.16 647.12,385.25 647.14,385.33"];
	"shao_2022_towards_better_understanding_with_uniformity_and_explicit_regularization_of_embeddings_in_embedding_based_neural_topic_\
models" -> ding_2018_coherence_aware_neural_topic_modeling	[pos="e,661.33,368.15 661.25,368.03 661.27,368.06 661.29,368.08 661.3,368.1"];
	gui_2021_understanding_patient_reviews_with_minimum_supervision	[color=yellow,
		height=2,
		id=gui_2021_understanding_patient_reviews_with_minimum_supervision,
		"k-core"=6,
		label=gui_2021,
		shape=circle,
		style=filled,
		width=2,
		zazaza="0.9920353293629114,-0.1259599039422742!"];
	gui_2021_understanding_patient_reviews_with_minimum_supervision -> devlin_2019_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding	[pos="e,578.34,517.16 577.8,516.67 577.9,516.76 577.99,516.84 578.08,516.92"];
	gui_2021_understanding_patient_reviews_with_minimum_supervision -> vaswani_2017_attention_is_all_you_need	[pos="e,585.28,508.52 584.93,508.28 584.99,508.32 585.05,508.36 585.11,508.4"];
	gui_2021_understanding_patient_reviews_with_minimum_supervision -> he_2017_an_unsupervised_neural_attention_model_for_aspect_extraction	[pos="e,471.1,424.48 471.22,424.57 471.19,424.55 471.17,424.53 471.15,424.52"];
	gui_2021_understanding_patient_reviews_with_minimum_supervision -> xu_2018_double_embeddings_and_cnn_based_sequence_labeling_for_aspect_extraction	[pos="e,451.92,469.26 452.32,469.26 452.25,469.26 452.19,469.26 452.12,469.26"];
	gui_2021_understanding_patient_reviews_with_minimum_supervision -> card_2017_neural_models_for_documents_with_metadata	[pos="e,578.44,418.82 577.98,419.24 578.06,419.17 578.14,419.1 578.21,419.03"];
	gui_2021_understanding_patient_reviews_with_minimum_supervision -> card_2018_neural_models_for_documents_with_metadata	[pos="e,576.97,417.15 576.58,417.54 576.64,417.47 576.71,417.41 576.77,417.34"];
	gui_2021_understanding_patient_reviews_with_minimum_supervision -> tulkens_2020_embarrassingly_simple_unsupervised_aspect_extraction	[pos="e,454.64,448.23 455,448.33 454.94,448.32 454.88,448.3 454.82,448.28"];
	tai_2022_hyperbolic_disentangled_representation_for_fine_grained_aspect_extraction	[color=blue,
		height=2,
		id=tai_2022_hyperbolic_disentangled_representation_for_fine_grained_aspect_extraction,
		"k-core"=7,
		label=tai_2022,
		shape=circle,
		style=filled,
		width=2,
		zazaza="7964.138031100518,-756.6403232423825!"];
	tai_2022_hyperbolic_disentangled_representation_for_fine_grained_aspect_extraction -> angelidis_2018_summarizing_opinions_aspect_extraction_meets_sentiment_prediction_and_they_are_both_weakly_supervised	[pos="e,421.4,432.07 421.47,432.01 421.45,432.02 421.44,432.03 421.43,432.04"];
	tai_2022_hyperbolic_disentangled_representation_for_fine_grained_aspect_extraction -> he_2017_an_unsupervised_neural_attention_model_for_aspect_extraction	[pos="e,471.05,424.43 471.02,424.4 471.03,424.41 471.03,424.41 471.04,424.42"];
	tai_2022_hyperbolic_disentangled_representation_for_fine_grained_aspect_extraction -> jang_2016_categorical_reparameterization_with_gumbel_softmax	[pos="e,512.07,361.41 511.57,361.81 511.66,361.74 511.74,361.68 511.82,361.61"];
	tai_2022_hyperbolic_disentangled_representation_for_fine_grained_aspect_extraction -> srivastava_2017_autoencoding_variational_inference_for_topic_models	[pos="e,527.23,396.76 526.92,396.8 526.97,396.8 527.02,396.79 527.08,396.78"];
	tai_2022_hyperbolic_disentangled_representation_for_fine_grained_aspect_extraction -> pablos_2018_w2vlda_almost_unsupervised_system_for_aspect_based_sentiment_analysis	[pos="e,417.53,442.94 417.61,442.86 417.59,442.88 417.58,442.9 417.56,442.91"];
	tai_2022_hyperbolic_disentangled_representation_for_fine_grained_aspect_extraction -> nickel_2017_poincare_embeddings_for_learning_hierarchical_representations	[pos="e,449.11,479.52 449.13,479.23 449.13,479.28 449.12,479.33 449.12,479.37"];
	tai_2022_hyperbolic_disentangled_representation_for_fine_grained_aspect_extraction -> nickel_2018_learning_continuous_hierarchies_in_the_lorentz_model_of_hyperbolic_geometry	[pos="e,426.03,473.42 426.2,473.03 426.17,473.1 426.14,473.16 426.12,473.23"];
	tai_2022_hyperbolic_disentangled_representation_for_fine_grained_aspect_extraction -> le_2019_inferring_concept_hierarchies_from_text_corpora_via_hyperbolic_embeddings	[pos="e,418.42,469.86 418.67,469.44 418.62,469.51 418.58,469.58 418.54,469.65"];
	tai_2022_hyperbolic_disentangled_representation_for_fine_grained_aspect_extraction -> tulkens_2020_embarrassingly_simple_unsupervised_aspect_extraction	[pos="e,442.09,444.65 442.12,444.57 442.12,444.59 442.11,444.6 442.11,444.62"];
	tai_2022_hyperbolic_disentangled_representation_for_fine_grained_aspect_extraction -> aly_2019_every_child_should_have_parents_a_taxonomy_refinement_algorithm_based_on_hyperbolic_term_embeddings	[pos="e,433.51,476.38 433.63,476 433.61,476.06 433.59,476.13 433.57,476.19"];
}
