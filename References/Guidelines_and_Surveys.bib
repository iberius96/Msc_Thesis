%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Samuele Ceol at 2022-10-27 21:27:56 +0200 


%% Saved with string encoding Unicode (UTF-8) 



@incollection{Ghadery_2019,
	author = {Erfan Ghadery and Sajad Movahedi and Masoud Jalili Sabet and Heshaam Faili and Azadeh Shakery},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:11:57 +0200},
	date-modified = {2022-10-23 18:11:57 +0200},
	doi = {10.1007/978-3-030-15712-8_37},
	pages = {575--589},
	publisher = {Springer International Publishing},
	title = {{LICD}: A Language-Independent Approach for Aspect Category Detection},
	url = {https://doi.org/10.1007%2F978-3-030-15712-8_37},
	year = 2019,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-15712-8_37},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-15712-8_37}}

@incollection{Mourad_2017,
	author = {Ahmed Mourad and Falk Scholer and Mark Sanderson},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:11:53 +0200},
	date-modified = {2022-10-23 18:11:53 +0200},
	doi = {10.1007/978-3-319-56608-5_26},
	pages = {331--342},
	publisher = {Springer International Publishing},
	title = {Language Influences on Tweeter Geolocation},
	url = {https://doi.org/10.1007%2F978-3-319-56608-5_26},
	year = 2017,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-319-56608-5_26},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-319-56608-5_26}}

@incollection{Meladianos_2018,
	author = {Polykarpos Meladianos and Christos Xypolopoulos and Giannis Nikolentzos and Michalis Vazirgiannis},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:11:49 +0200},
	date-modified = {2022-10-23 18:11:49 +0200},
	doi = {10.1007/978-3-319-76941-7_36},
	pages = {481--493},
	publisher = {Springer International Publishing},
	title = {An Optimization Approach for Sub-event Detection and Summarization in Twitter},
	url = {https://doi.org/10.1007%2F978-3-319-76941-7_36},
	year = 2018,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-319-76941-7_36},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-319-76941-7_36}}

@incollection{Bhattacharya_2019,
	author = {Paheli Bhattacharya and Kaustubh Hiware and Subham Rajgaria and Nilay Pochhi and Kripabandhu Ghosh and Saptarshi Ghosh},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:11:46 +0200},
	date-modified = {2022-10-23 18:11:46 +0200},
	doi = {10.1007/978-3-030-15712-8_27},
	pages = {413--428},
	publisher = {Springer International Publishing},
	title = {A Comparative Study of Summarization Algorithms Applied to Legal Case Judgments},
	url = {https://doi.org/10.1007%2F978-3-030-15712-8_27},
	year = 2019,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-15712-8_27},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-15712-8_27}}

@incollection{Almasian_2019,
	author = {Satya Almasian and Andreas Spitz and Michael Gertz},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:11:43 +0200},
	date-modified = {2022-10-23 18:11:43 +0200},
	doi = {10.1007/978-3-030-15712-8_20},
	pages = {307--322},
	publisher = {Springer International Publishing},
	title = {Word Embeddings for Entity-Annotated Texts},
	url = {https://doi.org/10.1007%2F978-3-030-15712-8_20},
	year = 2019,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-15712-8_20},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-15712-8_20}}

@incollection{Pritsos_2019,
	author = {Dimitrios Pritsos and Anderson Rocha and Efstathios Stamatatos},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:11:40 +0200},
	date-modified = {2022-10-23 18:11:40 +0200},
	doi = {10.1007/978-3-030-15719-7_1},
	pages = {3--11},
	publisher = {Springer International Publishing},
	title = {Open-Set Web Genre Identification Using Distributional Features and Nearest Neighbors Distance Ratio},
	url = {https://doi.org/10.1007%2F978-3-030-15719-7_1},
	year = 2019,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-15719-7_1},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-15719-7_1}}

@incollection{Mullick_2019,
	author = {Ankan Mullick and Sayan Ghosh and Ritam Dutt and Avijit Ghosh and Abhijnan Chakraborty},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:11:36 +0200},
	date-modified = {2022-10-23 18:11:36 +0200},
	doi = {10.1007/978-3-030-15719-7_23},
	pages = {180--187},
	publisher = {Springer International Publishing},
	title = {Public Sphere 2.0: Targeted Commenting in Online News Media},
	url = {https://doi.org/10.1007%2F978-3-030-15719-7_23},
	year = 2019,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-15719-7_23},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-15719-7_23}}

@incollection{Bondarenko_2021,
	author = {Alexander Bondarenko and Lukas Gienapp and Maik Fr{\"o}be and Meriem Beloucif and Yamen Ajjour and Alexander Panchenko and Chris Biemann and Benno Stein and Henning Wachsmuth and Martin Potthast and Matthias Hagen},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:11:33 +0200},
	date-modified = {2022-10-23 18:11:33 +0200},
	doi = {10.1007/978-3-030-72240-1_67},
	pages = {574--582},
	publisher = {Springer International Publishing},
	title = {Overview of Touch{\'{e}} 2021: Argument Retrieval},
	url = {https://doi.org/10.1007%2F978-3-030-72240-1_67},
	year = 2021,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-72240-1_67},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-72240-1_67}}

@incollection{Sumikawa_2018,
	author = {Yasunobu Sumikawa and Adam Jatowt},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:11:29 +0200},
	date-modified = {2022-10-23 18:11:29 +0200},
	doi = {10.1007/978-3-319-76941-7_69},
	pages = {729--736},
	publisher = {Springer International Publishing},
	title = {Classifying Short Descriptions of Past Events},
	url = {https://doi.org/10.1007%2F978-3-319-76941-7_69},
	year = 2018,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-319-76941-7_69},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-319-76941-7_69}}

@incollection{Wang_2022,
	author = {Xi Wang and Iadh Ounis and Craig Macdonald},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:11:25 +0200},
	date-modified = {2022-10-23 18:11:25 +0200},
	doi = {10.1007/978-3-030-99736-6_33},
	pages = {487--501},
	publisher = {Springer International Publishing},
	title = {Effective Rating Prediction Using an Attention-Based User Review Sentiment Model},
	url = {https://doi.org/10.1007%2F978-3-030-99736-6_33},
	year = 2022,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-99736-6_33},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-99736-6_33}}

@incollection{Ishigaki_2020,
	author = {Tatsuya Ishigaki and Kazuya Machida and Hayato Kobayashi and Hiroya Takamura and Manabu Okumura},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:11:22 +0200},
	date-modified = {2022-10-23 18:11:22 +0200},
	doi = {10.1007/978-3-030-45442-5_23},
	pages = {182--189},
	publisher = {Springer International Publishing},
	title = {Distant Supervision for Extractive Question Summarization},
	url = {https://doi.org/10.1007%2F978-3-030-45442-5_23},
	year = 2020,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-45442-5_23},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-45442-5_23}}

@incollection{Esuli_2022,
	author = {Andrea Esuli and Alejandro Moreo and Fabrizio Sebastiani},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:11:17 +0200},
	date-modified = {2022-10-23 18:11:17 +0200},
	doi = {10.1007/978-3-030-99739-7_47},
	pages = {374--381},
	publisher = {Springer International Publishing},
	title = {{LeQua}@{CLEF}2022: Learning to Quantify},
	url = {https://doi.org/10.1007%2F978-3-030-99739-7_47},
	year = 2022,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-99739-7_47},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-99739-7_47}}

@incollection{Chelliah_2020,
	author = {Muthusamy Chelliah and Manish Shrivastava and Jaidam Ram Tej},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:11:09 +0200},
	date-modified = {2022-10-23 18:11:09 +0200},
	doi = {10.1007/978-3-030-45442-5_88},
	pages = {663--668},
	publisher = {Springer International Publishing},
	title = {Principle-to-Program: Neural Methods for Similar Question Retrieval in Online Communities},
	url = {https://doi.org/10.1007%2F978-3-030-45442-5_88},
	year = 2020,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-45442-5_88},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-45442-5_88}}

@incollection{Zhang_2018,
	author = {Ruqing Zhang and Jiafeng Guo and Yanyan Lan and Jun Xu and Xueqi Cheng},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:11:02 +0200},
	date-modified = {2022-10-23 18:11:02 +0200},
	doi = {10.1007/978-3-319-76941-7_23},
	pages = {303--315},
	publisher = {Springer International Publishing},
	title = {Aggregating Neural Word Embeddings for Document Representation},
	url = {https://doi.org/10.1007%2F978-3-319-76941-7_23},
	year = 2018,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-319-76941-7_23},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-319-76941-7_23}}

@incollection{Fisher_2019,
	author = {Mark Fisher and Dyaa Albakour and Udo Kruschwitz and Miguel Martinez},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:10:58 +0200},
	date-modified = {2022-10-23 18:10:58 +0200},
	doi = {10.1007/978-3-030-15712-8_5},
	pages = {69--85},
	publisher = {Springer International Publishing},
	title = {Recognising Summary Articles},
	url = {https://doi.org/10.1007%2F978-3-030-15712-8_5},
	year = 2019,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-15712-8_5},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-15712-8_5}}

@incollection{Meng_2021,
	author = {Rui Meng and Zhen Yue and Alyssa Glass},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:10:54 +0200},
	date-modified = {2022-10-23 18:10:54 +0200},
	doi = {10.1007/978-3-030-72113-8_29},
	pages = {433--450},
	publisher = {Springer International Publishing},
	title = {Predicting User Engagement Status for~Online Evaluation of Intelligent Assistants},
	url = {https://doi.org/10.1007%2F978-3-030-72113-8_29},
	year = 2021,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-72113-8_29},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-72113-8_29}}

@incollection{Batra_2020,
	author = {Vishwash Batra and Aparajita Haldar and Yulan He and Hakan Ferhatosmanoglu and George Vogiatzis and Tanaya Guha},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:10:51 +0200},
	date-modified = {2022-10-23 18:10:51 +0200},
	doi = {10.1007/978-3-030-45439-5_4},
	pages = {50--64},
	publisher = {Springer International Publishing},
	title = {Variational Recurrent Sequence-to-Sequence Retrieval for Stepwise Illustration},
	url = {https://doi.org/10.1007%2F978-3-030-45439-5_4},
	year = 2020,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-45439-5_4},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-45439-5_4}}

@incollection{Abazari_Kia_2021,
	author = {Mahsa Abazari Kia},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:10:48 +0200},
	date-modified = {2022-10-23 18:10:48 +0200},
	doi = {10.1007/978-3-030-72240-1_78},
	pages = {667--671},
	publisher = {Springer International Publishing},
	title = {Automated Multi-document Text Summarization from Heterogeneous Data Sources},
	url = {https://doi.org/10.1007%2F978-3-030-72240-1_78},
	year = 2021,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-72240-1_78},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-72240-1_78}}

@incollection{Montazeralghaem_2020,
	author = {Ali Montazeralghaem and Razieh Rahimi and James Allan},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:10:44 +0200},
	date-modified = {2022-10-23 18:10:44 +0200},
	doi = {10.1007/978-3-030-45439-5_30},
	pages = {446--460},
	publisher = {Springer International Publishing},
	title = {Relevance Ranking Based on Query-Aware Context Analysis},
	url = {https://doi.org/10.1007%2F978-3-030-45439-5_30},
	year = 2020,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-45439-5_30},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-45439-5_30}}

@incollection{Lugo_2021,
	author = {Luis Lugo and Jose G. Moreno and Gilles Hubert},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:10:36 +0200},
	date-modified = {2022-10-23 18:10:36 +0200},
	doi = {10.1007/978-3-030-72113-8_27},
	pages = {405--418},
	publisher = {Springer International Publishing},
	title = {Modeling User Search Tasks with a Language-Agnostic Unsupervised Approach},
	url = {https://doi.org/10.1007%2F978-3-030-72113-8_27},
	year = 2021,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-72113-8_27},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-72113-8_27}}

@incollection{Kuzi_2021,
	author = {Saar Kuzi and ChengXiang Zhai},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:10:31 +0200},
	date-modified = {2022-10-23 18:10:31 +0200},
	doi = {10.1007/978-3-030-72113-8_19},
	pages = {284--297},
	publisher = {Springer International Publishing},
	title = {A Study of Distributed Representations for Figures of Research Articles},
	url = {https://doi.org/10.1007%2F978-3-030-72113-8_19},
	year = 2021,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-72113-8_19},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-72113-8_19}}

@incollection{Vu_2017,
	author = {Thanh Vu and Dat Quoc Nguyen and Mark Johnson and Dawei Song and Alistair Willis},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:10:29 +0200},
	date-modified = {2022-10-23 18:10:29 +0200},
	doi = {10.1007/978-3-319-56608-5_54},
	pages = {598--604},
	publisher = {Springer International Publishing},
	title = {Search Personalization with Embeddings},
	url = {https://doi.org/10.1007%2F978-3-319-56608-5_54},
	year = 2017,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-319-56608-5_54},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-319-56608-5_54}}

@incollection{Bi_2019,
	author = {Keping Bi and Qingyao Ai and W. Bruce Croft},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:10:26 +0200},
	date-modified = {2022-10-23 18:10:26 +0200},
	doi = {10.1007/978-3-030-15712-8_36},
	pages = {558--572},
	publisher = {Springer International Publishing},
	title = {Iterative Relevance Feedback for Answer Passage Retrieval with Passage-Level Semantic Match},
	url = {https://doi.org/10.1007%2F978-3-030-15712-8_36},
	year = 2019,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-15712-8_36},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-15712-8_36}}

@incollection{Potha_2019,
	author = {Nektaria Potha and Efstathios Stamatatos},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:10:24 +0200},
	date-modified = {2022-10-23 18:10:24 +0200},
	doi = {10.1007/978-3-030-15712-8_7},
	pages = {102--115},
	publisher = {Springer International Publishing},
	title = {Dynamic Ensemble Selection for Author Verification},
	url = {https://doi.org/10.1007%2F978-3-030-15712-8_7},
	year = 2019,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-15712-8_7},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-15712-8_7}}

@incollection{Kovalchuk_2020,
	author = {Pavlo Kovalchuk and Diogo Proen{\c{c}}a and Jos{\'{e}} Borbinha and Rui Henriques},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:10:21 +0200},
	date-modified = {2022-10-23 18:10:21 +0200},
	doi = {10.1007/978-3-030-45439-5_19},
	pages = {281--295},
	publisher = {Springer International Publishing},
	title = {Moving from Formal Towards Coherent Concept Analysis: Why, When and How},
	url = {https://doi.org/10.1007%2F978-3-030-45439-5_19},
	year = 2020,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-45439-5_19},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-45439-5_19}}

@incollection{Badjatiya_2018,
	author = {Pinkesh Badjatiya and Litton J. Kurisinkel and Manish Gupta and Vasudeva Varma},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:10:19 +0200},
	date-modified = {2022-10-23 18:10:19 +0200},
	doi = {10.1007/978-3-319-76941-7_14},
	pages = {180--193},
	publisher = {Springer International Publishing},
	title = {Attention-Based Neural Text Segmentation},
	url = {https://doi.org/10.1007%2F978-3-319-76941-7_14},
	year = 2018,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-319-76941-7_14},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-319-76941-7_14}}

@incollection{Jatowt_2021,
	author = {Adam Jatowt and I-Chen Hung and Michael F{\"a}rber and Ricardo Campos and Masatoshi Yoshikawa},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:10:16 +0200},
	date-modified = {2022-10-23 18:10:16 +0200},
	doi = {10.1007/978-3-030-72113-8_17},
	pages = {254--269},
	publisher = {Springer International Publishing},
	title = {Exploding {TV} Sets and Disappointing Laptops: Suggesting Interesting Content in News Archives Based on Surprise Estimation},
	url = {https://doi.org/10.1007%2F978-3-030-72113-8_17},
	year = 2021,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-72113-8_17},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-72113-8_17}}

@incollection{Brochier_2020,
	author = {Robin Brochier and Adrien Guille and Julien Velcin},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:10:14 +0200},
	date-modified = {2022-10-23 18:10:14 +0200},
	doi = {10.1007/978-3-030-45439-5_22},
	pages = {326--340},
	publisher = {Springer International Publishing},
	title = {Inductive Document Network Embedding with Topic-Word Attention},
	url = {https://doi.org/10.1007%2F978-3-030-45439-5_22},
	year = 2020,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-45439-5_22},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-45439-5_22}}

@incollection{Fard_2020,
	author = {Mazar Moradi Fard and Thibaut Thonet and Eric Gaussier},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:10:11 +0200},
	date-modified = {2022-10-23 18:10:11 +0200},
	doi = {10.1007/978-3-030-45439-5_1},
	pages = {3--16},
	publisher = {Springer International Publishing},
	title = {Seed-Guided Deep Document Clustering},
	url = {https://doi.org/10.1007%2F978-3-030-45439-5_1},
	year = 2020,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-45439-5_1},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-45439-5_1}}

@incollection{Bahrainian_2019,
	author = {Seyed Ali Bahrainian and Fattane Zarrinkalam and Ida Mele and Fabio Crestani},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:10:09 +0200},
	date-modified = {2022-10-23 18:10:09 +0200},
	doi = {10.1007/978-3-030-15712-8_17},
	pages = {261--275},
	publisher = {Springer International Publishing},
	title = {Predicting the Topic of Your Next Query for Just-In-Time {IR}},
	url = {https://doi.org/10.1007%2F978-3-030-15712-8_17},
	year = 2019,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-15712-8_17},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-15712-8_17}}

@incollection{Palencia_Olivar_2022,
	author = {Miguel Palencia-Olivar},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:10:06 +0200},
	date-modified = {2022-10-23 18:10:06 +0200},
	doi = {10.1007/978-3-030-99739-7_64},
	pages = {520--527},
	publisher = {Springer International Publishing},
	title = {A Topical Approach to Capturing Customer Insight Dynamics in Social Media},
	url = {https://doi.org/10.1007%2F978-3-030-99739-7_64},
	year = 2022,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-99739-7_64},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-99739-7_64}}

@incollection{Wang_2019,
	author = {Xi Wang and Anjie Fang and Iadh Ounis and Craig Macdonald},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:10:03 +0200},
	date-modified = {2022-10-23 18:10:03 +0200},
	doi = {10.1007/978-3-030-15712-8_54},
	pages = {787--794},
	publisher = {Springer International Publishing},
	title = {Evaluating Similarity Metrics for Latent Twitter Topics},
	url = {https://doi.org/10.1007%2F978-3-030-15712-8_54},
	year = 2019,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-15712-8_54},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-15712-8_54}}

@incollection{Fang_2017,
	author = {Anjie Fang and Craig Macdonald and Iadh Ounis and Philip Habel and Xiao Yang},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:10:01 +0200},
	date-modified = {2022-10-23 18:10:01 +0200},
	doi = {10.1007/978-3-319-56608-5_20},
	pages = {252--265},
	publisher = {Springer International Publishing},
	title = {Exploring Time-Sensitive Variational Bayesian Inference {LDA} for Social Media Data},
	url = {https://doi.org/10.1007%2F978-3-319-56608-5_20},
	year = 2017,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-319-56608-5_20},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-319-56608-5_20}}

@incollection{Bahrainian_2018,
	author = {Seyed Ali Bahrainian and Ida Mele and Fabio Crestani},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:09:57 +0200},
	date-modified = {2022-10-23 18:09:57 +0200},
	doi = {10.1007/978-3-319-76941-7_2},
	pages = {16--28},
	publisher = {Springer International Publishing},
	title = {Predicting Topics in Scholarly Papers},
	url = {https://doi.org/10.1007%2F978-3-319-76941-7_2},
	year = 2018,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-319-76941-7_2},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-319-76941-7_2}}

@incollection{Spitz_2018,
	author = {Andreas Spitz and Michael Gertz},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:09:55 +0200},
	date-modified = {2022-10-23 18:09:55 +0200},
	doi = {10.1007/978-3-319-76941-7_1},
	pages = {3--15},
	publisher = {Springer International Publishing},
	title = {Entity-Centric Topic Extraction and Exploration: A Network-Based Approach},
	url = {https://doi.org/10.1007%2F978-3-319-76941-7_1},
	year = 2018,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-319-76941-7_1},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-319-76941-7_1}}

@incollection{Azarbonyad_2017,
	author = {Hosein Azarbonyad and Mostafa Dehghani and Tom Kenter and Maarten Marx and Jaap Kamps and Maarten de Rijke},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:09:52 +0200},
	date-modified = {2022-10-23 18:09:52 +0200},
	doi = {10.1007/978-3-319-56608-5_6},
	pages = {68--81},
	publisher = {Springer International Publishing},
	title = {Hierarchical Re-estimation of Topic Models for Measuring Topical Diversity},
	url = {https://doi.org/10.1007%2F978-3-319-56608-5_6},
	year = 2017,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-319-56608-5_6},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-319-56608-5_6}}

@incollection{_ahinu__2021,
	author = {Furkan {\c{S}}ahinu{\c{c}} and Cagri Toraman},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:09:49 +0200},
	date-modified = {2022-10-23 18:09:49 +0200},
	doi = {10.1007/978-3-030-72240-1_50},
	pages = {471--478},
	publisher = {Springer International Publishing},
	title = {Tweet Length Matters: A Comparative Analysis on Topic Detection in Microblogs},
	url = {https://doi.org/10.1007%2F978-3-030-72240-1_50},
	year = 2021,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-72240-1_50},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-72240-1_50}}

@incollection{Aletras_2017,
	author = {Nikolaos Aletras and Arpit Mittal},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:09:46 +0200},
	date-modified = {2022-10-23 18:09:46 +0200},
	doi = {10.1007/978-3-319-56608-5_40},
	pages = {500--505},
	publisher = {Springer International Publishing},
	title = {Labeling Topics with Images Using a Neural Network},
	url = {https://doi.org/10.1007%2F978-3-319-56608-5_40},
	year = 2017,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-319-56608-5_40},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-319-56608-5_40}}

@incollection{Valero_2022,
	author = {Francisco B. Valero and Marion Baranes and Elena V. Epure},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:09:43 +0200},
	date-modified = {2022-10-23 18:09:43 +0200},
	doi = {10.1007/978-3-030-99736-6_32},
	pages = {472--486},
	publisher = {Springer International Publishing},
	title = {Topic Modeling on Podcast Short-Text Metadata},
	url = {https://doi.org/10.1007%2F978-3-030-99736-6_32},
	year = 2022,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-99736-6_32},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-99736-6_32}}

@incollection{Zosa_2022,
	author = {Elaine Zosa and Lidia Pivovarova and Michele Boggia and Sardana Ivanova},
	booktitle = {Lecture Notes in Computer Science},
	date-added = {2022-10-23 18:09:41 +0200},
	date-modified = {2022-10-23 18:09:41 +0200},
	doi = {10.1007/978-3-030-99739-7_29},
	pages = {248--256},
	publisher = {Springer International Publishing},
	title = {Multilingual Topic Labelling of News Topics Using Ontological Mapping},
	url = {https://doi.org/10.1007%2F978-3-030-99739-7_29},
	year = 2022,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-99739-7_29},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-99739-7_29}}

@incollection{Wenzel_2017,
	author = {Florian Wenzel and Th{\'{e}}o Galy-Fajou and Matth{\"a}us Deutsch and Marius Kloft},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	date-added = {2022-10-23 18:06:45 +0200},
	date-modified = {2022-10-23 18:06:45 +0200},
	doi = {10.1007/978-3-319-71249-9_19},
	pages = {307--322},
	publisher = {Springer International Publishing},
	title = {Bayesian Nonlinear Support Vector Machines for Big Data},
	url = {https://doi.org/10.1007%2F978-3-319-71249-9_19},
	year = 2017,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-319-71249-9_19},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-319-71249-9_19}}

@incollection{Yang_2021,
	author = {Haitian Yang and Weiqing Huang and Xuan Zhao and Yan Wang and Yuyan Chen and Bin Lv and Rui Mao and Ning Li},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	date-added = {2022-10-23 18:06:41 +0200},
	date-modified = {2022-10-23 18:06:41 +0200},
	doi = {10.1007/978-3-030-67664-3_35},
	pages = {584--599},
	publisher = {Springer International Publishing},
	title = {{AMQAN}: Adaptive Multi-Attention Question-Answer Networks for Answer Selection},
	url = {https://doi.org/10.1007%2F978-3-030-67664-3_35},
	year = 2021,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-67664-3_35},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-67664-3_35}}

@incollection{Liu_2019,
	author = {Peng Liu and Lemei Zhang and Jon Atle Gulla},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	date-added = {2022-10-23 18:06:34 +0200},
	date-modified = {2022-10-23 18:06:34 +0200},
	doi = {10.1007/978-3-030-10928-8_41},
	pages = {691--708},
	publisher = {Springer International Publishing},
	title = {Learning Multi-granularity Dynamic Network Representations for Social Recommendation},
	url = {https://doi.org/10.1007%2F978-3-030-10928-8_41},
	year = 2019,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-10928-8_41},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-10928-8_41}}

@incollection{Chalapathy_2019,
	author = {Raghavendra Chalapathy and Edward Toth and Sanjay Chawla},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	date-added = {2022-10-23 18:06:29 +0200},
	date-modified = {2022-10-23 18:06:29 +0200},
	doi = {10.1007/978-3-030-10925-7_11},
	pages = {173--189},
	publisher = {Springer International Publishing},
	title = {Group Anomaly Detection Using Deep Generative Models},
	url = {https://doi.org/10.1007%2F978-3-030-10925-7_11},
	year = 2019,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-10925-7_11},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-10925-7_11}}

@incollection{Audebert_2020,
	author = {Nicolas Audebert and Catherine Herold and Kuider Slimani and C{\'{e}}dric Vidal},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	date-added = {2022-10-23 18:06:24 +0200},
	date-modified = {2022-10-23 18:06:24 +0200},
	doi = {10.1007/978-3-030-43823-4_35},
	pages = {427--443},
	publisher = {Springer International Publishing},
	title = {Multimodal Deep Networks for Text and Image-Based Document Classification},
	url = {https://doi.org/10.1007%2F978-3-030-43823-4_35},
	year = 2020,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-43823-4_35},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-43823-4_35}}

@incollection{Khandelwal_2021,
	author = {Kanishka Khandelwal and Devendra Dhaka and Vivek Barsopia},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	date-added = {2022-10-23 18:06:19 +0200},
	date-modified = {2022-10-23 18:06:19 +0200},
	doi = {10.1007/978-3-030-67658-2_36},
	pages = {628--643},
	publisher = {Springer International Publishing},
	title = {Predicting Future Classifiers for Evolving Non-linear Decision Boundaries},
	url = {https://doi.org/10.1007%2F978-3-030-67658-2_36},
	year = 2021,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-67658-2_36},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-67658-2_36}}

@incollection{Barbieri_2017,
	author = {Nicola Barbieri and Giuseppe Manco and Ettore Ritacco},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	date-added = {2022-10-23 18:06:14 +0200},
	date-modified = {2022-10-23 18:06:14 +0200},
	doi = {10.1007/978-3-319-71249-9_41},
	pages = {684--700},
	publisher = {Springer International Publishing},
	title = {Survival Factorization on Diffusion Networks},
	url = {https://doi.org/10.1007%2F978-3-319-71249-9_41},
	year = 2017,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-319-71249-9_41},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-319-71249-9_41}}

@incollection{Harada_2021,
	author = {Shonosuke Harada and Hisashi Kashima},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	date-added = {2022-10-23 18:06:09 +0200},
	date-modified = {2022-10-23 18:06:09 +0200},
	doi = {10.1007/978-3-030-67658-2_31},
	pages = {542--558},
	publisher = {Springer International Publishing},
	title = {Counterfactual Propagation for Semi-supervised Individual Treatment Effect Estimation},
	url = {https://doi.org/10.1007%2F978-3-030-67658-2_31},
	year = 2021,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-67658-2_31},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-67658-2_31}}

@incollection{Farruque_2020,
	author = {Nawshad Farruque and Osmar Zaiane and Randy Goebel},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	date-added = {2022-10-23 18:06:04 +0200},
	date-modified = {2022-10-23 18:06:04 +0200},
	doi = {10.1007/978-3-030-46133-1_22},
	pages = {359--375},
	publisher = {Springer International Publishing},
	title = {Augmenting Semantic Representation of Depressive Language: From Forums to Microblogs},
	url = {https://doi.org/10.1007%2F978-3-030-46133-1_22},
	year = 2020,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-46133-1_22},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-46133-1_22}}

@incollection{Lim_2019,
	author = {Kwan Hui Lim and Sachini Jayasekara and Shanika Karunasekera and Aaron Harwood and Lucia Falzon and John Dunn and Glenn Burgess},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	date-added = {2022-10-23 18:06:00 +0200},
	date-modified = {2022-10-23 18:06:00 +0200},
	doi = {10.1007/978-3-030-10997-4_44},
	pages = {649--653},
	publisher = {Springer International Publishing},
	title = {{RAPID}: Real-time Analytics Platform for Interactive Data Mining},
	url = {https://doi.org/10.1007%2F978-3-030-10997-4_44},
	year = 2019,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-10997-4_44},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-10997-4_44}}

@incollection{Appel_2019,
	author = {Ana Paula Appel and Renato L. F. Cunha and Charu C. Aggarwal and Marcela Megumi Terakado},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	date-added = {2022-10-23 18:05:55 +0200},
	date-modified = {2022-10-23 18:05:55 +0200},
	doi = {10.1007/978-3-030-10928-8_1},
	pages = {3--18},
	publisher = {Springer International Publishing},
	title = {Temporally Evolving Community Detection and Prediction in Content-Centric Networks},
	url = {https://doi.org/10.1007%2F978-3-030-10928-8_1},
	year = 2019,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-10928-8_1},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-10928-8_1}}

@incollection{Saha_2017,
	author = {Tanay Kumar Saha and Shafiq Joty and Mohammad Al Hasan},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	date-added = {2022-10-23 18:05:49 +0200},
	date-modified = {2022-10-23 18:05:49 +0200},
	doi = {10.1007/978-3-319-71249-9_45},
	pages = {753--769},
	publisher = {Springer International Publishing},
	title = {Con-S2V: A Generic Framework for Incorporating Extra-Sentential Context into Sen2Vec},
	url = {https://doi.org/10.1007%2F978-3-319-71249-9_45},
	year = 2017,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-319-71249-9_45},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-319-71249-9_45}}

@inproceedings{10.1007/978-3-030-46133-1_33,
	abstract = {Although the majority of news articles are only viewed for days or weeks, there are a small fraction of news articles that are read across years, thus named as evergreen news articles. Because evergreen articles maintain a timeless quality and are consistently of interests to the public, understanding their characteristics better has huge implications for news outlets and platforms yet there are few studies that have explicitly investigated on evergreen articles. Addressing this gap, in this paper, we first propose a flexible parameterized definition of evergreen articles to capture their long-term high traffic patterns. Using a real dataset from the Washington Post, then, we unearth several distinctive characteristics of evergreen articles and build an early prediction model with encouraging results. Although less than {\$}{\$}1{\backslash}{\%}{\$}{\$} of news articles were identified as evergreen, our model achieves 0.961 in ROC AUC and 0.172 in PR AUC in 10-fold cross validation.},
	address = {Cham},
	author = {Liao, Yiming and Wang, Shuguang and Han, Eui-Hong (Sam) and Lee, Jongwuk and Lee, Dongwon},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	date-added = {2022-10-23 18:05:41 +0200},
	date-modified = {2022-10-23 18:05:41 +0200},
	editor = {Brefeld, Ulf and Fromont, Elisa and Hotho, Andreas and Knobbe, Arno and Maathuis, Marloes and Robardet, C{\'e}line},
	isbn = {978-3-030-46133-1},
	pages = {552--568},
	publisher = {Springer International Publishing},
	title = {Characterization and Early Detection of Evergreen News Articles},
	year = {2020}}

@incollection{Bai_2021,
	author = {Zilong Bai and S. S. Ravi and Ian Davidson},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	date-added = {2022-10-23 18:04:09 +0200},
	date-modified = {2022-10-23 18:04:09 +0200},
	doi = {10.1007/978-3-030-67664-3_3},
	pages = {37--53},
	publisher = {Springer International Publishing},
	title = {Towards Description of Block Model on Graph},
	url = {https://doi.org/10.1007%2F978-3-030-67664-3_3},
	year = 2021,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-67664-3_3},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-67664-3_3}}

@incollection{Melvin_2017,
	author = {Sara Melvin and Wenchao Yu and Peng Ju and Sean Young and Wei Wang},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	date-added = {2022-10-23 18:04:04 +0200},
	date-modified = {2022-10-23 18:04:04 +0200},
	doi = {10.1007/978-3-319-71273-4_8},
	pages = {89--101},
	publisher = {Springer International Publishing},
	title = {Event Detection and Summarization Using Phrase Network},
	url = {https://doi.org/10.1007%2F978-3-319-71273-4_8},
	year = 2017,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-319-71273-4_8},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-319-71273-4_8}}

@incollection{Zhang_2021,
	author = {Jason (Jiasheng) Zhang and Dongwon Lee},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	date-added = {2022-10-23 18:03:59 +0200},
	date-modified = {2022-10-23 18:03:59 +0200},
	doi = {10.1007/978-3-030-67658-2_15},
	pages = {249--265},
	publisher = {Springer International Publishing},
	title = {{PROMO} for Interpretable Personalized Social Emotion Mining},
	url = {https://doi.org/10.1007%2F978-3-030-67658-2_15},
	year = 2021,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-67658-2_15},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-67658-2_15}}

@incollection{Madrid_2020,
	author = {Jorge G. Madrid and Hugo Jair Escalante and Eduardo Morales},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	date-added = {2022-10-23 18:03:55 +0200},
	date-modified = {2022-10-23 18:03:55 +0200},
	doi = {10.1007/978-3-030-43823-4_6},
	pages = {57--67},
	publisher = {Springer International Publishing},
	title = {Meta-learning of Textual Representations},
	url = {https://doi.org/10.1007%2F978-3-030-43823-4_6},
	year = 2020,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-43823-4_6},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-43823-4_6}}

@incollection{Hu_2019,
	author = {Wangsu Hu and Zijun Yao and Sen Yang and Shuhong Chen and Peter J. Jin},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	date-added = {2022-10-23 18:03:45 +0200},
	date-modified = {2022-10-23 18:03:45 +0200},
	doi = {10.1007/978-3-030-10928-8_6},
	pages = {88--104},
	publisher = {Springer International Publishing},
	title = {Discovering Urban Travel Demands Through Dynamic Zone Correlation in Location-Based Social Networks},
	url = {https://doi.org/10.1007%2F978-3-030-10928-8_6},
	year = 2019,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-10928-8_6},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-10928-8_6}}

@incollection{Lan_2019,
	author = {Andrew S. Lan and Jonathan C. Spencer and Ziqi Chen and Christopher G. Brinton and Mung Chiang},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	date-added = {2022-10-23 18:03:40 +0200},
	date-modified = {2022-10-23 18:03:40 +0200},
	doi = {10.1007/978-3-030-10928-8_43},
	pages = {725--740},
	publisher = {Springer International Publishing},
	title = {Personalized Thread Recommendation for {MOOC} Discussion Forums},
	url = {https://doi.org/10.1007%2F978-3-030-10928-8_43},
	year = 2019,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-10928-8_43},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-10928-8_43}}

@incollection{Burkhardt_2017,
	author = {Sophie Burkhardt and Stefan Kramer},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	date-added = {2022-10-23 18:03:35 +0200},
	date-modified = {2022-10-23 18:03:35 +0200},
	doi = {10.1007/978-3-319-71246-8_12},
	pages = {189--204},
	publisher = {Springer International Publishing},
	title = {Online Sparse Collapsed Hybrid Variational-Gibbs Algorithm for Hierarchical Dirichlet Process Topic Models},
	url = {https://doi.org/10.1007%2F978-3-319-71246-8_12},
	year = 2017,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-319-71246-8_12},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-319-71246-8_12}}

@incollection{Ferner_2020,
	author = {Cornelia Ferner and Stefan Wegenkittl},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	date-added = {2022-10-23 18:03:28 +0200},
	date-modified = {2022-10-23 18:03:28 +0200},
	doi = {10.1007/978-3-030-46147-8_42},
	pages = {697--710},
	publisher = {Springer International Publishing},
	title = {A Semi-discriminative Approach for Sub-sentence Level Topic Classification on a Small Dataset},
	url = {https://doi.org/10.1007%2F978-3-030-46147-8_42},
	year = 2020,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-030-46147-8_42},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-46147-8_42}}

@inproceedings{10.1145/3132847.3132942,
	abstract = {Determining appropriate statistical distributions for modeling text corpora is important for accurate estimation of numerical characteristics. Based on the validity of the test on a claim that the data conforms to Poisson distribution we propose Poisson decomposition model (PDM), a statistical model for modeling count data of text corpora, which can straightly capture each document's multidimensional numerical characteristics on topics. In PDM, each topic is represented as a parameter vector with multidimensional Poisson distribution, which can be easily normalized to multinomial term probabilities and each document is represented as measurements on topics and thereby reduced to a measurement vector on topics. We use gradient descent methods and sampling algorithm for parameter estimation. We carry out extensive experiments on the topics produced by our models. The results demonstrate our approach can extract more coherent topics and is competitive in document clustering by using the PDM-based features, compared to PLSI and LDA.},
	address = {New York, NY, USA},
	author = {Jiang, Haixin and Zhou, Rui and Zhang, Limeng and Wang, Hua and Zhang, Yanchun},
	booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3132847.3132942},
	isbn = {9781450349185},
	keywords = {topic coherence, topic model, text classification, statistical testing, poisson decomposition},
	location = {Singapore, Singapore},
	numpages = {10},
	pages = {1489--1498},
	publisher = {Association for Computing Machinery},
	series = {CIKM '17},
	title = {A Topic Model Based on Poisson Decomposition},
	url = {https://doi.org/10.1145/3132847.3132942},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3132847.3132942}}

@inproceedings{10.1145/3132847.3133181,
	abstract = {Exploratory analysis of a text corpus is an important task that can be aided by informative visualization. One spatially-oriented form of document visualization is a scatterplot, whereby every document is associated with a coordinate, and relationships among documents can be perceived through their spatial distances. Semantic visualization further infuses the visualization space with latent semantics, by incorporating a topic model that has a representation in the visualization space, allowing users to also perceive relationships between documents and topics spatially. We illustrate how a semantic visualization system called SemVis could be used to navigate a text corpus interactively and topically via browsing and searching.},
	address = {New York, NY, USA},
	author = {Le, Tuan M. V. and Lauw, Hady W.},
	booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3132847.3133181},
	isbn = {9781450349185},
	keywords = {interactive topical analysis, topic model, semantic visualization},
	location = {Singapore, Singapore},
	numpages = {4},
	pages = {2487--2490},
	publisher = {Association for Computing Machinery},
	series = {CIKM '17},
	title = {SemVis: Semantic Visualization for Interactive Topical Analysis},
	url = {https://doi.org/10.1145/3132847.3133181},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3132847.3133181}}

@inproceedings{10.1145/3459637.3482398,
	abstract = {As a well-established probabilistic method, topic models seek to uncover latent semantics from plain text. In addition to having textual content, we observe that documents are usually compared in listwise rankings based on their content. For instance, world-wide countries are compared in an international ranking in terms of electricity production based on their national reports. Such document comparisons constitute additional information that reveal documents' relative similarities. Incorporating them into topic modeling could yield comparative topics that help to differentiate and rank documents. Furthermore, based on different comparison criteria, the observed document comparisons usually cover multiple aspects, each expressing a distinct ranked list. For example, a country may be ranked higher in terms of electricity production, but fall behind others in terms of life expectancy or government budget. Each comparison criterion, or aspect, observes a distinct ranking. Considering such multiple aspects of comparisons based on different ranking criteria allows us to derive one set of topics that inform heterogeneous document similarities. We propose a generative topic model aimed at learning topics that are well aligned to multi-aspect listwise comparisons. Experiments on public datasets demonstrate the advantage of the proposed method in jointly modeling topics and ranked lists against baselines comprehensively.},
	address = {New York, NY, USA},
	author = {Zhang, Delvin Ce and Lauw, Hady W.},
	booktitle = {Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3459637.3482398},
	isbn = {9781450384469},
	keywords = {text mining, generative topic model, comparative documents},
	location = {Virtual Event, Queensland, Australia},
	numpages = {10},
	pages = {2507--2516},
	publisher = {Association for Computing Machinery},
	series = {CIKM '21},
	title = {Topic Modeling for Multi-Aspect Listwise Comparisons},
	url = {https://doi.org/10.1145/3459637.3482398},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1145/3459637.3482398}}

@inproceedings{10.1145/3511808.3557410,
	abstract = {Two general approaches are common for evaluating automatically generated labels in topic modeling: direct human assessment; or performance metrics that can be calculated without, but still correlate with, human assessment. However, both approaches implicitly assume that the quality of a topic label is single-dimensional. In contrast, this paper provides evidence that human assessments about the quality of topic labels consist of multiple latent dimensions. This evidence comes from human assessments of four simple labeling techniques. For each label, study participants responded to several items asking them to assess each label according to a variety of different criteria. Exploratory factor analysis shows that these human assessments of labeling quality have a two-factor latent structure. Subsequent analysis demonstrates that this multi-item, two-factor assessment can reveal nuances that would be missed using either a single-item human assessment of perceived label quality or established performance metrics. The paper concludes by suggesting future directions for the development of human-centered approaches to evaluating NLP and ML systems more broadly.},
	address = {New York, NY, USA},
	author = {Hosseiny Marani, Amin and Levine, Joshua and Baumer, Eric P.S.},
	booktitle = {Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3511808.3557410},
	isbn = {9781450392365},
	keywords = {topic labeling, topic modeling, human assessment, performance metrics, exploratory factor analysis},
	location = {Atlanta, GA, USA},
	numpages = {12},
	pages = {768--779},
	publisher = {Association for Computing Machinery},
	series = {CIKM '22},
	title = {One Rating to Rule Them All? Evidence of Multidimensionality in Human Assessment of Topic Labeling Quality},
	url = {https://doi.org/10.1145/3511808.3557410},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1145/3511808.3557410}}

@inproceedings{10.1145/3132847.3133162,
	abstract = {Semantic similarity based retrieval is playing an increasingly important role in many IR systems such as modern web search, question-answering, similar document retrieval etc. Improvements in retrieval of semantically similar content are very significant to applications like Quora, Stack Overflow, Siri etc. We propose a novel unsupervised model for semantic similarity based content retrieval, where we construct semantic flow graphs for each query, and introduce the concept of "soft seeding" in graph based semi-supervised learning (SSL) to convert this into an unsupervised model.We demonstrate the effectiveness of our model on an equivalent question retrieval problem on the Stack Exchange QA dataset, where our unsupervised approach significantly outperforms the state-of-the-art unsupervised models, and produces comparable results to the best supervised models. Our research provides a method to tackle semantic similarity based retrieval without any training data, and allows seamless extension to different domain QA communities, as well as to other semantic equivalence tasks.},
	address = {New York, NY, USA},
	author = {Srivastava, Avikalp and Datt, Madhav},
	booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3132847.3133162},
	isbn = {9781450349185},
	keywords = {topic model application, semantic similarity, similar question retrieval, soft seeded semi-supervised learning graphs, document representation},
	location = {Singapore, Singapore},
	numpages = {4},
	pages = {2315--2318},
	publisher = {Association for Computing Machinery},
	series = {CIKM '17},
	title = {Soft Seeded SSL Graphs for Unsupervised Semantic Similarity-Based Retrieval},
	url = {https://doi.org/10.1145/3132847.3133162},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3132847.3133162}}

@inproceedings{10.1145/3269206.3271671,
	abstract = {Recently, dataless text classification has attracted increasing attention. It trains a classifier using seed words of categories, rather than labeled documents that are expensive to obtain. However, a small set of seed words may provide very limited and noisy supervision information, because many documents contain no seed words or only irrelevant seed words. In this paper, we address these issues using document manifold, assuming that neighboring documents tend to be assigned to a same category label. Following this idea, we propose a novel Laplacian seed word topic model (LapSWTM). In LapSWTM, we model each document as a mixture of hidden category topics, each of which corresponds to a distinctive category. Also, we assume that neighboring documents tend to have similar category topic distributions. This is achieved by incorporating a manifold regularizer into the log-likelihood function of the model, and then maximizing this regularized objective. Experimental results show that our LapSWTM significantly outperforms the existing dataless text classification algorithms and is even competitive with supervised algorithms to some extent. More importantly, it performs extremely well when the seed words are scarce.},
	address = {New York, NY, USA},
	author = {Li, Ximing and Li, Changchun and Chi, Jinjin and Ouyang, Jihong and Li, Chenliang},
	booktitle = {Proceedings of the 27th ACM International Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3269206.3271671},
	isbn = {9781450360142},
	keywords = {topic modeling, seed word, dataless text classification, document manifold},
	location = {Torino, Italy},
	numpages = {10},
	pages = {973--982},
	publisher = {Association for Computing Machinery},
	series = {CIKM '18},
	title = {Dataless Text Classification: A Topic Modeling Approach with Document Manifold},
	url = {https://doi.org/10.1145/3269206.3271671},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1145/3269206.3271671}}

@inproceedings{10.1145/3132847.3133145,
	abstract = {People often publish online texts to express their stances, which reflect the essential viewpoints they stand. Stance identification has been an important research topic in text analysis and facilitates many applications in business, public security and government decision making. Previous work on stance identification solely focuses on classifying the supportive or unsupportive attitude towards a certain topic/entity. The other important type of stance identification, multiple stance identification, was largely ignored in previous research. In contrast, multiple stance identification focuses on identifying different standpoints of multiple parties involved in online texts. In this paper, we address the problem of recognizing distinct standpoints implied in textual data. As people are inclined to discuss the topics favorable to their standpoints, topics thus can provide distinguishable information of different standpoints. We propose a topic-based method for standpoint identification. To acquire more distinguishable topics, we further enhance topic model by adding constraints on document-topic distributions. We finally conduct experimental studies on two real datasets to verify the effectiveness of our approach to multiple stance identification.},
	address = {New York, NY, USA},
	author = {Lin, Junjie and Mao, Wenji and Zhang, Yuhao},
	booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3132847.3133145},
	isbn = {9781450349185},
	keywords = {Multiple stance identification, constrained Nonnegative Matrix Factorization, topic modeling},
	location = {Singapore, Singapore},
	numpages = {4},
	pages = {2167--2170},
	publisher = {Association for Computing Machinery},
	series = {CIKM '17},
	title = {An Enhanced Topic Modeling Approach to Multiple Stance Identification},
	url = {https://doi.org/10.1145/3132847.3133145},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3132847.3133145}}

@inproceedings{10.1145/3132847.3133109,
	abstract = {Time series are ubiquitous in the world since they are used to measure various phenomena (e.g., temperature, spread of a virus, sales, etc.). Forecasting of time series is highly beneficial (and necessary) for optimizing decisions, yet is a very challenging problem; using only the historical values of the time series is often insufficient. In this paper, we study how to construct effective additional features based on related text data for time series forecasting. Besides the commonly used n-gram features, we propose a general strategy for constructing multiple topical features based on the topics discovered by a topic model. We evaluate feature effectiveness using a data set for predicting stock price changes where we constructed additional features from news text articles for stock market prediction. We found that: 1) Text-based features outperform time series-based features, suggesting the great promise of leveraging text data for improving time series forecasting. 2) Topic-based features are not very effective stand-alone, but they can further improve performance when added on top of n-gram features. 3) The best topic-based feature appears to be a long-term aggregation of topics over time with high weights on recent topics.},
	address = {New York, NY, USA},
	author = {Wang, Yiren and Seyler, Dominic and Santu, Shubhra Kanti Karmaker and Zhai, ChengXiang},
	booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3132847.3133109},
	isbn = {9781450349185},
	location = {Singapore, Singapore},
	numpages = {4},
	pages = {2347--2350},
	publisher = {Association for Computing Machinery},
	series = {CIKM '17},
	title = {A Study of Feature Construction for Text-Based Forecasting of Time Series Variables},
	url = {https://doi.org/10.1145/3132847.3133109},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3132847.3133109}}

@inproceedings{10.1145/3357384.3357941,
	abstract = {The rapid development of social media services has facilitated the communication of opinions through online news, blogs, microblogs, instant-messages, and so on. This article concentrates on the mining of readers' social sentiments evoked by social media materials. Existing methods are only applicable to a minority of social media like news portals with emotional voting information, while ignore the emotional contagion between writers and readers. However, incorporating such factors is challenging since the learned hidden variables would be very fuzzy (because of the short and noisy text in social networks). In this paper, we try to solve this problem by introducing a high-order network structure, i.e. communities. We first propose a new generative model called Community-Enhanced Social Sentiment Mining (CESSM), which 1) considers the emotional contagion between writers and readers to capture precise social sentiment, and 2) incorporates network communities to capture coherent topics. We then derive an inference algorithm based on Gibbs sampling. Empirical results show that, CESSM achieves significantly superior performance against the state-of-the-art techniques for text sentiment classification and interestingness in social sentiment mining.},
	address = {New York, NY, USA},
	author = {Wang, Xiaobao and Jin, Di and Liu, Mengquan and He, Dongxiao and Musial, Katarzyna and Dang, Jianwu},
	booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3357384.3357941},
	isbn = {9781450369763},
	keywords = {social sentiment, community, emotional contagion, social network},
	location = {Beijing, China},
	numpages = {10},
	pages = {1763--1772},
	publisher = {Association for Computing Machinery},
	series = {CIKM '19},
	title = {Emotional Contagion-Based Social Sentiment Mining in Social Networks by Introducing Network Communities},
	url = {https://doi.org/10.1145/3357384.3357941},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1145/3357384.3357941}}

@inproceedings{10.1145/3340531.3412050,
	abstract = {The task of session search focuses on using interaction data to improve relevance for the user's next query at the session level. In this paper, we formulate session search as a personalization task under the framework of learning to rank. Personalization approaches re-rank results to match a user model. Such user models are usually accumulated over time based on the user's browsing behaviour. We use a pre-computed and transparent set of user models based on concepts from the social science literature. Interaction data are used to map each session to these user models. Novel features are then estimated based on such models as well as sessions' interaction data. Extensive experiments on test collections from the TREC session track show statistically significant improvements over current session search algorithms.},
	address = {New York, NY, USA},
	author = {Aloteibi, Saad and Clark, Stephen},
	booktitle = {Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3340531.3412050},
	isbn = {9781450368599},
	keywords = {personalization, session search, retrieval model, user models},
	location = {Virtual Event, Ireland},
	numpages = {10},
	pages = {15--24},
	publisher = {Association for Computing Machinery},
	series = {CIKM '20},
	title = {Learning to Personalize for Web Search Sessions},
	url = {https://doi.org/10.1145/3340531.3412050},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1145/3340531.3412050}}

@inproceedings{10.1145/3511808.3557561,
	abstract = {In this paper, we present a large Chinese news article dataset with 4.4 million articles. These articles are obtained from different news channels and sources. They are labeled with multi-level topic categories, and some of them also have summaries. This is the first Chinese news dataset that has both hierarchical topic labels and article full texts. And it is also the largest Chinese news topic dataset. We describe the data collection, annotation and quality evaluation process. The basic statistics of the dataset, comparison with other datasets and benchmark experiments are also presented.},
	address = {New York, NY, USA},
	author = {Li, Quanzhi and Liu, Yingchi and Chao, Yang},
	booktitle = {Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3511808.3557561},
	isbn = {9781450392365},
	keywords = {hierarchical topic classification, chinese news dataset, news summary, news topic},
	location = {Atlanta, GA, USA},
	numpages = {6},
	pages = {4193--4198},
	publisher = {Association for Computing Machinery},
	series = {CIKM '22},
	title = {CNewsTS - A Large-Scale Chinese News Dataset with Hierarchical Topic Category and Summary},
	url = {https://doi.org/10.1145/3511808.3557561},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1145/3511808.3557561}}

@inproceedings{10.1145/3132847.3133011,
	abstract = {Vector representation of sentences is important for many text processing tasks that involve classifying, clustering, or ranking sentences. For solving these tasks, bag-of-word based representation has been used for a long time. In recent years, distributed representation of sentences learned by neural models from unlabeled data has been shown to outperform traditional bag-of-words representations. However, most existing methods belonging to the neural models consider only the content of a sentence, and disregard its relations with other sentences in the context. In this paper, we first characterize two types of contexts depending on their scope and utility. We then propose two approaches to incorporate contextual information into content-based models. We evaluate our sentence representation models in a setup, where context is available to infer sentence vectors. Experimental results demonstrate that our proposed models outshine existing models on three fundamental tasks, such as, classifying, clustering, and ranking sentences.},
	address = {New York, NY, USA},
	author = {Saha, Tanay Kumar and Joty, Shafiq and Hassan, Naeemul and Hasan, Mohammad Al},
	booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3132847.3133011},
	isbn = {9781450349185},
	keywords = {ranking, feature learning, sen2vec, retrofitting, distributed representation of sentences, discourse, clustering, classification},
	location = {Singapore, Singapore},
	numpages = {10},
	pages = {547--556},
	publisher = {Association for Computing Machinery},
	series = {CIKM '17},
	title = {Regularized and Retrofitted Models for Learning Sentence Representation with Context},
	url = {https://doi.org/10.1145/3132847.3133011},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3132847.3133011}}

@inproceedings{10.1145/3132847.3132864,
	abstract = {Emotion analysis of online customer service conservation is important for good user experience and customer satisfaction. However, conventional metrics do not fit this application scenario. In this work, by collecting and labeling online conversations of customer service on Twitter, we identify 8 new metrics, named as tones, to describe emotional information. To better interpret each tone, we extend the Latent Dirichlet Allocation (LDA) model to Tone LDA (T-LDA). In T-LDA, each latent topic is explicitly associated with one of three semantic categories, i.e., tone-related, domain-specific and auxiliary. By integrating tone label into learning, T-LDA can interfere the original unsupervised training process and thus is able to identify representative tone-related words. In evaluation, T-LDA shows better performance than baselines in predicting tone intensity. Also, a case study is conducted to analyze each tone via T-LDA output.},
	address = {New York, NY, USA},
	author = {Yin, Peifeng and Liu, Zhe and Xu, Anbang and Nakamura, Taiga},
	booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3132847.3132864},
	isbn = {9781450349185},
	keywords = {tone, topic modeling, emotion, online customer service},
	location = {Singapore, Singapore},
	numpages = {9},
	pages = {1887--1895},
	publisher = {Association for Computing Machinery},
	series = {CIKM '17},
	title = {Tone Analyzer for Online Customer Service: An Unsupervised Model with Interfered Training},
	url = {https://doi.org/10.1145/3132847.3132864},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3132847.3132864}}

@inproceedings{10.1145/3269206.3269309,
	abstract = {Topic detection and tracking in document streams is a critical task in many important applications, hence has been attracting research interest in recent decades. With the large size of data streams, there have been a number of works from different approaches that propose automatic methods for the task. However, there is only a few small benchmark datasets that are publicly available for evaluating the proposed methods. The lack of large datasets with fine-grained groundtruth implicitly restrains the development of more advanced methods. In this work, we address this issue by collecting and publishing W2E - a large dataset consisting of news articles from more than 50 prominent mass media channels worldwide. The articles cover a large set of popular events within a full year. W2E is more than 15 times larger than TREC's TDT2 dataset, which is widely used in prior work. We further conduct exploratory analysis to examine the dynamics and diversity of W2E and propose potential uses of the dataset in other research.},
	address = {New York, NY, USA},
	author = {Hoang, Tuan-Anh and Vo, Khoi Duy and Nejdl, Wolfgang},
	booktitle = {Proceedings of the 27th ACM International Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3269206.3269309},
	isbn = {9781450360142},
	keywords = {topic detection, benchmark dataset, topic tracking},
	location = {Torino, Italy},
	numpages = {4},
	pages = {1847--1850},
	publisher = {Association for Computing Machinery},
	series = {CIKM '18},
	title = {W2E: A Worldwide-Event Benchmark Dataset for Topic Detection and Tracking},
	url = {https://doi.org/10.1145/3269206.3269309},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1145/3269206.3269309}}

@inproceedings{10.1145/3132847.3132968,
	abstract = {Twitter provides us a convenient channel to get access to the immediate information about major events. However, it is challenging to acquire a clean and complete set of event-related data due to the characteristics of tweets, eg short and noisy. In this paper, we propose a semi-supervised method to obtain high quality event-related tweets from Twitter stream, in terms of precision and recall. Specifically, candidate event-related tweets are selected based on a set of keywords. We propose to generate and update these keywords dynamically along the event development. To be included in this keyword set, words are evaluated based on single word properties, property based on co-occurred words, and changes of word importance over time. Our solution is capable of capturing keywords of emerging aspects or aspects with increasing importance along event evolvement. By leveraging keyword importance information and a few labeled tweets, we propose a semi-supervised expectation maximization process to identify event-related tweets. This process significantly reduces human effort in acquiring high quality tweets. Experiments on three real world datasets show that our solution outperforms state-of-the-art approaches by up to 10% in F1 measure.},
	address = {New York, NY, USA},
	author = {Zheng, Xin and Sun, Aixin and Wang, Sibo and Han, Jialong},
	booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3132847.3132968},
	isbn = {9781450349185},
	keywords = {event-related tweet identification, dynamic keyword generation},
	location = {Singapore, Singapore},
	numpages = {10},
	pages = {1619--1628},
	publisher = {Association for Computing Machinery},
	series = {CIKM '17},
	title = {Semi-Supervised Event-Related Tweet Identification with Dynamic Keyword Generation},
	url = {https://doi.org/10.1145/3132847.3132968},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3132847.3132968}}

@inproceedings{10.1145/3132847.3132988,
	abstract = {Linking multiple news streams based on the reported events and analyzing the streams' temporal publishing patterns are two very important tasks for information analysis, discovering newsworthy stories, studying the event evolution, and detecting untrustworthy sources of information. In this paper, we propose techniques for cross-linking news streams based on the reported events with the purpose of analyzing the temporal dependencies among streams.Our research tackles two main issues: (1) how news streams are connected as reporting an event or the evolution of the same event and (2) how timely the newswires report related events using different publishing platforms. Our approach is based on dynamic topic modeling for detecting and tracking events over the timeline and on clustering news according to the events. We leverage the event-based clustering to link news across different streams and present two scoring functions for ranking the streams based on their timeliness in publishing news about a specific event.},
	address = {New York, NY, USA},
	author = {Mele, Ida and Bahrainian, Seyed Ali and Crestani, Fabio},
	booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3132847.3132988},
	isbn = {9781450349185},
	keywords = {event mining, temporal analysis, dynamic topic modeling, news streams},
	location = {Singapore, Singapore},
	numpages = {10},
	pages = {767--776},
	publisher = {Association for Computing Machinery},
	series = {CIKM '17},
	title = {Linking News across Multiple Streams for Timeliness Analysis},
	url = {https://doi.org/10.1145/3132847.3132988},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3132847.3132988}}

@inproceedings{10.1145/3459637.3482253,
	abstract = {Identifying the dynamic functions of different urban zones enables a variety of smart city applications, such as intelligent urban planning, real-time traffic scheduling, and community precision management. Traditional urban function research using government administrative zoning systems is often conducted in a coarse resolution with fixed split, and ignore the reshaping of zones by city growth. To solve this problem, we propose a two-stage framework in order to represent the high-definition distribution of urban function across the city, by analyzing continuous human traces extracted from the dense, widespread, and full-time cellular data. At the representation stage, we embed the locations of base stations by modeling the user movements with staying and transfer events, along with the consideration of dynamic trip purposes in continuous human traces. At the annotation stage, we first divide the city into the finest unit zones and each covers at least one base station. By clustering the base stations, we further group the unit zones into functional zones. Last, we annotate functional zones based on the local point-of-interest (POI) information. In experiments, we evaluate the proposed high-definition function study in two tasks: (i) in-zone crowd flow prediction, and (ii) zone-enhanced POI recommendation. The results demonstrate the advantage of the proposed method with both the effectiveness of city split and the high-quality function annotation.},
	address = {New York, NY, USA},
	author = {Liu, Chunyu and Yang, Yongjian and Yao, Zijun and Xu, Yuanbo and Chen, Weitong and Yue, Lin and Wu, Haomeng},
	booktitle = {Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3459637.3482253},
	isbn = {9781450384469},
	keywords = {mobile trajectory, zone embedding, signaling data, fine-grained functional zone, urban computing},
	location = {Virtual Event, Queensland, Australia},
	numpages = {10},
	pages = {1048--1057},
	publisher = {Association for Computing Machinery},
	series = {CIKM '21},
	title = {Discovering Urban Functions of High-Definition Zoning with Continuous Human Traces},
	url = {https://doi.org/10.1145/3459637.3482253},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1145/3459637.3482253}}

@inproceedings{10.1145/3132847.3133071,
	abstract = {Automatic tagging techniques are important for many applications such as searching and recommendation, which has attracted many researchers' attention in recent years. Existing methods mainly rely on users' tagging behavior or items' content information for tagging, yet users' consuming behavior is ignored. In this paper, we propose to leverage such information and introduce a probabilistic model called joint-tagging LDA to improve tagging accuracy. An effective algorithm based on Zero-Order Collapsed Variational Bayes is developed. Experiments conducted on a real dataset demonstrate that joint-tagging LDA outperforms existing competing methods.},
	address = {New York, NY, USA},
	author = {Liu, Shen and Liu, Hongyan},
	booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3132847.3133071},
	isbn = {9781450349185},
	keywords = {generative model, user behavior modeling, tag recommendation},
	location = {Singapore, Singapore},
	numpages = {4},
	pages = {2175--2178},
	publisher = {Association for Computing Machinery},
	series = {CIKM '17},
	title = {Exploiting User Consuming Behavior for Effective Item Tagging},
	url = {https://doi.org/10.1145/3132847.3133071},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3132847.3133071}}

@inproceedings{10.1145/3357384.3357828,
	abstract = {In the era of big data, online doctor review platforms, which enable patients to give feedback to their doctors, have become one of the most important components in healthcare systems. On one hand, they help patients to choose their doctors based on the experience of others. On the other hand, they help doctors to improve the quality of their service. Moreover, they provide important sources for us to discover common concerns of patients and existing problems in clinics, which potentially improve current healthcare systems. In this paper, we systematically investigate the dataset from one of such review platform, namely, ratemds.com, where each review for a doctor comes with an overall rating and ratings of four different aspects. A comprehensive statistical analysis is conducted first for reviews, ratings, and doctors. Then, we explore the content of reviews by extracting latent topics related to different aspects with unsupervised topic modeling techniques. As the core component of this paper, we propose a multi-task learning framework for the document-level multi-aspect sentiment classification. This task helps us to not only recover missing aspect-level ratings and detect inconsistent rating scores but also identify aspect-keywords for a given review based on ratings. The proposed model takes both features of doctors and aspect-keywords into consideration. Extensive experiments have been conducted on two subsets of ratemds dataset to demonstrate the effectiveness of the proposed model.},
	address = {New York, NY, USA},
	author = {Shi, Tian and Rakesh, Vineeth and Wang, Suhang and Reddy, Chandan K.},
	booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3357384.3357828},
	isbn = {9781450369763},
	keywords = {sentiment classification, multi-aspect, multi-task learning, attention mechanism, online reviews},
	location = {Beijing, China},
	numpages = {9},
	pages = {2723--2731},
	publisher = {Association for Computing Machinery},
	series = {CIKM '19},
	title = {Document-Level Multi-Aspect Sentiment Classification for Online Reviews of Medical Experts},
	url = {https://doi.org/10.1145/3357384.3357828},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1145/3357384.3357828}}

@inproceedings{10.1145/3269206.3271737,
	abstract = {Deep neural networks are gaining increasing popularity for the classic text classification task, due to their strong expressive power and less requirement for feature engineering. Despite such attractiveness, neural text classification models suffer from the lack of training data in many real-world applications. Although many semi-supervised and weakly-supervised text classification models exist, they cannot be easily applied to deep neural models and meanwhile support limited supervision types. In this paper, we propose a weakly-supervised method that addresses the lack of training data in neural text classification. Our method consists of two modules: (1) a pseudo-document generator that leverages seed information to generate pseudo-labeled documents for model pre-training, and (2) a self-training module that bootstraps on real unlabeled data for model refinement. Our method has the flexibility to handle different types of weak supervision and can be easily integrated into existing deep neural models for text classification. We have performed extensive experiments on three real-world datasets from different domains. The results demonstrate that our proposed method achieves inspiring performance without requiring excessive training data and outperforms baseline methods significantly.},
	address = {New York, NY, USA},
	author = {Meng, Yu and Shen, Jiaming and Zhang, Chao and Han, Jiawei},
	booktitle = {Proceedings of the 27th ACM International Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3269206.3271737},
	isbn = {9781450360142},
	keywords = {pseudo document generation, text classification, weakly-supervised learning, neural classification model},
	location = {Torino, Italy},
	numpages = {10},
	pages = {983--992},
	publisher = {Association for Computing Machinery},
	series = {CIKM '18},
	title = {Weakly-Supervised Neural Text Classification},
	url = {https://doi.org/10.1145/3269206.3271737},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1145/3269206.3271737}}

@inproceedings{10.1145/3132847.3133063,
	abstract = {This paper addresses the task of cross-domain social emotion classification of online documents. The cross-domain task is formulated as using abundant labeled documents from a source domain and a small amount of labeled documents from a target domain, to predict the emotion of unlabeled documents in the target domain. Although several cross-domain emotion classification algorithms have been proposed, they require that feature distributions of different domains share a sufficient overlapping, which is hard to meet in practical applications. This paper proposes a novel framework, which uses the emotion distribution of training documents at the cluster level, to alleviate the aforementioned issue. Experimental results on two datasets show the effectiveness of our proposed model on cross-domain social emotion classification.},
	address = {New York, NY, USA},
	author = {Zhu, Endong and Rao, Yanghui and Xie, Haoran and Liu, Yuwei and Yin, Jian and Wang, Fu Lee},
	booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3132847.3133063},
	isbn = {9781450349185},
	keywords = {emotion detection, clustering, cross-domain classification},
	location = {Singapore, Singapore},
	numpages = {4},
	pages = {2435--2438},
	publisher = {Association for Computing Machinery},
	series = {CIKM '17},
	title = {Cluster-Level Emotion Pattern Matching for Cross-Domain Social Emotion Classification},
	url = {https://doi.org/10.1145/3132847.3133063},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3132847.3133063}}

@inproceedings{10.1145/3132847.3133150,
	abstract = {Fact-checking political discussions has become an essential clog in computational journalism. This task encompasses an important sub-task---identifying the set of statements with 'check-worthy' claims. Previous work has treated this as a simple text classification problem discounting the nuances involved in determining what makes statements check-worthy. We introduce a dataset of political debates from the 2016 US Presidential election campaign annotated using all major fact-checking media outlets and show that there is a need to model conversation context, debate dynamics and implicit world knowledge. We design a multi-classifier system TATHYA, that models latent groupings in data and improves state-of-art systems in detecting check-worthy statements by 19.5% in F1-score on a held-out test set, gaining primarily gaining in Recall.},
	address = {New York, NY, USA},
	author = {Patwari, Ayush and Goldwasser, Dan and Bagchi, Saurabh},
	booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3132847.3133150},
	isbn = {9781450349185},
	keywords = {clustering, computational journalism, natural language processing},
	location = {Singapore, Singapore},
	numpages = {4},
	pages = {2259--2262},
	publisher = {Association for Computing Machinery},
	series = {CIKM '17},
	title = {TATHYA: A Multi-Classifier System for Detecting Check-Worthy Statements in Political Debates},
	url = {https://doi.org/10.1145/3132847.3133150},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3132847.3133150}}

@inproceedings{10.1145/3357384.3358020,
	abstract = {High-impact catastrophic events (bomb attacks, shootings) trigger posting of large volume of information on social media platforms such as Twitter. Recent works have proposed content-aware systems for summarizing this information, thereby facilitating post-disaster services. However, a significant proportion of the posted content is unverified, which restricts the practical usage of the existing summarization systems. In this paper, we work on the novel task of generating verified summaries of information posted on Twitter during disasters. We first jointly learn representations of content-classes and expression-classes of tweets posted during disasters using a novel LDA-based generative model. These representations of content &amp; expression classes are used in conjunction with pre-disaster user behavior and temporal signals (replies) for training a Tree-LSTM based tweet-verification model. The model infers tweet verification probabilities which are used, besides information content of tweets, in an Integer Linear Programming (ILP) framework for generating the desired verified summaries. The summaries are fine-tuned using the class information of the tweets as obtained from the LDA-based generative model. Extensive experiments are performed on a publicly-available labeled dataset of man-made disasters which demonstrate the effectiveness of our tweet-verification (3-13% gain over baselines) and summarization (12-48% gain in verified content proportion, 8-13% gain in ROUGE-score over state-of-the-art) systems. We make implementations of our various modules available online.},
	address = {New York, NY, USA},
	author = {Sharma, Ashish and Rudra, Koustav and Ganguly, Niloy},
	booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3357384.3358020},
	isbn = {9781450369763},
	keywords = {summarization, disaster, unverified information, microblogs},
	location = {Beijing, China},
	numpages = {10},
	pages = {921--930},
	publisher = {Association for Computing Machinery},
	series = {CIKM '19},
	title = {Going Beyond Content Richness: Verified Information Aware Summarization of Crisis-Related Microblogs},
	url = {https://doi.org/10.1145/3357384.3358020},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1145/3357384.3358020}}

@inproceedings{10.1145/3340531.3412878,
	abstract = {There are many existing retrieval and question answering datasets. However, most of them either focus on ranked list evaluation or single-candidate question answering. This divide makes it challenging to properly evaluate approaches concerned with ranking documents and providing snippets or answers for a given query. In this work, we present FiRA: a novel dataset of Fine-Grained Relevance Annotations. We extend the ranked retrieval annotations of the Deep Learning track of TREC 2019 with passage and word level graded relevance annotations for all relevant documents. We use our newly created data to study the distribution of relevance in long documents, as well as the attention of annotators to specific positions of the text. As an example, we evaluate the recently introduced TKL document ranking model. We find that although TKL exhibits state-of-the-art retrieval results for long documents, it misses many relevant passages.},
	address = {New York, NY, USA},
	author = {Hofst\"{a}tter, Sebastian and Zlabinger, Markus and Sertkan, Mete and Schr\"{o}der, Michael and Hanbury, Allan},
	booktitle = {Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3340531.3412878},
	isbn = {9781450368599},
	keywords = {relevance distribution, position bias, word-level relevance, fine-grained annotations},
	location = {Virtual Event, Ireland},
	numpages = {8},
	pages = {3031--3038},
	publisher = {Association for Computing Machinery},
	series = {CIKM '20},
	title = {Fine-Grained Relevance Annotations for Multi-Task Document Ranking and Question Answering},
	url = {https://doi.org/10.1145/3340531.3412878},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1145/3340531.3412878}}

@inproceedings{10.1145/3340531.3411932,
	abstract = {News recommendation systems? purpose is to tackle the immense amount of news and offer personalized recommendations to users. A major issue in news recommendation is to capture the precise news representations for the efficacy of recommended items. Commonly, news contents are filled with well-known entities of different types. However, existing recommendation systems overlook exploiting external knowledge about entities and topical relatedness among the news. To cope with the above problem, in this paper, we propose Topic-Enriched Knowledge Graph Recommendation System(TEKGR). Three encoders in TEKGR handle news titles in two perspectives to obtain news representation embedding: (1) to extract meaning of news words without considering latent knowledge features in the news and (2) to extract semantic knowledge of news through topic information and contextual information from a knowledge graph. After obtaining news representation vectors, an attention network compares clicked news to the candidate news in order to get the user's final embedding. Our TEKGR model is superior to existing news recommendation methods by manipulating topical relations among entities and contextual features of entities. Experimental results on two public datasets show that our approach outperforms state-of-the-art deep recommendation approaches.},
	address = {New York, NY, USA},
	author = {Lee, Dongho and Oh, Byungkook and Seo, Seungmin and Lee, Kyong-Ho},
	booktitle = {Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3340531.3411932},
	isbn = {9781450368599},
	keywords = {recommendation system, knowledge graphs, neural networks, news recommendation},
	location = {Virtual Event, Ireland},
	numpages = {10},
	pages = {695--704},
	publisher = {Association for Computing Machinery},
	series = {CIKM '20},
	title = {News Recommendation with Topic-Enriched Knowledge Graphs},
	url = {https://doi.org/10.1145/3340531.3411932},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1145/3340531.3411932}}

@inproceedings{10.1145/3511808.3557329,
	abstract = {State-of-the-art Graph Neural Networks (GNNs) have achieved tremendous success in social event detection tasks when restricted to a closed set of events. However, considering the large amount of data needed for training and the limited ability of a neural network in handling previously unknown data, it is hard for existing GNN-based methods to operate in an open set setting. To address this problem, we design a Quality-aware Self-improving Graph Neural Network (QSGNN) which extends the knowledge from known to unknown by leveraging the best of known samples and reliable knowledge transfer. Specifically, to fully exploit the labeled data, we propose a novel supervised pairwise loss with an additional orthogonal inter-class relation constraint to train the backbone GNN encoder. The learnt, already-known events further serve as strong reference bases for the unknown ones, which greatly prompts knowledge acquisition and transfer. When the model is generalized to unknown data, to ensure the effectiveness and reliability, we further leverage the reference similarity distribution vectors for pseudo pairwise label generation, selection and quality assessment. Following the diversity principle of active learning, our method selects diverse pair samples with the generated pseudo labels to fine-tune the GNN encoder. Besides, we propose a novel quality-guided optimization in which the contributions of pseudo labels are weighted based on consistency. Experimental results validate that our model achieves state-of-the-art results and extends well to unknown events.},
	address = {New York, NY, USA},
	author = {Ren, Jiaqian and Jiang, Lei and Peng, Hao and Cao, Yuwei and Wu, Jia and Yu, Philip S. and He, Lifang},
	booktitle = {Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3511808.3557329},
	isbn = {9781450392365},
	keywords = {contrastive learning, social event detection, graph neural network, active learning},
	location = {Atlanta, GA, USA},
	numpages = {10},
	pages = {1696--1705},
	publisher = {Association for Computing Machinery},
	series = {CIKM '22},
	title = {From Known to Unknown: Quality-Aware Self-Improving Graph Neural Network For Open Set Social Event Detection},
	url = {https://doi.org/10.1145/3511808.3557329},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1145/3511808.3557329}}

@inproceedings{10.1145/3357384.3358048,
	abstract = {Identifying the topic (domain) of each user's utterance in open-domain conversational systems is a crucial step for all subsequent language understanding and response tasks. In particular, for complex domains, an utterance is often routed to a single component responsible for that domain. Thus, correctly mapping a user utterance to the right domain is critical. This is a challenging task: users could mention entities like actors, singers or locations to implicitly indicate the domain, which requires extensive domain knowledge to interpret. To address this problem, we introduce ConCET: a Concurrent Entity-aware conversational Topic classifier, which incorporates entity type information together with the utterance content features. Specifically, ConCET utilizes entity information to enrich the utterance representation, combining character, word, and entity type embeddings into a single representation. However, for rich domains with millions of available entities, unrealistic amounts of labeled training data would be required. To complement our model, we propose a simple and effective method for generating synthetic training data, to augment the typically limited amounts of labeled training data, using commonly available knowledge bases as to generate additional labeled utterances. We extensively evaluate ConCET and our proposed training method first on an openly available human-human conversational dataset called Self-Dialogue, to calibrate our approach against previous state-of-the-art methods; second, we evaluate ConCET on a large dataset of human-machine conversations with real users, collected as part of the Amazon Alexa Prize. Our results show that ConCET significantly improves topic classification performance on both datasets, reaching 8-10% improvements compared to state-of-the-art deep learning methods. We complement our quantitative results with detailed analysis of system performance, which could be used for further improvements of conversational agents.},
	address = {New York, NY, USA},
	author = {Ahmadvand, Ali and Sahijwani, Harshita and Choi, Jason Ingyu and Agichtein, Eugene},
	booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3357384.3358048},
	isbn = {9781450369763},
	keywords = {conversational topic classification, entity-aware conversation domain classification, open-domain conversational agents},
	location = {Beijing, China},
	numpages = {10},
	pages = {1371--1380},
	publisher = {Association for Computing Machinery},
	series = {CIKM '19},
	title = {ConCET: Entity-Aware Topic Classification for Open-Domain Conversational Agents},
	url = {https://doi.org/10.1145/3357384.3358048},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1145/3357384.3358048}}

@inproceedings{10.1145/3269206.3272011,
	abstract = {We consider the problem of predicting the success of startup companies at their early development stages. We formulate the task as predicting whether a company that has already secured initial (seed or angel) funding will attract a further round of investment in a given period of time. Previous work on this task has mostly been restricted to mining structured data sources, such as databases of the startup ecosystem consisting of investors, incubators and startups. Instead, we investigate the potential of using web-based open sources for the startup success prediction task and model the task using a very rich set of signals from such sources. In particular, we enrich structured data about the startup ecosystem with information from a business- and employment-oriented social networking service and from the web in general. Using these signals, we train a robust machine learning pipeline encompassing multiple base models using gradient boosting. We show that utilizing companies' mentions on the Web yields a substantial performance boost in comparison to only using structured data about the startup ecosystem. We also provide a thorough analysis of the obtained model that allows one to obtain insights into both the types of useful signals discoverable on the Web and market mechanisms underlying the funding process.},
	address = {New York, NY, USA},
	author = {Sharchilev, Boris and Roizner, Michael and Rumyantsev, Andrey and Ozornin, Denis and Serdyukov, Pavel and de Rijke, Maarten},
	booktitle = {Proceedings of the 27th ACM International Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3269206.3272011},
	isbn = {9781450360142},
	keywords = {heterogeneous web data, gradient boosting, predictive modeling, mining open sources},
	location = {Torino, Italy},
	numpages = {9},
	pages = {2283--2291},
	publisher = {Association for Computing Machinery},
	series = {CIKM '18},
	title = {Web-Based Startup Success Prediction},
	url = {https://doi.org/10.1145/3269206.3272011},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1145/3269206.3272011}}

@inproceedings{10.1145/3132847.3132967,
	abstract = {Graph clustering aims to discovercommunity structures in networks, the task being fundamentally challenging mainly because the topology structure and the content of the graphs are difficult to represent for clustering analysis. Recently, graph clustering has moved from traditional shallow methods to deep learning approaches, thanks to the unique feature representation learning capability of deep learning. However, existing deep approaches for graph clustering can only exploit the structure information, while ignoring the content information associated with the nodes in a graph. In this paper, we propose a novel marginalized graph autoencoder (MGAE) algorithm for graph clustering. The key innovation of MGAE is that it advances the autoencoder to the graph domain, so graph representation learning can be carried out not only in a purely unsupervised setting by leveraging structure and content information, it can also be stacked in a deep fashion to learn effective representation. From a technical viewpoint, we propose a marginalized graph convolutional network to corrupt network node content, allowing node content to interact with network features, and marginalizes the corrupted features in a graph autoencoder context to learn graph feature representations. The learned features are fed into the spectral clustering algorithm for graph clustering. Experimental results on benchmark datasets demonstrate the superior performance of MGAE, compared to numerous baselines.},
	address = {New York, NY, USA},
	author = {Wang, Chun and Pan, Shirui and Long, Guodong and Zhu, Xingquan and Jiang, Jing},
	booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3132847.3132967},
	isbn = {9781450349185},
	keywords = {network representation, graph convolutional network, graph clustering, graph autoencoder, autoencoder},
	location = {Singapore, Singapore},
	numpages = {10},
	pages = {889--898},
	publisher = {Association for Computing Machinery},
	series = {CIKM '17},
	title = {MGAE: Marginalized Graph Autoencoder for Graph Clustering},
	url = {https://doi.org/10.1145/3132847.3132967},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3132847.3132967}}

@inproceedings{10.1145/3459637.3482075,
	abstract = {The economic policy uncertainty (EPU) index is one of the important text-based indexes in finance and economics fields. The EPU indexes of more than 26 countries have been constructed to reflect the policy uncertainty on country-level economic environments and serve as an important economic leading indicator. The EPU indexes are calculated based on the number of news articles with some manually-selected keywords related to economic, uncertainty, and policy. We find that the keyword-based EPU indexes contain noise, which will influence their explainability and predictability. In our experimental dataset, over 40% of news articles with the selected keywords are not related to the EPU. Instead of using keywords only, our proposed models take contextual information into account and get good performance on identifying the articles unrelated to EPU. The noise free EPU index performs better than the keyword-based EPU index in both explainability and predictability.},
	address = {New York, NY, USA},
	author = {Chen, Chung-Chi and Huang, Hen-Hsen and Huang, Yu-Lieh and Chen, Hsin-Hsi},
	booktitle = {Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3459637.3482075},
	isbn = {9781450384469},
	keywords = {denoise, economic index, document filtering, economic policy uncertainty},
	location = {Virtual Event, Queensland, Australia},
	numpages = {5},
	pages = {2915--2919},
	publisher = {Association for Computing Machinery},
	series = {CIKM '21},
	title = {Constructing Noise Free Economic Policy Uncertainty Index},
	url = {https://doi.org/10.1145/3459637.3482075},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1145/3459637.3482075}}

@inproceedings{10.1145/3132847.3133123,
	abstract = {An entity on the web can be referred by numerous morphs that are always ambiguous, implicit and informal, which makes it challenging to accurately identify all the morphs corresponding to a specific entity. In this paper, we introduce a novel method based on knowledge graph, which takes advantage of both knowledge reasoning and statistic learning. First, we present a model to build a knowledge graph for the given entity. The knowledge graph integrates the fragmented knowledge on how humans create morphs. Then, the candidate morphs are generated based on the rules summarized from the knowledge graph. At last, we use a classification method to filter the useless candidates and identify the target morphs. The experiments conducted on real world dataset demonstrate efficiency of our proposed method in terms of precision and recall.},
	address = {New York, NY, USA},
	author = {Huang, Longtao and Zhao, Lin and Lv, Shangwen and Lu, Fangzhou and Zhai, Yue and Hu, Songlin},
	booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3132847.3133123},
	isbn = {9781450349185},
	keywords = {entity morphs, language understanding, web mining, knowledge graph},
	location = {Singapore, Singapore},
	numpages = {4},
	pages = {2111--2114},
	publisher = {Association for Computing Machinery},
	series = {CIKM '17},
	title = {KIEM: A Knowledge Graph Based Method to Identify Entity Morphs},
	url = {https://doi.org/10.1145/3132847.3133123},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3132847.3133123}}

@inproceedings{10.1145/3269206.3269273,
	abstract = {This study takes the lead to study the aspect/sentiment-aware abstractive review summarization in domain adaptation scenario. The proposed model CASAS (neural attentive model for Cross-domain Aspect/Sentiment-aware Abstractive review Summarization) leverages domain classification task, working on datasets of both source and target domains, to recognize the domain information of texts and transfer knowledge from source domains to target domains. The extensive experiments on Amazon reviews demonstrate that CASAS outperforms the compared methods in both out-of-domain and in-domain setups.},
	address = {New York, NY, USA},
	author = {Yang, Min and Qu, Qiang and Zhu, Jia and Shen, Ying and Zhao, Zhou},
	booktitle = {Proceedings of the 27th ACM International Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3269206.3269273},
	isbn = {9781450360142},
	keywords = {abstractive review summarization, domain adaptation, topic modeling},
	location = {Torino, Italy},
	numpages = {4},
	pages = {1531--1534},
	publisher = {Association for Computing Machinery},
	series = {CIKM '18},
	title = {Cross-Domain Aspect/Sentiment-Aware Abstractive Review Summarization},
	url = {https://doi.org/10.1145/3269206.3269273},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1145/3269206.3269273}}

@inproceedings{10.1145/3357384.3358099,
	abstract = {Information-seeking conversation system aims at satisfying the information needs of users through conversations. Text matching between a user query and a pre-collected question is an important part of the information-seeking conversation in E-commerce. In the practical scenario, a sort of questions always correspond to a same answer. Naturally, these questions can form a bag. Learning the matching between user query and bag directly may improve the conversation performance, denoted as query-bag matching. Inspired by such opinion, we propose a query-bag matching model which mainly utilizes the mutual coverage between query and bag and measures the degree of the content in the query mentioned by the bag, and vice verse. In addition, the learned bag representation in word level helps find the main points of a bag in a fine grade and promotes the query-bag matching performance. Experiments on two datasets show the effectiveness of our model.},
	address = {New York, NY, USA},
	author = {Fu, Zhenxin and Ji, Feng and Hu, Wenpeng and Zhou, Wei and Zhao, Dongyan and Chen, Haiqing and Yan, Rui},
	booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3357384.3358099},
	isbn = {9781450369763},
	keywords = {ranking, coverage, bag, matching, e-commerce},
	location = {Beijing, China},
	numpages = {4},
	pages = {2337--2340},
	publisher = {Association for Computing Machinery},
	series = {CIKM '19},
	title = {Query-Bag Matching with Mutual Coverage for Information-Seeking Conversations in E-Commerce},
	url = {https://doi.org/10.1145/3357384.3358099},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1145/3357384.3358099}}

@inproceedings{10.1145/3132847.3132906,
	abstract = {Which venue is a tweet posted from? We referred this as fine-grained geolocation. To solve this problem effectively, we develop novel techniques to exploit each posting user's content history. This is motivated by our finding that most users do not share their visitation history, but have ample content history from tweet posts. We formulate fine-grained geolocation as a ranking problem whereby given a test tweet, we rank candidate venues. We propose several models that leverage on three types of signals from locations, users and peers. Firstly, the location signals are words that are indicative of venues. We propose a location-indicative weighting scheme to capture this. Next we exploit user signals from each user's content history to enrich the very limited content of their tweets which have been targeted for geolocation. The intuition is that the user's other tweets may have been from the test venue or related venues, thus providing informative words. In this regard, we propose query expansion as the enrichment approach. Finally, we exploit the signals from peer users who have similar content history and thus potentially similar visitation behavior as the users of the test tweets. This suggests collaborative filtering where visitation information is propagated via content similarities. We proposed several models incorporating different combinations of the three signals. Our experiments show that the best model incorporates all three signals. It performs 6% to 40% better than the baselines depending on the metric and dataset.},
	address = {New York, NY, USA},
	author = {Chong, Wen-Haw and Lim, Ee-Peng},
	booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3132847.3132906},
	isbn = {9781450349185},
	keywords = {tweet geolocation, query expansion, collaborative filtering},
	location = {Singapore, Singapore},
	numpages = {10},
	pages = {1279--1288},
	publisher = {Association for Computing Machinery},
	series = {CIKM '17},
	title = {Tweet Geolocation: Leveraging Location, User and Peer Signals},
	url = {https://doi.org/10.1145/3132847.3132906},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3132847.3132906}}

@inproceedings{10.1145/3132847.3132971,
	abstract = {Quality control is one of the major problems in crowdsourcing. One of the primary approaches to rectify this issue is to assign the same task to different workers and then aggregate their answers to obtain a reliable answer. In addition to simple aggregation approaches such as majority voting, various sophisticated probabilistic models have been proposed. However, given that most of the existing methods operate by strengthening the opinions of the majority, these models often fail when the tasks require highly specialized knowledge and the ability of a large majority of the workers is inadequate. In this paper, we focus on an important class of answer aggregation problems in which majority voting fails and propose the concept of hyper questions to devise effective aggregation methods. A hyper question is a set of single questions, and our key idea is that experts are more likely to provide correct answers to all of the single questions included in a hyper question than non-experts. Thus, experts are more likely to reach consensus on the hyper questions than non-experts, which strengthen their influences. We incorporate the concept of hyper questions into existing answer aggregation methods. The results of our experiments conducted using both synthetic datasets and real datasets demonstrate that our simple and easily usable approach works effectively in cases where only a few experts are available.},
	address = {New York, NY, USA},
	author = {Li, Jiyi and Baba, Yukino and Kashima, Hisashi},
	booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3132847.3132971},
	isbn = {9781450349185},
	keywords = {hyper question, answer aggregation, crowdsourcing, heterogeneous-answer multiple-choice questions},
	location = {Singapore, Singapore},
	numpages = {10},
	pages = {1069--1078},
	publisher = {Association for Computing Machinery},
	series = {CIKM '17},
	title = {Hyper Questions: Unsupervised Targeting of a Few Experts in Crowdsourcing},
	url = {https://doi.org/10.1145/3132847.3132971},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3132847.3132971}}

@inproceedings{10.1145/3340531.3411933,
	abstract = {Online health communities (OHCs) provide a popular channel for users to seek information, suggestions and support during their medical treatment and recovery processes. To help users find relevant information easily, we present CLIR, an effective system for recommending relevant discussion threads to users in OHCs. We identify that thread content and user interests can be categorized in two dimensions: topics and concepts. CLIR leverages Latent Dirichlet Allocation model to summarize the topic dimension and uses Convolutional Neural Network to encode the concept dimension. It then builds a thread neural network to capture thread characteristics and builds a user neural network to capture user interests by integrating these two dimensions and their interactions. Finally, it matches the target thread's characteristics with candidate users' interests to make recommendations. Experimental evaluation with multiple OHC datasets demonstrates the performance advantage of CLIR over the state-of-the-art recommender systems on various evaluation metrics.},
	address = {New York, NY, USA},
	author = {Li, Mingda and Gao, Weiting and Chen, Yi},
	booktitle = {Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3340531.3411933},
	isbn = {9781450368599},
	keywords = {online health community, discussion forum, thread recommendation, recommender systems, neural network, latent dirichlet allocation},
	location = {Virtual Event, Ireland},
	numpages = {10},
	pages = {765--774},
	publisher = {Association for Computing Machinery},
	series = {CIKM '20},
	title = {A Topic and Concept Integrated Model for Thread Recommendation in Online Health Communities},
	url = {https://doi.org/10.1145/3340531.3411933},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1145/3340531.3411933}}

@inproceedings{10.1145/3132847.3133007,
	abstract = {Recommending lifestyle articles is of immediate interest to the e-commerce industry and is beginning to attract research attention. Often followed strategies, such as recommending popular items are inadequate for this vertical because of two reasons. Firstly, users have their own personal preference over items, referred to as personal styles, which lead to the long-tail phenomenon. Secondly, each user displays multiple personas, each persona has a preference over items which could be dictated by a particular occasion, e.g. dressing for a party would be different from dressing to go to office. Recommendation in this vertical is crucially dependent on discovering styles for each of the multiple personas. There is no literature which addresses this problem.We posit a generative model which describes each user by a Simplex Over PERsona, SOPER, where a persona is described as the individuals preferences over prevailing styles modelled as topics over items. The choice of simplex and the long-tail nature necessitates the use of stick-breaking process. The main technical contribution is an efficient collapsed Gibbs sampling based algorithm for solving the attendant inference problem.Trained on large-scale interaction logs spanning more than half-a-million sessions collected from an e-commerce portal, SOPER outperforms previous baselines such as [9] by a large margin of 35% in identifying persona. Consequently it outperforms several competitive baselines comprehensively on the task of recommending from a catalogue of roughly 150 thousand lifestyle articles, by improving the recommendation quality as measured by AUC by a staggering 12.23%, in addition to aiding the interpretability of uncovered personal and fashionable styles thus advancing our precise understanding of the underlying phenomena.},
	address = {New York, NY, USA},
	author = {Dhakad, Lucky and Das, Mrinal and Bhattacharyya, Chiranjib and Datta, Samik and Kale, Mihir and Mehta, Vivek},
	booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3132847.3133007},
	isbn = {9781450349185},
	keywords = {topic models, stick-breaking process, lifestyle, fashion, bayesian nonparametrics},
	location = {Singapore, Singapore},
	numpages = {10},
	pages = {1609--1618},
	publisher = {Association for Computing Machinery},
	series = {CIKM '17},
	title = {SOPER: Discovering the Influence of Fashion and the Many Faces of User from Session Logs Using Stick Breaking Process},
	url = {https://doi.org/10.1145/3132847.3133007},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3132847.3133007}}

@inproceedings{10.1145/3132847.3132965,
	abstract = {The recorded student activities in Massive Open Online Course (MOOC) provide us a unique opportunity to model their learning behaviors, identify their particular learning intents, and enable personalized assistance and guidance in online education. In this work, based on a thorough qualitative study of students' behaviors recorded in two MOOC courses with large student enrollments, we develop a non-parametric Bayesian model to capture students' sequential learning activities in a generative manner. Homogeneity of students' learning behaviors is captured by clustering them into latent student groups, where shared model structure characterizes the transitional patterns, intensity and temporal distribution of their learning activities. In the meanwhile, heterogeneity is captured by clustering students into different groups. Both qualitative and quantitative studies on those two MOOC courses confirmed the effectiveness of the proposed model in identifying students' learning behavior patterns and clustering them into related groups for predictive analysis. The identified student groups accurately predict student retention, course satisfaction and demographics.},
	address = {New York, NY, USA},
	author = {Shi, Yuling and Peng, Zhiyong and Wang, Hongning},
	booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3132847.3132965},
	isbn = {9781450349185},
	keywords = {moocs, behavior modeling, sequential data mining, probabilistic modeling},
	location = {Singapore, Singapore},
	numpages = {10},
	pages = {979--988},
	publisher = {Association for Computing Machinery},
	series = {CIKM '17},
	title = {Modeling Student Learning Styles in MOOCs},
	url = {https://doi.org/10.1145/3132847.3132965},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3132847.3132965}}

@inproceedings{10.1145/3340531.3411906,
	abstract = {E-Commerce marketplaces support millions of daily transactions, and some disagreements between buyers and sellers are unavoidable. Resolving disputes in an accurate, fast, and fair manner is of great importance for maintaining a trustworthy platform. Simple cases can be automated, but intricate cases are not sufficiently addressed by hard-coded rules, and therefore most disputes are currently resolved by people. In this work we take a first step towards automatically assisting human agents in dispute resolution at scale. We construct a large dataset of disputes from the eBay online marketplace, and identify several interesting behavioral and linguistic patterns. We then train classifiers to predict dispute outcomes with high accuracy. We explore the model and the dataset, reporting interesting correlations, important features, and insights.},
	address = {New York, NY, USA},
	author = {Tsurel, David and Doron, Michael and Nus, Alexander and Dagan, Arnon and Guy, Ido and Shahaf, Dafna},
	booktitle = {Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3340531.3411906},
	isbn = {9781450368599},
	keywords = {online transactions, dispute resolution, e-commerce},
	location = {Virtual Event, Ireland},
	numpages = {10},
	pages = {1465--1474},
	publisher = {Association for Computing Machinery},
	series = {CIKM '20},
	title = {E-Commerce Dispute Resolution Prediction},
	url = {https://doi.org/10.1145/3340531.3411906},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1145/3340531.3411906}}

@inproceedings{10.1145/3340531.3411890,
	abstract = {False information detection on social media is challenging as it commonly requires tedious evidence-collecting but lacks available comparative information. Clues mined from user comments, as the wisdom of crowds, could be of considerable benefit to this task. However, it is non-trivial to capture the complex semantics from the contents and comments in consideration of their implicit correlations. Although deep neural networks have good expressive power, one major drawback is the lack of explainability. In this paper, we focus on how to learn from the post contents and related comments in social media to understand and detect the false information more effectively, with explainability. We thus propose a Quantum-probability based Signed Attention Network (QSAN) that integrates the quantum-driven text encoding and a novel signed attention mechanism in a unified framework. QSAN is not only able to distinguish important comments from the others, but also can exploit the conflicting social viewpoints in the comments to facilitate the detection. Moreover, QSAN is advantageous with its explainability in terms of transparency due to quantum physics meanings and the attention weights. Extensive experiments on real-world datasets show that our approach outperforms state-of-the-art baselines and can provide different kinds of user comments to explain why a piece of information is detected as false.},
	address = {New York, NY, USA},
	author = {Tian, Tian and Liu, Yudong and Yang, Xiaoyu and Lyu, Yuefei and Zhang, Xi and Fang, Binxing},
	booktitle = {Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3340531.3411890},
	isbn = {9781450368599},
	keywords = {quantum probability, false information detection, explainable AI, stance detection},
	location = {Virtual Event, Ireland},
	numpages = {10},
	pages = {1445--1454},
	publisher = {Association for Computing Machinery},
	series = {CIKM '20},
	title = {QSAN: A Quantum-Probability Based Signed Attention Network for Explainable False Information Detection},
	url = {https://doi.org/10.1145/3340531.3411890},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1145/3340531.3411890}}

@inproceedings{10.1145/3132847.3133023,
	abstract = {This paper studies the automated categorization and extraction of scientific concepts from titles of scientific articles, in order to gain a deeper understanding of their key contributions and facilitate the construction of a generic academic knowledgebase. Towards this goal, we propose an unsupervised, domain-independent, and scalable two-phase algorithm to type and extract key concept mentions into aspects of interest (e.g., Techniques, Applications, etc.). In the first phase of our algorithm we proposePhraseType, a probabilistic generative model which exploits textual features and limited POS tags to broadly segment text snippets into aspect-typed phrases. We extend this model to simultaneously learn aspect-specific features and identify academic domains in multi-domain corpora, since the two tasks mutually enhance each other. In the second phase, we propose an approach based on adaptor grammars to extract fine grained concept mentions from the aspect-typed phrases without the need for any external resources or human effort, in a purely data-driven manner. We apply our technique to study literature from diverse scientific domains and show significant gains over state-of-the-art concept extraction techniques. We also present a qualitative analysis of the results obtained.},
	address = {New York, NY, USA},
	author = {Krishnan, Adit and Sankar, Aravind and Zhi, Shi and Han, Jiawei},
	booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3132847.3133023},
	isbn = {9781450349185},
	keywords = {probabilistic model, adaptor grammar, concept extraction},
	location = {Singapore, Singapore},
	numpages = {10},
	pages = {1339--1348},
	publisher = {Association for Computing Machinery},
	series = {CIKM '17},
	title = {Unsupervised Concept Categorization and Extraction from Scientific Document Titles},
	url = {https://doi.org/10.1145/3132847.3133023},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3132847.3133023}}

@inproceedings{10.1145/3357384.3358017,
	abstract = {Interpretability of recommender systems has caused increasing attention due to its promotion of the effectiveness and persuasiveness of recommendation decision, and thus user satisfaction. Most existing methods, such as Matrix Factorization (MF), tend to be black-box machine learning models that lack interpretability and do not provide a straightforward explanation for their outputs. In this paper, we focus on probabilistic factorization model and further assume the absence of any auxiliary information, such as item content or user review. We propose an influence mechanism to evaluate the importance of the users' historical data, so that the most related users and items can be selected to explain each predicted rating. The proposed method is thus called Influencebased Interpretable Recommendation model (In2Rec). To further enhance the recommendation accuracy, we address the important issue of missing not at random, i.e., missing ratings are not independent from the observed and other unobserved ratings, because users tend to only interact what they like. In2Rec models the generative process for both observed and missing data, and integrates the influence mechanism in a Bayesian graphical model. A learning algorithm capitalizing on iterated condition modes is proposed to tackle the non-convex optimization problem pertaining to maximum a posteriori estimation for In2Rec. A series of experiments on four real-world datasets (Movielens 10M, Netflix, Epinions, and Yelp) have been conducted. By comparing with the state-of-the-art recommendation methods, the experimental results have shown that In2Rec can consistently benefit the recommendation system in both rating prediction and ranking estimation tasks, and friendly interpret the recommendation results with the aid of the proposed influence mechanism.},
	address = {New York, NY, USA},
	author = {Liu, Huafeng and Wen, Jingxuan and Jing, Liping and Yu, Jian and Zhang, Xiangliang and Zhang, Min},
	booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3357384.3358017},
	isbn = {9781450369763},
	keywords = {collaborative filtering, recommendation system, interpretable recommendation, probabilistic matrix factorization},
	location = {Beijing, China},
	numpages = {10},
	pages = {1803--1812},
	publisher = {Association for Computing Machinery},
	series = {CIKM '19},
	title = {In2Rec: Influence-Based Interpretable Recommendation},
	url = {https://doi.org/10.1145/3357384.3358017},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1145/3357384.3358017}}

@inproceedings{10.1145/3459637.3482450,
	abstract = {Neural text matching models have been widely used in community question answering, information retrieval, and dialogue. However, these models designed for short texts cannot well address the long-form text matching problem, because there are many contexts in long-form texts can not be directly aligned with each other, and it is difficult for existing models to capture the key matching signals from such noisy data. Besides, these models are computationally expensive for simply use all textual data indiscriminately. To tackle the effectiveness and efficiency problem, we propose a novel hierarchical noise filtering model, namely Match-Ignition. The main idea is to plug the well-known PageRank algorithm into the Transformer, to identify and filter both sentence and word level noisy information in the matching process. Noisy sentences are usually easy to detect because previous work has shown that their similarity can be explicitly evaluated by the word overlapping, so we directly use PageRank to filter such information based on a sentence similarity graph. Unlike sentences, words rely on their contexts to express concrete meanings, so we propose to jointly learn the filtering and matching process, to well capture the critical word-level matching signals. Specifically, a word graph is first built based on the attention scores in each self-attention block of Transformer, and key words are then selected by applying PageRank on this graph. In this way, noisy words will be filtered out layer by layer in the matching process. Experimental results show that Match-Ignition outperforms both SOTA short text matching models and recent long-form text matching models. We also conduct detailed analysis to show that Match-Ignition efficiently captures important sentences and words, to facilitate the long-form text matching process.},
	address = {New York, NY, USA},
	author = {Pang, Liang and Lan, Yanyan and Cheng, Xueqi},
	booktitle = {Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3459637.3482450},
	isbn = {9781450384469},
	keywords = {text matching, pagerank algorithm, long-form text},
	location = {Virtual Event, Queensland, Australia},
	numpages = {10},
	pages = {1396--1405},
	publisher = {Association for Computing Machinery},
	series = {CIKM '21},
	title = {Match-Ignition: Plugging PageRank into Transformer for Long-Form Text Matching},
	url = {https://doi.org/10.1145/3459637.3482450},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1145/3459637.3482450}}

@inproceedings{10.1145/3132847.3132963,
	abstract = {Entity disambiguation, also known as entity linking, is the task of mapping mentions in text to the corresponding entities in a given knowledge base, e.g. Wikipedia. Two key challenges are making use of mention's context to disambiguate (i.e. local objective), and promoting coherence of all the linked entities (i.e. global objective). In this paper, we propose a deep neural network model to effectively measure the semantic matching between mention's context and target entity. We are the first to employ the long short-term memory (LSTM) and attention mechanism for entity disambiguation. We also propose Pair-Linking, a simple but effective and significantly fast linking algorithm. Pair-Linking iteratively identifies and resolves pairs of mentions, starting from the most confident pair. It finishes linking all mentions in a document by scanning the pairs of mentions at most once. Our neural network model combined with Pair-Linking, named NeuPL, outperforms state-of-the-art systems over different types of documents including news, RSS, and tweets.},
	address = {New York, NY, USA},
	author = {Phan, Minh C. and Sun, Aixin and Tay, Yi and Han, Jialong and Li, Chenliang},
	booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
	date-added = {2022-10-23 17:57:02 +0200},
	date-modified = {2022-10-23 17:57:02 +0200},
	doi = {10.1145/3132847.3132963},
	isbn = {9781450349185},
	keywords = {semantic matching, pair-linking, entity disambiguation},
	location = {Singapore, Singapore},
	numpages = {10},
	pages = {1667--1676},
	publisher = {Association for Computing Machinery},
	series = {CIKM '17},
	title = {NeuPL: Attention-Based Semantic Matching and Pair-Linking for Entity Disambiguation},
	url = {https://doi.org/10.1145/3132847.3132963},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3132847.3132963}}

@inproceedings{10.1145/3447548.3467410,
	abstract = {Long story generation (LSG) is one of the coveted goals in natural language processing. Different from most text generation tasks, LSG requires to output a long story of rich content based on a much shorter text input, and often suffers from information sparsity. In this paper, we propose TopNet to alleviate this problem, by leveraging the recent advances in neural topic modeling to obtain high-quality skeleton words to complement the short input. In particular, instead of directly generating a story, we first learn to map the short text input to a low-dimensional topic distribution (which is pre-assigned by a topic model). Based on this latent topic distribution, we can use the reconstruction decoder of the topic model to sample a sequence of inter-related words as a skeleton for the story. Experiments on two benchmark datasets show that our proposed framework is highly effective in skeleton word selection and significantly outperforms the state-of-the-art models in both automatic evaluation and human evaluation.},
	address = {New York, NY, USA},
	author = {Yang, Yazheng and Pan, Boyuan and Cai, Deng and Sun, Huan},
	booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3447548.3467410},
	isbn = {9781450383325},
	keywords = {deep learning, long story generation, topic model, natural language processing, story telling},
	location = {Virtual Event, Singapore},
	numpages = {9},
	pages = {1997--2005},
	publisher = {Association for Computing Machinery},
	series = {KDD '21},
	title = {TopNet: Learning from Neural Topic Model to Generate Long Stories},
	url = {https://doi.org/10.1145/3447548.3467410},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1145/3447548.3467410}}

@inproceedings{10.1145/3534678.3542675,
	abstract = {Electronic health records (EHRs) provide rich clinical information and the opportunities to extract epidemiological patterns to understand and predict patient disease risks with suitable machine learning methods such as topic models. However, existing topic models do not generate identifiable topics each predicting a unique phenotype. One promising direction is to use known phenotype concepts to guide topic inference. We present a seed-guided Bayesian topic model called MixEHR-Seed with 3 contributions: (1) for each phenotype, we infer a dual-form of topic distribution: a seed-topic distribution over a small set of key EHR codes and a regular topic distribution over the entire EHR vocabulary; (2) we model age-dependent disease progression as Markovian dynamic topic priors; (3) we infer seed-guided multi-modal topics over distinct EHR data types. For inference, we developed a variational inference algorithm. Using MixEHR-Seed, we inferred 1569 PheCode-guided phenotype topics from an EHR database in Quebec, Canada covering 1.3 million patients for up to 20-year follow-up with 122 million records for 8539 and 1126 unique diagnostic and drug codes, respectively. We observed (1) accurate phenotype prediction by the guided topics, (2) clinically relevant PheCode-guided disease topics, (3) meaningful age-dependent disease prevalence. Source code is available at GitHub: https://github.com/li-lab-mcgill/MixEHR-Seed.},
	address = {New York, NY, USA},
	author = {Song, Ziyang and Hu, Yuanyi and Verma, Aman and Buckeridge, David L. and Li, Yue},
	booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3534678.3542675},
	isbn = {9781450393850},
	keywords = {variational autoencoder, predictive healthcare, topic modeling, electronic health records},
	location = {Washington DC, USA},
	numpages = {11},
	pages = {4713--4723},
	publisher = {Association for Computing Machinery},
	series = {KDD '22},
	title = {Automatic Phenotyping by a Seed-Guided Topic Model},
	url = {https://doi.org/10.1145/3534678.3542675},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1145/3534678.3542675}}

@inproceedings{10.1145/3447548.3467426,
	abstract = {Extreme Multi-label Learning (XML) involves assigning the subset of most relevant labels to a data point from millions of label choices. A hitherto unaddressed challenge in XML is that of predicting unseen labels with no training points. These form a significant fraction of total labels and contain fresh and personalized information desired by end users. Most existing extreme classifiers are not equipped for zero-shot label prediction and hence fail to leverage unseen labels. As a remedy, this paper proposes a novel approach called ZestXML for the task of Generalized Zero-shot XML (GZXML) where relevant labels have to be chosen from all available seen and unseen labels. ZestXML learns to project a data point's features close to the features of its relevant labels through a highly sparsified linear transform. This L0-constrained linear map between the two high-dimensional feature vectors is tractably recovered through a novel optimizer based on Hard Thresholding. By effectively leveraging the sparsities in features, labels and the learnt model, ZestXML achieves higher accuracy and smaller model size than existing XML approaches while also promoting efficient training &amp; prediction, real-time label update as well as explainable prediction.Experiments on large-scale GZXML datasets demonstrated that ZestXML can be up to 14% and 10% more accurate than state-of-the-art extreme classifiers and leading BERT-based dense retrievers respectively, while having 10x smaller model size. ZestXML trains on largest dataset with 31M labels in just 30 hours on a single core of a commodity desktop. When added to an large ensemble of existing models in Bing Sponsored Search Advertising, ZestXML significantly improved click yield of IR based system by 17% and unseen query coverage by 3.4% respectively. ZestXML's source code and benchmark datasets for GZXML will be publically released for research purposes here.},
	address = {New York, NY, USA},
	author = {Gupta, Nilesh and Bohra, Sakina and Prabhu, Yashoteja and Purohit, Saurabh and Varma, Manik},
	booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3447548.3467426},
	isbn = {9781450383325},
	keywords = {label metadata, sponsored search advertising, extreme multi-label classification, zero-shot learning},
	location = {Virtual Event, Singapore},
	numpages = {9},
	pages = {527--535},
	publisher = {Association for Computing Machinery},
	series = {KDD '21},
	title = {Generalized Zero-Shot Extreme Multi-Label Learning},
	url = {https://doi.org/10.1145/3447548.3467426},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1145/3447548.3467426}}

@inproceedings{10.1145/3534678.3539310,
	abstract = {While Variational Graph Auto-Encoder (VGAE) has presented promising ability to learn representations for documents, most existing VGAE methods do not model a latent topic structure and therefore lack semantic interpretability. Exploring hidden topics within documents and discovering key words associated with each topic allow us to develop a semantic interpretation of the corpus. Moreover, documents are usually associated with authors. For example, news reports have journalists specializing in writing certain type of events, academic papers have authors with expertise in certain research topics, etc. Modeling authorship information could benefit topic modeling, since documents by the same authors tend to reveal similar semantics. This observation also holds for documents published on the same venues. However, most topic models ignore the auxiliary authorship and publication venues. Given above two challenges, we propose a Variational Graph Author Topic Model for documents to integrate both semantic interpretability and authorship and venue modeling into a unified VGAE framework. For authorship and venue modeling, we construct a hierarchical multi-layered document graph with both intra- and cross-layer topic propagation. For semantic interpretability, three word relations (contextual, syntactic, semantic) are modeled and constitute three word sub-layers in the document graph. We further propose three alternatives for variational divergence. Experiments verify the effectiveness of our model on supervised and unsupervised tasks.},
	address = {New York, NY, USA},
	author = {Zhang, Delvin Ce and Lauw, Hady W.},
	booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3534678.3539310},
	isbn = {9781450393850},
	keywords = {author topic modeling, graph neural networks, text mining, variational graph auto-encoder},
	location = {Washington DC, USA},
	numpages = {10},
	pages = {2429--2438},
	publisher = {Association for Computing Machinery},
	series = {KDD '22},
	title = {Variational Graph Author Topic Modeling},
	url = {https://doi.org/10.1145/3534678.3539310},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1145/3534678.3539310}}

@inproceedings{10.1145/3097983.3098067,
	abstract = {While exploring human mobility can benefit many applications such as smart transportation, city planning, and urban economics, there are two key questions that need to be answered: (i) What is the nature of the spatial diffusion of human mobility across regions with different urban functions? (ii) How to spot and trace the trip purposes of human mobility trajectories? To answer these questions, we study large-scale and city-wide taxi trajectories; and furtherly organize them as arrival sequences according to the chronological arrival time. We figure out an important property across different regions from the arrival sequences, namely human mobility synchronization effect, which can be exploited to explain the phenomenon that two regions have similar arrival patterns in particular time periods if they share similar urban functions. In addition, the arrival sequences are mixed by arrival events with distinct trip purposes, which can be revealed by the regional environment of both the origins and destinations. To that end, in this paper, we develop a joint model that integrates Mixture of Hawkes Process (MHP) with a hierarchical topic model to capture the arrival sequences with mixed trip purposes. Essentially, the human mobility synchronization effect is encoded as a synchronization rate in the MHP; while the regional environment is modeled by introducing latent Trip Purpose and POI Topic to generate the Point of Interests (POIs) in the regions. Moreover, we provide an effective inference algorithm for parameter learning. Finally, we conduct intensive experiments on synthetic data and real-world data, and the experimental results have demonstrated the effectiveness of the proposed model.},
	address = {New York, NY, USA},
	author = {Wang, Pengfei and Fu, Yanjie and Liu, Guannan and Hu, Wenqing and Aggarwal, Charu},
	booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3097983.3098067},
	isbn = {9781450348874},
	keywords = {hawkes process, human mobility, synchronization, trip purpose, variational inference},
	location = {Halifax, NS, Canada},
	numpages = {9},
	pages = {495--503},
	publisher = {Association for Computing Machinery},
	series = {KDD '17},
	title = {Human Mobility Synchronization and Trip Purpose Detection with Mixture of Hawkes Processes},
	url = {https://doi.org/10.1145/3097983.3098067},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3097983.3098067}}

@inproceedings{10.1145/3097983.3098122,
	abstract = {Spatial item recommendation has become an important means to help people discover interesting locations, especially when people pay a visit to unfamiliar regions. Some current researches are focusing on modelling individual and collective geographical preferences for spatial item recommendation based on users' check-in records, but they fail to explore the phenomenon of user interest drift across geographical regions, i.e., users would show different interests when they travel to different regions. Besides, they ignore the influence of public comments for subsequent users' check-in behaviors. Specifically, it is intuitive that users would refuse to check in to a spatial item whose historical reviews seem negative overall, even though it might fit their interests. Therefore, it is necessary to recommend the right item to the right user at the right location. In this paper, we propose a latent probabilistic generative model called LSARS to mimic the decision-making process of users' check-in activities both in home-town and out-of-town scenarios by adapting to user interest drift and crowd sentiments, which can learn location-aware and sentiment-aware individual interests from the contents of spatial items and user reviews. Due to the sparsity of user activities in out-of-town regions, LSARS is further designed to incorporate the public preferences learned from local users' check-in behaviors. Finally, we deploy LSARS into two practical application scenes: spatial item recommendation and target user discovery. Extensive experiments on two large-scale location-based social networks (LBSNs) datasets show that LSARS achieves better performance than existing state-of-the-art methods.},
	address = {New York, NY, USA},
	author = {Wang, Hao and Fu, Yanmei and Wang, Qinyong and Yin, Hongzhi and Du, Changying and Xiong, Hui},
	booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3097983.3098122},
	isbn = {9781450348874},
	keywords = {check-in behavior, recommendation, crowd sentiment, user interest drift},
	location = {Halifax, NS, Canada},
	numpages = {9},
	pages = {1135--1143},
	publisher = {Association for Computing Machinery},
	series = {KDD '17},
	title = {A Location-Sentiment-Aware Recommender System for Both Home-Town and Out-of-Town Users},
	url = {https://doi.org/10.1145/3097983.3098122},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3097983.3098122}}

@inproceedings{10.1145/3292500.3330706,
	abstract = {In talent recruitment, the job interview aims at selecting the right candidates for the right jobs through assessing their skills and experiences in relation to the job positions. While tremendous efforts have been made in improving job interviews, a long-standing challenge is how to design appropriate interview questions for comprehensively assessing the competencies that may be deemed relevant and representative for person-job fit. To this end, in this research, we focus on the development of a personalized question recommender system, namely DuerQuiz, for enhancing the job interview assessment. DuerQuiz is a fully deployed system, in which a knowledge graph of job skills, Skill-Graph, has been built for comprehensively modeling the relevant competencies that should be assessed in the job interview. Specifically, we first develop a novel skill entity extraction approach based on a bidirectional Long Short-Term Memory (LSTM) with a Conditional Random Field (CRF) layer (LSTM-CRF) neural network enhanced with adapted gate mechanism. In particular, to improve the reliability of extracted skill entities, we design a label propagation method based on more than 10 billion click-through data from the large-scale Baidu query logs. Furthermore, we discover the hypernym-hyponym relations between skill entities and construct the Skill-Graph by leveraging the classifier trained with extensive contextual features. Finally, we design a personalized question recommendation algorithm based on the Skill-Graph for improving the efficiency and effectiveness of job interview assessment. Extensive experiments on real-world recruitment data clearly validate the effectiveness of DuerQuiz, which had been deployed for generating written exercises in the 2018 Baidu campus recruitment event and received remarkable performances in terms of efficiency and effectiveness for selecting outstanding talents compared with a traditional non-personalized human-only assessment approach.},
	address = {New York, NY, USA},
	author = {Qin, Chuan and Zhu, Hengshu and Zhu, Chen and Xu, Tong and Zhuang, Fuzhen and Ma, Chao and Zhang, Jingshuai and Xiong, Hui},
	booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3292500.3330706},
	isbn = {9781450362016},
	keywords = {intelligence interview system, question recommendation},
	location = {Anchorage, AK, USA},
	numpages = {9},
	pages = {2165--2173},
	publisher = {Association for Computing Machinery},
	series = {KDD '19},
	title = {DuerQuiz: A Personalized Question Recommender System for Intelligent Job Interview},
	url = {https://doi.org/10.1145/3292500.3330706},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1145/3292500.3330706}}

@inproceedings{10.1145/3097983.3098074,
	abstract = {Correlated topic modeling has been limited to small model and problem sizes due to their high computational cost and poor scaling. In this paper, we propose a new model which learns compact topic embeddings and captures topic correlations through the closeness between the topic vectors. Our method enables efficient inference in the low-dimensional embedding space, reducing previous cubic or quadratic time complexity to linear w.r.t the topic size. We further speedup variational inference with a fast sampler to exploit sparsity of topic occurrence. Extensive experiments show that our approach is capable of handling model and data scales which are several orders of magnitude larger than existing correlation results, without sacrificing modeling quality by providing competitive or superior performance in document classification and retrieval.},
	address = {New York, NY, USA},
	author = {He, Junxian and Hu, Zhiting and Berg-Kirkpatrick, Taylor and Huang, Ying and Xing, Eric P.},
	booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3097983.3098074},
	isbn = {9781450348874},
	keywords = {scalability, correlated topic models, topic embedding},
	location = {Halifax, NS, Canada},
	numpages = {9},
	pages = {225--233},
	publisher = {Association for Computing Machinery},
	series = {KDD '17},
	title = {Efficient Correlated Topic Modeling with Topic Embedding},
	url = {https://doi.org/10.1145/3097983.3098074},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3097983.3098074}}

@inproceedings{10.1145/3097983.3098017,
	abstract = {Autoencoders have been successful in learning meaningful representations from image datasets. However, their performance on text datasets has not been widely studied. Traditional autoencoders tend to learn possibly trivial representations of text documents due to their confoundin properties such as high-dimensionality, sparsity and power-law word distributions. In this paper, we propose a novel k-competitive autoencoder, called KATE, for text documents. Due to the competition between the neurons in the hidden layer, each neuron becomes specialized in recognizing specific data patterns, and overall the model can learn meaningful representations of textual data. A comprehensive set of experiments show that KATE can learn better representations than traditional autoencoders including denoising, contractive, variational, and k-sparse autoencoders. Our model also outperforms deep generative models, probabilistic topic models, and even word representation models (e.g., Word2Vec) in terms of several downstream tasks such as document classification, regression, and retrieval.},
	address = {New York, NY, USA},
	author = {Chen, Yu and Zaki, Mohammed J.},
	booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3097983.3098017},
	isbn = {9781450348874},
	keywords = {representation learning, competitive learning, text analytics, autoencoders},
	location = {Halifax, NS, Canada},
	numpages = {10},
	pages = {85--94},
	publisher = {Association for Computing Machinery},
	series = {KDD '17},
	title = {KATE: K-Competitive Autoencoder for Text},
	url = {https://doi.org/10.1145/3097983.3098017},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3097983.3098017}}

@inproceedings{10.1145/3219819.3219929,
	abstract = {Cultural activity is an inherent aspect of urban life and the success of a modern city is largely determined by its capacity to offer generous cultural entertainment to its citizens. To this end, the optimal allocation of cultural establishments and related resources across urban regions becomes of vital importance, as it can reduce financial costs in terms of planning and improve quality of life in the city, more generally. In this paper, we make use of a large longitudinal dataset of user location check-ins from the online social network WeChat to develop a data-driven framework for cultural planning in the city of Beijing. We exploit rich spatio-temporal representations on user activity at cultural venues and use a novel extended version of the traditional latent Dirichlet allocation model that incorporates temporal information to identify latent patterns of urban cultural interactions. Using the characteristic typologies of mobile user cultural activities emitted by the model, we determine the levels of demand for different types of cultural resources across urban areas. We then compare those with the corresponding levels of supply as driven by the presence and spatial reach of cultural venues in local areas to obtain high resolution maps that indicate urban regions with lack of cultural resources, and thus give suggestions for further urban cultural planning and investment optimisation.},
	address = {New York, NY, USA},
	author = {Zhou, Xiao and Noulas, Anastasios and Mascolo, Cecilia and Zhao, Zhongxiang},
	booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3219819.3219929},
	isbn = {9781450355520},
	keywords = {topic modeling, pattern mining, urban computing, spatial accessibility, spatio-temporal analysis},
	location = {London, United Kingdom},
	numpages = {10},
	pages = {1069--1078},
	publisher = {Association for Computing Machinery},
	series = {KDD '18},
	title = {Discovering Latent Patterns of Urban Cultural Interactions in WeChat for Modern City Planning},
	url = {https://doi.org/10.1145/3219819.3219929},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1145/3219819.3219929}}

@inproceedings{10.1145/3097983.3098110,
	abstract = {We propose a new model selection criterion based on the minimum description length principle in a name of the decomposed normalized maximum likelihood criterion. Our criterion can be applied to a large class of hierarchical latent variable models, such as the Naive Bayes models, stochastic block models and latent Dirichlet allocations, for which many conventional information criteria cannot be straightforwardly applied due to irregularity of latent variable models. Our method also has an advantage that it can be exactly evaluated without asymptotic approximation with small time complexity. Our experiments using synthetic and real data demonstrated validity of our method in terms of computational efficiency and model selection accuracy, while our criterion especially dominated the other criteria when sample size is small and when data are noisy.},
	address = {New York, NY, USA},
	author = {Wu, Tianyi and Sugawara, Shinya and Yamanishi, Kenji},
	booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3097983.3098110},
	isbn = {9781450348874},
	keywords = {topic and latent variable models, model selection, clustering},
	location = {Halifax, NS, Canada},
	numpages = {10},
	pages = {1165--1174},
	publisher = {Association for Computing Machinery},
	series = {KDD '17},
	title = {Decomposed Normalized Maximum Likelihood Codelength Criterion for Selecting Hierarchical Latent Variable Models},
	url = {https://doi.org/10.1145/3097983.3098110},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3097983.3098110}}

@inproceedings{10.1145/3394486.3403242,
	abstract = {Mining a set of meaningful topics organized into a hierarchy is intuitively appealing since topic correlations are ubiquitous in massive text corpora. To account for potential hierarchical topic structures, hierarchical topic models generalize flat topic models by incorporating latent topic hierarchies into their generative modeling process. However, due to their purely unsupervised nature, the learned topic hierarchy often deviates from users' particular needs or interests. To guide the hierarchical topic discovery process with minimal user supervision, we propose a new task, Hierarchical Topic Mining, which takes a category tree described by category names only, and aims to mine a set of representative terms for each category from a text corpus to help a user comprehend his/her interested topics. We develop a novel joint tree and text embedding method along with a principled optimization procedure that allows simultaneous modeling of the category tree structure and the corpus generative process in the spherical space for effective category-representative term discovery. Our comprehensive experiments show that our model, named JoSH, mines a high-quality set of hierarchical topics with high efficiency and benefits weakly-supervised hierarchical text classification tasks.},
	address = {New York, NY, USA},
	author = {Meng, Yu and Zhang, Yunyi and Huang, Jiaxin and Zhang, Yu and Zhang, Chao and Han, Jiawei},
	booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3394486.3403242},
	isbn = {9781450379984},
	keywords = {topic hierarchy, tree embedding, text embedding, topic mining},
	location = {Virtual Event, CA, USA},
	numpages = {10},
	pages = {1908--1917},
	publisher = {Association for Computing Machinery},
	series = {KDD '20},
	title = {Hierarchical Topic Mining via Joint Spherical Tree and Text Embedding},
	url = {https://doi.org/10.1145/3394486.3403242},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1145/3394486.3403242}}

@inproceedings{10.1145/3394486.3403244,
	abstract = {Taxonomy is not only a fundamental form of knowledge representation, but also crucial to vast knowledge-rich applications, such as question answering and web search. Most existing taxonomy construction methods extract hypernym-hyponym entity pairs to organize a "universal" taxonomy. However, these generic taxonomies cannot satisfy user's specific interest in certain areas and relations. Moreover, the nature of instance taxonomy treats each node as a single word, which has low semantic coverage for people to fully understand. In this paper, we propose a method for seed-guided topical taxonomy construction, which takes a corpus and a seed taxonomy described by concept names as input, and constructs a more complete taxonomy based on user's interest, wherein each node is represented by a cluster of coherent terms. Our framework, CoRel, has two modules to fulfill this goal. A relation transferring module learns and transfers the user's interested relation along multiple paths to expand the seed taxonomy structure in width and depth. A concept learning module enriches the semantics of each concept node by jointly embedding the taxonomy and text. Comprehensive experiments conducted on real-world datasets show that CoRel generates high-quality topical taxonomies and outperforms all the baselines significantly.},
	address = {New York, NY, USA},
	author = {Huang, Jiaxin and Xie, Yiqing and Meng, Yu and Zhang, Yunyi and Han, Jiawei},
	booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3394486.3403244},
	isbn = {9781450379984},
	keywords = {semantic computing, relation extraction, taxonomy construction, topic discovery},
	location = {Virtual Event, CA, USA},
	numpages = {9},
	pages = {1928--1936},
	publisher = {Association for Computing Machinery},
	series = {KDD '20},
	title = {CoRel: Seed-Guided Topical Taxonomy Construction by Concept Learning and Relation Transferring},
	url = {https://doi.org/10.1145/3394486.3403244},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1145/3394486.3403244}}

@inproceedings{10.1145/3219819.3220064,
	abstract = {Taxonomy construction is not only a fundamental task for semantic analysis of text corpora, but also an important step for applications such as information filtering, recommendation, and Web search. Existing pattern-based methods extract hypernym-hyponym term pairs and then organize these pairs into a taxonomy. However, by considering each term as an independent concept node, they overlook the topical proximity and the semantic correlations among terms. In this paper, we propose a method for constructing topic taxonomies, wherein every node represents a conceptual topic and is defined as a cluster of semantically coherent concept terms. Our method, TaxoGen, uses term embeddings and hierarchical clustering to construct a topic taxonomy in a recursive fashion. To ensure the quality of the recursive process, it consists of: (1) an adaptive spherical clustering module for allocating terms to proper levels when splitting a coarse topic into fine-grained ones; (2) a local embedding module for learning term embeddings that maintain strong discriminative power at different levels of the taxonomy. Our experiments on two real datasets demonstrate the effectiveness of TaxoGen compared with baseline methods.},
	address = {New York, NY, USA},
	author = {Zhang, Chao and Tao, Fangbo and Chen, Xiusi and Shen, Jiaming and Jiang, Meng and Sadler, Brian and Vanni, Michelle and Han, Jiawei},
	booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3219819.3220064},
	isbn = {9781450355520},
	keywords = {taxonomy construction, text mining, word embedding},
	location = {London, United Kingdom},
	numpages = {9},
	pages = {2701--2709},
	publisher = {Association for Computing Machinery},
	series = {KDD '18},
	title = {TaxoGen: Unsupervised Topic Taxonomy Construction by Adaptive Term Embedding and Clustering},
	url = {https://doi.org/10.1145/3219819.3220064},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1145/3219819.3220064}}

@inproceedings{10.1145/3534678.3539107,
	abstract = {Online education, which educates students that cannot be present at school, has become an important supplement to traditional education. Without the direct supervision and instruction of teachers, online education is always concerned with potential distractions and misunderstandings. Learning Style Classification (LSC) is proposed to analyze the learning behavior patterns of online learning users, based on which personalized learning paths are generated to help them learn and maintain their interests.Existing LSC studies rely on expert-labored labeling, which is infeasible in large-scale applications, so we resort to unsupervised classification techniques. However, current unsupervised classification methods are not applicable due to two important challenges: C1) the unawareness of the LSC problem formulation and pedagogy domain knowledge; C2) the absence of any supervision signals. In this paper, we give a formal definition of the unsupervised LSC problem and summarize the domain knowledge into problem-solving heuristics (which addresses C1). A rule-based approach is first designed to provide a tentative solution in a principled manner (which addresses C2). On top of that, a novel Deep Unsupervised Classifier with domain Knowledge (DUCK) is proposed to convert the discovered conclusions and domain knowledge into learnable model components (which addresses both C1 and C2), which significantly improves the effectiveness, efficiency, and robustness. Extensive offline experiments on both public and industrial datasets demonstrate the superiority of our proposed methods. Moreover, the proposed methods are now deployed in the Huawei Education Center, and the ongoing A/B testing results verify the effectiveness of the methods.},
	address = {New York, NY, USA},
	author = {He, Zhicheng and Xia, Wei and Dong, Kai and Guo, Huifeng and Tang, Ruiming and Xia, Dingyin and Zhang, Rui},
	booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3534678.3539107},
	isbn = {9781450393850},
	keywords = {user behavior analysis, unsupervised classification, educational data mining, deep clustering, learning style classification},
	location = {Washington DC, USA},
	numpages = {10},
	pages = {2997--3006},
	publisher = {Association for Computing Machinery},
	series = {KDD '22},
	title = {Unsupervised Learning Style Classification for Learning Path Generation in Online Education Platforms},
	url = {https://doi.org/10.1145/3534678.3539107},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1145/3534678.3539107}}

@inproceedings{10.1145/3292500.3330737,
	abstract = {Increasing rates of opioid drug abuse and heightened prevalence of online support communities underscore the necessity of employing data mining techniques to better understand drug addiction using these rapidly developing online resources. In this work, we obtained data from Reddit, an online collection of forums, to gather insight into drug use/misuse using text snippets from users narratives. Specifically, using users' posts, we trained a binary classifier which predicts a user's transitions from casual drug discussion forums to drug recovery forums. We also proposed a Cox regression model that outputs likelihoods of such transitions. In doing so, we found that utterances of select drugs and certain linguistic features contained in one's posts can help predict these transitions. Using unfiltered drug-related posts, our research delineates drugs that are associated with higher rates of transitions from recreational drug discussion to support/recovery discussion, offers insight into modern drug culture, and provides tools with potential applications in combating the opioid crisis.},
	address = {New York, NY, USA},
	author = {Lu, John and Sridhar, Sumati and Pandey, Ritika and Hasan, Mohammad Al and Mohler, Georege},
	booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3292500.3330737},
	isbn = {9781450362016},
	keywords = {text mining, reddit forum, drug addiction and recovery, cox regression},
	location = {Anchorage, AK, USA},
	numpages = {9},
	pages = {2367--2375},
	publisher = {Association for Computing Machinery},
	series = {KDD '19},
	title = {Investigate Transitions into Drug Addiction through Text Mining of Reddit Data},
	url = {https://doi.org/10.1145/3292500.3330737},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1145/3292500.3330737}}

@inproceedings{10.1145/3292500.3330698,
	abstract = {Tags of a Point of Interest (POI) can facilitate location-based services from many aspects like location search and place recommendation. However, many POI tags are often incomplete or imprecise, which may lead to performance degradation of tag-dependent applications. In this paper, we study the POI tag refinement problem which aims to automatically fill in the missing tags as well as correct noisy tags for POIs. We propose a tri-adaptive collaborative learning framework to search for an optimal POI-tag score matrix. The framework integrates three components to collaboratively (i) model the similarity matching between POI and tag, (ii) recover the POI-tag pattern via matrix factorization and (iii) learn to infer the most possible tags by maximum likelihood estimation. We devise an adaptively joint training process to optimize the model and regularize each component simultaneously. And the final refinement results are the consensus of multiple views from different components. We also discuss how to utilize various data sources to construct features for tag refinement, including user profile data, query data on Baidu Maps and basic properties of POIs. Finally, we conduct extensive experiments to demonstrate the effectiveness of our framework. And we further present a case study of the deployment of our framework on Baidu Maps.},
	address = {New York, NY, USA},
	author = {Zhou, Jingbo and Gou, Shan and Hu, Renjun and Zhang, Dongxiang and Xu, Jin and Jiang, Airong and Li, Ying and Xiong, Hui},
	booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3292500.3330698},
	isbn = {9781450362016},
	keywords = {collaborative learning, tag refinement, tag mining, location based service, point of interest},
	location = {Anchorage, AK, USA},
	numpages = {10},
	pages = {1752--1761},
	publisher = {Association for Computing Machinery},
	series = {KDD '19},
	title = {A Collaborative Learning Framework to Tag Refinement for Points of Interest},
	url = {https://doi.org/10.1145/3292500.3330698},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1145/3292500.3330698}}

@inproceedings{10.1145/3097983.3098068,
	abstract = {Motifs are a powerful tool for analyzing physiological waveform data. Standard motif methods, however, ignore important contextual information (e.g., what the patient was doing at the time the data were collected). We hypothesize that these additional contextual data could increase the utility of motifs. Thus, we propose an extension to motifs, contextual motifs, that incorporates context. Recognizing that, oftentimes, context may be unobserved or unavailable, we focus on methods to jointly infer motifs and context. Applied to both simulated and real physiological data, our proposed approach improves upon existing motif methods in terms of the discriminative utility of the discovered motifs. In particular, we discovered contextual motifs in continuous glucose monitor (CGM) data collected from patients with type 1 diabetes. Compared to their contextless counterparts, these contextual motifs led to better predictions of hypo- and hyperglycemic events. Our results suggest that even when inferred, context is useful in both a long- and short-term prediction horizon when processing and interpreting physiological waveform data.},
	address = {New York, NY, USA},
	author = {Fox, Ian and Ang, Lynn and Jaiswal, Mamta and Pop-Busui, Rodica and Wiens, Jenna},
	booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3097983.3098068},
	isbn = {9781450348874},
	keywords = {contextual motifs, motif discovery, blood glucose},
	location = {Halifax, NS, Canada},
	numpages = {10},
	pages = {155--164},
	publisher = {Association for Computing Machinery},
	series = {KDD '17},
	title = {Contextual Motifs: Increasing the Utility of Motifs Using Contextual Data},
	url = {https://doi.org/10.1145/3097983.3098068},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3097983.3098068}}

@inproceedings{10.1145/3292500.3330924,
	abstract = {Recently, network embedding (NE) has achieved great successes in learning low dimensional representations for network nodes and has been increasingly applied to various network analytic tasks. In this paper, we consider the representation learning problem for content-rich networks whose nodes are associated with rich content information. Content-rich network embedding is challenging in fusing the complex structural dependencies and the rich contents. To tackle the challenges, we propose a generative model, Network-to-Network Network Embedding (Net2Net-NE) model, which can effectively fuse the structure and content information into one continuous embedding vector for each node. Specifically, we regard the content-rich network as a pair of networks with different modalities, i.e., content network and node network. By exploiting the strong correlation between the focal node and the nodes to whom it is connected to, a multilayer recursively composable encoder is proposed to fuse the structure and content information of the entire ego network into the egocentric node embedding. Moreover, a cross-modal decoder is deployed to mapping the egocentric node embeddings into node identities in an interconnected network. By learning the identity of each node according to its content, the mapping from content network to node network is learned in a generative manner. Hence the latent encoding vectors learned by the Net2Net-NE can be used as effective node embeddings. Extensive experimental results on three real-world networks demonstrate the superiority of Net2Net-NE over state-of-the-art methods.},
	address = {New York, NY, USA},
	author = {He, Zhicheng and Liu, Jie and Li, Na and Huang, Yalou},
	booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3292500.3330924},
	isbn = {9781450362016},
	keywords = {network representation learning, egocentric embedding, network embedding, network to network},
	location = {Anchorage, AK, USA},
	numpages = {9},
	pages = {1037--1045},
	publisher = {Association for Computing Machinery},
	series = {KDD '19},
	title = {Learning Network-to-Network Model for Content-Rich Network Embedding},
	url = {https://doi.org/10.1145/3292500.3330924},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1145/3292500.3330924}}

@inproceedings{10.1145/3219819.3219964,
	abstract = {Stock comments from analysts contain important consulting information for investors to foresee stock volatility and market trends. Existing studies on stock comments usually focused on capturing coarse-grained opinion polarities or understanding market fundamentals. However, investors are often overwhelmed and confused by massive comments with huge noises and ambiguous opinions. Therefore, it is an emerging need to have a fine-grained stock comment analysis tool to identify more reliable stock comments. To this end, this paper provides a solution called StockAssIstant for modeling the reliability of stock comments by considering multiple factors, such as stock price trends, comment content, and the performances of analysts, in a holistic manner. Specifically, we first analyze the pattern of analysts' opinion dynamics from historical comments. Then, we extract key features from the time-series constructed by using the semantic information in comment text, stock prices and the historical behaviors of analysts. Based on these features, we propose an ensemble learning based approach for measuring the reliability of comments. Finally, we conduct extensive experiments and provide a trading simulation on real-world stock data. The experimental results and the profit achieved by the simulated trading in 12-month period clearly validate the effectiveness of our approach for modeling the reliability of stock comments.},
	address = {New York, NY, USA},
	author = {Zhang, Chen and Wang, Yijun and Chen, Can and Du, Changying and Yin, Hongzhi and Wang, Hao},
	booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3219819.3219964},
	isbn = {9781450355520},
	keywords = {stock comment, reliability modeling, time-series},
	location = {London, United Kingdom},
	numpages = {10},
	pages = {2710--2719},
	publisher = {Association for Computing Machinery},
	series = {KDD '18},
	title = {StockAssIstant: A Stock AI Assistant for Reliability Modeling of Stock Comments},
	url = {https://doi.org/10.1145/3219819.3219964},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1145/3219819.3219964}}

@inproceedings{10.1145/3447548.3467390,
	abstract = {What should a malicious user write next to fool a detection model? Identifying malicious users is critical to ensure the safety and integrity of internet platforms. Several deep learning based detection models have been created. However, malicious users can evade deep detection models by manipulating their behavior, rendering these models of little use. The vulnerability of such deep detection models against adversarial attacks is unknown. Here we create a novel adversarial attack model against deep user sequence embedding-based classification models, which use the sequence of user posts to generate user embeddings and detect malicious users. In the attack, the adversary generates a new post to fool the classifier. We propose a novel end-to-end Personalized Text Generation Attack model, called PETGEN, that simultaneously reduces the efficacy of the detection model and generates posts that have several key desirable properties. Specifically, PETGEN generates posts that are personalized to the user's writing style, have knowledge about a given target context, are aware of the user's historical posts on the target context, and encapsulate the user's recent topical interests. We conduct extensive experiments on two real-world datasets (Yelp and Wikipedia, both with ground-truth of malicious users) to show that PETGEN significantly reduces the performance of popular deep user sequence embedding-based classification models. PETGEN outperforms five attack baselines in terms of text quality and attack efficacy in both white-box and black-box classifier settings. Overall, this work paves the path towards the next generation of adversary-aware sequence classification models.},
	address = {New York, NY, USA},
	author = {He, Bing and Ahamad, Mustaque and Kumar, Srijan},
	booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3447548.3467390},
	isbn = {9781450383325},
	keywords = {deep learning, attack, user classification, sequence classification, adversarial text generation},
	location = {Virtual Event, Singapore},
	numpages = {10},
	pages = {575--584},
	publisher = {Association for Computing Machinery},
	series = {KDD '21},
	title = {PETGEN: Personalized Text Generation Attack on Deep Sequence Embedding-Based Classification Models},
	url = {https://doi.org/10.1145/3447548.3467390},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1145/3447548.3467390}}

@inproceedings{10.1145/3292500.3330721,
	abstract = {A large payment network contains millions of merchants and billions of transactions, and the merchants are described in a large number of attributes with incomplete values. Understanding its community structures is crucial to ensure its sustainable and long lasting. Knowing a merchant's community is also important from many applications - risk management, compliance, legal and marketing. To detect communities, an algorithm has to take advances from both attribute and topological information. Further, the method has to be able to handle incomplete and complex attributes. In this paper, we propose a framework named AGGMMR to effectively address the challenges come from scalability, mixed attributes, and incomplete value. We evaluate our proposed framework on four benchmark datasets against five strong baselines. More importantly, we provide a case study of running AGGMMR on a large network from PayPal which contains $100 million$ merchants with $1.5 billion$ transactions. The results demonstrate AGGMMR's effectiveness and practicability.},
	address = {New York, NY, USA},
	author = {Zhe, Chen and Sun, Aixin and Xiao, Xiaokui},
	booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3292500.3330721},
	isbn = {9781450362016},
	keywords = {large attributed network, community detection, complex attributes},
	location = {Anchorage, AK, USA},
	numpages = {9},
	pages = {2041--2049},
	publisher = {Association for Computing Machinery},
	series = {KDD '19},
	title = {Community Detection on Large Complex Attribute Network},
	url = {https://doi.org/10.1145/3292500.3330721},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1145/3292500.3330721}}

@inproceedings{10.1145/3447548.3467302,
	abstract = {Treatment effect estimation from observational data is a critical research topic across many domains. The foremost challenge in treatment effect estimation is how to capture hidden confounders. Recently, the growing availability of networked observational data offers a new opportunity to deal with the issue of hidden confounders. Unlike networked data in traditional graph learning tasks, such as node classification and link detection, the networked data under the causal inference problem has its particularity, i.e., imbalanced network structure. In this paper, we propose a Graph Infomax Adversarial Learning (GIAL) model for treatment effect estimation, which makes full use of the network structure to capture more information by recognizing the imbalance in network structure. We evaluate the performance of our GIAL model on two benchmark datasets, and the results demonstrate superiority over the state-of-the-art methods.},
	address = {New York, NY, USA},
	author = {Chu, Zhixuan and Rathbun, Stephen L. and Li, Sheng},
	booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3447548.3467302},
	isbn = {9781450383325},
	keywords = {graph mining, social network analysis, causal inference},
	location = {Virtual Event, Singapore},
	numpages = {9},
	pages = {176--184},
	publisher = {Association for Computing Machinery},
	series = {KDD '21},
	title = {Graph Infomax Adversarial Learning for Treatment Effect Estimation with Networked Observational Data},
	url = {https://doi.org/10.1145/3447548.3467302},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1145/3447548.3467302}}

@inproceedings{10.1145/3394486.3403179,
	abstract = {The competitive relationship of Points of Interest (POIs) refers to the degree of competition between two POIs for business opportunities from third parties in an urban area. Existing studies for competitive analysis usually focus on mining competitive relationships of entities, such as companies or products, from textual data. However, there are few studies which have a focus on competitive analysis for POIs. Indeed, the growing availability of user behavior data about POIs, such as POI reviews and human mobility data, enables a new paradigm for understanding the competitive relationships among POIs. To this end, in this paper, we study how to predict the POI competitive relationship. Along this line, a very first challenge is how to integrate heterogeneous user behavior data with the spatial features of POIs. As a solution, we first build a heterogeneous POI information network (HPIN) from POI reviews and map search data. Then, we develop a graph neural network-based deep learning framework, named DeepR, for POI competitive relationship prediction based on HPIN. Specifically, DeepR contains two components: a spatial adaptive graph neural network (SA-GNN) and a POI pairwise knowledge extraction learning (PKE) model. The SA-GNN is a novel GNN architecture with incorporating POI's spatial information and location distribution by a specially designed spatial oriented aggregation layer and spatial-dependency attentive propagation mechanism. In addition, PKE is devised to distill the POI pairwise knowledge in HPIN being useful for relationship prediction into condensate vectors with relational graph convolution and cross attention. Finally, extensive experiments on two real-world datasets demonstrate the effectiveness of our method.},
	address = {New York, NY, USA},
	author = {Li, Shuangli and Zhou, Jingbo and Xu, Tong and Liu, Hao and Lu, Xinjiang and Xiong, Hui},
	booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3394486.3403179},
	isbn = {9781450379984},
	keywords = {graph neural networks, competitive analysis, point of interest, heterogeneous information network},
	location = {Virtual Event, CA, USA},
	numpages = {10},
	pages = {1265--1274},
	publisher = {Association for Computing Machinery},
	series = {KDD '20},
	title = {Competitive Analysis for Points of Interest},
	url = {https://doi.org/10.1145/3394486.3403179},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1145/3394486.3403179}}

@inproceedings{10.1145/3219819.3219827,
	abstract = {The automatic extraction of breaking news events from natural language text is a valuable capability for decision support systems. Traditional systems tend to focus on extracting events from a single media source and often ignore cross-media references. Here, we describe a large-scale automated system for extracting natural disasters and critical events from both newswire text and social media. We outline a comprehensive architecture that can identify, categorize and summarize seven different event types - namely floods, storms, fires, armed conflict, terrorism, infrastructure breakdown, and labour unavailability. The system comprises fourteen modules and is equipped with a novel coreference mechanism, capable of linking events extracted from the two complementary data sources. Additionally, the system is easily extensible to accommodate new event types. Our experimental evaluation demonstrates the effectiveness of the system.},
	address = {New York, NY, USA},
	author = {Petroni, Fabio and Raman, Natraj and Nugent, Tim and Nourbakhsh, Armineh and Pani\'{c}, \v{Z}arko and Shah, Sameena and Leidner, Jochen L.},
	booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
	date-added = {2022-10-23 17:41:11 +0200},
	date-modified = {2022-10-23 17:41:11 +0200},
	doi = {10.1145/3219819.3219827},
	isbn = {9781450355520},
	keywords = {event extraction, news analytics, information extraction, event coreference, first story detection},
	location = {London, United Kingdom},
	numpages = {10},
	pages = {626--635},
	publisher = {Association for Computing Machinery},
	series = {KDD '18},
	title = {An Extensible Event Extraction System With Cross-Media Event Resolution},
	url = {https://doi.org/10.1145/3219819.3219827},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1145/3219819.3219827}}

@inproceedings{10.1145/3477495.3531877,
	abstract = {We present a novel semantic context prior-based venue recommendation system that uses only the title and the abstract of a paper. Based on the intuition that the text in the title and abstract have both semantic and syntactic components, we demonstrate that a joint training of a semantic feature extractor and syntactic feature extractor collaboratively leverages meaningful information that helps to provide venues for papers. The proposed methodology that we call DeSCoVeR at first elicits these semantic and syntactic features using a Neural Topic Model and text classifier respectively. The model then executes a transfer learning optimization procedure to perform a contextual transfer between the feature distributions of the Neural Topic Model and the text classifier during the training phase. DeSCoVeR also mitigates the document-level label bias using a Causal back-door path criterion and a sentence-level keyword bias removal technique. Experiments on the DBLP dataset show that DeSCoVeR outperforms the state-of-the-art methods.},
	address = {New York, NY, USA},
	author = {Rajanala, Sailaja and Pal, Arghya and Singh, Manish and Phan, Rapha\"{e}l C.-W. and Wong, KokSheik},
	booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:37:58 +0200},
	date-modified = {2022-10-23 17:37:58 +0200},
	doi = {10.1145/3477495.3531877},
	isbn = {9781450387323},
	keywords = {document classification, joint learning, mutual transfer, causal debiasing, topic modeling},
	location = {Madrid, Spain},
	numpages = {6},
	pages = {2456--2461},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '22},
	title = {DeSCoVeR: Debiased Semantic Context Prior for Venue Recommendation},
	url = {https://doi.org/10.1145/3477495.3531877},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1145/3477495.3531877}}

@inproceedings{10.1145/3477495.3531812,
	abstract = {When searching the web for answers to health questions, people can make incorrect decisions that have a negative effect on their lives if the search results contain misinformation. To reduce health misinformation in search results, we need to be able to detect documents with correct answers and promote them over documents containing misinformation. Determining the correct answer has been a difficult hurdle to overcome for participants in the TREC Health Misinformation Track. In the 2021 track, automatic runs were not allowed to use the known answer to a topic's health question, and as a result, the top automatic run had a compatibility-difference score of 0.043 while the top manual run, which used the known answer, had a score of 0.259. The compatibility-difference measures the ability of methods to rank correct and credible documents before incorrect and non-credible documents. By using an existing set of health questions and their known answers, we show it is possible to learn which web hosts are trustworthy, from which we can predict the correct answers to the 2021 health questions with an accuracy of 76%. Using our predicted answers, we can promote documents that we predict contain this answer and achieve a compatibility-difference score of 0.129, which is a three-fold increase in performance over the best previous automatic method.},
	address = {New York, NY, USA},
	author = {Zhang, Dake and Vakili Tahami, Amir and Abualsaud, Mustafa and Smucker, Mark D.},
	booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:37:58 +0200},
	date-modified = {2022-10-23 17:37:58 +0200},
	doi = {10.1145/3477495.3531812},
	isbn = {9781450387323},
	keywords = {stance detection, web search, health misinformation},
	location = {Madrid, Spain},
	numpages = {6},
	pages = {2099--2104},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '22},
	title = {Learning Trustworthy Web Sources to Derive Correct Answers and Reduce Health Misinformation in Search},
	url = {https://doi.org/10.1145/3477495.3531812},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1145/3477495.3531812}}

@inproceedings{10.1145/3477495.3531817,
	abstract = {Dialogue topic segmentation is a challenging task in which dialogues are split into segments with pre-defined topics. Existing works on topic segmentation adopt a two-stage paradigm, including text segmentation and segment labeling. However, such methods tend to focus on the local context in segmentation, and the inter-segment dependency is not well captured. Besides, the ambiguity and labeling noise in dialogue segment bounds bring further challenges to existing models. In this work, we propose the Parallel Extraction Network with Neighbor Smoothing (PEN-NS) to address the above issues. Specifically, we propose the parallel extraction network to perform segment extractions, optimizing the bipartite matching cost of segments to capture inter-segment dependency. Furthermore, we propose neighbor smoothing to handle the segment-bound noise and ambiguity. Experiments on a dialogue-based and a document-based topic segmentation dataset show that PEN-NS outperforms state-the-of-art models significantly.},
	address = {New York, NY, USA},
	author = {Xia, Jinxiong and Liu, Cao and Chen, Jiansong and Li, Yuchen and Yang, Fan and Cai, Xunliang and Wan, Guanglu and Wang, Houfeng},
	booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:37:58 +0200},
	date-modified = {2022-10-23 17:37:58 +0200},
	doi = {10.1145/3477495.3531817},
	isbn = {9781450387323},
	keywords = {dialogue topic segmentation, neighbor smoothing., boundary ambiguity, parallel extraction, data noise},
	location = {Madrid, Spain},
	numpages = {6},
	pages = {2126--2131},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '22},
	title = {Dialogue Topic Segmentation via Parallel Extraction Network with Neighbor Smoothing},
	url = {https://doi.org/10.1145/3477495.3531817},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1145/3477495.3531817}}

@inproceedings{10.1145/3477495.3531784,
	abstract = {Previous studies about event-level sentiment analysis (SA) usually model the event as a topic, a category or target terms, while the structured arguments (e.g., subject, object, time and location) that have potential effects on the sentiment are not well studied. In this paper, we redefine the task as structured event-level SA and propose an End-to-End Event-level Sentiment Analysis (E3SA) approach to solve this issue. Specifically, we explicitly extract and model the event structure information for enhancing event-level SA. Extensive experiments demonstrate the great advantages of our proposed approach over the state-of-the-art methods. Noting the lack of the dataset, we also release a large-scale real-world dataset with event arguments and sentiment labelling for promoting more researches.},
	address = {New York, NY, USA},
	author = {Zhang, Qi and Zhou, Jie and Chen, Qin and Bai, Qingchun and He, Liang},
	booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:37:58 +0200},
	date-modified = {2022-10-23 17:37:58 +0200},
	doi = {10.1145/3477495.3531784},
	isbn = {9781450387323},
	keywords = {datasets, structured, event-level sentiment analysis},
	location = {Madrid, Spain},
	numpages = {6},
	pages = {1944--1949},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '22},
	title = {Enhancing Event-Level Sentiment Analysis with Structured Arguments},
	url = {https://doi.org/10.1145/3477495.3531784},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1145/3477495.3531784}}

@inproceedings{10.1145/3477495.3532084,
	abstract = {Community question answering (CQA) becomes increasingly prevalent in recent years, providing platforms for users with various backgrounds to obtain information and share knowledge. However, the redundancy and lengthiness issues of crowd-sourced answers limit the performance of answer selection, thus leading to difficulties in reading or even misunderstandings for community users. To solve these problems, we propose the dual graph question-answer attention networks (DGQAN) for answer selection task. Aims to fully understand the internal structure of the question and the corresponding answer, firstly, we construct a dual-CQA concept graph with graph convolution networks using the original question and answer text. Specifically, our CQA concept graph exploits the correlation information between question-answer pairs to construct two sub-graphs (QSubject-Answer and QBody-Answer), respectively. Further, a novel dual attention mechanism is incorporated to model both the internal and external semantic relations among questions and answers. More importantly, we conduct experiment to investigate the impact of each layer in the BERT model. The experimental results show that DGQAN model achieves state-of-the-art performance on three datasets (SemEval-2015, 2016, and 2017), outperforming all the baseline models.},
	address = {New York, NY, USA},
	author = {Yang, Haitian and Zhao, Xuan and Wang, Yan and Li, Min and Chen, Wei and Huang, Weiqing},
	booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:37:58 +0200},
	date-modified = {2022-10-23 17:37:58 +0200},
	doi = {10.1145/3477495.3532084},
	isbn = {9781450387323},
	keywords = {dual graph attention, community question answering, answer selection},
	location = {Madrid, Spain},
	numpages = {10},
	pages = {1230--1239},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '22},
	title = {DGQAN: Dual Graph Question-Answer Attention Networks for Answer Selection},
	url = {https://doi.org/10.1145/3477495.3532084},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1145/3477495.3532084}}

@inproceedings{10.1145/3404835.3463080,
	abstract = {We propose VADEC, a multi-task framework that exploits the correlation between the categorical and dimensional models of emotion representation for better subjectivity analysis. Focusing primarily on the effective detection of emotions from tweets, we jointly train multi-label emotion classification and multi-dimensional emotion regression, thereby utilizing the inter-relatedness between the tasks. Co-training especially helps in improving the performance of the classification task as we outperform the strongest baselines with 3.4%, 11%, and 3.9% gains in Jaccard Accuracy, Macro-F1, and Micro-F1 scores respectively on the AIT dataset [17]. We also achieve state-of-the-art results with 11.3% gains averaged over six different metrics on the SenWave dataset [27]. For the regression task, VADEC, when trained with SenWave, achieves 7.6% and 16.5% gains in Pearson Correlation scores over the current state-of-the-art on the EMOBANK dataset [5] for the Valence (V) and Dominance (D) affect dimensions respectively. We conclude our work with a case study on COVID-19 tweets posted by Indians that further helps in establishing the efficacy of our proposed solution.},
	address = {New York, NY, USA},
	author = {Mukherjee, Rajdeep and Naik, Atharva and Poddar, Sriyash and Dasgupta, Soham and Ganguly, Niloy},
	booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:37:32 +0200},
	date-modified = {2022-10-23 17:37:32 +0200},
	doi = {10.1145/3404835.3463080},
	isbn = {9781450380379},
	keywords = {multi-task learning, COVID, coarse-grained emotion analysis, twitter, fine-grained emotion analysis, valence-arousal-dominance},
	location = {Virtual Event, Canada},
	numpages = {5},
	pages = {2303--2307},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '21},
	title = {Understanding the Role of Affect Dimensions in Detecting Emotions from Tweets: A Multi-Task Approach},
	url = {https://doi.org/10.1145/3404835.3463080},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1145/3404835.3463080}}

@inproceedings{10.1145/3404835.3462975,
	abstract = {Understanding how knowledge is technically transferred across academic disciplines is very relevant for understanding and facilitating innovation. There are two challenges for this purpose, namely the semantic ambiguity and the asymmetric influence across disciplines. In this paper we investigate knowledge propagation and characterize semantic correlations for cross discipline paper recommendation. We adopt a generative model to represent a paper content as the probabilistic association with an existing hierarchically classified discipline to reduce the ambiguity of word semantics. The semantic correlation across disciplines is represented by an influence function, a correlation metric and a ranking mechanism. Then a user interest is represented as a probabilistic distribution over the target domain semantics and the correlated papers are recommended. Experimental results on real datasets show the effectiveness of our methods. We also discuss the intrinsic factors of results in an interpretable way. Compared with traditional word embedding based methods, our approach supports the evolution of domain semantics that accordingly lead to the update of semantic correlation. Another advantage of our approach is its flexibility and uniformity in supporting user interest specifications by either a list of papers or a query of key words, which is suited for practical scenarios.},
	address = {New York, NY, USA},
	author = {Xie, Yi and Sun, Yuqing and Bertino, Elisa},
	booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:37:32 +0200},
	date-modified = {2022-10-23 17:37:32 +0200},
	doi = {10.1145/3404835.3462975},
	isbn = {9781450380379},
	keywords = {academic paper, recommendation, semantic correlation},
	location = {Virtual Event, Canada},
	numpages = {10},
	pages = {706--715},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '21},
	title = {Learning Domain Semantics and Cross-Domain Correlations for Paper Recommendation},
	url = {https://doi.org/10.1145/3404835.3462975},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1145/3404835.3462975}}

@inproceedings{10.1145/3404835.3462938,
	abstract = {Twitter is currently a popular online social media platform which allows users to share their user-generated content. This publicly-generated user data is also crucial to healthcare technologies because the discovered patterns would hugely benefit them in several ways. One of the applications is in automatically discovering mental health problems, e.g., depression. Previous studies to automatically detect a depressed user on online social media have largely relied upon the user behaviour and their linguistic patterns including user's social interactions. The downside is that these models are trained on several irrelevant content which might not be crucial towards detecting a depressed user. Besides, these content have a negative impact on the overall efficiency and effectiveness of the model. To overcome the shortcomings in the existing automatic depression detection methods, we propose a novel computational framework for automatic depression detection that initially selects relevant content through a hybrid extractive and abstractive summarization strategy on the sequence of all user tweets leading to a more fine-grained and relevant content. The content then goes to our novel deep learning framework comprising of a unified learning machinery comprising of Convolutional Neural Network (CNN) coupled with attention-enhanced Gated Recurrent Units (GRU) models leading to better empirical performance than existing strong baselines.},
	address = {New York, NY, USA},
	author = {Zogan, Hamad and Razzak, Imran and Jameel, Shoaib and Xu, Guandong},
	booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:37:32 +0200},
	date-modified = {2022-10-23 17:37:32 +0200},
	doi = {10.1145/3404835.3462938},
	isbn = {9781450380379},
	keywords = {machine learning, deep learning, text summarization, social network, depression detection},
	location = {Virtual Event, Canada},
	numpages = {10},
	pages = {133--142},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '21},
	title = {DepressionNet: Learning Multi-Modalities with User Post Summarization for Depression Detection on Social Media},
	url = {https://doi.org/10.1145/3404835.3462938},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1145/3404835.3462938}}

@inproceedings{10.1145/3404835.3463100,
	abstract = {We propose AutoName, an unsupervised framework that extracts a name for a set of query entities from a large-scale text corpus. Entity-set naming is useful in many tasks related to natural language processing and information retrieval such as session-based and conversational information seeking. Previous studies mainly extract set names from knowledge bases which provide highly reliable entity relations, but suffer from limited coverage of entities and set names that represent broad semantic classes. To address these problems, AutoName generates hypernym-anchored candidate phrases via probing a pre-trained language model and the entities' context in documents. Phrases are then clustered to identify ones that describe common concepts among query entities. Finally, AutoName ranks refined phrases based on the co-occurrences of their words with query entities and the conceptual integrity of their respective clusters. We built a new benchmark dataset for this task, consisting of 130 entity sets with name labels. Experimental results show that AutoName generates coherent and meaningful set names and significantly outperforms all baselines.},
	address = {New York, NY, USA},
	author = {Huang, Zhiqi and Rahimi, Razieh and Yu, Puxuan and Shang, Jingbo and Allan, James},
	booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:37:32 +0200},
	date-modified = {2022-10-23 17:37:32 +0200},
	doi = {10.1145/3404835.3463100},
	isbn = {9781450380379},
	keywords = {conceptual clustering, entity set naming, language model probing},
	location = {Virtual Event, Canada},
	numpages = {5},
	pages = {2101--2105},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '21},
	title = {AutoName: A Corpus-Based Set Naming Framework},
	url = {https://doi.org/10.1145/3404835.3463100},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1145/3404835.3463100}}

@inproceedings{10.1145/3404835.3462798,
	abstract = {We present the IR Anthology, a corpus of information retrieval publications accessible via a metadata browser and a full-text search engine. Following the example of the well-known ACL Anthology, the IR Anthology serves as a hub for researchers interested in information retrieval. Our search engine ChatNoir indexes the publications' full texts, enabling a focused search and linking users to the respective publisher's site for personal access. Listing more than 40,000 publications at the time of writing, the IR Anthology can be freely accessed at https://IR.webis.de.},
	address = {New York, NY, USA},
	author = {Potthast, Martin and G\"{u}nther, Sebastian and Bevendorff, Janek and Bittner, Jan Philipp and Bondarenko, Alexander and Fr\"{o}be, Maik and Kahmann, Christian and Niekler, Andreas and V\"{o}lske, Michael and Stein, Benno and Hagen, Matthias},
	booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:37:32 +0200},
	date-modified = {2022-10-23 17:37:32 +0200},
	doi = {10.1145/3404835.3462798},
	isbn = {9781450380379},
	keywords = {bibliography, scientific literature analysis, scholarly search},
	location = {Virtual Event, Canada},
	numpages = {6},
	pages = {2550--2555},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '21},
	title = {The Information Retrieval Anthology},
	url = {https://doi.org/10.1145/3404835.3462798},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1145/3404835.3462798}}

@inproceedings{10.1145/3397271.3401168,
	abstract = {Document categorization, which aims to assign a topic label to each document, plays a fundamental role in a wide variety of applications. Despite the success of existing studies in conventional supervised document classification, they are less concerned with two real problems: (1)the presence of metadata: in many domains, text is accompanied by various additional information such as authors and tags. Such metadata serve as compelling topic indicators and should be leveraged into the categorization framework; (2)label scarcity: labeled training samples are expensive to obtain in some cases, where categorization needs to be performed using only a small set of annotated data. In recognition of these two challenges, we propose MetaCat, a minimally supervised framework to categorize text with metadata. Specifically, we develop a generative process describing the relationships between words, documents, labels, and metadata. Guided by the generative model, we embed text and metadata into the same semantic space to encode heterogeneous signals. Then, based on the same generative process, we synthesize training samples to address the bottleneck of label scarcity. We conduct a thorough evaluation on a wide range of datasets. Experimental results prove the effectiveness of MetaCat over many competitive baselines.},
	address = {New York, NY, USA},
	author = {Zhang, Yu and Meng, Yu and Huang, Jiaxin and Xu, Frank F. and Wang, Xuan and Han, Jiawei},
	booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:37:04 +0200},
	date-modified = {2022-10-23 17:37:04 +0200},
	doi = {10.1145/3397271.3401168},
	isbn = {9781450380164},
	keywords = {weak supervision, text classification, metadata},
	location = {Virtual Event, China},
	numpages = {10},
	pages = {1231--1240},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '20},
	title = {Minimally Supervised Categorization of Text with Metadata},
	url = {https://doi.org/10.1145/3397271.3401168},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1145/3397271.3401168}}

@inproceedings{10.1145/3397271.3401179,
	abstract = {Aspect-based sentiment analysis is a substantial step towards text understanding which benefits numerous applications. Since most existing algorithms require a large amount of labeled data or substantial external language resources, applying them on a new domain or a new language is usually expensive and time-consuming. We aim to build an aspect-based sentiment analysis model from an unlabeled corpus with minimal guidance from users, i.e., only a small set of seed words for each aspect class and each sentiment class. We employ an autoencoder structure with attention to learn two dictionary matrices for aspect and sentiment respectively where each row of the dictionary serves as an embedding vector for an aspect or a sentiment class. We propose to utilize the user-given seed words to regularize the dictionary learning. In addition, we improve the model by joining the aspect and sentiment encoder in the reconstruction of sentiment in sentences. The joint structure enables sentiment embeddings in the dictionary to be tuned towards the aspect-specific sentiment words for each aspect, which benefits the classification performance. We conduct experiments on two real data sets to verify the effectiveness of our models.},
	address = {New York, NY, USA},
	author = {Zhuang, Honglei and Guo, Fang and Zhang, Chao and Liu, Liyuan and Han, Jiawei},
	booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:37:04 +0200},
	date-modified = {2022-10-23 17:37:04 +0200},
	doi = {10.1145/3397271.3401179},
	isbn = {9781450380164},
	keywords = {aspect-based sentiment analysis, autoencoder, weakly-supervised},
	location = {Virtual Event, China},
	numpages = {10},
	pages = {1241--1250},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '20},
	title = {Joint Aspect-Sentiment Analysis with Minimal User Guidance},
	url = {https://doi.org/10.1145/3397271.3401179},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1145/3397271.3401179}}

@inproceedings{10.1145/3397271.3401185,
	abstract = {Topic modelling is a popular unsupervised method for identifying the underlying themes in document collections that has many applications in information retrieval. A topic is usually represented by a list of terms ranked by their probability but, since these can be difficult to interpret, various approaches have been developed to assign descriptive labels to topics. Previous work on the automatic assignment of labels to topics has relied on a two-stage approach: (1) candidate labels are retrieved from a large pool (e.g. Wikipedia article titles); and then (2) re-ranked based on their semantic similarity to the topic terms. However, these extractive approaches can only assign candidate labels from a restricted set that may not include any suitable ones. This paper proposes using a sequence-to-sequence neural-based approach to generate labels that does not suffer from this limitation. The model is trained over a new large synthetic dataset created using distant supervision. The method is evaluated by comparing the labels it generates to ones rated by humans.},
	address = {New York, NY, USA},
	author = {Alokaili, Areej and Aletras, Nikolaos and Stevenson, Mark},
	booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:37:04 +0200},
	date-modified = {2022-10-23 17:37:04 +0200},
	doi = {10.1145/3397271.3401185},
	isbn = {9781450380164},
	keywords = {topic representation, neural network, topic modeling},
	location = {Virtual Event, China},
	numpages = {4},
	pages = {1965--1968},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '20},
	title = {Automatic Generation of Topic Labels},
	url = {https://doi.org/10.1145/3397271.3401185},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1145/3397271.3401185}}

@inproceedings{10.1145/3397271.3401269,
	abstract = {Manually extracting relevant aspects and opinions from large volumes of user-generated text is a time-consuming process. Summaries, on the other hand, help readers with limited time budgets to quickly consume the key ideas from the data. State-of-the-art approaches for multi-document summarization, however, do not consider user preferences while generating summaries. In this work, we argue the need and propose a solution for generating personalized aspect-based opinion summaries from large collections of online tourist reviews. We let our readers decide and control several attributes of the summary such as the length and specific aspects of interest among others. Specifically, we take an unsupervised approach to extract coherent aspects from tourist reviews posted onTripAdvisor. We then propose an Integer Linear Programming (ILP) based extractive technique to select an informative subset of opinions around the identified aspects while respecting the user-specified values for various control parameters. Finally, we evaluate and compare our summaries using crowdsourcing and ROUGE-based metrics and obtain competitive results.},
	address = {New York, NY, USA},
	author = {Mukherjee, Rajdeep and Peruri, Hari Chandana and Vishnu, Uppada and Goyal, Pawan and Bhattacharya, Sourangshu and Ganguly, Niloy},
	booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:37:04 +0200},
	date-modified = {2022-10-23 17:37:04 +0200},
	doi = {10.1145/3397271.3401269},
	isbn = {9781450380164},
	keywords = {personalization, controllable summarization, aspect-based opinion mining, tourism, unsupervised extractive opinion summarization},
	location = {Virtual Event, China},
	numpages = {4},
	pages = {1825--1828},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '20},
	title = {Read What You Need: Controllable Aspect-Based Opinion Summarization of Tourist Reviews},
	url = {https://doi.org/10.1145/3397271.3401269},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1145/3397271.3401269}}

@inproceedings{10.1145/3397271.3401128,
	abstract = {Many sellers on e-commerce platforms offer buyers product bundles, which package together two or more different items. The identification of such bundles is a necessary step to support a variety of related services, from recommendation to dynamic pricing. In this work, we present a comprehensive study of bundle identification on a large e-commerce website. Our analysis of bundle compared to non-bundle listed items reveals several key differentiating characteristics, spanning the listing's title, image, and attributes. Following, we experiment with a multi-modal classifier, which takes advantage of these characteristics as features. Our analysis also shows that a bundle indicator input by sellers tends to be highly noisy and carries only a weak signal. The bundle identification task therefore faces the challenge of having a small set of manually-labeled clean examples and a larger set of noisy-labeled examples, in conjunction with class imbalance due to the relative scarcity of bundles.Our experiments with basic supervised classifiers, using the manually-labeled and/or the noisy-labeled data for training, demonstrates only moderate performance. We therefore turn to a semisupervised approach and propose GREED, a self-training ensemblebased algorithm with a greedy model selection. Our evaluation over two different meta-categories shows a superior performance of semi-supervised approaches for the bundle identification task, with GREED outperforming several semi-supervised alternatives. The combination of textual, image, and some metadata features is shown to yield the best performance, reaching an AUC of 0.89 and 0.92 for the two meta-categories, respectively},
	address = {New York, NY, USA},
	author = {Tzaban, Hen and Guy, Ido and Greenstein-Messica, Asnat and Dagan, Arnon and Rokach, Lior and Shapira, Bracha},
	booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:37:04 +0200},
	date-modified = {2022-10-23 17:37:04 +0200},
	doi = {10.1145/3397271.3401128},
	isbn = {9781450380164},
	keywords = {product bundling, semi-supervised learning, self-training, electronic commerce, ensemble learning},
	location = {Virtual Event, China},
	numpages = {10},
	pages = {791--800},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '20},
	title = {Product Bundle Identification Using Semi-Supervised Learning},
	url = {https://doi.org/10.1145/3397271.3401128},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1145/3397271.3401128}}

@inproceedings{10.1145/3397271.3401150,
	abstract = {In this work, we aim to investigate the practical task of flexible fashion search with attribute manipulation, where users can retrieve the target fashion items by replacing the unwanted attributes of an available query image with the desired ones (e.g., changing the collar attribute from v-neck to round). Although several pioneer efforts have been dedicated to fulfilling the task, they mainly ignore the potential of generative models in enhancing the visual understanding of target fashion items. To this end, we propose an end-to-end generative attribute manipulation scheme, which consists of a generator and a discriminator. The generator works on producing the prototype image that meets the user's requirement of attribute manipulation over the query image with the regularization of visual-semantic consistency and pixel-wise consistency. Besides, the discriminator aims to jointly fulfill the semantic learning towards correct attribute manipulation and adversarial metric learning for fashion search. Pertaining to the adversarial metric learning, we provide two general paradigms: the pair-based scheme and the triplet-based scheme, where the fake generated prototype images that closely resemble the ground truth images of target items are incorporated as hard negative samples to boost the model performance. Extensive experiments on two real-world datasets verify the effectiveness of our scheme.},
	address = {New York, NY, USA},
	author = {Yang, Xin and Song, Xuemeng and Han, Xianjing and Wen, Haokun and Nie, Jie and Nie, Liqiang},
	booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:37:04 +0200},
	date-modified = {2022-10-23 17:37:04 +0200},
	doi = {10.1145/3397271.3401150},
	isbn = {9781450380164},
	keywords = {attribute manipulation, fashion search, deep metric learning, generative adversarial networks},
	location = {Virtual Event, China},
	numpages = {10},
	pages = {941--950},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '20},
	title = {Generative Attribute Manipulation Scheme for Flexible Fashion Search},
	url = {https://doi.org/10.1145/3397271.3401150},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1145/3397271.3401150}}

@inproceedings{10.1145/3397271.3401047,
	abstract = {Recent years have witnessed a growing trend of fashion compatibility modeling, which scores the matching degree of the given outfit and then provides people with some dressing advice. Existing methods have primarily solved this problem by analyzing the discrete interaction among multiple complementary items. However, the fashion items would present certain occlusion and deformation when they are worn on the body. Therefore, the discrete item interaction cannot capture the fashion compatibility in a combined manner due to the neglect of a crucial factor: the overall try-on appearance. In light of this, we propose a multi-modal try-on-guided compatibility modeling scheme to jointly characterize the discrete interaction and try-on appearance of the outfit. In particular, we first propose a multi-modal try-on template generator to automatically generate a try-on template from the visual and textual information of the outfit, depicting the overall look of its composing fashion items. Then, we introduce a new compatibility modeling scheme which integrates the outfit try-on appearance into the traditional discrete item interaction modeling. To fulfill the proposal, we construct a large-scale real-world dataset from SSENSE, named FOTOS, consisting of 11,000 well-matched outfits and their corresponding realistic try-on images. Extensive experiments have demonstrated its superiority to state-of-the-arts.},
	address = {New York, NY, USA},
	author = {Dong, Xue and Wu, Jianlong and Song, Xuemeng and Dai, Hongjun and Nie, Liqiang},
	booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:37:04 +0200},
	date-modified = {2022-10-23 17:37:04 +0200},
	doi = {10.1145/3397271.3401047},
	isbn = {9781450380164},
	keywords = {fashion analysis, compatibility modeling, try-on-guided scheme},
	location = {Virtual Event, China},
	numpages = {10},
	pages = {771--780},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '20},
	title = {Fashion Compatibility Modeling through a Multi-Modal Try-on-Guided Scheme},
	url = {https://doi.org/10.1145/3397271.3401047},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1145/3397271.3401047}}

@inproceedings{10.1145/3331184.3331287,
	abstract = {Social emotion classification is to estimate the distribution of readers' emotion evoked by an article. In this paper, we design a new neural network model by encoding sentence syntactic dependency and document topical information into the document representation. We first use a dependency embedded recursive neural network to learn syntactic features for each sentence, and then use a gated recurrent unit to transform the sentences' vectors into a document vector. We also use a multi-layer perceptron to encode the topical information of a document into a topic vector. Finally, a gate layer is used to compose the document representation from the gated summation of the document vector and the topic vector. Experiment results on two public datasets indicate that our proposed model outperforms the state-of-the-art methods in terms of better average Pearson correlation coefficient and MicroF1 performance.},
	address = {New York, NY, USA},
	author = {Wang, Chang and Wang, Bang and Xiang, Wei and Xu, Minghua},
	booktitle = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:36:07 +0200},
	date-modified = {2022-10-23 17:36:07 +0200},
	doi = {10.1145/3331184.3331287},
	isbn = {9781450361729},
	keywords = {dependency embedding, topic model, social emotion classification, recursive neural network},
	location = {Paris, France},
	numpages = {4},
	pages = {881--884},
	publisher = {Association for Computing Machinery},
	series = {SIGIR'19},
	title = {Encoding Syntactic Dependency and Topical Information for Social Emotion Classification},
	url = {https://doi.org/10.1145/3331184.3331287},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1145/3331184.3331287}}

@inproceedings{10.1145/3331184.3331367,
	abstract = {Targeted stance detection aims to classify the attitude of an opinionated text towards a pre-defined target. Previous methods mainly focus on in-target setting that models are trained and tested using data specific to the same target. In practical cases, the target we concern may have few or no labeled data, which restrains us from training a target-specific model. In this paper we study the problem of cross-target stance detection, utilizing labeled data of a source target to learn models that can be adapted to a destination target. To this end, we propose an effective method, the core intuition of which is to leverage shared latent topics between two targets as transferable knowledge to facilitate model adaptation. Our method acquires topic knowledge with neural variational inference, and further adopts adversarial training that encourages the model to learn target-invariant representations. Experimental results verify that our proposed method is superior to the state-of-the-art methods.},
	address = {New York, NY, USA},
	author = {Wei, Penghui and Mao, Wenji},
	booktitle = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:36:07 +0200},
	date-modified = {2022-10-23 17:36:07 +0200},
	doi = {10.1145/3331184.3331367},
	isbn = {9781450361729},
	keywords = {cross-target stance detection, variational transfer network, transferable topics},
	location = {Paris, France},
	numpages = {4},
	pages = {1173--1176},
	publisher = {Association for Computing Machinery},
	series = {SIGIR'19},
	title = {Modeling Transferable Topics for Cross-Target Stance Detection},
	url = {https://doi.org/10.1145/3331184.3331367},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1145/3331184.3331367}}

@inproceedings{10.1145/3331184.3331228,
	abstract = {Community-based question answering (CQA), which provides a platform for people with diverse backgrounds to share information and knowledge, has become increasingly popular. With the accumulation of site data, methods to detect duplicate questions in CQA sites have attracted considerable attention. Existing methods typically use only questions to complete the task. However, the paired answers may also provide valuable information. In this paper, we propose an answer information- enhanced adaptive multi-attention network (AMAN) to perform this task. AMAN takes full advantage of the semantic information in the paired answers while alleviating the noise problem caused by adding the answers. To evaluate the proposed method, we use a CQADupStack set and the Quora question-pair dataset expanded with paired answers. Experimental results demonstrate that the proposed model can achieve state-of-the-art performance on the above two data sets.},
	address = {New York, NY, USA},
	author = {Liang, Di and Zhang, Fubao and Zhang, Weidong and Zhang, Qi and Fu, Jinlan and Peng, Minlong and Gui, Tao and Huang, Xuanjing},
	booktitle = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:36:07 +0200},
	date-modified = {2022-10-23 17:36:07 +0200},
	doi = {10.1145/3331184.3331228},
	isbn = {9781450361729},
	keywords = {duplicate question detection, community-based question answering, adaptive multi-attention},
	location = {Paris, France},
	numpages = {10},
	pages = {95--104},
	publisher = {Association for Computing Machinery},
	series = {SIGIR'19},
	title = {Adaptive Multi-Attention Network Incorporating Answer Information for Duplicate Question Detection},
	url = {https://doi.org/10.1145/3331184.3331228},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1145/3331184.3331228}}

@inproceedings{10.1145/3331184.3338062,
	abstract = {We improve the measurement accuracy of retrieval system performance by better modeling the noise present in test collection scores. Our technique draws its inspiration from two approaches: one, which exploits the variable measurement accuracy of topics; the other, which randomly splits document collections into shards. We describe and theoretically analyze an ANOVA model able to capture the effects of topics, systems, and document shards as well as their interactions. Using multiple TREC collections, we empirically confirm theoretical results in terms of improved estimation accuracy and robustness of found significant differences. The improvements compared to widely used test collection measurement techniques are substantial. We speculate that our technique works because we do not assume that the topics of a test collection measure performance equally.},
	address = {New York, NY, USA},
	author = {Ferro, Nicola and Sanderson, Mark},
	booktitle = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:36:07 +0200},
	date-modified = {2022-10-23 17:36:07 +0200},
	doi = {10.1145/3331184.3338062},
	isbn = {9781450361729},
	keywords = {anova, multiple comparison, effectiveness model},
	location = {Paris, France},
	numpages = {10},
	pages = {805--814},
	publisher = {Association for Computing Machinery},
	series = {SIGIR'19},
	title = {Improving the Accuracy of System Performance Estimation by Using Shards},
	url = {https://doi.org/10.1145/3331184.3338062},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1145/3331184.3338062}}

@inproceedings{10.1145/3331184.3331216,
	abstract = {User reviews contain rich semantics towards the preference of users to features of items. Recently, many deep learning based solutions have been proposed by exploiting reviews for recommendation. The attention mechanism is mainly adopted in these works to identify words or aspects that are important for rating prediction. However, it is still hard to understand whether a user likes or dislikes an aspect of an item according to what viewpoint the user holds and to what extent, without examining the review details. Here, we consider a pair of a viewpoint held by a user and an aspect of an item as a logic unit. Reasoning a rating behavior by discovering the informative logic units from the reviews and resolving their corresponding sentiments could enable a better rating prediction with explanation.To this end, in this paper, we propose a capsule network based model for rating prediction with user reviews, named CARP. For each user-item pair, CARP is devised to extract the informative logic units from the reviews and infer their corresponding sentiments. The model firstly extracts the viewpoints and aspects from the user and item review documents respectively. Then we derive the representation of each logic unit based on its constituent viewpoint and aspect. A sentiment capsule architecture with a novel Routing by Bi-Agreement mechanism is proposed to identify the informative logic unit and the sentiment based representations in user-item level for rating prediction. Extensive experiments are conducted over seven real-world datasets with diverse characteristics. Our results demonstrate that the proposed CARP obtains substantial performance gain over recently proposed state-of-the-art models in terms of prediction accuracy. Further analysis shows that our model can successfully discover the interpretable reasons at a finer level of granularity.},
	address = {New York, NY, USA},
	author = {Li, Chenliang and Quan, Cong and Peng, Li and Qi, Yunwei and Deng, Yuming and Wu, Libing},
	booktitle = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:36:07 +0200},
	date-modified = {2022-10-23 17:36:07 +0200},
	doi = {10.1145/3331184.3331216},
	isbn = {9781450361729},
	keywords = {deep learning, user reviews, recommender system},
	location = {Paris, France},
	numpages = {10},
	pages = {275--284},
	publisher = {Association for Computing Machinery},
	series = {SIGIR'19},
	title = {A Capsule Network for Recommendation and Explaining What You Like and Dislike},
	url = {https://doi.org/10.1145/3331184.3331216},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1145/3331184.3331216}}

@inproceedings{10.1145/3209978.3210046,
	abstract = {Email continues to be one of the most important means of online communication. People spend a significant amount of time sending, reading, searching and responding to email in order to manage tasks, exchange information, etc. In this paper, we focus on information exchange over enterprise email in the form of questions and answers. We study a large scale publicly available email dataset to characterize information exchange via questions and answers in enterprise email. We augment our analysis with a survey to gain insights on the types of questions exchanged, when and how do people get back to them and whether this behavior is adequately supported by existing email management and search functionality. We leverage this understanding to define the task of extracting question/answer pairs from threaded email conversations. We propose a neural network based approach that matches the question to the answer considering comparisons at different levels of granularity. We also show that we can improve the performance by leveraging external data of question and answer pairs. We test our approach using a manually labeled email data collected using a crowd-sourcing annotation study. Our findings have implications for designing email clients and intelligent agents that support question answering and information lookup in email.},
	address = {New York, NY, USA},
	author = {Yang, Xiao and Awadallah, Ahmed Hassan and Khabsa, Madian and Wang, Wei and Wang, Miaosen},
	booktitle = {The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval},
	date-added = {2022-10-23 17:34:43 +0200},
	date-modified = {2022-10-23 17:34:43 +0200},
	doi = {10.1145/3209978.3210046},
	isbn = {9781450356572},
	keywords = {question answering, email, information retrieval},
	location = {Ann Arbor, MI, USA},
	numpages = {10},
	pages = {345--354},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '18},
	title = {Characterizing and Supporting Question Answering in Human-to-Human Communication},
	url = {https://doi.org/10.1145/3209978.3210046},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1145/3209978.3210046}}

@inproceedings{10.1145/3209978.3209984,
	abstract = {Sections are the building blocks of Wikipedia articles. They enhance readability and can be used as a structured entry point for creating and expanding articles. Structuring a new or already existing Wikipedia article with sections is a hard task for humans, especially for newcomers or less experienced editors, as it requires significant knowledge about how a well-written article looks for each possible topic. Inspired by this need, the present paper defines the problem of section recommendation for Wikipedia articles and proposes several approaches for tackling it. Our systems can help editors by recommending what sections to add to already existing or newly created Wikipedia articles. Our basic paradigm is to generate recommendations by sourcing sections from articles that are similar to the input article. We explore several ways of defining similarity for this purpose (based on topic modeling, collaborative filtering, and Wikipedia's category system). We use both automatic and human evaluation approaches for assessing the performance of our recommendation system, concluding that the category-based approach works best, achieving precision@10 of about 80% in the human evaluation.},
	address = {New York, NY, USA},
	author = {Piccardi, Tiziano and Catasta, Michele and Zia, Leila and West, Robert},
	booktitle = {The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval},
	date-added = {2022-10-23 17:34:43 +0200},
	date-modified = {2022-10-23 17:34:43 +0200},
	doi = {10.1145/3209978.3209984},
	isbn = {9781450356572},
	keywords = {recommender system, category network, wikipedia, sections},
	location = {Ann Arbor, MI, USA},
	numpages = {10},
	pages = {665--674},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '18},
	title = {Structuring Wikipedia Articles with Section Recommendations},
	url = {https://doi.org/10.1145/3209978.3209984},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1145/3209978.3209984}}

@inproceedings{10.1145/3209978.3209985,
	abstract = {Learning to rank has been intensively studied and widely applied in information retrieval. Typically, a global ranking function is learned from a set of labeled data, which can achieve good performance on average but may be suboptimal for individual queries by ignoring the fact that relevant documents for different queries may have different distributions in the feature space. Inspired by the idea of pseudo relevance feedback where top ranked documents, which we refer as the local ranking context, can provide important information about the query's characteristics, we propose to use the inherent feature distributions of the top results to learn a Deep Listwise Context Model that helps us fine tune the initial ranked list. Specifically, we employ a recurrent neural network to sequentially encode the top results using their feature vectors, learn a local context model and use it to re-rank the top results. There are three merits with our model: (1) Our model can capture the local ranking context based on the complex interactions between top results using a deep neural network; (2) Our model can be built upon existing learning-to-rank methods by directly using their extracted feature vectors; (3) Our model is trained with an attention-based loss function, which is more effective and efficient than many existing listwise methods. Experimental results show that the proposed model can significantly improve the state-of-the-art learning to rank methods on benchmark retrieval corpora.},
	address = {New York, NY, USA},
	author = {Ai, Qingyao and Bi, Keping and Guo, Jiafeng and Croft, W. Bruce},
	booktitle = {The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval},
	date-added = {2022-10-23 17:34:43 +0200},
	date-modified = {2022-10-23 17:34:43 +0200},
	doi = {10.1145/3209978.3209985},
	isbn = {9781450356572},
	keywords = {local ranking context, learning to rank, deep neural network},
	location = {Ann Arbor, MI, USA},
	numpages = {10},
	pages = {135--144},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '18},
	title = {Learning a Deep Listwise Context Model for Ranking Refinement},
	url = {https://doi.org/10.1145/3209978.3209985},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1145/3209978.3209985}}

@inproceedings{10.1145/3209978.3210054,
	abstract = {Online streaming services are prevalent. Major service providers, such as Netflix (for movies) and Spotify (for music), usually have a large customer base. More often than not, users may share an account. This has attracted increasing attention recently, as account sharing not only compromises the service provider's financial interests but also impairs the performance of recommendation systems and consequently the quality of service provided to the users. To address this issue, this paper focuses on the problem of user identification in shared accounts. Our goal is three-fold: (1) Given an account, along with its historical session logs, we identify a set of users who share such account; (2) Given a new session issued by an account, we find the corresponding user among the identified users of such account; (3) We aim to boost the performance of item recommendation by user identification. While the mapping between users and accounts is unknown, we propose an unsupervised learning-based framework, Session-based Heterogeneous graph Embedding for User Identification (SHE-UI), to differentiate and model the preferences of users in an account, and to group sessions by these users. In SHE-UI, a heterogeneous graph is constructed to represent items such as songs and their available metadata such as artists, genres, and albums. An item-based session embedding technique is proposed using a normalized random walk in the heterogeneous graph. Our experiments conducted on two large-scale music streaming datasets, Last.fm and KKBOX, show that SHE-UI not only accurately identifies users, but also significantly improves the performance of item recommendation over the state-of-the-art methods.},
	address = {New York, NY, USA},
	author = {Jiang, Jyun-Yu and Li, Cheng-Te and Chen, Yian and Wang, Wei},
	booktitle = {The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval},
	date-added = {2022-10-23 17:34:43 +0200},
	date-modified = {2022-10-23 17:34:43 +0200},
	doi = {10.1145/3209978.3210054},
	isbn = {9781450356572},
	keywords = {user session clustering, user identification, heterogeneous graph embedding, shared accounts, recommender systems},
	location = {Ann Arbor, MI, USA},
	numpages = {10},
	pages = {65--74},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '18},
	title = {Identifying Users behind Shared Accounts in Online Streaming Services},
	url = {https://doi.org/10.1145/3209978.3210054},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1145/3209978.3210054}}

@inproceedings{10.1145/3077136.3080772,
	abstract = {With the advancement of mobile computing technology and cloud-based streaming music service, user-centered music retrieval has become increasingly important. User-specific information has a fundamental impact on personal music preferences and interests. However, existing research pays little attention to the modeling and integration of user-specific information in music retrieval algorithms/models to facilitate music search. In this paper, we propose a novel model, named User-Information-Aware Music Interest Topic (UIA-MIT) model. The model is able to effectively capture the influence of user-specific information on music preferences, and further associate users' music preferences and search terms under the same latent space. Based on this model, a user information aware retrieval system is developed, which can search and re-rank the results based on age- and/or gender-specific music preferences. A comprehensive experimental study demonstrates that our methods can significantly improve the search accuracy over existing text-based music retrieval methods.},
	address = {New York, NY, USA},
	author = {Cheng, Zhiyong and Shen, Jialie and Nie, Liqiang and Chua, Tat-Seng and Kankanhalli, Mohan},
	booktitle = {Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:34:01 +0200},
	date-modified = {2022-10-23 17:34:01 +0200},
	doi = {10.1145/3077136.3080772},
	isbn = {9781450350228},
	keywords = {topic model, user demographic information, re-ranking, semantic music retrieval},
	location = {Shinjuku, Tokyo, Japan},
	numpages = {10},
	pages = {655--664},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '17},
	title = {Exploring User-Specific Information in Music Retrieval},
	url = {https://doi.org/10.1145/3077136.3080772},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3077136.3080772}}

@inproceedings{10.1145/3077136.3080781,
	abstract = {One important way for people to make their voice heard is to comment on the articles they have read online, such as news reports and each other's posts. The user-generated comments together with the commented documents form a unique correspondence structure. Properly modeling the dependency in such data is thus vital for one to obtain accurate insight of people's opinions and attention.In this work, we develop a Commented Correspondence Topic Model to model correspondence in commented text data. We focus on two levels of correspondence. First, to capture topic-level correspondence, we treat the topic assignments in commented documents as the prior to their comments' topic proportions. This captures the thematic dependency between commented documents and their comments. Second, to capture word-level correspondence, we utilize the Dirichlet compound multinomial distribution to model topics. This captures the word repetition patterns within the commented data. By integrating these two aspects, our model demonstrated encouraging performance in capturing the correspondence sturcture, which provides improved results in modeling user-generated content, spam comment detection, and sentence-based comment retrieval compared with state-of-the-art topic model solutions for correspondence modeling.},
	address = {New York, NY, USA},
	author = {Cai, Renqin and Wang, Chi and Wang, Hongning},
	booktitle = {Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:34:01 +0200},
	date-modified = {2022-10-23 17:34:01 +0200},
	doi = {10.1145/3077136.3080781},
	isbn = {9781450350228},
	keywords = {user comments, topic models, social media, text correspondence modeling},
	location = {Shinjuku, Tokyo, Japan},
	numpages = {10},
	pages = {365--374},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '17},
	title = {Accounting for the Correspondence in Commented Data},
	url = {https://doi.org/10.1145/3077136.3080781},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3077136.3080781}}

@inproceedings{10.1145/3077136.3084138,
	abstract = {Tweets summarization aims to find a group of representative tweets for a specific topic. In recent times, there have been several research efforts toward devising a variety of techniques to summarize tweets in Twitter. However, these techniques are either not personal (i.e., consider only tweets in the timeline of a specific user) or are too expensive to be realized on a mobile device. Given that 80% of active Twitter users access the site on mobile devices, in this demonstration we present a lightweight, personalized, on-demand, topic modeling-based tweets summarization engine called TOTEM, designed for such devices. Specifically, TOTEM summarizes most recent tweets on a user's timeline and enables her to visualize and navigate representative topics and associated tweets in a user-friendly tap-and-swipe manner.},
	address = {New York, NY, USA},
	author = {Chin, Jin Yao and Bhowmick, Sourav S. and Jatowt, Adam},
	booktitle = {Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:34:01 +0200},
	date-modified = {2022-10-23 17:34:01 +0200},
	doi = {10.1145/3077136.3084138},
	isbn = {9781450350228},
	keywords = {mobile device, tweets, personal, topic modeling, summarization},
	location = {Shinjuku, Tokyo, Japan},
	numpages = {4},
	pages = {1305--1308},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '17},
	title = {TOTEM: Personal Tweets Summarization on Mobile Devices},
	url = {https://doi.org/10.1145/3077136.3084138},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3077136.3084138}}

@inproceedings{10.1145/3077136.3080703,
	abstract = {We propose a method to clarify the evolution of users' information needs related to a user's interests and actions based upon life events such as "childbirth." First, we extract topic transitions using dynamic topic models from blogs posted by users who have experienced life events. Next, we select the topics by computing the differences in topic probabilities before and after the life event. We evaluated our method based on three life events: "childbirth," "finding employment," and "marriage." Our method selected life event-relevant topics such as "child development," "working life," and "wedding ceremony." We found mothers' information needs such as "how to introduce baby food," employees' information needs such as "preparing an induction programme," and couples' information needs such as "wedding reception planning" in each topic.},
	address = {New York, NY, USA},
	author = {Takeda, Naoto and Seki, Yohei and Morishita, Mimpei and Inagaki, Yoichi},
	booktitle = {Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2022-10-23 17:34:01 +0200},
	date-modified = {2022-10-23 17:34:01 +0200},
	doi = {10.1145/3077136.3080703},
	isbn = {9781450350228},
	keywords = {dtms (dynamic topic models), life event, information needs},
	location = {Shinjuku, Tokyo, Japan},
	numpages = {4},
	pages = {1009--1012},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '17},
	title = {Evolution of Information Needs Based on Life Event Experiences with Topic Transition},
	url = {https://doi.org/10.1145/3077136.3080703},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3077136.3080703}}

@article{2022_Chauhan,
	abstract = {We are not able to deal with a mammoth text corpus without summarizing them into a relatively small subset. A computational tool is extremely needed to understand such a gigantic pool of text. Probabilistic Topic Modeling discovers and explains the enormous collection of documents by reducing them in a topical subspace. In this work, we study the background and advancement of topic modeling techniques. We first introduce the preliminaries of the topic modeling techniques and review its extensions and variations, such as topic modeling over various domains, hierarchical topic modeling, word embedded topic models, and topic models in multilingual perspectives. Besides, the research work for topic modeling in a distributed environment, topic visualization approaches also have been explored. We also covered the implementation and evaluation techniques for topic models in brief. Comparison matrices have been shown over the experimental results of the various categories of topic modeling. Diverse technical challenges and future directions have been discussed.},
	address = {New York, NY, USA},
	articleno = {145},
	author = {Chauhan, Uttam and Shah, Apurva},
	date-added = {2022-10-22 10:47:42 +0200},
	date-modified = {2022-10-22 10:48:03 +0200},
	doi = {10.1145/3462478},
	issn = {0360-0300},
	issue_date = {September 2022},
	journal = {ACM Comput. Surv.},
	keywords = {probabilistic model, statistical inference, Topic modeling, gibbs sampling, latent dirichlet allocation},
	month = {sep},
	number = {7},
	numpages = {35},
	publisher = {Association for Computing Machinery},
	title = {Topic Modeling Using Latent Dirichlet Allocation: A Survey},
	url = {https://doi.org/10.1145/3462478},
	volume = {54},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1145/3462478}}

@article{2021_Silva,
	abstract = {Topic modeling using models such as Latent Dirichlet Allocation (LDA) is a text mining technique to extract human-readable semantic ``topics''(i.e., word clusters) from a corpus of textual documents. In software engineering, topic modeling has been used to analyze textual data in empirical studies (e.g., to find out what developers talk about online), but also to build new techniques to support software engineering tasks (e.g., to support source code comprehension). Topic modeling needs to be applied carefully (e.g., depending on the type of textual data analyzed and modeling parameters). Our study aims at describing how topic modeling has been applied in software engineering research with a focus on four aspects: (1) which topic models and modeling techniques have been applied, (2) which textual inputs have been used for topic modeling, (3) how textual data was ``prepared''(i.e., pre-processed) for topic modeling, and (4) how generated topics (i.e., word clusters) were named to give them a human-understandable meaning. We analyzed topic modeling as applied in 111 papers from ten highly-ranked software engineering venues (five journals and five conferences) published between 2009 and 2020. We found that (1) LDA and LDA-based techniques are the most frequent topic modeling techniques, (2) developer communication and bug reports have been modelled most, (3) data pre-processing and modeling parameters vary quite a bit and are often vaguely reported, and (4) manual topic naming (such as deducting names based on frequent words in a topic) is common.},
	author = {Silva, Camila Costa and Galster, Matthias and Gilson, Fabian},
	date = {2021/09/06},
	date-added = {2022-10-22 10:47:01 +0200},
	date-modified = {2022-10-22 10:47:12 +0200},
	doi = {10.1007/s10664-021-10026-0},
	id = {Silva2021},
	isbn = {1573-7616},
	journal = {Empirical Software Engineering},
	number = {6},
	pages = {120},
	title = {Topic modeling in software engineering research},
	url = {https://doi.org/10.1007/s10664-021-10026-0},
	volume = {26},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1007/s10664-021-10026-0}}

@article{2021_Churchill,
	abstract = {Topic models have been applied to everything from books to newspapers to social media posts in an effort to identify the most prevalent themes of a text corpus. We provide an in-depth analysis of unsupervised topic models from their inception to today. We trace the origins of different types of contemporary topic models, beginning in the 1990s, and we compare their proposed algorithms, as well as their different evaluation approaches. Throughout, we also describe settings in which topic models have worked well and areas where new research is needed, setting the stage for the next generation of topic models.},
	address = {New York, NY, USA},
	author = {Churchill, Rob and Singh, Lisa},
	date-added = {2022-10-22 10:46:24 +0200},
	date-modified = {2022-10-22 10:46:39 +0200},
	doi = {10.1145/3507900},
	issn = {0360-0300},
	journal = {ACM Comput. Surv.},
	keywords = {temporal topic modeling, topic modeling, social media, online topic modeling},
	month = {dec},
	note = {Just Accepted},
	publisher = {Association for Computing Machinery},
	title = {The Evolution of Topic Modeling},
	url = {https://doi.org/10.1145/3507900},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1145/3507900}}

@inproceedings{2019_Xia,
	author = {Xia, Linzhong and Luo, Dean and Zhang, Chunxiao and Wu, Zhou},
	booktitle = {2019 2nd International Conference on Artificial Intelligence and Big Data (ICAIBD)},
	date-added = {2022-10-22 10:45:35 +0200},
	date-modified = {2022-10-22 10:45:50 +0200},
	doi = {10.1109/ICAIBD.2019.8836970},
	pages = {244-250},
	title = {A Survey of Topic Models in Text Classification},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1109/ICAIBD.2019.8836970}}

@article{2019_Likhitha,
	author = {Likhitha, S and Harish, B S and Keerthi Kumar, H M},
	date-added = {2022-10-22 10:42:56 +0200},
	date-modified = {2022-10-22 10:43:15 +0200},
	doi = {10.5120/ijca2019919265},
	journal = {International Journal of Computer Applications},
	month = {08},
	pages = {975-8887},
	title = {A Detailed Survey on Topic Modeling for Document and Short Text Data},
	volume = {178},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.5120/ijca2019919265}}

@article{2019_Jipeng,
	author = {Jipeng, Qiang and Zhenyu, Qian and Yun, Li and Yunhao, Yuan and Xindong, Wu},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-10-22 10:42:17 +0200},
	date-modified = {2022-10-22 10:42:35 +0200},
	doi = {10.48550/ARXIV.1904.07695},
	keywords = {Information Retrieval (cs.IR), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Short Text Topic Modeling Techniques, Applications, and Performance: A Survey},
	url = {https://arxiv.org/abs/1904.07695},
	year = {2019},
	bdsk-url-1 = {https://arxiv.org/abs/1904.07695},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1904.07695}}

@article{2016_Chen,
	abstract = {Researchers in software engineering have attempted to improve software development by mining and analyzing software repositories. Since the majority of the software engineering data is unstructured, researchers have applied Information Retrieval (IR) techniques to help software development. The recent advances of IR, especially statistical topic models, have helped make sense of unstructured data in software repositories even more. However, even though there are hundreds of studies on applying topic models to software repositories, there is no study that shows how the models are used in the software engineering research community, and which software engineering tasks are being supported through topic models. Moreover, since the performance of these topic models is directly related to the model parameters and usage, knowing how researchers use the topic models may also help future studies make optimal use of such models. Thus, we surveyed 167 articles from the software engineering literature that make use of topic models. We find that i) most studies centre around a limited number of software engineering tasks; ii) most studies use only basic topic models; iii) and researchers usually treat topic models as black boxes without fully exploring their underlying assumptions and parameter values. Our paper provides a starting point for new researchers who are interested in using topic models, and may help new researchers and practitioners determine how to best apply topic models to a particular software engineering task.},
	author = {Chen, Tse-Hsun and Thomas, Stephen W. and Hassan, Ahmed E.},
	date = {2016/10/01},
	date-added = {2022-10-22 10:41:36 +0200},
	date-modified = {2022-10-22 10:41:49 +0200},
	doi = {10.1007/s10664-015-9402-8},
	id = {Chen2016},
	isbn = {1573-7616},
	journal = {Empirical Software Engineering},
	number = {5},
	pages = {1843--1919},
	title = {A survey on the use of topic models when mining software repositories},
	url = {https://doi.org/10.1007/s10664-015-9402-8},
	volume = {21},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.1007/s10664-015-9402-8}}

@article{2022_Kitchenham,
	author = {Kitchenham, Barbara Ann and Madeyski, Lech and Budgen, David},
	date-added = {2022-10-22 10:39:57 +0200},
	date-modified = {2022-10-22 10:40:14 +0200},
	doi = {10.1109/TSE.2022.3174092},
	journal = {IEEE Transactions on Software Engineering},
	pages = {1-1},
	title = {SEGRESS: Software Engineering Guidelines for REporting Secondary Studies},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1109/TSE.2022.3174092}}

@article{2015_Petersen,
	abstract = {Context
Systematic mapping studies are used to structure a research area, while systematic reviews are focused on gathering and synthesizing evidence. The most recent guidelines for systematic mapping are from 2008. Since that time, many suggestions have been made of how to improve systematic literature reviews (SLRs). There is a need to evaluate how researchers conduct the process of systematic mapping and identify how the guidelines should be updated based on the lessons learned from the existing systematic maps and SLR guidelines.
Objective
To identify how the systematic mapping process is conducted (including search, study selection, analysis and presentation of data, etc.); to identify improvement potentials in conducting the systematic mapping process and updating the guidelines accordingly.
Method
We conducted a systematic mapping study of systematic maps, considering some practices of systematic review guidelines as well (in particular in relation to defining the search and to conduct a quality assessment).
Results
In a large number of studies multiple guidelines are used and combined, which leads to different ways in conducting mapping studies. The reason for combining guidelines was that they differed in the recommendations given.
Conclusion
The most frequently followed guidelines are not sufficient alone. Hence, there was a need to provide an update of how to conduct systematic mapping studies. New guidelines have been proposed consolidating existing findings.},
	author = {Kai Petersen and Sairam Vakkalanka and Ludwik Kuzniarz},
	date-added = {2022-10-22 10:39:18 +0200},
	date-modified = {2022-10-22 10:39:29 +0200},
	doi = {https://doi.org/10.1016/j.infsof.2015.03.007},
	issn = {0950-5849},
	journal = {Information and Software Technology},
	keywords = {Systematic mapping studies, Software engineering, Guidelines},
	pages = {1-18},
	title = {Guidelines for conducting systematic mapping studies in software engineering: An update},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584915000646},
	volume = {64},
	year = {2015},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0950584915000646},
	bdsk-url-2 = {https://doi.org/10.1016/j.infsof.2015.03.007}}

@article{2012_Vicente,
	abstract = {A new size-independent indicator of scientific journal prestige, the SJR2 indicator, is proposed. This indicator takes into account not only the prestige of the citing scientific journal but also its closeness to the cited journal using the cosine of the angle between the vectors of the two journals' cocitation profiles. To eliminate the size effect, the accumulated prestige is divided by the fraction of the journal's citable documents, thus eliminating the decreasing tendency of this type of indicator and giving meaning to the scores. Its method of computation is described, and the results of its implementation on the Scopus 2008 dataset is compared with those of an ad hoc Journal Impact Factor, JIF(3y), and SNIP, the comparison being made both overall and within specific scientific areas. All three, the SJR2 indicator, the SNIP indicator and the JIF distributions, were found to fit well to a logarithmic law. Although the three metrics were strongly correlated, there were major changes in rank. In addition, the SJR2 was distributed more equalized than the JIF by Subject Area and almost as equalized as the SNIP, and better than both at the lower level of Specific Subject Areas. The incorporation of the cosine increased the values of the flows of prestige between thematically close journals.},
	author = {Vicente P. Guerrero-Bote and F{\'e}lix Moya-Aneg{\'o}n},
	date-added = {2022-10-22 10:38:23 +0200},
	date-modified = {2022-10-22 10:38:38 +0200},
	doi = {https://doi.org/10.1016/j.joi.2012.07.001},
	issn = {1751-1577},
	journal = {Journal of Informetrics},
	keywords = {SJR2 indicator, Academic journals, Journal prestige, Eigenvector centrality, Citation networks},
	number = {4},
	pages = {674-688},
	title = {A further step forward in measuring journals' scientific prestige: The SJR2 indicator},
	url = {https://www.sciencedirect.com/science/article/pii/S1751157712000521},
	volume = {6},
	year = {2012},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S1751157712000521},
	bdsk-url-2 = {https://doi.org/10.1016/j.joi.2012.07.001}}

@article{2004_Kitchenham,
	author = {Kitchenham, Barbara},
	date-added = {2022-10-22 10:36:10 +0200},
	date-modified = {2022-10-22 10:37:45 +0200},
	journal = {Keele, UK, Keele Univ.},
	month = {08},
	title = {Procedures for Performing Systematic Reviews},
	volume = {33},
	year = {2004},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBOLi4vR3VpZGVsaW5lcy8yMDA0X0tpdGNoZW5oYW1fUHJvY2VkdXJlc19mb3JfUGVyZm9ybWluZ19TeXN0ZW1hdGljX1Jldmlld3MucGRmTxECsgAAAAACsgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAA33RqZUJEAAH/////HzIwMDRfS2l0Y2hlbmhhbV9QciNGRkZGRkZGRi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP/////fW5IwAAAAAAAAAAAAAQACAAAKIGN1AAAAAAAAAAAAAAAAAApHdWlkZWxpbmVzAAIAqS86VXNlcnM6c2FtdWVsZWNlb2w6TGlicmFyeTpNb2JpbGUgRG9jdW1lbnRzOmNvbX5hcHBsZX5DbG91ZERvY3M6TXNjOlllYXIgMjpTZW1lc3RlciAzOlRoZXNpczpHdWlkZWxpbmVzOjIwMDRfS2l0Y2hlbmhhbV9Qcm9jZWR1cmVzX2Zvcl9QZXJmb3JtaW5nX1N5c3RlbWF0aWNfUmV2aWV3cy5wZGYAAA4AggBAADIAMAAwADQAXwBLAGkAdABjAGgAZQBuAGgAYQBtAF8AUAByAG8AYwBlAGQAdQByAGUAcwBfAGYAbwByAF8AUABlAHIAZgBvAHIAbQBpAG4AZwBfAFMAeQBzAHQAZQBtAGEAdABpAGMAXwBSAGUAdgBpAGUAdwBzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgCnVXNlcnMvc2FtdWVsZWNlb2wvTGlicmFyeS9Nb2JpbGUgRG9jdW1lbnRzL2NvbX5hcHBsZX5DbG91ZERvY3MvTXNjL1llYXIgMi9TZW1lc3RlciAzL1RoZXNpcy9HdWlkZWxpbmVzLzIwMDRfS2l0Y2hlbmhhbV9Qcm9jZWR1cmVzX2Zvcl9QZXJmb3JtaW5nX1N5c3RlbWF0aWNfUmV2aWV3cy5wZGYAABMAAS8AABUAAgAS//8AAAAIAA0AGgAkAHUAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAADKw==}}

@article{1973_Small,
	author = {Small, Henry},
	date-added = {2022-10-22 10:35:31 +0200},
	date-modified = {2022-10-22 10:37:30 +0200},
	doi = {10.1002/asi.4630240406},
	journal = {Journal of the American Society for Information Science},
	month = {07},
	pages = {265 - 269},
	title = {Co-Citation in the Scientific Literature: A New Measure of the Relationship Between Two Documents},
	volume = {24},
	year = {1973},
	bdsk-url-1 = {https://doi.org/10.1002/asi.4630240406}}

@comment{BibDesk Static Groups{
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<array>
	<dict>
		<key>group name</key>
		<string>Guidelines</string>
		<key>keys</key>
		<string>1973_Small,2004_Kitchenham,2012_Vicente,2015_Petersen,2022_Kitchenham</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Surveys</string>
		<key>keys</key>
		<string>2016_Chen,2019_Jipeng,2019_Likhitha,2019_Xia,2021_Churchill,2021_Silva,2022_Chauhan</string>
	</dict>
</array>
</plist>
}}
