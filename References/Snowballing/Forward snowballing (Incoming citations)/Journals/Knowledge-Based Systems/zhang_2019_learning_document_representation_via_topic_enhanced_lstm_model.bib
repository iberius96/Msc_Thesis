%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Samuele Ceol at 2022-11-25 15:16:58 +0100 


%% Saved with string encoding Unicode (UTF-8) 



@article{wan_2020_a_novel_sentence_embedding_based_topic_detection_method_for_microblogs,
	author = {Wan, Cong and Jiang, Shan and Wang, Cong and Yuan, Ying and Wang, Cuirong},
	doi = {10.1109/ACCESS.2020.3036043},
	file = {Full Text:files/1158/Wan et al. - 2020 - A Novel Sentence Embedding Based Topic Detection M.pdf:application/pdf},
	issn = {2169-3536},
	journal = {IEEE Access},
	pages = {202980--202992},
	title = {A {Novel} {Sentence} {Embedding} {Based} {Topic} {Detection} {Method} for {Microblogs}},
	url = {https://ieeexplore.ieee.org/document/9249247/},
	urldate = {2022-11-25},
	volume = {8},
	year = {2020},
	bdsk-url-1 = {https://ieeexplore.ieee.org/document/9249247/},
	bdsk-url-2 = {https://doi.org/10.1109/ACCESS.2020.3036043}}

@incollection{safaryan_2021_semantic_recommendation_system_for_bilingual_corpus_of_academic_papers,
	address = {Cham},
	author = {Safaryan, Anna and Filchenkov, Petr and Yan, Weijia and Kutuzov, Andrey and Nikishina, Irina},
	booktitle = {Recent {Trends} in {Analysis} of {Images}, {Social} {Networks} and {Texts}},
	doi = {10.1007/978-3-030-71214-3_3},
	editor = {van der Aalst, Wil M. P. and Batagelj, Vladimir and Buzmakov, Alexey and Ignatov, Dmitry I. and Kalenkova, Anna and Khachay, Michael and Koltsova, Olessia and Kutuzov, Andrey and Kuznetsov, Sergei O. and Lomazova, Irina A. and Loukachevitch, Natalia and Makarov, Ilya and Napoli, Amedeo and Panchenko, Alexander and Pardalos, Panos M. and Pelillo, Marcello and Savchenko, Andrey V. and Tutubalina, Elena},
	isbn = {978-3-030-71213-6 978-3-030-71214-3},
	language = {en},
	note = {Series Title: Communications in Computer and Information Science},
	pages = {22--36},
	publisher = {Springer International Publishing},
	title = {Semantic {Recommendation} {System} for {Bilingual} {Corpus} of {Academic} {Papers}},
	url = {https://link.springer.com/10.1007/978-3-030-71214-3_3},
	urldate = {2022-11-25},
	volume = {1357},
	year = {2021},
	bdsk-url-1 = {https://link.springer.com/10.1007/978-3-030-71214-3_3},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-71214-3_3}}

@article{fu_2021_output_based_transfer_learning_in_genetic_programming_for_document_classification,
	author = {Fu, Wenlong and Xue, Bing and Gao, Xiaoying and Zhang, Mengjie},
	doi = {10.1016/j.knosys.2020.106597},
	issn = {09507051},
	journal = {Knowledge-Based Systems},
	language = {en},
	month = jan,
	pages = {106597},
	title = {Output-based transfer learning in genetic programming for document classification},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705120307267},
	urldate = {2022-11-25},
	volume = {212},
	year = {2021},
	bdsk-url-1 = {https://linkinghub.elsevier.com/retrieve/pii/S0950705120307267},
	bdsk-url-2 = {https://doi.org/10.1016/j.knosys.2020.106597}}

@article{zhou_2020_a_discriminative_convolutional_neural_network_with_context_aware_attention,
	abstract = {Feature representation and feature extraction are two crucial procedures in text mining. Convolutional Neural Networks (CNN) have shown overwhelming success for text-mining tasks, since they are capable of efficiently extracting
              n
              -gram features from source data. However, vanilla CNN has its own weaknesses on feature representation and feature extraction. A certain amount of filters in CNN are inevitably duplicate and thus hinder to discriminatively represent a given text. In addition, most existing CNN models extract features in a fixed way (i.e., max pooling) that either limit the CNN to local optimum nor without considering the relation between all features, thereby unable to learn a contextual
              n
              -gram features adaptively. In this article, we propose a discriminative CNN with context-aware attention to solve the challenges of vanilla CNN. Specifically, our model mainly encourages discrimination across different filters via maximizing their earth mover distances and estimates the salience of feature candidates by considering the relation between context features. We validate carefully our findings against baselines on five benchmark datasets of classification and two datasets of summarization. The results of the experiments verify the competitive performance of our proposed model.},
	author = {Zhou, Yuxiang and Liao, Lejian and Gao, Yang and Huang, Heyan and Wei, Xiaochi},
	doi = {10.1145/3397464},
	issn = {2157-6904, 2157-6912},
	journal = {ACM Transactions on Intelligent Systems and Technology},
	language = {en},
	month = oct,
	number = {5},
	pages = {1--21},
	title = {A {Discriminative} {Convolutional} {Neural} {Network} with {Context}-aware {Attention}},
	url = {https://dl.acm.org/doi/10.1145/3397464},
	urldate = {2022-11-25},
	volume = {11},
	year = {2020},
	bdsk-url-1 = {https://dl.acm.org/doi/10.1145/3397464},
	bdsk-url-2 = {https://doi.org/10.1145/3397464}}

@article{zhou_2022_increasing_naturalness_of_human__machine_dialogue_the_users_choices_inference_of_options_in_machine_raised_questions,
	author = {Zhou, Xiaoling and Wu, Ou and Jiang, Chao},
	doi = {10.1016/j.knosys.2022.108485},
	issn = {09507051},
	journal = {Knowledge-Based Systems},
	language = {en},
	month = may,
	pages = {108485},
	shorttitle = {Increasing naturalness of human--machine dialogue},
	title = {Increasing naturalness of human--machine dialogue: {The} users' choices inference of options in machine-raised questions},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705122002064},
	urldate = {2022-11-25},
	volume = {243},
	year = {2022},
	bdsk-url-1 = {https://linkinghub.elsevier.com/retrieve/pii/S0950705122002064},
	bdsk-url-2 = {https://doi.org/10.1016/j.knosys.2022.108485}}

@article{yan_2019_application_of_a_parallel_particle_swarm_optimization_long_short_term_memory_model_to_improve_water_quality_data,
	abstract = {Water quality data cleaning is important for the management of water environments. A framework for water quality time series cleaning is proposed in this paper. Considering the nonlinear relationships among water quality indicators, support vector regression (SVR) is used to forecast water quality indicators when some indicators are missing or when they show abnormal values at a certain point in time. Considering the time series of water quality information, long short-term memory (LSTM) networks are used to forecast water quality indicators when all indicators are missing at a certain point in time. A parallel model based on particle swarm optimization (PSO) and LSTM is realized based on a microservices architecture to improve the efficiency of model execution and the predictive accuracy of the LSTM networks. The performance of the model is evaluated in terms of the mean absolute error (MAE) and root-mean-square error (RMSE). Inlet water quality data from a wastewater treatment plant in Gaobeidian, Beijing, China is considered as a case study to examine the effectiveness of this approach. The experimental results reveal that this model has better predictive accuracy than other data-driven models because of smaller MAE and RMSE and has an advantage in terms of time consumption compared with standalone serial algorithms.},
	author = {Yan, Jianzhuo and Chen, Xinyue and Yu, Yongchuan and Zhang, Xiaojuan},
	doi = {10.3390/w11071317},
	file = {Full Text:files/1150/Yan et al. - 2019 - Application of a Parallel Particle Swarm Optimizat.pdf:application/pdf},
	issn = {2073-4441},
	journal = {Water},
	language = {en},
	month = jun,
	number = {7},
	pages = {1317},
	title = {Application of a {Parallel} {Particle} {Swarm} {Optimization}-{Long} {Short} {Term} {Memory} {Model} to {Improve} {Water} {Quality} {Data}},
	url = {https://www.mdpi.com/2073-4441/11/7/1317},
	urldate = {2022-11-25},
	volume = {11},
	year = {2019},
	bdsk-url-1 = {https://www.mdpi.com/2073-4441/11/7/1317},
	bdsk-url-2 = {https://doi.org/10.3390/w11071317}}

@article{trinh_2021_nested_variational_autoencoder_for_topic_modelling_on_microtexts_with_word_vectors,
	author = {Trinh, Trung and Quan, Tho and Mai, Trung},
	doi = {10.1111/exsy.12639},
	issn = {0266-4720, 1468-0394},
	journal = {Expert Systems},
	language = {en},
	month = mar,
	number = {2},
	title = {Nested variational autoencoder for topic modelling on microtexts with word vectors},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/exsy.12639},
	urldate = {2022-11-25},
	volume = {38},
	year = {2021},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/10.1111/exsy.12639},
	bdsk-url-2 = {https://doi.org/10.1111/exsy.12639}}

@article{diallo_2021_deep_embedding_clustering_based_on_contractive_autoencoder,
	author = {Diallo, Bassoma and Hu, Jie and Li, Tianrui and Khan, Ghufran Ahmad and Liang, Xinyan and Zhao, Yimiao},
	doi = {10.1016/j.neucom.2020.12.094},
	issn = {09252312},
	journal = {Neurocomputing},
	language = {en},
	month = apr,
	pages = {96--107},
	title = {Deep embedding clustering based on contractive autoencoder},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231220320063},
	urldate = {2022-11-25},
	volume = {433},
	year = {2021},
	bdsk-url-1 = {https://linkinghub.elsevier.com/retrieve/pii/S0925231220320063},
	bdsk-url-2 = {https://doi.org/10.1016/j.neucom.2020.12.094}}

@article{wei_2020_bilstm_with_multi_polarity_orthogonal_attention_for_implicit_sentiment_analysis,
	author = {Wei, Jiyao and Liao, Jian and Yang, Zhenfei and Wang, Suge and Zhao, Qiang},
	doi = {10.1016/j.neucom.2019.11.054},
	issn = {09252312},
	journal = {Neurocomputing},
	language = {en},
	month = mar,
	pages = {165--173},
	title = {{BiLSTM} with {Multi}-{Polarity} {Orthogonal} {Attention} for {Implicit} {Sentiment} {Analysis}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S092523121931656X},
	urldate = {2022-11-25},
	volume = {383},
	year = {2020},
	bdsk-url-1 = {https://linkinghub.elsevier.com/retrieve/pii/S092523121931656X},
	bdsk-url-2 = {https://doi.org/10.1016/j.neucom.2019.11.054}}

@article{ijirana_2020_patterns_of_metacognitive_skills_and_external_representation_of_students_in_chemistry_problem_solving,
	abstract = {This research aims to examine the pattern of external representation and metacognitive skills in chemistry problem solving for students of chemistry education at Tadulako University. This picture will enrich the treasures of thinking skills in the field of science, namely how students/prospective teachers think in the context of metacognitive skills and how these students display an external representation system on chemistry concepts. The subject of this qualitative study was obtained through a purposive random sampling of 97 students who have been programmed Basic Chemistry course 2017/2018 academic year. Subjects were selected based on the results of the screening using a metacognitive skills assessment questionnaire (MCAI). Two problems solved by the subject by setting one-on-one thinking aloud. Subjects who complete the issue by setting further interviews at different times. The problem-solving activity was recorded using a video camera. The subject uses a type of representation and aspects of metacognitive skills and how to use the sequence of activities, analyzed in detail. The results showed that students of chemical education used metacognitive skills and external representations. So students solve chemical problems. Students also can improve knowledge retention related to linking new knowledge with previous knowledge, creating ideas, organizing, and even synthesizing knowledge. Students become productive and find solutions for problem-solving well},
	author = {Ijirana, Ijirana and Mansyur, Jusman},
	doi = {10.17977/um048v25i2p58-65},
	file = {Full Text:files/1161/Ijirana and Mansyur - 2020 - Patterns of Metacognitive Skills and External Repr.pdf:application/pdf},
	issn = {2442-8655, 0215-9643},
	journal = {Jurnal Ilmu Pendidikan},
	month = may,
	number = {2},
	pages = {58},
	title = {Patterns of {Metacognitive} {Skills} and {External} {Representation} of {Students} in {Chemistry} {Problem} {Solving}},
	url = {http://journal2.um.ac.id/index.php/jip/article/view/14092},
	urldate = {2022-11-25},
	volume = {25},
	year = {2020},
	bdsk-url-1 = {http://journal2.um.ac.id/index.php/jip/article/view/14092},
	bdsk-url-2 = {https://doi.org/10.17977/um048v25i2p58-65}}

@article{cholissodin_2021_social_computing_to_create_government_public_policy_document_blueprint_draft_based_on_social_media_data_about_covid_19_using_lstm_and_mmr_hybrid_algorithms,
	abstract = {Abstract- Determining a policy is often limited in a short time so that decisions are prone to inaccuracies and are ultimately judged to be less targeted. Therefore, there is a necessity to use data mining technology. Currently, especially due to the continuously increasing case of the spread of COVID-19 in Indonesia, in order to reduce the rate of spread of COVID-19, the government has established a COVID-19 vaccination and emergency Community Activity Restriction Implementation (PPKM) policies. For the success of the policies, the government is required to ascertain and understand the attitude of the society. Hence, the policies can be accepted and supported by the society. YouTube is one of the sources to discover people's attitudes because in YouTube, people can express their opinions freely. In this study, a model based on Natural Language Processing (NLP) with the Deep Learning method was developed to analyze people's attitudes from their writings or posts on social media. As for the algorithm stages, first the model analysis was created using the Long Short-Term Memory (LSTM) and Bidirectional Long Short-Term Memory (Bi-LSTM) algorithms as a comparison. In the COVID-19 vaccination policy, the Bi-LSTM algorithm provided a better evaluation value, i.e., the accuracy value of 87.20\%, recall of 87.14\%, precision of 87.14\%, and F1-score of 87.14\%. In the emergency PPKM policy, the LSTM algorithm provided a better evaluation value of 95.13\%, recall of 93.94\%, precision of 94.08\%, and F1-score of 94.01\%. In addition, using the Maximum Marginal Relevance (MMR) method to obtain recommendations related to the COVID-19 vaccination policy, the result showed that the government needs to carry out re-socialization regarding vaccination and the impact of the vaccine so that the society can become more cooperative and the emergency PPKM policy needs to be reviewed because it has an impact on the society's economy.},
	author = {Cholissodin, Imam},
	doi = {10.18860/icgt.v11i1.1394},
	file = {Full Text:files/1165/Cholissodin - 2021 - Social Computing to Create Government Public Polic.pdf:application/pdf},
	issn = {2580-7099, 2580-7080},
	journal = {Proceedings of the International Conference on Green Technology},
	month = nov,
	number = {1},
	pages = {6},
	title = {Social {Computing} to {Create} {Government} {Public} {Policy} {Document} {Blueprint} {Draft} {Based} on {Social} {Media} {Data} {About} {Covid}-19 {Using} {LSTM} and {MMR} {Hybrid} {Algorithms}},
	url = {http://conferences.uin-malang.ac.id/index.php/ICGT/article/view/1394},
	urldate = {2022-11-25},
	volume = {11},
	year = {2021},
	bdsk-url-1 = {http://conferences.uin-malang.ac.id/index.php/ICGT/article/view/1394},
	bdsk-url-2 = {https://doi.org/10.18860/icgt.v11i1.1394}}

@article{pathik_2021_an_efficient_sentiment_analysis_using_topic_model_based_optimized_recurrent_neural_network,
	abstract = {Abstract
            In recent years, topic modeling and deep neural network-based methods have attracted much attention in sentiment analysis of online reviews. This paper presents a hybrid topic model-based approach for aspect extraction and sentiment classification of textual reviews. Latent Dirichlet allocation applied for aspect extraction and two-layer bi-directional long short-term memory (LSTM) for sentiment classification. This work also proposes a hill climbing-based approach for tunning model hyperparameters. The proposed model evaluated on three different datasets. Compared to the single-layer Bi-LSTM model, the proposed model gives 95, 95, and 86\% accuracy for the movie, mobile, and hotel domain, respectively.},
	author = {Pathik, Nikhlesh and Shukla, Pragya},
	doi = {10.21307/ijssis-2021-011},
	file = {Full Text:files/1157/Pathik and Shukla - 2021 - An efficient sentiment analysis using topic model .pdf:application/pdf},
	issn = {1178-5608},
	journal = {International Journal on Smart Sensing and Intelligent Systems},
	language = {en},
	month = jan,
	number = {1},
	pages = {1--12},
	title = {An efficient sentiment analysis using topic model based optimized recurrent neural network},
	url = {https://www.sciendo.com/article/10.21307/ijssis-2021-011},
	urldate = {2022-11-25},
	volume = {14},
	year = {2021},
	bdsk-url-1 = {https://www.sciendo.com/article/10.21307/ijssis-2021-011},
	bdsk-url-2 = {https://doi.org/10.21307/ijssis-2021-011}}

@article{yu_2021_additive_densenet_dense_connections_based_on_simple_addition_operations,
	abstract = {The Densely Connected Network (DenseNet) has been widely recognized as a highly competitive architecture in Deep Neural Networks. And its most outstanding property is called Dense Connections, which represent each layer's input by concatenating all the preceding layers' outputs and thus improve the performance by encouraging feature reuse to the extreme. However, it is Dense Connections that cause the challenge of dimension-enlarging, making DenseNet very resource-intensive and low efficiency. In the light of this, inspired by the Residual Network (ResNet), we propose an improved DenseNet named Additive DenseNet, which features replacing concatenation operations (used in Dense Connections) with addition operations (used in ResNet), and in terms of feature reuse, it upgrades addition operations to accumulating operations (namely ∑ (·)), thus enables each layer's input to be the summation of all the preceding layers' outputs. Consequently, Additive DenseNet can not only preserve the dimension of input from enlarging, but also retain the effect of Dense Connections. In this paper, Additive DenseNet is applied to text classification task. The experimental results reveal that compared to DenseNet, our Additive DenseNet can reduce the model complexity by a large margin, such as GPU memory usage and quantity of parameters. And despite its high resource economy, Additive DenseNet can still outperform DenseNet on 6 text classification datasets in terms of accuracy and show competitive performance for model training.},
	author = {Yu, Dawei and Yang, Jie and Zhang, Yun and Yu, Shujuan},
	doi = {10.3233/JIFS-201758},
	issn = {10641246, 18758967},
	journal = {Journal of Intelligent \& Fuzzy Systems},
	month = mar,
	number = {3},
	pages = {5015--5025},
	shorttitle = {Additive {DenseNet}},
	title = {Additive {DenseNet}: {Dense} connections based on simple addition operations},
	url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/JIFS-201758},
	urldate = {2022-11-25},
	volume = {40},
	year = {2021},
	bdsk-url-1 = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/JIFS-201758},
	bdsk-url-2 = {https://doi.org/10.3233/JIFS-201758}}

@article{woo_2020_content_noise_detection_model_using_deep_learning_in_web_forums,
	abstract = {Spam posts in web forum discussions cause user inconvenience and lower the value of the web forum as an open source of user opinion. In this regard, as the importance of a web post is evaluated in terms of the number of involved authors, noise distorts the analysis results by adding unnecessary data to the opinion analysis. Here, in this work, an automatic detection model for spam posts in web forums using both conventional machine learning and deep learning is proposed. To automatically differentiate between normal posts and spam, evaluators were asked to recognize spam posts in advance. To construct the machine learning-based model, text features from posted content using text mining techniques from the perspective of linguistics were extracted, and supervised learning was performed to distinguish content noise from normal posts. For the deep learning model, raw text including and excluding special characters was utilized. A comparison analysis on deep neural networks using the two different recurrent neural network (RNN) models of the simple RNN and long short-term memory (LSTM) network was also performed. Furthermore, the proposed model was applied to two web forums. The experimental results indicate that the deep learning model affords significant improvements over the accuracy of conventional machine learning associated with text features. The accuracy of the proposed model using LSTM reaches 98.56\%, and the precision and recall of the noise class reach 99\% and 99.53\%, respectively.},
	author = {Woo, Jiyoung and Yun, Jaeseok},
	doi = {10.3390/su12125074},
	file = {Full Text:files/1160/Woo and Yun - 2020 - Content Noise Detection Model Using Deep Learning .pdf:application/pdf},
	issn = {2071-1050},
	journal = {Sustainability},
	language = {en},
	month = jun,
	number = {12},
	pages = {5074},
	title = {Content {Noise} {Detection} {Model} {Using} {Deep} {Learning} in {Web} {Forums}},
	url = {https://www.mdpi.com/2071-1050/12/12/5074},
	urldate = {2022-11-25},
	volume = {12},
	year = {2020},
	bdsk-url-1 = {https://www.mdpi.com/2071-1050/12/12/5074},
	bdsk-url-2 = {https://doi.org/10.3390/su12125074}}

@incollection{ma_2021_an_image_enhanced_topic_modeling_method_for_neuroimaging_literature,
	address = {Cham},
	author = {Ma, Lianfang and Chen, Jianhui and Zhong, Ning},
	booktitle = {Brain {Informatics}},
	doi = {10.1007/978-3-030-86993-9_28},
	editor = {Mahmud, Mufti and Kaiser, M Shamim and Vassanelli, Stefano and Dai, Qionghai and Zhong, Ning},
	isbn = {978-3-030-86992-2 978-3-030-86993-9},
	language = {en},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {299--309},
	publisher = {Springer International Publishing},
	title = {An {Image}-{Enhanced} {Topic} {Modeling} {Method} for {Neuroimaging} {Literature}},
	url = {https://link.springer.com/10.1007/978-3-030-86993-9_28},
	urldate = {2022-11-25},
	volume = {12960},
	year = {2021},
	bdsk-url-1 = {https://link.springer.com/10.1007/978-3-030-86993-9_28},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-86993-9_28}}

@article{ganji_2020_kernel_compositional_embedding_and_its_application_in_linguistic_structured_data_classification,
	author = {Ganji, Hamed and Ebadzadeh, Mohammad Mehdi and Khadivi, Shahram},
	doi = {10.1016/j.knosys.2020.105553},
	issn = {09507051},
	journal = {Knowledge-Based Systems},
	language = {en},
	month = apr,
	pages = {105553},
	title = {Kernel compositional embedding and its application in linguistic structured data classification},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705120300460},
	urldate = {2022-11-25},
	volume = {194},
	year = {2020},
	bdsk-url-1 = {https://linkinghub.elsevier.com/retrieve/pii/S0950705120300460},
	bdsk-url-2 = {https://doi.org/10.1016/j.knosys.2020.105553}}

@article{oyedotun_2021_deep_network_compression_with_teacher_latent_subspace_learning_and_lasso,
	author = {Oyedotun, Oyebade K. and Shabayek, Abd El Rahman and Aouada, Djamila and Ottersten, Bj{\"o}rn},
	doi = {10.1007/s10489-020-01858-2},
	file = {Submitted Version:files/1164/Oyedotun et al. - 2021 - Deep network compression with teacher latent subsp.pdf:application/pdf},
	issn = {0924-669X, 1573-7497},
	journal = {Applied Intelligence},
	language = {en},
	month = feb,
	number = {2},
	pages = {834--853},
	title = {Deep network compression with teacher latent subspace learning and {LASSO}},
	url = {https://link.springer.com/10.1007/s10489-020-01858-2},
	urldate = {2022-11-25},
	volume = {51},
	year = {2021},
	bdsk-url-1 = {https://link.springer.com/10.1007/s10489-020-01858-2},
	bdsk-url-2 = {https://doi.org/10.1007/s10489-020-01858-2}}

@article{van_houdt_2020_a_review_on_the_long_short_term_memory_model,
	author = {Van Houdt, Greg and Mosquera, Carlos and N{\'a}poles, Gonzalo},
	doi = {10.1007/s10462-020-09838-1},
	file = {Submitted Version:files/1159/Van Houdt et al. - 2020 - A review on the long short-term memory model.pdf:application/pdf},
	issn = {0269-2821, 1573-7462},
	journal = {Artificial Intelligence Review},
	language = {en},
	month = dec,
	number = {8},
	pages = {5929--5955},
	title = {A review on the long short-term memory model},
	url = {https://link.springer.com/10.1007/s10462-020-09838-1},
	urldate = {2022-11-25},
	volume = {53},
	year = {2020},
	bdsk-url-1 = {https://link.springer.com/10.1007/s10462-020-09838-1},
	bdsk-url-2 = {https://doi.org/10.1007/s10462-020-09838-1}}

@article{suarez_cansino_2022_automatic_generation_of_learning_outcomes_based_on_long_short__term_memory_artificial_neural_network1,
	abstract = {Building a good instructional design requires a sound organization management to program and articulate several tasks based for instance on the time availability, process follow-up, social and educational context. Furthermore, learning outcomes are the basis involving every educational activity. Thus, based on a predefined ontology, including the instructional educative model and its characteristics, we propose the use of a Long Short--Term Memory Artificial Neural Network (LSTM) to organize the structure and automatize the obtention of learning outcomes for a focused instructional design. We present encouraging results in this direction through the use of a LSTM using as the training data, a small learning outcomes set predefined by the user, focused on the characteristics of an educative model previously defined.},
	author = {Su{\'a}rez-Cansino, Joel and L{\'o}pez-Morales, Virgilio and Ramos-Fern{\'a}ndez, Julio C{\'e}sar},
	doi = {10.3233/JIFS-219234},
	editor = {Pinto, David and Beltr{\'a}n, Beatriz and Singh, Vivek},
	issn = {10641246, 18758967},
	journal = {Journal of Intelligent \& Fuzzy Systems},
	month = mar,
	number = {5},
	pages = {4449--4461},
	title = {Automatic generation of learning outcomes based on long short--term memory artificial neural network1},
	url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/JIFS-219234},
	urldate = {2022-11-25},
	volume = {42},
	year = {2022},
	bdsk-url-1 = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/JIFS-219234},
	bdsk-url-2 = {https://doi.org/10.3233/JIFS-219234}}

@article{sheng_2020_a_topic_learning_pipeline_for_curating_brain_cognitive_researches,
	author = {Sheng, Ying and Chen, Jianhui and He, Xiaobo and Xu, Zhe and Gao, Jiangfan and Lin, Shaofu},
	doi = {10.1109/ACCESS.2020.3032173},
	file = {Full Text:files/1166/Sheng et al. - 2020 - A Topic Learning Pipeline for Curating Brain Cogni.pdf:application/pdf},
	issn = {2169-3536},
	journal = {IEEE Access},
	pages = {191758--191774},
	title = {A {Topic} {Learning} {Pipeline} for {Curating} {Brain} {Cognitive} {Researches}},
	url = {https://ieeexplore.ieee.org/document/9229383/},
	urldate = {2022-11-25},
	volume = {8},
	year = {2020},
	bdsk-url-1 = {https://ieeexplore.ieee.org/document/9229383/},
	bdsk-url-2 = {https://doi.org/10.1109/ACCESS.2020.3032173}}

@techreport{li_2021_an_improved_term_weighting_method_based_on_relevance_frequency_for_text_classification,
	abstract = {Abstract
          As a vital step of text classification (TC) task, the assignment of term weight has a great influence on the performance of TC. Currently, masses of term weighting schemes can be utilized, such as term frequency-inverse documents frequency (TF-IDF) and term frequency-relevance frequency (TF-RF), and they are all consisted of local part (TF) and global part (e.g., IDF, RF). However, most of these schemes adopt the logarithmic processing on their respective global parts, and it is natural to consider whether the logarithmic processing apply to all these schemes or not. Actually, for a specific term weighting scheme, due to its different ratio of local weight and global weight resulting from logarithmic processing, it usually shows diverse text clasification results on different text sets, which presents poor robustness. To explore the influence of logarithmic processing imposed on the global weight on the classification result of term weighting schemes, TF-RF is selected as the representative because it can achieve a better performance among these schemes adopting logarithmic processing. Then, two propositions along with corresponding methods about the relation between TF part and RF part are proposed based on TF-RF. In addition, two groups of experiments are conducted on the two methods. The first group of experiments proves that one method (denoted as TF-ERF) is more helpful to the improvement than the other one (denoted as ETF-RF). The second group of experiments shows that TF-ERF not only ourperforms TF-RF but also obtains better performance than other existing term weighting schemes.},
	author = {Li, Chuanxiao and Li, Wenqiang and Tang, Zhong and Li, Song and Xiang, Hai},
	doi = {10.21203/rs.3.rs-680515/v1},
	file = {Submitted Version:files/1163/Li et al. - 2021 - An Improved Term Weighting Method Based on Relevan.pdf:application/pdf},
	institution = {In Review},
	month = aug,
	title = {An {Improved} {Term} {Weighting} {Method} {Based} on {Relevance} {Frequency} for {Text} {Classification}},
	type = {preprint},
	url = {https://www.researchsquare.com/article/rs-680515/v1},
	urldate = {2022-11-25},
	year = {2021},
	bdsk-url-1 = {https://www.researchsquare.com/article/rs-680515/v1},
	bdsk-url-2 = {https://doi.org/10.21203/rs.3.rs-680515/v1}}

@inproceedings{yavary_2021_document_embedding_using_piped_elm_gan_model,
	address = {Seoul, Korea (South)},
	author = {Yavary, Arefeh and Sajedi, Hedieh},
	booktitle = {2021 15th {International} {Conference} on {Ubiquitous} {Information} {Management} and {Communication} ({IMCOM})},
	doi = {10.1109/IMCOM51814.2021.9377413},
	isbn = {978-1-66542-318-2},
	month = jan,
	pages = {1--4},
	publisher = {IEEE},
	title = {Document {Embedding} using piped {ELM}-{GAN} {Model}},
	url = {https://ieeexplore.ieee.org/document/9377413/},
	urldate = {2022-11-25},
	year = {2021},
	bdsk-url-1 = {https://ieeexplore.ieee.org/document/9377413/},
	bdsk-url-2 = {https://doi.org/10.1109/IMCOM51814.2021.9377413}}

@article{geng_2022_webpage_retrieval_based_on_query_by_example_for_think_tank_construction,
	author = {Geng, Qian and Chuai, Ziang and Jin, Jian},
	doi = {10.1016/j.ipm.2021.102767},
	issn = {03064573},
	journal = {Information Processing \& Management},
	language = {en},
	month = jan,
	number = {1},
	pages = {102767},
	title = {Webpage retrieval based on query by example for think tank construction},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306457321002478},
	urldate = {2022-11-25},
	volume = {59},
	year = {2022},
	bdsk-url-1 = {https://linkinghub.elsevier.com/retrieve/pii/S0306457321002478},
	bdsk-url-2 = {https://doi.org/10.1016/j.ipm.2021.102767}}

@article{rezaeenour_2022_systematic_review_of_content_analysis_algorithms_based_on_deep_neural_networks,
	author = {Rezaeenour, Jalal and Ahmadi, Mahnaz and Jelodar, Hamed and Shahrooei, Roshan},
	doi = {10.1007/s11042-022-14043-z},
	file = {Full Text:files/1162/Rezaeenour et al. - 2022 - Systematic review of content analysis algorithms b.pdf:application/pdf},
	issn = {1380-7501, 1573-7721},
	journal = {Multimedia Tools and Applications},
	language = {en},
	month = oct,
	title = {Systematic review of content analysis algorithms based on deep neural networks},
	url = {https://link.springer.com/10.1007/s11042-022-14043-z},
	urldate = {2022-11-25},
	year = {2022},
	bdsk-url-1 = {https://link.springer.com/10.1007/s11042-022-14043-z},
	bdsk-url-2 = {https://doi.org/10.1007/s11042-022-14043-z}}
