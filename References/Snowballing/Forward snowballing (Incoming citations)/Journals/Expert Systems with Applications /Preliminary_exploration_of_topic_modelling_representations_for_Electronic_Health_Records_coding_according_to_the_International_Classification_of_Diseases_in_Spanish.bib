
@techreport{wu_comparison_2022,
	type = {preprint},
	title = {A {Comparison} of {Representation} {Learning} {Methods} for {Medical} {Concepts} in {MIMIC}-{IV}},
	url = {http://medrxiv.org/lookup/doi/10.1101/2022.08.21.22278835},
	abstract = {Abstract
          
            Objective
            To compare and release the diagnosis (ICD-10-CM), procedure (ICD-10-PCS), and medication (NDC) concept (code) embeddings trained by Latent Dirichlet Allocation (LDA), Word2Vec, GloVe, and BERT, for more efficient electronic health record (EHR) data analysis.
          
          
            Materials and Methods
            The embeddings were pre-trained by the four aforementioned models separately using the diagnosis, procedure, and medication information in MIMIC-IV. We interpreted the embeddings by visualizing them in 2D space and used the silhouette coefficient to assess the clustering ability of these embeddings. Furthermore, we evaluated the embeddings in three downstream tasks without fine-tuning: next visit diagnoses prediction, ICU patients mortality prediction, and medication recommendation.
          
          
            Results
            We found that embeddings pre-trained by GloVe have the best performance in the downstream tasks and the best interpretability for all diagnosis, procedure, and medication codes. In the next-visit diagnosis prediction, the accuracy of using GloVe embeddings was 12.2\% higher than the baseline, which is the random generator. In the other two prediction tasks, GloVe improved the accuracy by 2\%-3\% over the baseline. LDA, Word2Vec, and BERT marginally improved the results over the baseline in most cases.
          
          
            Discussion and Conclusion
            GloVe shows superiority in mining diagnoses, procedures, and medications information of MIMIC-IV compared with LDA, Word2Vec, and BERT. Besides, we found that the granularity of training samples can affect the performance of models according to the downstream task and pre-train data.},
	language = {en},
	urldate = {2022-11-25},
	institution = {Health Informatics},
	author = {Wu, Xuan and Zhao, Yizheng and Yang, Yang and Liu, Zhangdaihong and Clifton, David A.},
	month = aug,
	year = {2022},
	doi = {10.1101/2022.08.21.22278835},
	file = {Submitted Version:files/1431/Wu et al. - 2022 - A Comparison of Representation Learning Methods fo.pdf:application/pdf},
}

@article{poreddy_improvement_2023,
	title = {Improvement of accuracy of under-performing classifier in decision making using discrete memoryless channel model and {Particle} {Swarm} {Optimization}},
	volume = {213},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417422019479},
	doi = {10.1016/j.eswa.2022.118929},
	language = {en},
	urldate = {2022-11-25},
	journal = {Expert Systems with Applications},
	author = {Poreddy, Rajasekharreddy and Gopi, E.S.},
	month = mar,
	year = {2023},
	pages = {118929},
}
