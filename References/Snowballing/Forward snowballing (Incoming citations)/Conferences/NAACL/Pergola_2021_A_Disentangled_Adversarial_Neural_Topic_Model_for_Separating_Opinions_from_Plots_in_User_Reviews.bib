
@article{lu_2022_event_centric_question_answering_via_contrastive_learning_and_invertible_event_transformation,
	title = {Event-{Centric} {Question} {Answering} via {Contrastive} {Learning} and {Invertible} {Event} {Transformation}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2210.12902},
	doi = {10.48550/ARXIV.2210.12902},
	abstract = {Human reading comprehension often requires reasoning of event semantic relations in narratives, represented by Event-centric Question-Answering (QA). To address event-centric QA, we propose a novel QA model with contrastive learning and invertible event transformation, call TranCLR. Our proposed model utilizes an invertible transformation matrix to project semantic vectors of events into a common event embedding space, trained with contrastive learning, and thus naturally inject event semantic knowledge into mainstream QA pipelines. The transformation matrix is fine-tuned with the annotated event relation types between events that occurred in questions and those in answers, using event-aware question vectors. Experimental results on the Event Semantic Relation Reasoning (ESTER) dataset show significant improvements in both generative and extractive settings compared to the existing strong baselines, achieving over 8.4\% gain in the token-level F1 score and 3.0\% gain in Exact Match (EM) score under the multi-answer setting. Qualitative analysis reveals the high quality of the generated answers by TranCLR, demonstrating the feasibility of injecting event knowledge into QA model learning. Our code and models can be found at https://github.com/LuJunru/TranCLR.},
	urldate = {2022-11-25},
	author = {Lu, Junru and Tan, Xingwei and Pergola, Gabriele and Gui, Lin and He, Yulan},
	year = {2022},
	note = {Publisher: arXiv
Version Number: 1},
	keywords = {FOS: Computer and information sciences, Computation and Language (cs.CL)},
	annote = {Other
Findings of EMNLP 2022},
}

@article{zhu_2022_disentangled_learning_of_stance_and_aspect_topics_for_vaccine_attitude_detection_in_social_media,
	title = {Disentangled {Learning} of {Stance} and {Aspect} {Topics} for {Vaccine} {Attitude} {Detection} in {Social} {Media}},
	copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
	url = {https://arxiv.org/abs/2205.03296},
	doi = {10.48550/ARXIV.2205.03296},
	abstract = {Building models to detect vaccine attitudes on social media is challenging because of the composite, often intricate aspects involved, and the limited availability of annotated data. Existing approaches have relied heavily on supervised training that requires abundant annotations and pre-defined aspect categories. Instead, with the aim of leveraging the large amount of unannotated data now available on vaccination, we propose a novel semi-supervised approach for vaccine attitude detection, called VADet. A variational autoencoding architecture based on language models is employed to learn from unlabelled data the topical information of the domain. Then, the model is fine-tuned with a few manually annotated examples of user attitudes. We validate the effectiveness of VADet on our annotated data and also on an existing vaccination corpus annotated with opinions on vaccines. Our results show that VADet is able to learn disentangled stance and aspect topics, and outperforms existing aspect-based sentiment analysis models on both stance detection and tweet clustering.},
	urldate = {2022-11-25},
	author = {Zhu, Lixing and Fang, Zheng and Pergola, Gabriele and Procter, Rob and He, Yulan},
	year = {2022},
	note = {Publisher: arXiv
Version Number: 2},
	keywords = {FOS: Computer and information sciences, Computation and Language (cs.CL)},
}

@inproceedings{marcacini_2021_aspect_based_sentiment_analysis_using_bert_with_disentangled_attention,
	title = {Aspect-based {Sentiment} {Analysis} using {BERT} with {Disentangled} {Attention}},
	url = {https://research.latinxinai.org/papers/icml/2021/pdf/paper_28.pdf},
	doi = {10.52591/lxai2021072410},
	abstract = {Aspect-Based Sentiment Analysis (ABSA) tasks aim to identify consumers’ opinions about different aspects of products or services. BERT-based language models have been used successfully in applications that require a deep understanding of the language, such as sentiment analysis. This paper investigates the use of disentangled learning to improve BERT-based textual representations in ABSA tasks. Motivated by the success of disentangled representation learning in the field of computer vision, which aims to obtain explanatory factors of the data representations, we explored the recent DeBERTa model (Decoding-enhanced BERT with Disentangled Attention) to disentangle the syntactic and semantics features from a BERT architecture. Experimental results show that incorporating disentangled attention and a simple fine-tuning strategy for downstream tasks outperforms state-of-the-art models in ABSA’s benchmark datasets.},
	urldate = {2022-11-25},
	booktitle = {{LatinX} in {AI} at {International} {Conference} on {Machine} {Learning} 2021},
	publisher = {Journal of LatinX in AI Research},
	author = {Marcacini, Ricardo and Silva, Emanuel},
	month = jul,
	year = {2021},
	file = {Full Text:files/73/Marcacini and Silva - 2021 - Aspect-based Sentiment Analysis using BERT with Di.pdf:application/pdf},
}

@inproceedings{li_2021_a_deep_decomposable_model_for_disentangling_syntax_and_semantics_in_sentence_representation,
	address = {Punta Cana, Dominican Republic},
	title = {A {Deep} {Decomposable} {Model} for {Disentangling} {Syntax} and {Semantics} in {Sentence} {Representation}},
	url = {https://aclanthology.org/2021.findings-emnlp.364},
	doi = {10.18653/v1/2021.findings-emnlp.364},
	language = {en},
	urldate = {2022-11-25},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {EMNLP} 2021},
	publisher = {Association for Computational Linguistics},
	author = {Li, Dingcheng and Fei, Hongliang and Ren, Shaogang and Li, Ping},
	year = {2021},
	pages = {4300--4310},
	file = {Full Text:files/74/Li et al. - 2021 - A Deep Decomposable Model for Disentangling Syntax.pdf:application/pdf},
}

@article{caton_2021_evaluating_public_consultation_in_urban_planning_via_neural_language_models_and_topic_modelling,
	title = {Evaluating {Public} {Consultation} in {Urban} {Planning} via {Neural} {Language} {Models} and {Topic} {Modelling}},
	copyright = {Creative Commons Attribution 4.0 International, Open Access},
	url = {https://zenodo.org/record/5767188},
	doi = {10.5281/ZENODO.5767188},
	abstract = {Urban planning has the fundamental role of managing the cooperative development of ever bigger cities and the community's cultures inhabiting those places. To make the best decisions, urban planners need to analyse relevant data and community responses, spread through abundant reports. This process can be labour intensive and might lead to overlooking less prominent but still relevant concerns of minorities. In this study, we present a Natural Language Processing framework to assist the analysis of consultation reports. The framework leverages state-of-the-art techniques that enable the urban planners to easily describe the issues of interest in free text and, as a result, to accurately identify the emerging concerns from different stakeholders. A first assessment of the London Plan's Green Belt policy has shown the capability of detecting specific community interests about urban planner problems, allowing quick identification of minorities' issues, otherwise overlooked due to the vast amount of data.},
	urldate = {2022-11-25},
	author = {Caton, Christian and Pergola, Gabriele and Novack, Tessio and He, Yulan},
	month = dec,
	year = {2021},
	note = {Publisher: Zenodo},
	keywords = {diversity and minorities, Green Belt, natural language processing, neural language models, the London Plan, urban planning},
}

@article{bonet_2022_contrip_consensus_sentiment_review_analysis_and_platform_ratings_in_a_single_score,
	title = {{ConTrip}: {Consensus} {Sentiment} review {Analysis} and {Platform} ratings in a single score},
	copyright = {Creative Commons Attribution Share Alike 4.0 International},
	shorttitle = {{ConTrip}},
	url = {https://arxiv.org/abs/2201.02113},
	doi = {10.48550/ARXIV.2201.02113},
	abstract = {People unequivocally employ reviews to decide on purchasing an item or an experience on the internet. In that regard, the growing significance and number of opinions have led to the development of methods to assess their sentiment content automatically. However, it is not straightforward for the models to create a consensus value that embodies the agreement of the different reviews and differentiates across equal ratings for an item. Based on the approach proposed by Nguyen et al. in 2020, we derive a novel consensus value named ConTrip that merges their consensus score and the overall rating of a platform for an item. ConTrip lies in the rating range values, which makes it more interpretable while maintaining the ability to differentiate across equally rated experiences. ConTrip is implemented and freely available under MIT license at https://github.com/pepebonet/contripscore},
	urldate = {2022-11-25},
	author = {Bonet, José and Bonet, José},
	year = {2022},
	note = {Publisher: arXiv
Version Number: 1},
	keywords = {FOS: Computer and information sciences, Computation and Language (cs.CL)},
	annote = {Other
4 pagines, 1 figure},
}
