%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Samuele Ceol at 2022-11-25 12:44:33 +0100 


%% Saved with string encoding Unicode (UTF-8) 



@booklet{zhengtong_pan_2022_ontology_driven_scientific_literature_classification_using_clustering_and_self_supervised_learning,
	author = {Zhengtong Pan, Patrick Soong, Setareh Rafatirad},
	date-added = {2022-11-25 12:44:32 +0100},
	date-modified = {2022-11-25 12:44:32 +0100},
	howpublished = {EasyChair Preprint no. 7288},
	title = {Ontology-Driven Scientific Literature Classification using Clustering and Self-Supervised Learning},
	year = {2022}}

@article{ider_2022_forecasting_cryptocurrency_returns_from_sentiment_signals_an_analysis_of_bert_classifiers_and_weak_supervision,
	abstract = {Anticipating price developments in financial markets is a topic of continued interest in forecasting. Funneled by advancements in deep learning and natural language processing (NLP) together with the availability of vast amounts of textual data in form of news articles, social media postings, etc., an increasing number of studies incorporate text-based predictors in forecasting models. We contribute to this literature by introducing weak learning, a recently proposed NLP approach to address the problem that text data is unlabeled. Without a dependent variable, it is not possible to finetune pretrained NLP models on a custom corpus. We confirm that finetuning using weak labels enhances the predictive value of text-based features and raises forecast accuracy in the context of predicting cryptocurrency returns. More fundamentally, the modeling paradigm we present, weak labeling domain-specific text and finetuning pretrained NLP models, is universally applicable in (financial) forecasting and unlocks new ways to leverage text data.},
	annote = {Other
29 pages},
	author = {Ider, Duygu and Lessmann, Stefan},
	copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
	doi = {10.48550/ARXIV.2204.05781},
	keywords = {FOS: Computer and information sciences, Machine Learning (cs.LG), FOS: Economics and business, Statistical Finance (q-fin.ST)},
	note = {Publisher: arXiv Version Number: 2},
	shorttitle = {Forecasting {Cryptocurrency} {Returns} from {Sentiment} {Signals}},
	title = {Forecasting {Cryptocurrency} {Returns} from {Sentiment} {Signals}: {An} {Analysis} of {BERT} {Classifiers} and {Weak} {Supervision}},
	url = {https://arxiv.org/abs/2204.05781},
	urldate = {2022-11-25},
	year = {2022},
	bdsk-url-1 = {https://arxiv.org/abs/2204.05781},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.2204.05781}}

@article{rosati_2022_moving_beyond_word_lists_towards_abstractive_topic_labels_for_human_like_topics_of_scientific_documents,
	abstract = {Topic models represent groups of documents as a list of words (the topic labels). This work asks whether an alternative approach to topic labeling can be developed that is closer to a natural language description of a topic than a word list. To this end, we present an approach to generating human-like topic labels using abstractive multi-document summarization (MDS). We investigate our approach with an exploratory case study. We model topics in citation sentences in order to understand what further research needs to be done to fully operationalize MDS for topic labeling. Our case study shows that in addition to more human-like topics there are additional advantages to evaluation by using clustering and summarization measures instead of topic model measures. However, we find that there are several developments needed before we can design a well-powered study to evaluate MDS for topic modeling fully. Namely, improving cluster cohesion, improving the factuality and faithfulness of MDS, and increasing the number of documents that might be supported by MDS. We present a number of ideas on how these can be tackled and conclude with some thoughts on how topic modeling can also be used to improve MDS in general.},
	annote = {Other
Accepted to WIESP @ AACL-IJCNLP},
	author = {Rosati, Domenic},
	copyright = {Creative Commons Attribution 4.0 International},
	doi = {10.48550/ARXIV.2211.05599},
	keywords = {FOS: Computer and information sciences, Computation and Language (cs.CL)},
	note = {Publisher: arXiv Version Number: 1},
	shorttitle = {Moving beyond word lists},
	title = {Moving beyond word lists: towards abstractive topic labels for human-like topics of scientific documents},
	url = {https://arxiv.org/abs/2211.05599},
	urldate = {2022-11-25},
	year = {2022},
	bdsk-url-1 = {https://arxiv.org/abs/2211.05599},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.2211.05599}}

@incollection{zosa_2022_multilingual_topic_labelling_of_news_topics_using_ontological_mapping,
	address = {Cham},
	author = {Zosa, Elaine and Pivovarova, Lidia and Boggia, Michele and Ivanova, Sardana},
	booktitle = {Advances in {Information} {Retrieval}},
	doi = {10.1007/978-3-030-99739-7_29},
	editor = {Hagen, Matthias and Verberne, Suzan and Macdonald, Craig and Seifert, Christin and Balog, Krisztian and N{\o}rv{\aa}g, Kjetil and Setty, Vinay},
	file = {Accepted Version:files/207/Zosa et al. - 2022 - Multilingual Topic Labelling of News Topics Using .pdf:application/pdf},
	isbn = {978-3-030-99738-0 978-3-030-99739-7},
	language = {en},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {248--256},
	publisher = {Springer International Publishing},
	title = {Multilingual {Topic} {Labelling} of {News} {Topics} {Using} {Ontological} {Mapping}},
	url = {https://link.springer.com/10.1007/978-3-030-99739-7_29},
	urldate = {2022-11-25},
	volume = {13186},
	year = {2022},
	bdsk-url-1 = {https://link.springer.com/10.1007/978-3-030-99739-7_29},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-030-99739-7_29}}

@article{qasim_2022_a_fine_tuned_bert_based_transfer_learning_approach_for_text_classification,
	abstract = {Text Classification problem has been thoroughly studied in information retrieval problems and data mining tasks. It is beneficial in multiple tasks including medical diagnose health and care department, targeted marketing, entertainment industry, and group filtering processes. A recent innovation in both data mining and natural language processing gained the attention of researchers from all over the world to develop automated systems for text classification. NLP allows categorizing documents containing different texts. A huge amount of data is generated on social media sites through social media users. Three datasets have been used for experimental purposes including the COVID-19 fake news dataset, COVID-19 English tweet dataset, and extremist-non-extremist dataset which contain news blogs, posts, and tweets related to coronavirus and hate speech. Transfer learning approaches do not experiment on COVID-19 fake news and extremist-non-extremist datasets. Therefore, the proposed work applied transfer learning classification models on both these datasets to check the performance of transfer learning models. Models are trained and evaluated on the accuracy, precision, recall, and F1-score. Heat maps are also generated for every model. In the end, future directions are proposed.},
	author = {Qasim, Rukhma and Bangyal, Waqas Haider and Alqarni, Mohammed A. and Ali Almazroi, Abdulwahab},
	doi = {10.1155/2022/3498123},
	editor = {Taiar, Redha},
	file = {Full Text:files/205/Qasim et al. - 2022 - A Fine-Tuned BERT-Based Transfer Learning Approach.pdf:application/pdf},
	issn = {2040-2309, 2040-2295},
	journal = {Journal of Healthcare Engineering},
	language = {en},
	month = jan,
	pages = {1--17},
	title = {A {Fine}-{Tuned} {BERT}-{Based} {Transfer} {Learning} {Approach} for {Text} {Classification}},
	url = {https://www.hindawi.com/journals/jhe/2022/3498123/},
	urldate = {2022-11-25},
	volume = {2022},
	year = {2022},
	bdsk-url-1 = {https://www.hindawi.com/journals/jhe/2022/3498123/},
	bdsk-url-2 = {https://doi.org/10.1155/2022/3498123}}

@inproceedings{university_of_helsinki_2021_not_all_comments_are_equal_insights_into_comment_moderation_from_a_topic_aware_model,
	author = {{University of Helsinki, Finland} and Zosa, Elaine and Shekhar, Ravi and {Queen Mary University of London, UK} and Karan, Mladen and {Queen Mary University of London, UK} and Purver, Matthew and {Queen Mary University of London, UK} and {Jo{\v z}ef Stefan Institute, Ljubljana , Slovenia}},
	booktitle = {Proceedings of the {Conference} {Recent} {Advances} in {Natural} {Language} {Processing} - {Deep} {Learning} for {Natural} {Language} {Processing} {Methods} and {Applications}},
	doi = {10.26615/978-954-452-072-4_185},
	file = {Full Text:files/206/University of Helsinki, Finland et al. - 2021 - Not All Comments are Equal Insights into Comment .pdf:application/pdf},
	isbn = {978-954-452-072-4},
	pages = {1652--1662},
	publisher = {INCOMA Ltd. Shoumen, BULGARIA},
	shorttitle = {Not {All} {Comments} are {Equal}},
	title = {Not {All} {Comments} are {Equal}: {Insights} into {Comment} {Moderation} from a {Topic}-{Aware} {Model}},
	url = {https://acl-bg.org/proceedings/2021/RANLP%202021/pdf/2021.ranlp-1.185.pdf},
	urldate = {2022-11-25},
	year = {2021},
	bdsk-url-1 = {https://acl-bg.org/proceedings/2021/RANLP%202021/pdf/2021.ranlp-1.185.pdf},
	bdsk-url-2 = {https://doi.org/10.26615/978-954-452-072-4_185}}
