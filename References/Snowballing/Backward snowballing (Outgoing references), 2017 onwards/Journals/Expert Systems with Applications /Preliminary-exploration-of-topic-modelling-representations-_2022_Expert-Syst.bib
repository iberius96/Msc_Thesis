@incollection{unknown-a,
  title = {This work was partially funded by the Spanish Ministry of Science WordNetLemmatizer from the nltk library (Bird et al., 2009},
  booktitle = {and Innovation (DOTT-HEALTH/PAT-MED PID2019-106942RB-C31), European Commission (FEDER) and by the Basque Government},
  address = {Spain}
}
@misc{it--a,
  author = {IT-1343-19, I.X.A. and PRE-2019-1-0158), Predoctoral Grant},
  title = {We gratefully A.2. Flow diagram and libraries acknowledge the support of NVIDIA Corporation with the donation of the Titan V GPU used for this research. Fig. A.4 shows the outline of the steps taken in the research employ-The authors would like to thank the anonymous reviewers for care- ing PLDA representation. The outline using LDA is similar. In each step fully reading the manuscript and providing constructive suggestions we have used the following libraries: that helped to improve our work},
  note = {1. Document pre-processing: As explained before, in this step we Appendix. Research steps have used Gensim (Řehůřek & Sojka, 2010) and nltk (Bird et al., 2009) libraries. 2. Model generation: the models needed to generate the topic A.1. Document pre-processing vectors from the documents have been generated using the Tomotopy library (Fenstermacher, 2020).}
}
@incollection{hinton1990a,
  title = {Following the background trend, the datasets have been pre-processed 3. Vector representation: Using the models and Tomotopy library using stopwords followed by a lemmatizer and stemmer. the vector representation of the text has been generated. 4. Pointwise mutual information: The normalized pointwise mutual},
  author = {Hinton, G.E.},
  date = {1990},
  pages = {555–610},
  note = {information of the vectors have been computed following Eq.},
  volume = {3},
  publisher = {Elsevier},
  booktitle = {Machine learning}
}
@article{hofmann2001a,
  author = {Hofmann, T.},
  date = {2001},
  title = {Unsupervised learning by probabilistic latent semantic analysis. in Section 3.2},
  volume = {42},
  pages = {177–196},
  journal = {Machine Learning},
  number = {1–2}
}
@article{johnson2016a,
  citation-number = {5.},
  title = {Classifier: In order to assess the downstream task, both ML-k-NN},
  author = {Johnson, A.E. and Pollard, T.J. and Shen, L. and Li-Wei, H.L. and Feng, M. and Ghassemi, M.},
  date = {2016},
  volume = {3},
  note = {implementation available in scikit-multilearn (Pedregosa, et al., 1–9.},
  journal = {Scientific Data},
  number = {1}
}
@article{kalyan2020a,
  citation-number = {2011},
  author = {Kalyan, K.S. and Sangeetha, S.},
  date = {2020},
  title = {Secnlp: A survey of embeddings in clinical natural language processing},
  volume = {101, Article 103323},
  journal = {Journal of Biomedical Informatics}
}
@misc{liu2019a,
  author = {Liu, X. and He, P. and Chen, W. and Gao, J.},
  date = {2019},
  title = {Multi-task deep neural networks for natural}
}
@misc{unknown-b,
  title = {References language understanding},
  note = {arXiv preprint arXiv:1901.11504.},
  arxiv = {1901.11504}
}
@misc{mikolov2013a,
  author = {Mikolov, T. and Sutskever, I. and Chen, K. and Corrado, G.S. and Dean, J.},
  date = {2013},
  title = {Distributed}
}
@article{abdulaziz2019a,
  author = {Abdulaziz, W. and Ameen, M. and M. and Ahmed, B.},
  date = {2019},
  title = {An overview of bag of representations of words and phrases and their compositionality},
  pages = {200–204},
  volume = {26},
  journal = {Advances in Neural words;importance, implementation, applications, and challenges}
}
@inproceedings{alshuweihi2021a,
  author = {AlShuweihi, M. and Salloum, S.A. and Shaalan, K. and Miranda-Escalada, A. and Gonzalez-Agirre, A. and Armengol-Estapé, J. and Krallinger, M.},
  date = {2021},
  title = {Biomedical corpora and natural},
  pages = {491–509},
  booktitle = {Recent advances in intelligent systems and smart applications}
}
@misc{bird2009a,
  author = {Bird, S. and Klein, E. and Loper, E. and Mullenbach, J. and Wiegreffe, S. and Duke, J. and Sun, J. and Eisenstein, J.},
  date = {2009},
  title = {Natural language processing with python: analyzing},
  publisher = {O’Reilly},
  note = {prediction of medical codes from clinical text. CoRR, arXiv:1802.05695.},
  arxiv = {1802.05695},
  address = {Beijing}
}
@article{blanco2020a,
  author = {Blanco, A. and Pérez, A. and Casillas, A. and Névéol, A. and Dalianis, H. and Velupillai, S. and Savova, G. and Zweigenbaum, P. and Blei, D.M.},
  date = {2020},
  title = {Extreme multi-label ICD classification},
  volume = {8},
  pages = {183534–183545},
  journal = {IEEE Access},
  number = {4},
  series = {natural language processing in languages other than English: opportunities and}
}
@article{blei2003a,
  author = {Blei, D.M. and Ng, A.Y. and Jordan, M.I. and Névéol, A. and Robert, A. and Grippo, F. and Morgand, C. and Orsi, C. and Pelikan, L. and Brown, P.F. and Della Pietra, V.J. and Desouza, P.V. and Lai, J.C. and Mercer, R.L. and al and M.},
  date = {2003},
  title = {Latent dirichlet allocation},
  volume = {3},
  pages = {993–1022},
  editor = {C.L.E.F. and Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O.},
  note = {Scikit-learn: Machine learning in python. Journal of Machine Learning Chaney, A. J.-B., & Blei, D.},
  journal = {Journal of},
  number = {Jan}
}
@inproceedings{chen2019a,
  author = {Chen, Q. and Peng, Y. and Lu, Z. and Ramage, D. and Manning, C.D. and Dumais, S.},
  date = {2019},
  title = {BioSentVec: creating sentence embeddings for},
  pages = {457–465},
  booktitle = {2019 IEEE international conference on healthcare informatics}
}
@article{deerwester1990a,
  author = {Deerwester, S. and Dumais, S.T. and Furnas, G.W. and Landauer, T.K. and Harshman, R. and Řehůřek, R. and Sojka, P.},
  date = {1990},
  title = {Software framework for topic modelling with large Indexing by latent semantic analysis. Journal of the American Society for Information corpora},
  volume = {41},
  pages = {391–407 45–50},
  publisher = {ELRA},
  journal = {Proceedings of the LREC 2010 workshop on new challenges for NLP Science},
  number = {6},
  address = {Valletta, Malta}
}
@inproceedings{dermouche2016a,
  author = {Dermouche, M. and Looten, V. and Flicoteaux, R. and Chevret, S. and Velcin, J. and Taright, N. and Röder, M. and Both, A. and Hinneburg, A.},
  date = {2016},
  title = {Exploring the space of topic coherence ECSTRA-INSERM@ CLEF eHealth2016-task 2: ICD10 code extraction from death measures},
  pages = {61–68},
  booktitle = {Proceedings of the Eighth ACM international conference on web search certificates. In CLEF}
}
@article{devlin2019a,
  author = {Devlin, J. and Chang, M.-W. and Lee, K. and Toutanova, K. and Rubin, T.N. and Chambers, A. and Smyth, P. and Steyvers, M. and Sechidis, K. and Tsoumakas, G. and Vlahavas, I.},
  date = {2019},
  title = {BERT: Pre-training of deep},
  volume = {88},
  pages = {157–208},
  publisher = {Association for Computational Linguistics. databases},
  journal = {Proceedings of the 2019 for multi-label document classification. Machine Learning},
  number = {1–2},
  series = {long and short papers},
  address = {Minnesota}
}
@inproceedings{dieng2020a,
  author = {Dieng, A.B. and Ruiz, F.J. and Blei, D.M. and Stevens, K. and Kegelmeyer, P. and Andrzejewski, D. and Buttler, D. and Dörendahl, A. and Leich, N. and Hummel, B. and Schönfelder, G. and Grune, B.},
  date = {2020},
  title = {Topic modeling in embedding spaces},
  pages = {952–961},
  booktitle = {Proceedings of the 2012}
}
@article{fenstermacher2020a,
  author = {Fenstermacher, D. and Uzuner, Ö. and South, B.R. and Shen, S. and DuVall, S.L. and T., Jayasimha and A., Krishnan and S., G. and S., S.K. and Vaswani, A. and Shazeer, N. and Parmar, N. and Uszkoreit, J. and Jones, L. and Gomez, A.N. and C.},
  date = {2020},
  title = {Tomotopy: Gibbs-sampling based topic model python library},
  volume = {18},
  pages = {552–556},
  producer = {L., Biderman and S., Black and S., Golding and L., Hoppe and T., Foster},
  journal = {Advances in neural information processing systems Gao},
  number = {5}
}
@incollection{voorhees2012a,
  title = {The pile: An 800GB dataset of diverse text for language modeling},
  edition = {arXiv preprint},
  author = {Voorhees, E.M. and Hersh, W.R.},
  date = {2012},
  booktitle = {TREC}
}
@inproceedings{goeuriot2009a,
  author = {Goeuriot, L. and Suominen, H. and Kelly, L. and Miranda-Escalada, A. and Krallinger, M. and Liu, Z. and Wang, Y. and Bai, H. and Stanton, M. and Chen, W.-Y. and Chang, E.Y.},
  date = {2009},
  title = {Plda: Parallel al},
  pages = {255–271},
  publisher = {Springer},
  booktitle = {International con- latent dirichlet allocation for large-scale applications. In International conference on ference of the cross-language evaluation forum for European languages}
}
@article{springer2007a,
  author = {Springer. Zhang, M.-L. and Zhou, Z.-H.},
  date = {2007},
  title = {ML-KNN: A lazy learning approach to multi-label learning},
  volume = {40},
  pages = {2038–2048},
  journal = {Pattern Recognition},
  number = {7}
}
