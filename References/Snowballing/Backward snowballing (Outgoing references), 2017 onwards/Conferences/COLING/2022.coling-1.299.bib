%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Samuele Ceol at 2022-11-17 15:54:49 +0100 


%% Saved with string encoding Unicode (UTF-8) 



@article{doi:10.1146/annurev-economics-081919-050239,
	abstract = { How do the Internet and social media affect political outcomes? We review empirical evidence from the recent political economy literature, focusing primarily on work that considers traits that distinguish the Internet and social media from traditional off-line media, such as low barriers to entry and reliance on user-generated content. We discuss the main results about the effects of the Internet in general, and social media in particular, on voting, street protests, attitudes toward government, political polarization, xenophobia, and politicians' behavior. We also review evidence on the role of social media in the dissemination of fake news, and we summarize results about the strategies employed by autocratic regimes to censor the Internet and to use social media for surveillance and propaganda. We conclude by highlighting open questions about how the Internet and social media shape politics in democracies and autocracies. },
	author = {Zhuravskaya, Ekaterina and Petrova, Maria and Enikolopov, Ruben},
	date-added = {2022-11-17 15:54:22 +0100},
	date-modified = {2022-11-17 15:54:22 +0100},
	doi = {10.1146/annurev-economics-081919-050239},
	eprint = {https://doi.org/10.1146/annurev-economics-081919-050239},
	journal = {Annual Review of Economics},
	number = {1},
	pages = {415-438},
	title = {Political Effects of the Internet and Social Media},
	url = {https://doi.org/10.1146/annurev-economics-081919-050239},
	volume = {12},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1146/annurev-economics-081919-050239}}

@article{Yang_2021,
	author = {Qi Yang and Weinan Wang and Lucas Pierce and Rajan Vaish and Xiaolin Shi and Neil Shah},
	date-added = {2022-11-17 15:54:10 +0100},
	date-modified = {2022-11-17 15:54:10 +0100},
	doi = {10.1609/icwsm.v15i1.18107},
	journal = {Proceedings of the International {AAAI} Conference on Web and Social Media},
	month = {may},
	pages = {830--840},
	publisher = {Association for the Advancement of Artificial Intelligence ({AAAI})},
	title = {Online Communication Shifts in the Midst of the Covid-19 Pandemic: A Case Study on Snapchat},
	url = {https://doi.org/10.1609%2Ficwsm.v15i1.18107},
	volume = {15},
	year = 2021,
	bdsk-url-1 = {https://doi.org/10.1609%2Ficwsm.v15i1.18107},
	bdsk-url-2 = {https://doi.org/10.1609/icwsm.v15i1.18107}}

@article{Tajbakhsh_2019,
	author = {Mir Saman Tajbakhsh and Jamshid Bagherzadeh},
	date-added = {2022-11-17 15:54:02 +0100},
	date-modified = {2022-11-17 15:54:02 +0100},
	doi = {10.3233/ida-183998},
	journal = {Intelligent Data Analysis},
	month = {apr},
	number = {3},
	pages = {609--622},
	publisher = {{IOS} Press},
	title = {Semantic knowledge {LDA} with topic vector for recommending hashtags: Twitter use case},
	url = {https://doi.org/10.3233%2Fida-183998},
	volume = {23},
	year = 2019,
	bdsk-url-1 = {https://doi.org/10.3233%2Fida-183998},
	bdsk-url-2 = {https://doi.org/10.3233/ida-183998}}

@article{Hu_2021,
	author = {Danqi Hu and Charles M. Jones and Valerie Zhang and Xiaoyan Zhang},
	date-added = {2022-11-17 15:53:45 +0100},
	date-modified = {2022-11-17 15:53:45 +0100},
	doi = {10.2139/ssrn.3807655},
	journal = {{SSRN} Electronic Journal},
	publisher = {Elsevier {BV}},
	title = {The Rise of Reddit: How Social Media Affects Retail Investors and Short-sellers' Roles in Price Discovery},
	url = {https://doi.org/10.2139%2Fssrn.3807655},
	year = 2021,
	bdsk-url-1 = {https://doi.org/10.2139%2Fssrn.3807655},
	bdsk-url-2 = {https://doi.org/10.2139/ssrn.3807655}}

@article{Egger_2022,
	author = {Roman Egger and Joanne Yu},
	date-added = {2022-11-17 15:53:29 +0100},
	date-modified = {2022-11-17 15:53:29 +0100},
	doi = {10.3389/fsoc.2022.886498},
	journal = {Frontiers in Sociology},
	month = {may},
	publisher = {Frontiers Media {SA}},
	title = {A Topic Modeling Comparison Between {LDA}, {NMF}, Top2Vec, and {BERTopic} to Demystify Twitter Posts},
	url = {https://doi.org/10.3389%2Ffsoc.2022.886498},
	volume = {7},
	year = 2022,
	bdsk-url-1 = {https://doi.org/10.3389%2Ffsoc.2022.886498},
	bdsk-url-2 = {https://doi.org/10.3389/fsoc.2022.886498}}

@misc{https://doi.org/10.48550/arxiv.1910.03771,
	author = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and Davison, Joe and Shleifer, Sam and von Platen, Patrick and Ma, Clara and Jernite, Yacine and Plu, Julien and Xu, Canwen and Scao, Teven Le and Gugger, Sylvain and Drame, Mariama and Lhoest, Quentin and Rush, Alexander M.},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 15:52:34 +0100},
	date-modified = {2022-11-17 15:52:34 +0100},
	doi = {10.48550/ARXIV.1910.03771},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {HuggingFace's Transformers: State-of-the-art Natural Language Processing},
	url = {https://arxiv.org/abs/1910.03771},
	year = {2019},
	bdsk-url-1 = {https://arxiv.org/abs/1910.03771},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1910.03771}}

@article{Stier_2018,
	author = {Sebastian Stier and Arnim Bleier and Haiko Lietz and Markus Strohmaier},
	date-added = {2022-11-17 15:52:21 +0100},
	date-modified = {2022-11-17 15:52:21 +0100},
	doi = {10.1080/10584609.2017.1334728},
	journal = {Political Communication},
	month = {jan},
	number = {1},
	pages = {50--74},
	publisher = {Informa {UK} Limited},
	title = {Election Campaigning on Social Media: Politicians, Audiences, and the Mediation of Political Communication on Facebook and Twitter},
	url = {https://doi.org/10.1080%2F10584609.2017.1334728},
	volume = {35},
	year = 2018,
	bdsk-url-1 = {https://doi.org/10.1080%2F10584609.2017.1334728},
	bdsk-url-2 = {https://doi.org/10.1080/10584609.2017.1334728}}

@article{STIEGLITZ2018156,
	abstract = {Since an ever-increasing part of the population makes use of social media in their day-to-day lives, social media data is being analysed in many different disciplines. The social media analytics process involves four distinct steps, data discovery, collection, preparation, and analysis. While there is a great deal of literature on the challenges and difficulties involving specific data analysis methods, there hardly exists research on the stages of data discovery, collection, and preparation. To address this gap, we conducted an extended and structured literature analysis through which we identified challenges addressed and solutions proposed. The literature search revealed that the volume of data was most often cited as a challenge by researchers. In contrast, other categories have received less attention. Based on the results of the literature search, we discuss the most important challenges for researchers and present potential solutions. The findings are used to extend an existing framework on social media analytics. The article provides benefits for researchers and practitioners who wish to collect and analyse social media data.},
	author = {Stefan Stieglitz and Milad Mirbabaie and Bj{\"o}rn Ross and Christoph Neuberger},
	date-added = {2022-11-17 15:52:13 +0100},
	date-modified = {2022-11-17 15:52:13 +0100},
	doi = {https://doi.org/10.1016/j.ijinfomgt.2017.12.002},
	issn = {0268-4012},
	journal = {International Journal of Information Management},
	keywords = {Social media analytics, Social media, Information systems, Big data},
	pages = {156-168},
	title = {Social media analytics -- Challenges in topic discovery, data collection, and data preparation},
	url = {https://www.sciencedirect.com/science/article/pii/S0268401217308526},
	volume = {39},
	year = {2018},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0268401217308526},
	bdsk-url-2 = {https://doi.org/10.1016/j.ijinfomgt.2017.12.002}}

@inproceedings{steinskog-etal-2017-twitter,
	address = {Gothenburg, Sweden},
	author = {Steinskog, Asbj{\o}rn and Therkelsen, Jonas and Gamb{\"a}ck, Bj{\"o}rn},
	booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
	date-added = {2022-11-17 15:52:09 +0100},
	date-modified = {2022-11-17 15:52:09 +0100},
	month = may,
	pages = {77--86},
	publisher = {Association for Computational Linguistics},
	title = {{T}witter Topic Modeling by Tweet Aggregation},
	url = {https://aclanthology.org/W17-0210},
	year = {2017},
	bdsk-url-1 = {https://aclanthology.org/W17-0210}}

@inproceedings{Silveira2021TopicMO,
	author = {Raquel Silveira and Carlos G. Fernandes and Jo{\~a}o A. Monteiro Neto and Vasco Furtado and Jos{\'e} Ernesto Pimentel Filho},
	date-added = {2022-11-17 15:52:04 +0100},
	date-modified = {2022-11-17 15:52:04 +0100},
	title = {Topic Modelling of Legal Documents via LEGAL-BERT1},
	year = {2021}}

@article{PEREIRA2018359,
	abstract = {In many important application domains, such as text categorization, scene classification, biomolecular analysis and medical diagnosis, examples are naturally associated with more than one class label, giving rise to multi-label classification problems. This fact has led, in recent years, to a substantial amount of research in multi-label classification. In order to evaluate and compare multi-label classifiers, researchers have adapted evaluation measures from the single-label paradigm, like Precision and Recall; and also have developed many different measures specifically for the multi-label paradigm, like Hamming Loss and Subset Accuracy. However, these evaluation measures have been used arbitrarily in multi-label classification experiments, without an objective analysis of correlation or bias. This can lead to misleading conclusions, as the experimental results may appear to favor a specific behavior depending on the subset of measures chosen. Also, as different papers in the area currently employ distinct subsets of measures, it is difficult to compare results across papers. In this work, we provide a thorough analysis of multi-label evaluation measures, and we give concrete suggestions for researchers to make an informed decision when choosing evaluation measures for multi-label classification.},
	author = {Rafael B. Pereira and Alexandre Plastino and Bianca Zadrozny and Luiz H.C. Merschmann},
	date-added = {2022-11-17 15:51:59 +0100},
	date-modified = {2022-11-17 15:51:59 +0100},
	doi = {https://doi.org/10.1016/j.ipm.2018.01.002},
	issn = {0306-4573},
	journal = {Information Processing & Management},
	keywords = {Multi-label classification, Evaluation measures},
	number = {3},
	pages = {359-369},
	title = {Correlation analysis of performance measures for multi-label classification},
	url = {https://www.sciencedirect.com/science/article/pii/S0306457318300165},
	volume = {54},
	year = {2018},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0306457318300165},
	bdsk-url-2 = {https://doi.org/10.1016/j.ipm.2018.01.002}}

@article{Nugroho:2020aa,
	abstract = {In recent years, studies related to topic derivation in Twitter have gained a lot of interest from businesses and academics. The interconnection between users and information has made social media, especially Twitter, an ultimate platform for propagation of information about events in real time. Many applications require topic derivation from this social media platform. These include, for example, disaster management, outbreak detection, situation awareness, surveillance, and market analysis. Deriving topics from Twitter is challenging due to the short content of the individual posts. The environment itself is also highly dynamic. This paper presents a review of recent methods proposed to derive topics from social media platform from algorithms to evaluations. With regard to algorithms, we classify them based on the features they exploit, such as content, social interactions, and temporal aspects. In terms of evaluations, we discuss the datasets and metrics generally used to evaluate the methods. Finally, we highlight the gaps in the research this far and the problems that remain to be addressed.},
	author = {Nugroho, Robertus and Paris, Cecile and Nepal, Surya and Yang, Jian and Zhao, Weiliang},
	date = {2020/07/01},
	date-added = {2022-11-17 15:51:48 +0100},
	date-modified = {2022-11-17 15:51:48 +0100},
	doi = {10.1007/s10115-019-01429-z},
	id = {Nugroho2020},
	isbn = {0219-3116},
	journal = {Knowledge and Information Systems},
	number = {7},
	pages = {2485--2519},
	title = {A survey of recent methods on deriving topics from Twitter: algorithm to evaluation},
	url = {https://doi.org/10.1007/s10115-019-01429-z},
	volume = {62},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1007/s10115-019-01429-z}}

@inproceedings{nguyen-etal-2020-bertweet,
	abstract = {We present BERTweet, the first public large-scale pre-trained language model for English Tweets. Our BERTweet, having the same architecture as BERT-base (Devlin et al., 2019), is trained using the RoBERTa pre-training procedure (Liu et al., 2019). Experiments show that BERTweet outperforms strong baselines RoBERTa-base and XLM-R-base (Conneau et al., 2020), producing better performance results than the previous state-of-the-art models on three Tweet NLP tasks: Part-of-speech tagging, Named-entity recognition and text classification. We release BERTweet under the MIT License to facilitate future research and applications on Tweet data. Our BERTweet is available at https://github.com/VinAIResearch/BERTweet},
	address = {Online},
	author = {Nguyen, Dat Quoc and Vu, Thanh and Tuan Nguyen, Anh},
	booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
	date-added = {2022-11-17 15:51:32 +0100},
	date-modified = {2022-11-17 15:51:32 +0100},
	doi = {10.18653/v1/2020.emnlp-demos.2},
	month = oct,
	pages = {9--14},
	publisher = {Association for Computational Linguistics},
	title = {{BERT}weet: A pre-trained language model for {E}nglish Tweets},
	url = {https://aclanthology.org/2020.emnlp-demos.2},
	year = {2020},
	bdsk-url-1 = {https://aclanthology.org/2020.emnlp-demos.2},
	bdsk-url-2 = {https://doi.org/10.18653/v1/2020.emnlp-demos.2}}

@inproceedings{mohammad-etal-2018-semeval,
	abstract = {We present the SemEval-2018 Task 1: Affect in Tweets, which includes an array of subtasks on inferring the affectual state of a person from their tweet. For each task, we created labeled data from English, Arabic, and Spanish tweets. The individual tasks are: 1. emotion intensity regression, 2. emotion intensity ordinal classification, 3. valence (sentiment) regression, 4. valence ordinal classification, and 5. emotion classification. Seventy-five teams (about 200 team members) participated in the shared task. We summarize the methods, resources, and tools used by the participating teams, with a focus on the techniques and resources that are particularly useful. We also analyze systems for consistent bias towards a particular race or gender. The data is made freely available to further improve our understanding of how people convey emotions through language.},
	address = {New Orleans, Louisiana},
	author = {Mohammad, Saif and Bravo-Marquez, Felipe and Salameh, Mohammad and Kiritchenko, Svetlana},
	booktitle = {Proceedings of the 12th International Workshop on Semantic Evaluation},
	date-added = {2022-11-17 15:51:27 +0100},
	date-modified = {2022-11-17 15:51:27 +0100},
	doi = {10.18653/v1/S18-1001},
	month = jun,
	pages = {1--17},
	publisher = {Association for Computational Linguistics},
	title = {{S}em{E}val-2018 Task 1: Affect in Tweets},
	url = {https://aclanthology.org/S18-1001},
	year = {2018},
	bdsk-url-1 = {https://aclanthology.org/S18-1001},
	bdsk-url-2 = {https://doi.org/10.18653/v1/S18-1001}}

@misc{https://doi.org/10.48550/arxiv.1712.09405,
	author = {Mikolov, Tomas and Grave, Edouard and Bojanowski, Piotr and Puhrsch, Christian and Joulin, Armand},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 15:51:24 +0100},
	date-modified = {2022-11-17 15:51:24 +0100},
	doi = {10.48550/ARXIV.1712.09405},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Advances in Pre-Training Distributed Word Representations},
	url = {https://arxiv.org/abs/1712.09405},
	year = {2017},
	bdsk-url-1 = {https://arxiv.org/abs/1712.09405},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1712.09405}}

@misc{https://doi.org/10.48550/arxiv.2202.03829,
	author = {Loureiro, Daniel and Barbieri, Francesco and Neves, Leonardo and Anke, Luis Espinosa and Camacho-Collados, Jose},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 15:51:18 +0100},
	date-modified = {2022-11-17 15:51:18 +0100},
	doi = {10.48550/ARXIV.2202.03829},
	keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {TimeLMs: Diachronic Language Models from Twitter},
	url = {https://arxiv.org/abs/2202.03829},
	year = {2022},
	bdsk-url-1 = {https://arxiv.org/abs/2202.03829},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.2202.03829}}

@misc{https://doi.org/10.48550/arxiv.1711.05101,
	author = {Loshchilov, Ilya and Hutter, Frank},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 15:51:05 +0100},
	date-modified = {2022-11-17 15:51:05 +0100},
	doi = {10.48550/ARXIV.1711.05101},
	keywords = {Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), Optimization and Control (math.OC), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
	publisher = {arXiv},
	title = {Decoupled Weight Decay Regularization},
	url = {https://arxiv.org/abs/1711.05101},
	year = {2017},
	bdsk-url-1 = {https://arxiv.org/abs/1711.05101},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1711.05101}}

@misc{https://doi.org/10.48550/arxiv.1907.11692,
	author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 15:51:01 +0100},
	date-modified = {2022-11-17 15:51:01 +0100},
	doi = {10.48550/ARXIV.1907.11692},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
	url = {https://arxiv.org/abs/1907.11692},
	year = {2019},
	bdsk-url-1 = {https://arxiv.org/abs/1907.11692},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1907.11692}}

@misc{https://doi.org/10.48550/arxiv.2102.01951,
	author = {Lazaridou, Angeliki and Kuncoro, Adhiguna and Gribovskaya, Elena and Agrawal, Devang and Liska, Adam and Terzi, Tayfun and Gimenez, Mai and d'Autume, Cyprien de Masson and Kocisky, Tomas and Ruder, Sebastian and Yogatama, Dani and Cao, Kris and Young, Susannah and Blunsom, Phil},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 15:50:56 +0100},
	date-modified = {2022-11-17 15:50:56 +0100},
	doi = {10.48550/ARXIV.2102.01951},
	keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Mind the Gap: Assessing Temporal Generalization in Neural Language Models},
	url = {https://arxiv.org/abs/2102.01951},
	year = {2021},
	bdsk-url-1 = {https://arxiv.org/abs/2102.01951},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.2102.01951}}

@misc{https://doi.org/10.48550/arxiv.2203.05794,
	author = {Grootendorst, Maarten},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 15:50:35 +0100},
	date-modified = {2022-11-17 15:50:35 +0100},
	doi = {10.48550/ARXIV.2203.05794},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {BERTopic: Neural topic modeling with a class-based TF-IDF procedure},
	url = {https://arxiv.org/abs/2203.05794},
	year = {2022},
	bdsk-url-1 = {https://arxiv.org/abs/2203.05794},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.2203.05794}}

@article{ELAKROUCHI2021106650,
	abstract = {An extremely competitive business environment requires every company to monitor its competitors and anticipate future opportunities and risks, creating a dire need for competitive intelligence. In response to this need, foresight study became a prominent field, especially the concept of weak signal detection. This research area has been widely studied for its utility, but it is limited by the need of human expert judgments on these signals. Moreover, the increase in the volume of information on the Internet through blogs and web news has made the detection process difficult, which has created a need for automation. Recent studies have attempted topic modeling techniques, specifically latent Dirichlet allocation (LDA), for automating the weak signal detection process; however, these approaches do not cover all parts of the process. In this study, we propose a fully automatic LDA-based weak signal detection method, consisting of two filtering functions: the weakness function aimed at filtering topics, which potentially contains weak signals, and the potential warning function, which helps to extract only early warning signs from the previously filtered topics. We took this approach with a famous daily web news dataset, and we could detect the risk of the COVID19 pandemic at an early stage.},
	author = {Manal {El Akrouchi} and Houda Benbrahim and Ismail Kassou},
	date-added = {2022-11-17 15:50:23 +0100},
	date-modified = {2022-11-17 15:50:23 +0100},
	doi = {https://doi.org/10.1016/j.knosys.2020.106650},
	issn = {0950-7051},
	journal = {Knowledge-Based Systems},
	keywords = {Weak signals, Topic modeling, Latent Dirichlet allocation},
	pages = {106650},
	title = {End-to-end LDA-based automatic weak signal detection in web news},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705120307796},
	volume = {212},
	year = {2021},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0950705120307796},
	bdsk-url-2 = {https://doi.org/10.1016/j.knosys.2020.106650}}

@article{Eid2020InternetUA,
	author = {Mohammad Al Haj Eid and Nawras M. Nusairat and Mahmud Alkailani and Hamad Rashid Al-ghadeer},
	date-added = {2022-11-17 15:50:17 +0100},
	date-modified = {2022-11-17 15:50:17 +0100},
	journal = {Management Science Letters},
	pages = {2361-2370},
	title = {Internet users' attitudes towards social media advertisements: The role of advertisement design and users' motives},
	volume = {10},
	year = {2020}}

@misc{https://doi.org/10.48550/arxiv.1810.04805,
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 15:50:04 +0100},
	date-modified = {2022-11-17 15:50:04 +0100},
	doi = {10.48550/ARXIV.1810.04805},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	url = {https://arxiv.org/abs/1810.04805},
	year = {2018},
	bdsk-url-1 = {https://arxiv.org/abs/1810.04805},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1810.04805}}

@inproceedings{chakravarthi-2020-hopeedi,
	abstract = {Over the past few years, systems have been developed to control online content and eliminate abusive, offensive or hate speech content. However, people in power sometimes misuse this form of censorship to obstruct the democratic right of freedom of speech. Therefore, it is imperative that research should take a positive reinforcement approach towards online content that is encouraging, positive and supportive contents. Until now, most studies have focused on solving this problem of negativity in the English language, though the problem is much more than just harmful content. Furthermore, it is multilingual as well. Thus, we have constructed a Hope Speech dataset for Equality, Diversity and Inclusion (HopeEDI) containing user-generated comments from the social media platform YouTube with 28,451, 20,198 and 10,705 comments in English, Tamil and Malayalam, respectively, manually labelled as containing hope speech or not. To our knowledge, this is the first research of its kind to annotate hope speech for equality, diversity and inclusion in a multilingual setting. We determined that the inter-annotator agreement of our dataset using Krippendorff{'}s alpha. Further, we created several baselines to benchmark the resulting dataset and the results have been expressed using precision, recall and F1-score. The dataset is publicly available for the research community. We hope that this resource will spur further research on encouraging inclusive and responsive speech that reinforces positiveness.},
	address = {Barcelona, Spain (Online)},
	author = {Chakravarthi, Bharathi Raja},
	booktitle = {Proceedings of the Third Workshop on Computational Modeling of People's Opinions, Personality, and Emotion's in Social Media},
	date-added = {2022-11-17 15:49:59 +0100},
	date-modified = {2022-11-17 15:49:59 +0100},
	month = dec,
	pages = {41--53},
	publisher = {Association for Computational Linguistics},
	title = {{H}ope{EDI}: A Multilingual Hope Speech Detection Dataset for Equality, Diversity, and Inclusion},
	url = {https://aclanthology.org/2020.peoples-1.5},
	year = {2020},
	bdsk-url-1 = {https://aclanthology.org/2020.peoples-1.5}}

@misc{https://doi.org/10.48550/arxiv.2206.14774,
	author = {Camacho-Collados, Jose and Rezaee, Kiamehr and Riahi, Talayeh and Ushio, Asahi and Loureiro, Daniel and Antypas, Dimosthenis and Boisson, Joanne and Espinosa-Anke, Luis and Liu, Fangyu and Mart{\'\i}nez-C{\'a}mara, Eugenio and Medina, Gonzalo and Buhrmann, Thomas and Neves, Leonardo and Barbieri, Francesco},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 15:49:55 +0100},
	date-modified = {2022-11-17 15:49:55 +0100},
	doi = {10.48550/ARXIV.2206.14774},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {TweetNLP: Cutting-Edge Natural Language Processing for Social Media},
	url = {https://arxiv.org/abs/2206.14774},
	year = {2022},
	bdsk-url-1 = {https://arxiv.org/abs/2206.14774},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.2206.14774}}

@article{https://doi.org/10.48550/arxiv.2004.03688,
	author = {Banda, Juan M. and Tekumalla, Ramya and Wang, Guanyu and Yu, Jingyuan and Liu, Tuo and Ding, Yuning and Artemova, Katya and Tutubalina, Elena and Chowell, Gerardo},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 15:49:51 +0100},
	date-modified = {2022-11-17 15:49:51 +0100},
	doi = {10.48550/ARXIV.2004.03688},
	keywords = {Social and Information Networks (cs.SI), Information Retrieval (cs.IR), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {A large-scale COVID-19 Twitter chatter dataset for open scientific research -- an international collaboration},
	url = {https://arxiv.org/abs/2004.03688},
	year = {2020},
	bdsk-url-1 = {https://arxiv.org/abs/2004.03688},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.2004.03688}}

@misc{https://doi.org/10.48550/arxiv.2008.09470,
	author = {Angelov, Dimo},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 15:49:39 +0100},
	date-modified = {2022-11-17 15:49:39 +0100},
	doi = {10.48550/ARXIV.2008.09470},
	keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Top2Vec: Distributed Representations of Topics},
	url = {https://arxiv.org/abs/2008.09470},
	year = {2020},
	bdsk-url-1 = {https://arxiv.org/abs/2008.09470},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.2008.09470}}

@article{ABUZAYED2021191,
	abstract = {Topic modeling is an unsupervised machine learning technique for finding abstract topics in a large collection of documents. It helps in organizing, understanding and summarizing large collections of textual information and discovering the latent topics that vary among documents in a given corpus. Latent Dirichlet allocation (LDA) and Non-Negative Matrix Factorization (NMF) are two of the most popular topic modeling techniques. LDA uses a probabilistic approach whereas NMF uses matrix factorization approach, however, new techniques that are based on BERT for topic modeling do exist. In this paper, we aim to experiment with BERTopic using different Pre-Trained Arabic Language Models as embeddings, and compare its results against LDA and NMF techniques. We used Normalized Pointwise Mutual Information (NPMI) measure to evaluate the results of topic modeling techniques. The overall results generated by BERTopic showed better results compared to NMF and LDA.},
	author = {Abeer Abuzayed and Hend Al-Khalifa},
	date-added = {2022-11-17 15:49:33 +0100},
	date-modified = {2022-11-17 15:49:33 +0100},
	doi = {https://doi.org/10.1016/j.procs.2021.05.096},
	issn = {1877-0509},
	journal = {Procedia Computer Science},
	keywords = {Topic modeling, BERT, BERTopic, LDA, NMF, NPMI, Arabic Language},
	note = {AI in Computational Linguistics},
	pages = {191-194},
	title = {BERT for Arabic Topic Modeling: An Experimental Study on BERTopic Technique},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050921012199},
	volume = {189},
	year = {2021},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S1877050921012199},
	bdsk-url-2 = {https://doi.org/10.1016/j.procs.2021.05.096}}
