%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Samuele Ceol at 2022-11-18 18:15:19 +0100 


%% Saved with string encoding Unicode (UTF-8) 



@article{zhang_2017_processing_long_queries_against_short_text_top_k_advertisement_matching_in_news_stream_applications,
	abstract = {Many real applications in real-time news stream advertising call for efficient processing of long queries against short text. In such applications, dynamic news feeds are regarded as queries to match against an advertisement (ad) database for retrieving the k most relevant ads. The existing approaches to keyword retrieval cannot work well in this search scenario when queries are triggered at a very high frequency. To address the problem, we introduce new techniques to significantly improve search performance. First, we devise a two-level partitioning for tight upper bound estimation and a lazy evaluation scheme to delay full evaluation of unpromising candidates, which can bring three to four times performance boosting in a database with 7 million ads. Second, we propose a novel rank-aware block-oriented inverted index to further improve performance. In this index scheme, each entry in an inverted list is assigned a rank according to its importance in the ad. Then, we introduce a block-at-a-time search strategy based on the index scheme to support a much tighter upper bound estimation and a very early termination. We have conducted experiments with real datasets, and the results show that the rank-aware method can further improve performance by an order of magnitude.},
	address = {New York, NY, USA},
	articleno = {28},
	author = {Zhang, Dongxiang and Li, Yuchen and Fan, Ju and Gao, Lianli and Shen, Fumin and Shen, Heng Tao},
	date-added = {2022-11-18 18:15:16 +0100},
	date-modified = {2022-11-18 18:15:16 +0100},
	doi = {zhang_2017_processing_long_queries_against_short_text_top_k_advertisement_matching_in_news_stream_applications},
	issn = {1046-8188},
	issue_date = {July 2017},
	journal = {ACM Trans. Inf. Syst.},
	keywords = {inverted index, short text, rank-aware partitioning, Long queries, top-k retrieval},
	month = {may},
	number = {3},
	numpages = {27},
	publisher = {Association for Computing Machinery},
	title = {Processing Long Queries Against Short Text: Top-k Advertisement Matching in News Stream Applications},
	url = {https://doi.org/10.1145/3052772},
	volume = {35},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3052772}}

@article{xuan_2017_explicitly_and_implicitly_exploiting_the_hierarchical_structure_for_mining_website_interests_on_news_events,
	author = {Junyu Xuan and Xiangfeng Luo and Jie Lu and Guangquan Zhang},
	date-added = {2022-11-18 18:15:10 +0100},
	date-modified = {2022-11-18 18:15:10 +0100},
	doi = {10.1016/j.ins.2017.08.056},
	journal = {Information Sciences},
	month = {dec},
	pages = {263--277},
	publisher = {Elsevier {BV}},
	title = {Explicitly and implicitly exploiting the hierarchical structure for mining website interests on news events},
	url = {https://doi.org/10.1016%2Fj.ins.2017.08.056},
	volume = {420},
	year = 2017,
	bdsk-url-1 = {https://doi.org/10.1016/j.ins.2017.08.056}}

@article{xu_2017_incorporating_wikipedia_concepts_and_categories_as_prior_knowledge_into_topic_models,
	abstractnote = {Topic models have been widely applied in discovering topics that underly a collection of documents. Incorporating human knowledge can guide conventional topic models to produce topics which are easily interpreted and semantically coherent. Several knowledge-based topic models have been proposed, but these models just leverage lexical knowledge of words that are often not in accordance with topics. To solve the problem, we recognize entity mentions, besides words, in the documents and incorporate entity knowledge from external knowledge bases. In this paper, we study to utilize entity knowledge, concepts and categories in Wikipedia, as prior knowledge into topic models to discover more coherent topics. A novel knowledge-based topic model, WCM-LDA (Wikipedia-Category-concept-Mention Latent Dirichlet Allocation), is proposed, which not only models the relationship between words and topics, but also utilizes concept and category knowledge of entities to model the semantic relation of entities and topics. We compare WCM-LDA with the state-of-the-art knowledge-based topic models, on three datasets. Experimental results show that our approach outperforms the existing baseline methods on all three datasets. Moreover, our model can visualize topics with top words, concepts and categories such that topics are made easily to be interpreted and classified.},
	author = {Xu, Kang and Qi, Guilin and Huang, Junheng and Wu, Tianxing},
	date-added = {2022-11-18 18:14:59 +0100},
	date-modified = {2022-11-18 18:14:59 +0100},
	doi = {10.3233/IDA-160021},
	issn = {1088467X, 15714128},
	journal = {Intelligent Data Analysis},
	month = {Mar},
	number = {2},
	pages = {443--461},
	place = {NL},
	publisher = {IOS Press},
	title = {Incorporating Wikipedia concepts and categories as prior knowledge into topic models},
	url = {https://doi.org/10.3233/IDA-160021},
	volume = {21},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.3233/IDA-160021}}
