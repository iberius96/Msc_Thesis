%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Samuele Ceol at 2022-11-18 15:38:52 +0100 


%% Saved with string encoding Unicode (UTF-8) 



@inproceedings{10.1145/3336191.3371770,
	abstract = {User representation learning is vital to capture diverse user preferences, while it is also challenging as user intents are latent and scattered among complex and different modalities of user-generated data, thus, not directly measurable. Inspired by the concept of user schema in social psychology, we take a new perspective to perform user representation learning by constructing a shared latent space to capture the dependency among different modalities of user-generated data. Both users and topics are embedded to the same space to encode users' social connections and text content, to facilitate joint modeling of different modalities, via a probabilistic generative framework. We evaluated the proposed solution on large collections of Yelp reviews and StackOverflow discussion posts, with their associated network structures. The proposed model outperformed several state-of-the-art topic modeling based user models with better predictive power in unseen documents, and state-of-the-art network embedding based user models with improved link prediction quality in unseen nodes. The learnt user representations are also proved to be useful in content recommendation, e.g., expert finding in StackOverflow.},
	address = {New York, NY, USA},
	author = {Gong, Lin and Lin, Lu and Song, Weihao and Wang, Hongning},
	booktitle = {Proceedings of the 13th International Conference on Web Search and Data Mining},
	date-added = {2022-11-18 15:38:47 +0100},
	date-modified = {2022-11-18 15:38:47 +0100},
	doi = {10.1145/3336191.3371770},
	isbn = {9781450368223},
	keywords = {social networks, topic modeling, representation learning, network embedding},
	location = {Houston, TX, USA},
	numpages = {9},
	pages = {205--213},
	publisher = {Association for Computing Machinery},
	series = {WSDM '20},
	title = {JNET: Learning User Representations via Joint Network Embedding and Topic Embedding},
	url = {https://doi.org/10.1145/3336191.3371770},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1145/3336191.3371770}}

@article{Hyun_2019,
	author = {Dongmin Hyun and Chanyoung Park and Min-Chul Yang and Ilhyeon Song and Jung-Tae Lee and Hwanjo Yu},
	date-added = {2022-11-18 15:38:42 +0100},
	date-modified = {2022-11-18 15:38:42 +0100},
	doi = {10.1016/j.ins.2019.03.076},
	journal = {Information Sciences},
	month = {jul},
	pages = {166--178},
	publisher = {Elsevier {BV}},
	title = {Target-aware convolutional neural network for target-level sentiment analysis},
	url = {https://doi.org/10.1016%2Fj.ins.2019.03.076},
	volume = {491},
	year = 2019,
	bdsk-url-1 = {https://doi.org/10.1016/j.ins.2019.03.076}}

@article{Wan_2020,
	author = {Changxuan Wan and Yun Peng and Keli Xiao and Xiping Liu and Tengjiao Jiang and Dexi Liu},
	date-added = {2022-11-18 15:38:39 +0100},
	date-modified = {2022-11-18 15:38:39 +0100},
	doi = {10.1016/j.ins.2020.01.036},
	journal = {Information Sciences},
	month = {may},
	pages = {243--259},
	publisher = {Elsevier {BV}},
	title = {An association-constrained {LDA} model for joint extraction of product aspects and opinions},
	url = {https://doi.org/10.1016%2Fj.ins.2020.01.036},
	volume = {519},
	year = 2020,
	bdsk-url-1 = {https://doi.org/10.1016/j.ins.2020.01.036}}

@article{Ozyurt_2021,
	author = {Baris Ozyurt and M. Ali Akcayol},
	date-added = {2022-11-18 15:38:35 +0100},
	date-modified = {2022-11-18 15:38:35 +0100},
	doi = {10.1016/j.eswa.2020.114231},
	journal = {Expert Systems with Applications},
	month = {apr},
	pages = {114231},
	publisher = {Elsevier {BV}},
	title = {A new topic modeling based approach for aspect extraction in aspect based sentiment analysis: {SS}-{LDA}},
	url = {https://doi.org/10.1016%2Fj.eswa.2020.114231},
	volume = {168},
	year = 2021,
	bdsk-url-1 = {https://doi.org/10.1016/j.eswa.2020.114231}}

@article{Dong_2018,
	author = {Lu-yu Dong and Shu-juan Ji and Chun-jin Zhang and Qi Zhang and DicksonK.W. Chiu and Li-qing Qiu and Da Li},
	date-added = {2022-11-18 15:38:31 +0100},
	date-modified = {2022-11-18 15:38:31 +0100},
	doi = {10.1016/j.eswa.2018.07.005},
	journal = {Expert Systems with Applications},
	month = {dec},
	pages = {210--223},
	publisher = {Elsevier {BV}},
	title = {An unsupervised topic-sentiment joint probabilistic model for detecting deceptive reviews},
	url = {https://doi.org/10.1016%2Fj.eswa.2018.07.005},
	volume = {114},
	year = 2018,
	bdsk-url-1 = {https://doi.org/10.1016/j.eswa.2018.07.005}}

@article{Tang_2019,
	author = {Feilong Tang and Luoyi Fu and Bin Yao and Wenchao Xu},
	date-added = {2022-11-18 15:38:27 +0100},
	date-modified = {2022-11-18 15:38:27 +0100},
	doi = {10.1016/j.ins.2019.02.064},
	journal = {Information Sciences},
	month = {jul},
	pages = {190--204},
	publisher = {Elsevier {BV}},
	title = {Aspect based fine-grained sentiment analysis for online reviews},
	url = {https://doi.org/10.1016%2Fj.ins.2019.02.064},
	volume = {488},
	year = 2019,
	bdsk-url-1 = {https://doi.org/10.1016/j.ins.2019.02.064}}

@article{Garc_a_Pablos_2018,
	author = {Aitor Garc{\'{\i}}a-Pablos and Montse Cuadros and German Rigau},
	date-added = {2022-11-18 15:38:24 +0100},
	date-modified = {2022-11-18 15:38:24 +0100},
	doi = {10.1016/j.eswa.2017.08.049},
	journal = {Expert Systems with Applications},
	month = {jan},
	pages = {127--137},
	publisher = {Elsevier {BV}},
	title = {W2VLDA: Almost unsupervised system for Aspect Based Sentiment Analysis},
	url = {https://doi.org/10.1016%2Fj.eswa.2017.08.049},
	volume = {91},
	year = 2018,
	bdsk-url-1 = {https://doi.org/10.1016/j.eswa.2017.08.049}}

@article{Fu_2018,
	author = {Xianghua Fu and Xudong Sun and Haiying Wu and Laizhong Cui and Joshua Zhexue Huang},
	date-added = {2022-11-18 15:38:20 +0100},
	date-modified = {2022-11-18 15:38:20 +0100},
	doi = {10.1016/j.knosys.2018.02.012},
	journal = {Knowledge-Based Systems},
	month = {may},
	pages = {43--54},
	publisher = {Elsevier {BV}},
	title = {Weakly supervised topic sentiment joint model with word embeddings},
	url = {https://doi.org/10.1016%2Fj.knosys.2018.02.012},
	volume = {147},
	year = 2018,
	bdsk-url-1 = {https://doi.org/10.1016/j.knosys.2018.02.012}}

@article{shen2021topic,
	author = {Shen, Dazhong and Qin, Chuan and Wang, Chao and Dong, Zheng and Zhu, Hengshu and Xiong, Hui},
	date-added = {2022-11-18 15:38:03 +0100},
	date-modified = {2022-11-18 15:38:03 +0100},
	journal = {Advances in Neural Information Processing Systems},
	pages = {14681--14693},
	title = {Topic Modeling Revisited: A Document Graph-based Neural Network Perspective},
	volume = {34},
	year = {2021}}

@article{Amplayo_2018,
	author = {Reinald Kim Amplayo and Seanie Lee and Min Song},
	date-added = {2022-11-18 15:37:57 +0100},
	date-modified = {2022-11-18 15:37:57 +0100},
	doi = {10.1016/j.ins.2018.04.079},
	journal = {Information Sciences},
	month = {jul},
	pages = {200--215},
	publisher = {Elsevier {BV}},
	title = {Incorporating product description to sentiment topic models for improved aspect-based sentiment analysis},
	url = {https://doi.org/10.1016%2Fj.ins.2018.04.079},
	volume = {454-455},
	year = 2018,
	bdsk-url-1 = {https://doi.org/10.1016/j.ins.2018.04.079}}

@article{Xiong_2018,
	author = {Shufeng Xiong and Kuiyi Wang and Donghong Ji and Bingkun Wang},
	date-added = {2022-11-18 15:37:51 +0100},
	date-modified = {2022-11-18 15:37:51 +0100},
	doi = {10.1016/j.neucom.2018.02.034},
	journal = {Neurocomputing},
	month = {jul},
	pages = {94--102},
	publisher = {Elsevier {BV}},
	title = {A short text sentiment-topic model for product reviews},
	url = {https://doi.org/10.1016%2Fj.neucom.2018.02.034},
	volume = {297},
	year = 2018,
	bdsk-url-1 = {https://doi.org/10.1016/j.neucom.2018.02.034}}

@article{sengupta2021ljst,
	author = {Sengupta, Ayan and Roy, Suman and Ranjan, Gaurav},
	date-added = {2022-11-18 15:37:48 +0100},
	date-modified = {2022-11-18 15:37:48 +0100},
	journal = {SN Computer Science},
	number = {4},
	pages = {1--16},
	publisher = {Springer},
	title = {LJST: a semi-supervised joint sentiment-topic model for short texts},
	volume = {2},
	year = {2021}}

@article{Chen_2020,
	author = {Xiaojun Chen and Shengbin Jia and Yang Xiang},
	date-added = {2022-11-18 15:37:41 +0100},
	date-modified = {2022-11-18 15:37:41 +0100},
	doi = {10.1016/j.eswa.2019.112948},
	journal = {Expert Systems with Applications},
	month = {mar},
	pages = {112948},
	publisher = {Elsevier {BV}},
	title = {A review: Knowledge reasoning over knowledge graph},
	url = {https://doi.org/10.1016%2Fj.eswa.2019.112948},
	volume = {141},
	year = 2020,
	bdsk-url-1 = {https://doi.org/10.1016/j.eswa.2019.112948}}

@inproceedings{wang2021fastsgg,
	author = {Wang, Chaokun and Wang, Binbin and Huang, Bingyang and Song, Shaoxu and Li, Zai},
	booktitle = {2021 IEEE 37th International Conference on Data Engineering (ICDE)},
	date-added = {2022-11-18 15:37:37 +0100},
	date-modified = {2022-11-18 15:37:37 +0100},
	organization = {IEEE},
	pages = {564--575},
	title = {FastSGG: efficient social graph generation using a degree distribution generation model},
	year = {2021}}

@article{Shanavas:2021aa,
	abstract = {Automatic text classification using machine learning is significantly affected by the text representation model. The structural information in text is necessary for natural language understanding, which is usually ignored in vector-based representations. In this paper, we present a graph kernel-based text classification framework which utilises the structural information in text effectively through the weighting and enrichment of a graph-based representation. We introduce weighted co-occurrence graphs to represent text documents, which weight the terms and their dependencies based on their relevance to text classification. We propose a novel method to automatically enrich the weighted graphs using semantic knowledge in the form of a word similarity matrix. The similarity between enriched graphs, knowledge-driven graph similarity, is calculated using a graph kernel. The semantic knowledge in the enriched graphs ensures that the graph kernel goes beyond exact matching of terms and patterns to compute the semantic similarity of documents. In the experiments on sentiment classification and topic classification tasks, our knowledge-driven similarity measure significantly outperforms the baseline text similarity measures on five benchmark text classification datasets.},
	author = {Shanavas, Niloofer and Wang, Hui and Lin, Zhiwei and Hawe, Glenn},
	date = {2021/04/01},
	date-added = {2022-11-18 15:37:30 +0100},
	date-modified = {2022-11-18 15:37:30 +0100},
	doi = {10.1007/s13042-020-01221-4},
	id = {Shanavas2021},
	isbn = {1868-808X},
	journal = {International Journal of Machine Learning and Cybernetics},
	number = {4},
	pages = {1067--1081},
	title = {Knowledge-driven graph similarity for text classification},
	url = {https://doi.org/10.1007/s13042-020-01221-4},
	volume = {12},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1007/s13042-020-01221-4}}

@article{Zhou_2022,
	author = {Tao Zhou and Kris M.Y. Law},
	date-added = {2022-11-18 15:37:24 +0100},
	date-modified = {2022-11-18 15:37:24 +0100},
	doi = {10.1016/j.eswa.2022.116560},
	journal = {Expert Systems with Applications},
	month = {jun},
	pages = {116560},
	publisher = {Elsevier {BV}},
	title = {Semantic Relatedness Enhanced Graph Network for aspect category sentiment analysis},
	url = {https://doi.org/10.1016%2Fj.eswa.2022.116560},
	volume = {195},
	year = 2022,
	bdsk-url-1 = {https://doi.org/10.1016/j.eswa.2022.116560}}

@article{chen2020graph,
	author = {Chen, Fenxiao and Wang, Yun-Cheng and Wang, Bin and Kuo, C-C Jay},
	date-added = {2022-11-18 15:37:20 +0100},
	date-modified = {2022-11-18 15:37:20 +0100},
	journal = {APSIPA Transactions on Signal and Information Processing},
	publisher = {Cambridge University Press},
	title = {Graph representation learning: a survey},
	volume = {9},
	year = {2020}}

@article{Goyal_2018,
	author = {Palash Goyal and Emilio Ferrara},
	date-added = {2022-11-18 15:37:12 +0100},
	date-modified = {2022-11-18 15:37:12 +0100},
	doi = {10.1016/j.knosys.2018.03.022},
	journal = {Knowledge-Based Systems},
	month = {jul},
	pages = {78--94},
	publisher = {Elsevier {BV}},
	title = {Graph embedding techniques, applications, and performance: A survey},
	url = {https://doi.org/10.1016%2Fj.knosys.2018.03.022},
	volume = {151},
	year = 2018,
	bdsk-url-1 = {https://doi.org/10.1016/j.knosys.2018.03.022}}

@inproceedings{10.1145/3219819.3219947,
	abstract = {Convolutional neural networks (CNNs) have achieved great success on grid-like data such as images, but face tremendous challenges in learning from more generic data such as graphs. In CNNs, the trainable local filters enable the automatic extraction of high-level features. The computation with filters requires a fixed number of ordered units in the receptive fields. However, the number of neighboring units is neither fixed nor are they ordered in generic graphs, thereby hindering the applications of convolutional operations. Here, we address these challenges by proposing the learnable graph convolutional layer (LGCL). LGCL automatically selects a fixed number of neighboring nodes for each feature based on value ranking in order to transform graph data into grid-like structures in 1-D format, thereby enabling the use of regular convolutional operations on generic graphs. To enable model training on large-scale graphs, we propose a sub-graph training method to reduce the excessive memory and computational resource requirements suffered by prior methods on graph convolutions. Our experimental results on node classification tasks in both transductive and inductive learning settings demonstrate that our methods can achieve consistently better performance on the Cora, Citeseer, Pubmed citation network, and protein-protein interaction network datasets. Our results also indicate that the proposed methods using sub-graph training strategy are more efficient as compared to prior approaches.},
	address = {New York, NY, USA},
	author = {Gao, Hongyang and Wang, Zhengyang and Ji, Shuiwang},
	booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
	date-added = {2022-11-18 15:37:06 +0100},
	date-modified = {2022-11-18 15:37:06 +0100},
	doi = {10.1145/3219819.3219947},
	isbn = {9781450355520},
	keywords = {graph mining, large-scale learning, deep learning, graph convolutional networks},
	location = {London, United Kingdom},
	numpages = {9},
	pages = {1416--1424},
	publisher = {Association for Computing Machinery},
	series = {KDD '18},
	title = {Large-Scale Learnable Graph Convolutional Networks},
	url = {https://doi.org/10.1145/3219819.3219947},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1145/3219819.3219947}}

@article{Gao_2017,
	author = {Shengxiang Gao and Xian Li and Zhengtao Yu and Yu Qin and Yang Zhang},
	date-added = {2022-11-18 15:37:01 +0100},
	date-modified = {2022-11-18 15:37:01 +0100},
	doi = {10.1016/j.neucom.2016.12.074},
	journal = {Neurocomputing},
	month = {sep},
	pages = {136--143},
	publisher = {Elsevier {BV}},
	title = {Combining paper cooperative network and topic model for expert topic analysis and extraction},
	url = {https://doi.org/10.1016%2Fj.neucom.2016.12.074},
	volume = {257},
	year = 2017,
	bdsk-url-1 = {https://doi.org/10.1016/j.neucom.2016.12.074}}

@inproceedings{10.1145/3394486.3403150,
	abstract = {Graph Convolutional Networks (GCNs) achieved tremendous success by effectively gathering local features for nodes. However, commonly do GCNs focus more on node features but less on graph structures within the neighborhood, especially higher-order structural patterns. However, such local structural patterns are shown to be indicative of node properties in numerous fields. In addition, it is not just single patterns, but the distribution over all these patterns matter, because networks are complex and the neighborhood of each node consists of a mixture of various nodes and structural patterns. Correspondingly, in this paper, we propose Graph Structural topic Neural Network, abbreviated GraphSTONE 1, a GCN model that utilizes topic models of graphs, such that the structural topics capture indicative graph structures broadly from a probabilistic aspect rather than merely a few structures. Specifically, we build topic models upon graphs using anonymous walks and Graph Anchor LDA, an LDA variant that selects significant structural patterns first, so as to alleviate the complexity and generate structural topics efficiently. In addition, we design multi-view GCNs to unify node features and structural topic features and utilize structural topics to guide the aggregation. We evaluate our model through both quantitative and qualitative experiments, where our model exhibits promising performance, high efficiency, and clear interpretability.},
	address = {New York, NY, USA},
	author = {Long, Qingqing and Jin, Yilun and Song, Guojie and Li, Yi and Lin, Wei},
	booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
	date-added = {2022-11-18 15:36:57 +0100},
	date-modified = {2022-11-18 15:36:57 +0100},
	doi = {10.1145/3394486.3403150},
	isbn = {9781450379984},
	keywords = {topic modeling, structural GCN, graph convolutional network, local structural patterns},
	location = {Virtual Event, CA, USA},
	numpages = {9},
	pages = {1065--1073},
	publisher = {Association for Computing Machinery},
	series = {KDD '20},
	title = {Graph Structural-Topic Neural Network},
	url = {https://doi.org/10.1145/3394486.3403150},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1145/3394486.3403150}}

@article{van2022graph,
	author = {Van Linh, Ngo and Bach, Tran Xuan and Than, Khoat},
	date-added = {2022-11-18 15:36:51 +0100},
	date-modified = {2022-11-18 15:36:51 +0100},
	journal = {Neurocomputing},
	pages = {345--359},
	publisher = {Elsevier},
	title = {A graph convolutional topic model for short and noisy text streams},
	volume = {468},
	year = {2022}}

@misc{https://doi.org/10.48550/arxiv.1711.07553,
	author = {Bresson, Xavier and Laurent, Thomas},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-18 15:36:44 +0100},
	date-modified = {2022-11-18 15:36:44 +0100},
	doi = {10.48550/ARXIV.1711.07553},
	keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Residual Gated Graph ConvNets},
	url = {https://arxiv.org/abs/1711.07553},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.48550/arXiv.1711.07553}}

@misc{https://doi.org/10.48550/arxiv.1801.10247,
	author = {Chen, Jie and Ma, Tengfei and Xiao, Cao},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-18 15:36:41 +0100},
	date-modified = {2022-11-18 15:36:41 +0100},
	doi = {10.48550/ARXIV.1801.10247},
	keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling},
	url = {https://arxiv.org/abs/1801.10247},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.48550/arXiv.1801.10247}}

@article{huang2018adaptive,
	author = {Huang, Wenbing and Zhang, Tong and Rong, Yu and Huang, Junzhou},
	date-added = {2022-11-18 15:36:37 +0100},
	date-modified = {2022-11-18 15:36:37 +0100},
	journal = {Advances in neural information processing systems},
	title = {Adaptive sampling towards fast graph representation learning},
	volume = {31},
	year = {2018}}

@inproceedings{10.1145/3132847.3132942,
	abstract = {Determining appropriate statistical distributions for modeling text corpora is important for accurate estimation of numerical characteristics. Based on the validity of the test on a claim that the data conforms to Poisson distribution we propose Poisson decomposition model (PDM), a statistical model for modeling count data of text corpora, which can straightly capture each document's multidimensional numerical characteristics on topics. In PDM, each topic is represented as a parameter vector with multidimensional Poisson distribution, which can be easily normalized to multinomial term probabilities and each document is represented as measurements on topics and thereby reduced to a measurement vector on topics. We use gradient descent methods and sampling algorithm for parameter estimation. We carry out extensive experiments on the topics produced by our models. The results demonstrate our approach can extract more coherent topics and is competitive in document clustering by using the PDM-based features, compared to PLSI and LDA.},
	address = {New York, NY, USA},
	author = {Jiang, Haixin and Zhou, Rui and Zhang, Limeng and Wang, Hua and Zhang, Yanchun},
	booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
	date-added = {2022-11-18 15:36:31 +0100},
	date-modified = {2022-11-18 15:36:31 +0100},
	doi = {10.1145/3132847.3132942},
	isbn = {9781450349185},
	keywords = {topic coherence, statistical testing, poisson decomposition, text classification, topic model},
	location = {Singapore, Singapore},
	numpages = {10},
	pages = {1489--1498},
	publisher = {Association for Computing Machinery},
	series = {CIKM '17},
	title = {A Topic Model Based on Poisson Decomposition},
	url = {https://doi.org/10.1145/3132847.3132942},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3132847.3132942}}

@article{mukherjee2020uncertainty,
	author = {Mukherjee, Subhabrata and Awadallah, Ahmed},
	date-added = {2022-11-18 15:36:27 +0100},
	date-modified = {2022-11-18 15:36:27 +0100},
	journal = {Advances in Neural Information Processing Systems},
	pages = {21199--21212},
	title = {Uncertainty-aware self-training for few-shot text classification},
	volume = {33},
	year = {2020}}

@article{Qian_2018,
	author = {Pengjiang Qian and Chen Xi and Min Xu and Yizhang Jiang and Kuan-Hao Su and Shitong Wang and Raymond F. Muzic},
	date-added = {2022-11-18 15:36:19 +0100},
	date-modified = {2022-11-18 15:36:19 +0100},
	doi = {10.1016/j.ins.2017.08.093},
	journal = {Information Sciences},
	month = {jan},
	pages = {51--76},
	publisher = {Elsevier {BV}},
	title = {{SSC}-{EKE}: Semi-supervised classification with extensive knowledge exploitation},
	url = {https://doi.org/10.1016%2Fj.ins.2017.08.093},
	volume = {422},
	year = 2018,
	bdsk-url-1 = {https://doi.org/10.1016/j.ins.2017.08.093}}

@inproceedings{lin2020shoestring,
	author = {Lin, Wanyu and Gao, Zhaolin and Li, Baochun},
	booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	date-added = {2022-11-18 15:36:15 +0100},
	date-modified = {2022-11-18 15:36:15 +0100},
	pages = {4174--4182},
	title = {Shoestring: Graph-based semi-supervised classification with severely limited labeled data},
	year = {2020}}

@inproceedings{shen-etal-2021-taxoclass,
	abstract = {Hierarchical multi-label text classification (HMTC) aims to tag each document with a set of classes from a taxonomic class hierarchy. Most existing HMTC methods train classifiers using massive human-labeled documents, which are often too costly to obtain in real-world applications. In this paper, we explore to conduct HMTC based on only class surface names as supervision signals. We observe that to perform HMTC, human experts typically first pinpoint a few most essential classes for the document as its {``}core classes{''}, and then check core classes{'} ancestor classes to ensure the coverage. To mimic human experts, we propose a novel HMTC framework, named TaxoClass. Specifically, TaxoClass (1) calculates document-class similarities using a textual entailment model, (2) identifies a document{'}s core classes and utilizes confident core classes to train a taxonomy-enhanced classifier, and (3) generalizes the classifier via multi-label self-training. Our experiments on two challenging datasets show TaxoClass can achieve around 0.71 Example-F1 using only class names, outperforming the best previous method by 25{\%}.},
	address = {Online},
	author = {Shen, Jiaming and Qiu, Wenda and Meng, Yu and Shang, Jingbo and Ren, Xiang and Han, Jiawei},
	booktitle = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
	date-added = {2022-11-18 15:36:09 +0100},
	date-modified = {2022-11-18 15:36:09 +0100},
	doi = {10.18653/v1/2021.naacl-main.335},
	month = jun,
	pages = {4239--4249},
	publisher = {Association for Computational Linguistics},
	title = {{T}axo{C}lass: Hierarchical Multi-Label Text Classification Using Only Class Names},
	url = {https://aclanthology.org/2021.naacl-main.335},
	year = {2021},
	bdsk-url-1 = {https://aclanthology.org/2021.naacl-main.335},
	bdsk-url-2 = {https://doi.org/10.18653/v1/2021.naacl-main.335}}

@inproceedings{10.1145/3269206.3271737,
	abstract = {Deep neural networks are gaining increasing popularity for the classic text classification task, due to their strong expressive power and less requirement for feature engineering. Despite such attractiveness, neural text classification models suffer from the lack of training data in many real-world applications. Although many semi-supervised and weakly-supervised text classification models exist, they cannot be easily applied to deep neural models and meanwhile support limited supervision types. In this paper, we propose a weakly-supervised method that addresses the lack of training data in neural text classification. Our method consists of two modules: (1) a pseudo-document generator that leverages seed information to generate pseudo-labeled documents for model pre-training, and (2) a self-training module that bootstraps on real unlabeled data for model refinement. Our method has the flexibility to handle different types of weak supervision and can be easily integrated into existing deep neural models for text classification. We have performed extensive experiments on three real-world datasets from different domains. The results demonstrate that our proposed method achieves inspiring performance without requiring excessive training data and outperforms baseline methods significantly.},
	address = {New York, NY, USA},
	author = {Meng, Yu and Shen, Jiaming and Zhang, Chao and Han, Jiawei},
	booktitle = {Proceedings of the 27th ACM International Conference on Information and Knowledge Management},
	date-added = {2022-11-18 15:36:04 +0100},
	date-modified = {2022-11-18 15:36:04 +0100},
	doi = {10.1145/3269206.3271737},
	isbn = {9781450360142},
	keywords = {text classification, pseudo document generation, neural classification model, weakly-supervised learning},
	location = {Torino, Italy},
	numpages = {10},
	pages = {983--992},
	publisher = {Association for Computing Machinery},
	series = {CIKM '18},
	title = {Weakly-Supervised Neural Text Classification},
	url = {https://doi.org/10.1145/3269206.3271737},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1145/3269206.3271737}}

@inproceedings{jiang-etal-2019-challenge,
	abstract = {Aspect-based sentiment analysis (ABSA) has attracted increasing attention recently due to its broad applications. In existing ABSA datasets, most sentences contain only one aspect or multiple aspects with the same sentiment polarity, which makes ABSA task degenerate to sentence-level sentiment analysis. In this paper, we present a new large-scale Multi-Aspect Multi-Sentiment (MAMS) dataset, in which each sentence contains at least two different aspects with different sentiment polarities. The release of this dataset would push forward the research in this field. In addition, we propose simple yet effective CapsNet and CapsNet-BERT models which combine the strengths of recent NLP advances. Experiments on our new dataset show that the proposed model significantly outperforms the state-of-the-art baseline methods},
	address = {Hong Kong, China},
	author = {Jiang, Qingnan and Chen, Lei and Xu, Ruifeng and Ao, Xiang and Yang, Min},
	booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
	date-added = {2022-11-18 15:35:23 +0100},
	date-modified = {2022-11-18 15:35:23 +0100},
	doi = {10.18653/v1/D19-1654},
	month = nov,
	pages = {6280--6285},
	publisher = {Association for Computational Linguistics},
	title = {A Challenge Dataset and Effective Models for Aspect-Based Sentiment Analysis},
	url = {https://aclanthology.org/D19-1654},
	year = {2019},
	bdsk-url-1 = {https://aclanthology.org/D19-1654},
	bdsk-url-2 = {https://doi.org/10.18653/v1/D19-1654}}
