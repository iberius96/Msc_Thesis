%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Samuele Ceol at 2022-11-17 17:28:50 +0100 


%% Saved with string encoding Unicode (UTF-8) 



@misc{https://doi.org/10.48550/arxiv.1812.09551,
	author = {Zhang, Chao and Tao, Fangbo and Chen, Xiusi and Shen, Jiaming and Jiang, Meng and Sadler, Brian and Vanni, Michelle and Han, Jiawei},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 17:28:44 +0100},
	date-modified = {2022-11-17 17:28:44 +0100},
	doi = {10.48550/ARXIV.1812.09551},
	keywords = {Databases (cs.DB), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {TaxoGen: Unsupervised Topic Taxonomy Construction by Adaptive Term Embedding and Clustering},
	url = {https://arxiv.org/abs/1812.09551},
	year = {2018},
	bdsk-url-1 = {https://arxiv.org/abs/1812.09551},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1812.09551}}

@article{Yang_2017,
	author = {Shuo Yang and Lei Zou and Zhongyuan Wang and Jun Yan and Ji-Rong Wen},
	date-added = {2022-11-17 17:28:29 +0100},
	date-modified = {2022-11-17 17:28:29 +0100},
	doi = {10.1609/aaai.v31i1.10956},
	journal = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
	month = {feb},
	number = {1},
	publisher = {Association for the Advancement of Artificial Intelligence ({AAAI})},
	title = {Efficiently Answering Technical Questions {\textemdash} A Knowledge Graph Approach},
	url = {https://doi.org/10.1609%2Faaai.v31i1.10956},
	volume = {31},
	year = 2017,
	bdsk-url-1 = {https://doi.org/10.1609%2Faaai.v31i1.10956},
	bdsk-url-2 = {https://doi.org/10.1609/aaai.v31i1.10956}}

@misc{https://doi.org/10.48550/arxiv.1906.03158,
	author = {Soares, Livio Baldini and FitzGerald, Nicholas and Ling, Jeffrey and Kwiatkowski, Tom},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 17:28:23 +0100},
	date-modified = {2022-11-17 17:28:23 +0100},
	doi = {10.48550/ARXIV.1906.03158},
	keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Matching the Blanks: Distributional Similarity for Relation Learning},
	url = {https://arxiv.org/abs/1906.03158},
	year = {2019},
	bdsk-url-1 = {https://arxiv.org/abs/1906.03158},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1906.03158}}

@misc{https://doi.org/10.48550/arxiv.1910.08194,
	author = {Shen, Jiaming and Wu, Zeqiu and Lei, Dongming and Zhang, Chao and Ren, Xiang and Vanni, Michelle T. and Sadler, Brian M. and Han, Jiawei},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 17:28:19 +0100},
	date-modified = {2022-11-17 17:28:19 +0100},
	doi = {10.48550/ARXIV.1910.08194},
	keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {HiExpan: Task-Guided Taxonomy Construction by Hierarchical Tree Expansion},
	url = {https://arxiv.org/abs/1910.08194},
	year = {2019},
	bdsk-url-1 = {https://arxiv.org/abs/1910.08194},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1910.08194}}

@misc{https://doi.org/10.48550/arxiv.1910.08192,
	author = {Shen, Jiaming and Wu, Zeqiu and Lei, Dongming and Shang, Jingbo and Ren, Xiang and Han, Jiawei},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 17:28:14 +0100},
	date-modified = {2022-11-17 17:28:14 +0100},
	doi = {10.48550/ARXIV.1910.08192},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {SetExpan: Corpus-Based Set Expansion via Context Feature Selection and Rank Ensemble},
	url = {https://arxiv.org/abs/1910.08192},
	year = {2019},
	bdsk-url-1 = {https://arxiv.org/abs/1910.08192},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1910.08192}}

@misc{https://doi.org/10.48550/arxiv.1702.04457,
	author = {Shang, Jingbo and Liu, Jialu and Jiang, Meng and Ren, Xiang and Voss, Clare R and Han, Jiawei},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 17:28:09 +0100},
	date-modified = {2022-11-17 17:28:09 +0100},
	doi = {10.48550/ARXIV.1702.04457},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Automated Phrase Mining from Massive Text Corpora},
	url = {https://arxiv.org/abs/1702.04457},
	year = {2017},
	bdsk-url-1 = {https://arxiv.org/abs/1702.04457},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1702.04457}}

@misc{https://doi.org/10.48550/arxiv.1711.03226,
	author = {Qu, Meng and Ren, Xiang and Zhang, Yu and Han, Jiawei},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 17:28:03 +0100},
	date-modified = {2022-11-17 17:28:03 +0100},
	doi = {10.48550/ARXIV.1711.03226},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Weakly-supervised Relation Extraction by Pattern-enhanced Embedding Learning},
	url = {https://arxiv.org/abs/1711.03226},
	year = {2017},
	bdsk-url-1 = {https://arxiv.org/abs/1711.03226},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1711.03226}}

@misc{https://doi.org/10.48550/arxiv.1705.08039,
	author = {Nickel, Maximilian and Kiela, Douwe},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 17:27:59 +0100},
	date-modified = {2022-11-17 17:27:59 +0100},
	doi = {10.48550/ARXIV.1705.08039},
	keywords = {Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Poincar{\'e} Embeddings for Learning Hierarchical Representations},
	url = {https://arxiv.org/abs/1705.08039},
	year = {2017},
	bdsk-url-1 = {https://arxiv.org/abs/1705.08039},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1705.08039}}

@article{https://doi.org/10.48550/arxiv.2007.09536,
	author = {Meng, Yu and Zhang, Yunyi and Huang, Jiaxin and Zhang, Yu and Zhang, Chao and Han, Jiawei},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 17:27:54 +0100},
	date-modified = {2022-11-17 17:27:54 +0100},
	doi = {10.48550/ARXIV.2007.09536},
	keywords = {Computation and Language (cs.CL), Information Retrieval (cs.IR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Hierarchical Topic Mining via Joint Spherical Tree and Text Embedding},
	url = {https://arxiv.org/abs/2007.09536},
	year = {2020},
	bdsk-url-1 = {https://arxiv.org/abs/2007.09536},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.2007.09536}}

@misc{https://doi.org/10.48550/arxiv.1911.01196,
	author = {Meng, Yu and Huang, Jiaxin and Wang, Guangyuan and Zhang, Chao and Zhuang, Honglei and Kaplan, Lance and Han, Jiawei},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 17:27:49 +0100},
	date-modified = {2022-11-17 17:27:49 +0100},
	doi = {10.48550/ARXIV.1911.01196},
	keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Spherical Text Embedding},
	url = {https://arxiv.org/abs/1911.01196},
	year = {2019},
	bdsk-url-1 = {https://arxiv.org/abs/1911.01196},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1911.01196}}

@article{https://doi.org/10.48550/arxiv.1908.07162,
	author = {Meng, Yu and Huang, Jiaxin and Wang, Guangyuan and Wang, Zihan and Zhang, Chao and Zhang, Yu and Han, Jiawei},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 17:27:45 +0100},
	date-modified = {2022-11-17 17:27:45 +0100},
	doi = {10.48550/ARXIV.1908.07162},
	keywords = {Computation and Language (cs.CL), Information Retrieval (cs.IR), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Discriminative Topic Mining via Category-Name Guided Text Embedding},
	url = {https://arxiv.org/abs/1908.07162},
	year = {2019},
	bdsk-url-1 = {https://arxiv.org/abs/1908.07162},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1908.07162}}

@misc{https://doi.org/10.48550/arxiv.1902.00913,
	author = {Le, Matt and Roller, Stephen and Papaxanthos, Laetitia and Kiela, Douwe and Nickel, Maximilian},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 17:27:41 +0100},
	date-modified = {2022-11-17 17:27:41 +0100},
	doi = {10.48550/ARXIV.1902.00913},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Inferring Concept Hierarchies from Text Corpora via Hyperbolic Embeddings},
	url = {https://arxiv.org/abs/1902.00913},
	year = {2019},
	bdsk-url-1 = {https://arxiv.org/abs/1902.00913},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1902.00913}}

@article{https://doi.org/10.48550/arxiv.2001.10106,
	author = {Huang, Jiaxin and Xie, Yiqing and Meng, Yu and Shen, Jiaming and Zhang, Yunyi and Han, Jiawei},
	copyright = {Creative Commons Attribution 4.0 International},
	date-added = {2022-11-17 17:27:37 +0100},
	date-modified = {2022-11-17 17:27:37 +0100},
	doi = {10.48550/ARXIV.2001.10106},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Guiding Corpus-based Set Expansion by Auxiliary Sets Generation and Co-Expansion},
	url = {https://arxiv.org/abs/2001.10106},
	year = {2020},
	bdsk-url-1 = {https://arxiv.org/abs/2001.10106},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.2001.10106}}

@inproceedings{han-etal-2018-fewrel,
	abstract = {We present a Few-Shot Relation Classification Dataset (dataset), consisting of 70, 000 sentences on 100 relations derived from Wikipedia and annotated by crowdworkers. The relation of each sentence is first recognized by distant supervision methods, and then filtered by crowdworkers. We adapt the most recent state-of-the-art few-shot learning methods for relation classification and conduct thorough evaluation of these methods. Empirical results show that even the most competitive few-shot learning models struggle on this task, especially as compared with humans. We also show that a range of different reasoning skills are needed to solve our task. These results indicate that few-shot relation classification remains an open problem and still requires further research. Our detailed analysis points multiple directions for future research.},
	address = {Brussels, Belgium},
	author = {Han, Xu and Zhu, Hao and Yu, Pengfei and Wang, Ziyun and Yao, Yuan and Liu, Zhiyuan and Sun, Maosong},
	booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
	date-added = {2022-11-17 17:27:31 +0100},
	date-modified = {2022-11-17 17:27:31 +0100},
	doi = {10.18653/v1/D18-1514},
	month = oct # {-} # nov,
	pages = {4803--4809},
	publisher = {Association for Computational Linguistics},
	title = {{F}ew{R}el: A Large-Scale Supervised Few-Shot Relation Classification Dataset with State-of-the-Art Evaluation},
	url = {https://aclanthology.org/D18-1514},
	year = {2018},
	bdsk-url-1 = {https://aclanthology.org/D18-1514},
	bdsk-url-2 = {https://doi.org/10.18653/v1/D18-1514}}

@article{Gao_2019,
	author = {Tianyu Gao and Xu Han and Zhiyuan Liu and Maosong Sun},
	date-added = {2022-11-17 17:27:26 +0100},
	date-modified = {2022-11-17 17:27:26 +0100},
	doi = {10.1609/aaai.v33i01.33016407},
	journal = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
	month = {jul},
	number = {01},
	pages = {6407--6414},
	publisher = {Association for the Advancement of Artificial Intelligence ({AAAI})},
	title = {Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification},
	url = {https://doi.org/10.1609%2Faaai.v33i01.33016407},
	volume = {33},
	year = 2019,
	bdsk-url-1 = {https://doi.org/10.1609%2Faaai.v33i01.33016407},
	bdsk-url-2 = {https://doi.org/10.1609/aaai.v33i01.33016407}}

@misc{https://doi.org/10.48550/arxiv.1810.04805,
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 17:27:21 +0100},
	date-modified = {2022-11-17 17:27:21 +0100},
	doi = {10.48550/ARXIV.1810.04805},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	url = {https://arxiv.org/abs/1810.04805},
	year = {2018},
	bdsk-url-1 = {https://arxiv.org/abs/1810.04805},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1810.04805}}

@article{https://doi.org/10.48550/arxiv.1909.10572,
	author = {Dash, Sarthak and Chowdhury, Md Faisal Mahbub and Gliozzo, Alfio and Mihindukulasooriya, Nandana and Fauceglia, Nicolas Rodolfo},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 17:27:16 +0100},
	date-modified = {2022-11-17 17:27:16 +0100},
	doi = {10.48550/ARXIV.1909.10572},
	keywords = {Artificial Intelligence (cs.AI), Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Hypernym Detection Using Strict Partial Order Networks},
	url = {https://arxiv.org/abs/1909.10572},
	year = {2019},
	bdsk-url-1 = {https://arxiv.org/abs/1909.10572},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1909.10572}}

@inproceedings{chang-etal-2018-distributional,
	abstract = {Modeling hypernymy, such as poodle is-a dog, is an important generalization aid to many NLP tasks, such as entailment, relation extraction, and question answering. Supervised learning from labeled hypernym sources, such as WordNet, limits the coverage of these models, which can be addressed by learning hypernyms from unlabeled text. Existing unsupervised methods either do not scale to large vocabularies or yield unacceptably poor accuracy. This paper introduces distributional inclusion vector embedding (DIVE), a simple-to-implement unsupervised method of hypernym discovery via per-word non-negative vector embeddings which preserve the inclusion property of word contexts. In experimental evaluations more comprehensive than any previous literature of which we are aware{---}evaluating on 11 datasets using multiple existing as well as newly proposed scoring functions{---}we find that our method provides up to double the precision of previous unsupervised methods, and the highest average performance, using a much more compact word representation, and yielding many new state-of-the-art results.},
	address = {New Orleans, Louisiana},
	author = {Chang, Haw-Shiuan and Wang, Ziyun and Vilnis, Luke and McCallum, Andrew},
	booktitle = {Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
	date-added = {2022-11-17 17:27:09 +0100},
	date-modified = {2022-11-17 17:27:09 +0100},
	doi = {10.18653/v1/N18-1045},
	month = jun,
	pages = {485--495},
	publisher = {Association for Computational Linguistics},
	title = {Distributional Inclusion Vector Embedding for Unsupervised Hypernymy Detection},
	url = {https://aclanthology.org/N18-1045},
	year = {2018},
	bdsk-url-1 = {https://aclanthology.org/N18-1045},
	bdsk-url-2 = {https://doi.org/10.18653/v1/N18-1045}}
