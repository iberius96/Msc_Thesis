%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Samuele Ceol at 2023-02-22 16:44:13 +0100 


%% Saved with string encoding Unicode (UTF-8) 



@article{weigelt_2019_unsupervised_multi_topic_labeling_for_spoken_utterances,
	author = {Sebastian Weigelt and Jan Keim and Tobias Hey and Walter F. Tichy},
	date-added = {2023-02-22 16:41:41 +0100},
	date-modified = {2023-02-22 16:43:54 +0100},
	journal = {2019 IEEE International Conference on Humanized Computing and Communication (HCC)},
	pages = {38-45},
	title = {Unsupervised Multi-Topic Labeling for Spoken Utterances},
	year = {2019}}

@misc{zhang_2019_bertscore_evaluating_text_generation_with_bert,
	author = {Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q. and Artzi, Yoav},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 16:12:39 +0100},
	date-modified = {2022-11-17 16:12:39 +0100},
	doi = {10.48550/ARXIV.1904.09675},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {BERTScore: Evaluating Text Generation with BERT},
	url = {https://arxiv.org/abs/1904.09675},
	year = {2019},
	bdsk-url-1 = {https://arxiv.org/abs/1904.09675},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1904.09675}}

@misc{vaswani_2017_attention_is_all_you_need,
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 16:12:19 +0100},
	date-modified = {2022-11-17 16:12:19 +0100},
	doi = {10.48550/ARXIV.1706.03762},
	keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Attention Is All You Need},
	url = {https://arxiv.org/abs/1706.03762},
	year = {2017},
	bdsk-url-1 = {https://arxiv.org/abs/1706.03762},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1706.03762}}

@inproceedings{sorodoc_2017_multimodal_topic_labelling,
	abstract = {Topics generated by topic models are typically presented as a list of topic terms. Automatic topic labelling is the task of generating a succinct label that summarises the theme or subject of a topic, with the intention of reducing the cognitive load of end-users when interpreting these topics. Traditionally, topic label systems focus on a single label modality, e.g. textual labels. In this work we propose a multimodal approach to topic labelling using a simple feedforward neural network. Given a topic and a candidate image or textual label, our method automatically generates a rating for the label, relative to the topic. Experiments show that this multimodal approach outperforms single-modality topic labelling systems.},
	address = {Valencia, Spain},
	author = {Sorodoc, Ionut and Lau, Jey Han and Aletras, Nikolaos and Baldwin, Timothy},
	booktitle = {Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers},
	date-added = {2022-11-17 16:12:03 +0100},
	date-modified = {2022-11-17 16:12:03 +0100},
	month = apr,
	pages = {701--706},
	publisher = {Association for Computational Linguistics},
	title = {Multimodal Topic Labelling},
	url = {https://aclanthology.org/E17-2111},
	year = {2017},
	bdsk-url-1 = {https://aclanthology.org/E17-2111}}

@inproceedings{radford_2019_language_models_are_unsupervised_multitask_learners,
	author = {Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
	date-added = {2022-11-17 16:11:58 +0100},
	date-modified = {2022-11-17 16:11:58 +0100},
	title = {Language Models are Unsupervised Multitask Learners},
	year = {2019}}

@misc{liu_2019_roberta_a_robustly_optimized_bert_pretraining_approach,
	author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 16:11:52 +0100},
	date-modified = {2022-11-17 16:11:52 +0100},
	doi = {10.48550/ARXIV.1907.11692},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
	url = {https://arxiv.org/abs/1907.11692},
	year = {2019},
	bdsk-url-1 = {https://arxiv.org/abs/1907.11692},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1907.11692}}

@misc{lewis_2019_bart_denoising_sequence_to_sequence_pre_training_for_natural_language_generation_translation_and_comprehension,
	author = {Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 16:11:46 +0100},
	date-modified = {2022-11-17 16:11:46 +0100},
	doi = {10.48550/ARXIV.1910.13461},
	keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},
	url = {https://arxiv.org/abs/1910.13461},
	year = {2019},
	bdsk-url-1 = {https://arxiv.org/abs/1910.13461},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1910.13461}}

@misc{keskar_2019_ctrl_a_conditional_transformer_language_model_for_controllable_generation,
	author = {Keskar, Nitish Shirish and McCann, Bryan and Varshney, Lav R. and Xiong, Caiming and Socher, Richard},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 16:11:40 +0100},
	date-modified = {2022-11-17 16:11:40 +0100},
	doi = {10.48550/ARXIV.1909.05858},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {CTRL: A Conditional Transformer Language Model for Controllable Generation},
	url = {https://arxiv.org/abs/1909.05858},
	year = {2019},
	bdsk-url-1 = {https://arxiv.org/abs/1909.05858},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1909.05858}}

@incollection{gourru_2018_united_we_stand_using_multiple_strategies_for_topic_labeling,
	author = {Antoine Gourru and Julien Velcin and Mathieu Roche and Christophe Gravier and Pascal Poncelet},
	booktitle = {Natural Language Processing and Information Systems},
	date-added = {2022-11-17 16:11:34 +0100},
	date-modified = {2022-11-17 16:11:34 +0100},
	doi = {10.1007/978-3-319-91947-8_37},
	pages = {352--363},
	publisher = {Springer International Publishing},
	title = {United We Stand: Using Multiple Strategies for Topic Labeling},
	url = {https://doi.org/10.1007%2F978-3-319-91947-8_37},
	year = 2018,
	bdsk-url-1 = {https://doi.org/10.1007%2F978-3-319-91947-8_37},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-319-91947-8_37}}

@misc{devlin_2018_bert_pre_training_of_deep_bidirectional_transformers_for_language_understanding,
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 16:11:13 +0100},
	date-modified = {2022-11-17 16:11:13 +0100},
	doi = {10.48550/ARXIV.1810.04805},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	url = {https://arxiv.org/abs/1810.04805},
	year = {2018},
	bdsk-url-1 = {https://arxiv.org/abs/1810.04805},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1810.04805}}

@article{alokaili_2020_automatic_generation_of_topic_labels,
	author = {Alokaili, Areej and Aletras, Nikolaos and Stevenson, Mark},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 16:11:08 +0100},
	date-modified = {2022-11-17 16:11:08 +0100},
	doi = {10.48550/ARXIV.2006.00127},
	keywords = {Information Retrieval (cs.IR), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Automatic Generation of Topic Labels},
	url = {https://arxiv.org/abs/2006.00127},
	year = {2020},
	bdsk-url-1 = {https://arxiv.org/abs/2006.00127},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.2006.00127}}
