%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Samuele Ceol at 2022-11-18 18:47:43 +0100 


%% Saved with string encoding Unicode (UTF-8) 



@inproceedings{ramrakhiyani_2017_measuring_topic_coherence_through_optimal_word_buckets,
	author = {Nitin Ramrakhiyani and Sachin Pawar and Swapnil Hingmire and Girish Palshikar},
	booktitle = {Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers},
	date-added = {2022-11-18 18:47:40 +0100},
	date-modified = {2022-11-18 18:47:40 +0100},
	doi = {10.18653/v1/e17-2070},
	publisher = {Association for Computational Linguistics},
	title = {Measuring Topic Coherence through Optimal Word Buckets},
	url = {https://doi.org/10.18653%2Fv1%2Fe17-2070},
	year = 2017,
	bdsk-url-1 = {http://dx.doi.org/10.18653/v1/E17-2070}}

@article{morstatter_2017_in_search_of_coherence_and_consensus_measuring_the_interpretability_of_statistical_topics,
	abstract = {Topic modeling is an important tool in natural language processing. Topic models provide two forms of output. The first is a predictive model. This type of model has the ability to predict unseen documents (e.g., their categories). When topic models are used in this way, there are ample measures to assess their performance. The second output of these models is the topics themselves. Topics are lists of keywords that describe the top words pertaining to each topic. Often, these lists of keywords are presented to a human subject who then assesses the meaning of the topic, which is ultimately subjective. One of the fundamental problems of topic models lies in assessing the quality of the topics from the perspective of human interpretability. Naturally, human subjects need to be employed to evaluate interpretability of a topic. Lately, crowdsourcing approaches are widely used to serve the role of human subjects in evaluation. In this work we study measures of interpretability and propose to measure topic interpretability from two perspectives: topic coherence and topic consensus. We start with an existing measure for topic coherence--model precision. It evaluates coherence of a topic by introducing an intruded word and measuring how well a human subject or a crowdsourcing approach could identify the intruded word: if it is easy to identify, the topic is coherent. We then investigate how we can measure coherence comprehensively by examining dimensions of topic coherence. For the second perspective of topic interpretability, we suggest topic consensus that measures how well the results of a crowdsourcing approach matches those given categories of topics. Good topics should lead to good categories, thus, high topic consensus. Therefore, if there is low topic consensus in terms of categories, topics could be of low interpretability. We then further discuss how topic coherence and topic consensus assess different aspects of topic interpretability and hope that this work can pave way for comprehensive measures of topic interpretability.},
	author = {Morstatter, Fred and Liu, Huan},
	date-added = {2022-11-18 18:46:48 +0100},
	date-modified = {2022-11-18 18:46:48 +0100},
	doi = {10.5555/3122009.3242026},
	issn = {1532-4435},
	issue_date = {January 2017},
	journal = {J. Mach. Learn. Res.},
	month = {jan},
	number = {1},
	numpages = {32},
	pages = {6177--6208},
	publisher = {JMLR.org},
	title = {In Search of Coherence and Consensus: Measuring the Interpretability of Statistical Topics},
	volume = {18},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.5555/3122009.3242026}}

@misc{zhao_2017_metalda_a_topic_model_that_efficiently_incorporates_meta_information,
	author = {Zhao, He and Du, Lan and Buntine, Wray and Liu, Gang},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 18:05:29 +0100},
	date-modified = {2022-11-17 18:05:29 +0100},
	doi = {10.48550/ARXIV.1709.06365},
	keywords = {Computation and Language (cs.CL), Applications (stat.AP), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {MetaLDA: a Topic Model that Efficiently Incorporates Meta information},
	url = {https://arxiv.org/abs/1709.06365},
	year = {2017},
	bdsk-url-1 = {https://arxiv.org/abs/1709.06365},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1709.06365}}

@misc{zhao_2021_topic_modelling_meets_deep_neural_networks_a_survey,
	author = {Zhao, He and Phung, Dinh and Huynh, Viet and Jin, Yuan and Du, Lan and Buntine, Wray},
	copyright = {Creative Commons Attribution 4.0 International},
	date-added = {2022-11-17 18:04:55 +0100},
	date-modified = {2022-11-17 18:04:55 +0100},
	doi = {10.48550/ARXIV.2103.00498},
	keywords = {Machine Learning (cs.LG), Computation and Language (cs.CL), Information Retrieval (cs.IR), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Topic Modelling Meets Deep Neural Networks: A Survey},
	url = {https://arxiv.org/abs/2103.00498},
	year = {2021},
	bdsk-url-1 = {https://arxiv.org/abs/2103.00498},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.2103.00498}}

@article{zhang_2020_topic_modeling_on_document_networks_with_adjacent_encoder,
	author = {Ce Zhang and Hady W. Lauw},
	date-added = {2022-11-17 18:04:41 +0100},
	date-modified = {2022-11-17 18:04:41 +0100},
	doi = {10.1609/aaai.v34i04.6152},
	journal = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
	month = {apr},
	number = {04},
	pages = {6737--6745},
	publisher = {Association for the Advancement of Artificial Intelligence ({AAAI})},
	title = {Topic Modeling on Document Networks with Adjacent-Encoder},
	url = {https://doi.org/10.1609%2Faaai.v34i04.6152},
	volume = {34},
	year = 2020,
	bdsk-url-1 = {https://doi.org/10.1609%2Faaai.v34i04.6152},
	bdsk-url-2 = {https://doi.org/10.1609/aaai.v34i04.6152}}

@article{xue_2020_public_discourse_and_sentiment_during_the_covid_19_pandemic_using_latent_dirichlet_allocation_for_topic_modeling_on_twitter,
	author = {Jia Xue and Junxiang Chen and Chen Chen and Chengda Zheng and Sijia Li and Tingshao Zhu},
	date-added = {2022-11-17 18:04:33 +0100},
	date-modified = {2022-11-17 18:04:33 +0100},
	doi = {10.1371/journal.pone.0239441},
	editor = {Jichang Zhao},
	journal = {{PLOS} {ONE}},
	month = {sep},
	number = {9},
	pages = {e0239441},
	publisher = {Public Library of Science ({PLoS})},
	title = {Public discourse and sentiment during the {COVID} 19 pandemic: Using Latent Dirichlet Allocation for topic modeling on Twitter},
	url = {https://doi.org/10.1371%2Fjournal.pone.0239441},
	volume = {15},
	year = 2020,
	bdsk-url-1 = {https://doi.org/10.1371%2Fjournal.pone.0239441},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pone.0239441}}

@inproceedings{wang_2018_astm_an_attentional_segmentation_based_topic_model_for_short_texts,
	author = {Wang, Jiamiao and Chen, Ling and Qin, Lu and Wu, Xindong},
	booktitle = {2018 IEEE International Conference on Data Mining (ICDM)},
	date-added = {2022-11-17 18:04:23 +0100},
	date-modified = {2022-11-17 18:04:23 +0100},
	doi = {10.1109/ICDM.2018.00073},
	pages = {577-586},
	title = {ASTM: An Attentional Segmentation Based Topic Model for Short Texts},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1109/ICDM.2018.00073}}

@article{symeonidis_2018_a_comparative_evaluation_of_pre_processing_techniques_and_their_interactions_for_twitter_sentiment_analysis,
	abstract = {Pre-processing is the first step in text classification, and choosing right pre-processing techniques can improve classification effectiveness. We experimentally compare 16 commonly used pre-processing techniques on two Twitter datasets for Sentiment Analysis, employing four popular machine learning algorithms, namely, Linear SVC, Bernoulli Na{\"\i}ve Bayes, Logistic Regression, and Convolutional Neural Networks. We evaluate the pre-processing techniques on their resulting classification accuracy and number of features they produce. We find that techniques like lemmatization, removing numbers, and replacing contractions, improve accuracy, while others like removing punctuation do not. Finally, in order to investigate interactions---desirable or otherwise---between the techniques when they are employed simultaneously in a pipeline fashion, an ablation and combination study is contacted. The results of ablation and combination show the significance of techniques such as replacing numbers and replacing repetitions of punctuation.},
	author = {Symeon Symeonidis and Dimitrios Effrosynidis and Avi Arampatzis},
	date-added = {2022-11-17 18:04:17 +0100},
	date-modified = {2022-11-17 18:04:17 +0100},
	doi = {https://doi.org/10.1016/j.eswa.2018.06.022},
	issn = {0957-4174},
	journal = {Expert Systems with Applications},
	keywords = {Sentiment analysis, Text pre-processing, Machine learning, Text classification, Ablation study, Combination study},
	pages = {298-310},
	title = {A comparative evaluation of pre-processing techniques and their interactions for twitter sentiment analysis},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417418303683},
	volume = {110},
	year = {2018},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0957417418303683},
	bdsk-url-2 = {https://doi.org/10.1016/j.eswa.2018.06.022}}

@article{sinnenberg_2017_twitter_as_a_tool_for_health_research_a_systematic_review,
	author = {Lauren Sinnenberg and Alison M. Buttenheim and Kevin Padrez and Christina Mancheno and Lyle Ungar and Raina M. Merchant},
	date-added = {2022-11-17 18:04:11 +0100},
	date-modified = {2022-11-17 18:04:11 +0100},
	doi = {10.2105/ajph.2016.303512},
	journal = {American Journal of Public Health},
	month = {jan},
	number = {1},
	pages = {e1--e8},
	publisher = {American Public Health Association},
	title = {Twitter as a Tool for Health Research: A Systematic Review},
	url = {https://doi.org/10.2105%2Fajph.2016.303512},
	volume = {107},
	year = 2017,
	bdsk-url-1 = {https://doi.org/10.2105%2Fajph.2016.303512},
	bdsk-url-2 = {https://doi.org/10.2105/ajph.2016.303512}}

@article{nerghes_2019_narratives_of_the_refugee_crisis_a_comparative_study_of_mainstream_media_and_twitter,
	author = {Adina Nerghes and Ju-Sung Lee},
	date-added = {2022-11-17 18:03:59 +0100},
	date-modified = {2022-11-17 18:03:59 +0100},
	doi = {10.17645/mac.v7i2.1983},
	journal = {Media and Communication},
	month = {jun},
	number = {2},
	pages = {275--288},
	publisher = {Cogitatio},
	title = {Narratives of the Refugee Crisis: A Comparative Study of Mainstream-Media and Twitter},
	url = {https://doi.org/10.17645%2Fmac.v7i2.1983},
	volume = {7},
	year = 2019,
	bdsk-url-1 = {https://doi.org/10.17645%2Fmac.v7i2.1983},
	bdsk-url-2 = {https://doi.org/10.17645/mac.v7i2.1983}}

@inproceedings{morstatter_2018_from_alt_right_to_alt_rechts_twitter_analysis_of_the_2017_german_federal_election,
	abstract = {In the 2017 German Federal elections, the "Alternative for Deutschland'', or AfD, party was able to take control of many seats in German parliament. Their success was credited, in part, to their large online presence. Like other "alt-right'' organizations worldwide, this party is tech savvy, generating a large social media footprint, especially on Twitter, which provides an ample opportunity to understand their online behavior. In this work we present an analysis of Twitter data related to the aforementioned election. We show how users self-organize into communities, and identify the themes that define those communities. Next we analyze the content generated by those communities, and the extent to which these communities interact. Despite these elections being held in Germany, we note a substantial impact from the English-speaking Twittersphere. Specifically, we note that many of these accounts appear to be from the American alt-right movement, and support the German alt-right movement.},
	address = {Republic and Canton of Geneva, CHE},
	author = {Morstatter, Fred and Shao, Yunqiu and Galstyan, Aram and Karunasekera, Shanika},
	booktitle = {Companion Proceedings of the The Web Conference 2018},
	date-added = {2022-11-17 18:03:47 +0100},
	date-modified = {2022-11-17 18:03:47 +0100},
	doi = {morstatter_2018_from_alt_right_to_alt_rechts_twitter_analysis_of_the_2017_german_federal_election},
	isbn = {9781450356404},
	keywords = {bots, social networks, online campaigns},
	location = {Lyon, France},
	numpages = {8},
	pages = {621--628},
	publisher = {International World Wide Web Conferences Steering Committee},
	series = {WWW '18},
	title = {From Alt-Right to Alt-Rechts: Twitter Analysis of the 2017 German Federal Election},
	url = {https://doi.org/10.1145/3184558.3188733},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1145/3184558.3188733}}

@article{maier_2018_applying_lda_topic_modeling_in_communication_research_toward_a_valid_and_reliable_methodology,
	author = {Daniel Maier and A. Waldherr and P. Miltner and G. Wiedemann and A. Niekler and A. Keinert and B. Pfetsch and G. Heyer and U. Reber and T. H{\"a}ussler and H. Schmid-Petri and S. Adam},
	date-added = {2022-11-17 18:03:34 +0100},
	date-modified = {2022-11-17 18:03:34 +0100},
	doi = {10.1080/19312458.2018.1430754},
	journal = {Communication Methods and Measures},
	month = {feb},
	number = {2-3},
	pages = {93--118},
	publisher = {Informa {UK} Limited},
	title = {Applying {LDA} Topic Modeling in Communication Research: Toward a Valid and Reliable Methodology},
	url = {https://doi.org/10.1080%2F19312458.2018.1430754},
	volume = {12},
	year = 2018,
	bdsk-url-1 = {https://doi.org/10.1080%2F19312458.2018.1430754},
	bdsk-url-2 = {https://doi.org/10.1080/19312458.2018.1430754}}

@article{lyu_2021_understanding_the_public_discussion_about_the_centers_for_disease_control_and_prevention_during_the_covid_19_pandemic_using_twitter_data_text_mining_analysis_study,
	author = {Joanne Chen Lyu and Garving K Luli},
	date-added = {2022-11-17 18:03:26 +0100},
	date-modified = {2022-11-17 18:03:26 +0100},
	doi = {10.2196/25108},
	journal = {Journal of Medical Internet Research},
	month = {feb},
	number = {2},
	pages = {e25108},
	publisher = {{JMIR} Publications Inc.},
	title = {Understanding the Public Discussion About the Centers for Disease Control and Prevention During the {COVID}-19 Pandemic Using Twitter Data: Text Mining Analysis Study},
	url = {https://doi.org/10.2196%2F25108},
	volume = {23},
	year = 2021,
	bdsk-url-1 = {https://doi.org/10.2196%2F25108},
	bdsk-url-2 = {https://doi.org/10.2196/25108}}

@misc{lund_2019_automatic_evaluation_of_local_topic_quality,
	author = {Lund, Jeffrey and Armstrong, Piper and Fearn, Wilson and Cowley, Stephen and Byun, Courtni and Boyd-Graber, Jordan and Seppi, Kevin},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 18:03:14 +0100},
	date-modified = {2022-11-17 18:03:14 +0100},
	doi = {10.48550/ARXIV.1905.13126},
	keywords = {Information Retrieval (cs.IR), Computation and Language (cs.CL), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Automatic Evaluation of Local Topic Quality},
	url = {https://arxiv.org/abs/1905.13126},
	year = {2019},
	bdsk-url-1 = {https://arxiv.org/abs/1905.13126},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1905.13126}}

@misc{lipton_2016_the_mythos_of_model_interpretability,
	author = {Lipton, Zachary C.},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2022-11-17 18:03:10 +0100},
	date-modified = {2022-11-17 18:03:10 +0100},
	doi = {10.48550/ARXIV.1606.03490},
	keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {The Mythos of Model Interpretability},
	url = {https://arxiv.org/abs/1606.03490},
	year = {2016},
	bdsk-url-1 = {https://arxiv.org/abs/1606.03490},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1606.03490}}

@article{li_2018_short_text_topic_modeling_by_exploring_original_documents,
	abstract = {Topic modeling for short texts faces a tough challenge, owing to the sparsity problem. An effective solution is to aggregate short texts into long pseudo-documents before training a standard topic model. The main concern of this solution is the way of aggregating short texts. A recent developed self-aggregation-based topic model (SATM) can adaptively aggregate short texts without using heuristic information. However, the model definition of SATM is a bit rigid, and more importantly, it tends to overfitting and time-consuming for large-scale corpora. To improve SATM, we propose a generalized topic model for short texts, namely latent topic model (LTM). In LTM, we assume that the observable short texts are snippets of normal long texts (namely original documents) generated by a given standard topic model, but their original document memberships are unknown. With Gibbs sampling, LTM drives an adaptive aggregation process of short texts, and simultaneously estimates other latent variables of interest. Additionally, we propose a mini-batch scheme for fast inference. Experimental results indicate that LTM is competitive with the state-of-the-art baseline models on short text topic modeling.},
	author = {Li, Ximing and Li, Changchun and Chi, Jinjin and Ouyang, Jihong},
	date = {2018/08/01},
	date-added = {2022-11-17 18:03:03 +0100},
	date-modified = {2022-11-17 18:03:03 +0100},
	doi = {10.1007/s10115-017-1099-0},
	id = {Li2018},
	isbn = {0219-3116},
	journal = {Knowledge and Information Systems},
	number = {2},
	pages = {443--462},
	title = {Short text topic modeling by exploring original documents},
	url = {https://doi.org/10.1007/s10115-017-1099-0},
	volume = {56},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1007/s10115-017-1099-0}}

@article{korencic_2018_document_based_topic_coherence_measures_for_news_media_text,
	abstract = {There is a rising need for automated analysis of news text, and topic models have proven to be useful tools for this task. However, as the quality of the topics induced by topic models greatly varies, much research effort has been devoted to their automated evaluation. Recent research has focused on topic coherence as a measure of a topic's quality. Existing topic coherence measures work by considering the semantic similarity of topic words. This makes them unfit to detect the coherence of transient topics with semantically unrelated topic words, which abound in news media texts. In this paper, we introduce the notion of document-based topic coherence and propose novel topic coherence measures that estimate topic coherence based on topic documents rather than topic words. We evaluate the proposed measures on two datasets containing topics manually labeled for document-based coherence, on which the proposed measures outperform a strong baseline as well as word-based coherence measures. We also demonstrate the usefulness of document-based coherence measures for automated topic discovery from news media texts.},
	author = {Damir Koren{\v c}i{\'c} and Strahil Ristov and Jan {\v S}najder},
	date-added = {2022-11-17 18:02:55 +0100},
	date-modified = {2022-11-17 18:02:55 +0100},
	doi = {https://doi.org/10.1016/j.eswa.2018.07.063},
	issn = {0957-4174},
	journal = {Expert Systems with Applications},
	keywords = {Topic models, Topic coherence, Topic model evaluation, Text analysis, News text, Exploratory analysis},
	pages = {357-373},
	title = {Document-based topic coherence measures for news media text},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417418304883},
	volume = {114},
	year = {2018},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0957417418304883},
	bdsk-url-2 = {https://doi.org/10.1016/j.eswa.2018.07.063}}

@article{kirilenko_2021_automated_topic_modeling_of_tourist_reviews_does_the_anna_karenina_principle_apply,
	abstract = {Automated content analysis of online travel reviews allows identification of topics of travelers' satisfaction, yet its domain is not well researched. We suggest that the Anna Karenina principle positing a greater variability of the factors leading to business failure as opposed to those leading to success can be applied to the domain of visitors' reviews of historic and cultural attractions. The larger variability of issues in reviews of dissatisfied visitors is likely to result in limitations for automated topic modeling. We confirm our proposition using TripAdvisor reviews of the Terracotta Army museum in China, and validate the outcome with two additional sites. The study strongly suggests that application of unsupervised topic mining algorithms to negative reviews may be problematic and the results should be treated with caution. The main themes of dissatisfaction of visitors to all three sites are reported and practical implications for management of the attractions are discussed.},
	author = {Andrei P. Kirilenko and Svetlana O. Stepchenkova and Xiangyi Dai},
	date-added = {2022-11-17 18:02:50 +0100},
	date-modified = {2022-11-17 18:02:50 +0100},
	doi = {https://doi.org/10.1016/j.tourman.2020.104241},
	issn = {0261-5177},
	journal = {Tourism Management},
	keywords = {Traveler satisfaction, Latent Dirichlet allocation, Anna Karenina principle, TripAdvisor, Social media},
	pages = {104241},
	title = {Automated topic modeling of tourist reviews: Does the Anna Karenina principle apply?},
	url = {https://www.sciencedirect.com/science/article/pii/S0261517720301679},
	volume = {83},
	year = {2021},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0261517720301679},
	bdsk-url-2 = {https://doi.org/10.1016/j.tourman.2020.104241}}

@article{karami_2020_twitter_and_research_a_systematic_literature_review_through_text_mining,
	author = {Karami, Amir and Lundy, Morgan and Webb, Frank and Dwivedi, Yogesh K.},
	date-added = {2022-11-17 18:02:45 +0100},
	date-modified = {2022-11-17 18:02:45 +0100},
	doi = {10.1109/ACCESS.2020.2983656},
	journal = {IEEE Access},
	pages = {67698-67717},
	title = {Twitter and Research: A Systematic Literature Review Through Text Mining},
	volume = {8},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1109/ACCESS.2020.2983656}}

@article{karami_2018_characterizing_diabetes_diet_exercise_and_obesity_comments_on_twitter,
	abstract = {Social media provide a platform for users to express their opinions and share information. Understanding public health opinions on social media, such as Twitter, offers a unique approach to characterizing common health issues such as diabetes, diet, exercise, and obesity (DDEO); however, collecting and analyzing a large scale conversational public health data set is a challenging research task. The goal of this research is to analyze the characteristics of the general public's opinions in regard to diabetes, diet, exercise and obesity (DDEO) as expressed on Twitter. A multi-component semantic and linguistic framework was developed to collect Twitter data, discover topics of interest about DDEO, and analyze the topics. From the extracted 4.5 million tweets, 8% of tweets discussed diabetes, 23.7% diet, 16.6% exercise, and 51.7% obesity. The strongest correlation among the topics was determined between exercise and obesity (p<.0002). Other notable correlations were: diabetes and obesity (p<.0005), and diet and obesity (p<.001). DDEO terms were also identified as subtopics of each of the DDEO topics. The frequent subtopics discussed along with ``Diabetes'', excluding the DDEO terms themselves, were blood pressure, heart attack, yoga, and Alzheimer. The non-DDEO subtopics for ``Diet'' included vegetarian, pregnancy, celebrities, weight loss, religious, and mental health, while subtopics for ``Exercise'' included computer games, brain, fitness, and daily plan. Non-DDEO subtopics for ``Obesity'' included Alzheimer, cancer, and children. With 2.67 billion social media users in 2016, publicly available data such as Twitter posts can be utilized to support clinical providers, public health experts, and social scientists in better understanding common public opinions in regard to diabetes, diet, exercise, and obesity.},
	author = {Amir Karami and Alicia A. Dahl and Gabrielle Turner-McGrievy and Hadi Kharrazi and George Shaw},
	date-added = {2022-11-17 18:02:38 +0100},
	date-modified = {2022-11-17 18:02:38 +0100},
	doi = {https://doi.org/10.1016/j.ijinfomgt.2017.08.002},
	issn = {0268-4012},
	journal = {International Journal of Information Management},
	keywords = {Health, Diabetes, Diet, Obesity, Exercise, Topic model, Text mining, Twitter},
	number = {1},
	pages = {1-6},
	title = {Characterizing diabetes, diet, exercise, and obesity comments on Twitter},
	url = {https://www.sciencedirect.com/science/article/pii/S0268401217306126},
	volume = {38},
	year = {2018},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0268401217306126},
	bdsk-url-2 = {https://doi.org/10.1016/j.ijinfomgt.2017.08.002}}

@article{kagashe_2017_enhancing_seasonal_influenza_surveillance_topic_analysis_of_widely_used_medicinal_drugs_using_twitter_data,
	author = {Ireneus Kagashe and Zhijun Yan and Imran Suheryani},
	date-added = {2022-11-17 18:02:32 +0100},
	date-modified = {2022-11-17 18:02:32 +0100},
	doi = {10.2196/jmir.7393},
	journal = {Journal of Medical Internet Research},
	month = {sep},
	number = {9},
	pages = {e315},
	publisher = {{JMIR} Publications Inc.},
	title = {Enhancing Seasonal Influenza Surveillance: Topic Analysis of Widely Used Medicinal Drugs Using Twitter Data},
	url = {https://doi.org/10.2196%2Fjmir.7393},
	volume = {19},
	year = 2017,
	bdsk-url-1 = {https://doi.org/10.2196%2Fjmir.7393},
	bdsk-url-2 = {https://doi.org/10.2196/jmir.7393}}

@article{hecking_2019_can_topic_models_be_used_in_research_evaluations_reproducibility_validity_and_reliability_when_compared_with_semantic_maps,
	abstract = {{We replicate and analyze the topic model which was commissioned to King's College and Digital Science for the Research Evaluation Framework (REF 2014) in the United Kingdom: 6,638 case descriptions of societal impact were submitted by 154 higher-education institutes. We compare the Latent Dirichlet Allocation (LDA) model with Principal Component Analysis (PCA) of document-term matrices using the same data. Since topic models are almost by definition applied to text corpora which are too large to read, validation of the results of these models is hardly possible; furthermore the models are irreproducible for a number of reasons. However, removing a small fraction of the documents from the sample---a test for reliability---has on average a larger impact in terms of decay on LDA than on PCA-based models. The semantic coherence of LDA models outperforms PCA-based models. In our opinion, results of the topic models are statistical and should not be used for grant selections and micro decision-making about research without follow-up using domain-specific semantic maps.}},
	author = {Hecking, Tobias and Leydesdorff, Loet},
	date-added = {2022-11-17 18:02:17 +0100},
	date-modified = {2022-11-17 18:02:17 +0100},
	doi = {hecking_2019_can_topic_models_be_used_in_research_evaluations_reproducibility_validity_and_reliability_when_compared_with_semantic_maps},
	eprint = {https://academic.oup.com/rev/article-pdf/28/3/263/28994022/rvz015.pdf},
	issn = {0958-2029},
	journal = {Research Evaluation},
	month = {07},
	number = {3},
	pages = {263-272},
	title = {{Can topic models be used in research evaluations? Reproducibility, validity, and reliability when compared with semantic maps}},
	url = {https://doi.org/10.1093/reseval/rvz015},
	volume = {28},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1093/reseval/rvz015}}

@article{doogan_2020_public_perceptions_and_attitudes_toward_covid_19_nonpharmaceutical_interventions_across_six_countries_a_topic_modeling_analysis_of_twitter_data,
	author = {Caitlin Doogan and Wray Buntine and Henry Linger and Samantha Brunt},
	date-added = {2022-11-17 18:01:58 +0100},
	date-modified = {2022-11-17 18:01:58 +0100},
	doi = {10.2196/21419},
	journal = {Journal of Medical Internet Research},
	month = {sep},
	number = {9},
	pages = {e21419},
	publisher = {{JMIR} Publications Inc.},
	title = {Public Perceptions and Attitudes Toward {COVID}-19 Nonpharmaceutical Interventions Across Six Countries: A Topic Modeling Analysis of Twitter Data},
	url = {https://doi.org/10.2196%2F21419},
	volume = {22},
	year = 2020,
	bdsk-url-1 = {https://doi.org/10.2196%2F21419},
	bdsk-url-2 = {https://doi.org/10.2196/21419}}

@article{brown_2018_methodological_cyborg_as_black_feminist_technology_constructing_the_social_self_using_computational_digital_autoethnography_and_social_media,
	author = {Nicole Marie Brown},
	date-added = {2022-11-17 18:01:50 +0100},
	date-modified = {2022-11-17 18:01:50 +0100},
	doi = {10.1177/1532708617750178},
	journal = {Cultural Studies $\leftrightarrow$ Critical Methodologies},
	month = {jan},
	number = {1},
	pages = {55--67},
	publisher = {{SAGE} Publications},
	title = {Methodological Cyborg as Black Feminist Technology: Constructing the Social Self Using Computational Digital Autoethnography and Social Media},
	url = {https://doi.org/10.1177%2F1532708617750178},
	volume = {19},
	year = 2018,
	bdsk-url-1 = {https://doi.org/10.1177%2F1532708617750178},
	bdsk-url-2 = {https://doi.org/10.1177/1532708617750178}}

@article{blair_2020_aggregated_topic_models_for_increasing_social_media_topic_coherence,
	abstract = {This research presents a novel aggregating method for constructing an aggregated topic model that is composed of the topics with greater coherence than individual models. When generating a topic model, a number of parameters have to be specified. The resulting topics can be very general or very specific, which depend on the chosen parameters. In this study we investigate the process of aggregating multiple topic models generated using different parameters with a focus on whether combining the general and specific topics is able to increase topic coherence. We employ cosine similarity and Jensen-Shannon divergence to compute the similarity among topics and combine them into an aggregated model when their similarity scores exceed a predefined threshold. The model is evaluated against the standard topics models generated by the latent Dirichlet allocation and Non-negative Matrix Factorisation. Specifically we use the coherence of topics to compare the individual models that create aggregated models against those of the aggregated model and models generated by Non-negative Matrix Factorisation, respectively. The results demonstrate that the aggregated model outperforms those topic models at a statistically significant level in terms of topic coherence over an external corpus. We also make use of the aggregated topic model on social media data to validate the method in a realistic scenario and find that again it outperforms individual topic models.},
	author = {Blair, Stuart J. and Bi, Yaxin and Mulvenna, Maurice D.},
	date = {2020/01/01},
	date-added = {2022-11-17 18:01:34 +0100},
	date-modified = {2022-11-17 18:01:34 +0100},
	doi = {10.1007/s10489-019-01438-z},
	id = {Blair2020},
	isbn = {1573-7497},
	journal = {Applied Intelligence},
	number = {1},
	pages = {138--156},
	title = {Aggregated topic models for increasing social media topic coherence},
	url = {https://doi.org/10.1007/s10489-019-01438-z},
	volume = {50},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1007/s10489-019-01438-z}}

@inproceedings{bhatia_2018_topic_intrusion_for_automatic_topic_model_evaluation,
	abstract = {Topic coherence is increasingly being used to evaluate topic models and filter topics for end-user applications. Topic coherence measures how well topic words relate to each other, but offers little insight on the utility of the topics in describing the documents. In this paper, we explore the topic intrusion task {---} the task of guessing an outlier topic given a document and a few topics {---} and propose a method to automate it. We improve upon the state-of-the-art substantially, demonstrating its viability as an alternative method for topic model evaluation.},
	address = {Brussels, Belgium},
	author = {Bhatia, Shraey and Lau, Jey Han and Baldwin, Timothy},
	booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
	date-added = {2022-11-17 18:01:22 +0100},
	date-modified = {2022-11-17 18:01:22 +0100},
	doi = {10.18653/v1/D18-1098},
	month = oct # {-} # nov,
	pages = {844--849},
	publisher = {Association for Computational Linguistics},
	title = {Topic Intrusion for Automatic Topic Model Evaluation},
	url = {https://aclanthology.org/D18-1098},
	year = {2018},
	bdsk-url-1 = {https://aclanthology.org/D18-1098},
	bdsk-url-2 = {https://doi.org/10.18653/v1/D18-1098}}

@inproceedings{bhatia_2017_an_automatic_approach_for_document_level_topic_model_evaluation,
	abstract = {Topic models jointly learn topics and document-level topic distribution. Extrinsic evaluation of topic models tends to focus exclusively on topic-level evaluation, e.g. by assessing the coherence of topics. We demonstrate that there can be large discrepancies between topic- and document-level model quality, and that basing model evaluation on topic-level analysis can be highly misleading. We propose a method for automatically predicting topic model quality based on analysis of document-level topic allocations, and provide empirical evidence for its robustness.},
	address = {Vancouver, Canada},
	author = {Bhatia, Shraey and Lau, Jey Han and Baldwin, Timothy},
	booktitle = {Proceedings of the 21st Conference on Computational Natural Language Learning ({C}o{NLL} 2017)},
	date-added = {2022-11-17 18:01:10 +0100},
	date-modified = {2022-11-17 18:01:10 +0100},
	doi = {10.18653/v1/K17-1022},
	month = aug,
	pages = {206--215},
	publisher = {Association for Computational Linguistics},
	title = {An Automatic Approach for Document-level Topic Model Evaluation},
	url = {https://aclanthology.org/K17-1022},
	year = {2017},
	bdsk-url-1 = {https://aclanthology.org/K17-1022},
	bdsk-url-2 = {https://doi.org/10.18653/v1/K17-1022}}

@article{baumer_2017_comparing_grounded_theory_and_topic_modeling_extreme_divergence_or_unlikely_convergence,
	author = {Eric P. S. Baumer and David Mimno and Shion Guha and Emily Quan and Geri K. Gay},
	date-added = {2022-11-17 18:01:05 +0100},
	date-modified = {2022-11-17 18:01:05 +0100},
	doi = {10.1002/asi.23786},
	journal = {Journal of the Association for Information Science and Technology},
	month = {apr},
	number = {6},
	pages = {1397--1410},
	publisher = {Wiley},
	title = {Comparing grounded theory and topic modeling: Extreme divergence or unlikely convergence?},
	url = {https://doi.org/10.1002%2Fasi.23786},
	volume = {68},
	year = 2017,
	bdsk-url-1 = {https://doi.org/10.1002%2Fasi.23786},
	bdsk-url-2 = {https://doi.org/10.1002/asi.23786}}

@article{andreotta_2019_analyzing_social_media_data_a_mixed_methods_framework_combining_computational_and_qualitative_text_analysis,
	abstract = {To qualitative researchers, social media offers a novel opportunity to harvest a massive and diverse range of content without the need for intrusive or intensive data collection procedures. However, performing a qualitative analysis across a massive social media data set is cumbersome and impractical. Instead, researchers often extract a subset of content to analyze, but a framework to facilitate this process is currently lacking. We present a four-phased framework for improving this extraction process, which blends the capacities of data science techniques to compress large data sets into smaller spaces, with the capabilities of qualitative analysis to address research questions. We demonstrate this framework by investigating the topics of Australian Twitter commentary on climate change, using quantitative (non-negative matrix inter-joint factorization; topic alignment) and qualitative (thematic analysis) techniques. Our approach is useful for researchers seeking to perform qualitative analyses of social media, or researchers wanting to supplement their quantitative work with a qualitative analysis of broader social context and meaning.},
	author = {Andreotta, Matthew and Nugroho, Robertus and Hurlstone, Mark J. and Boschetti, Fabio and Farrell, Simon and Walker, Iain and Paris, Cecile},
	date = {2019/08/01},
	date-added = {2022-11-17 18:00:47 +0100},
	date-modified = {2022-11-17 18:00:47 +0100},
	doi = {10.3758/s13428-019-01202-8},
	id = {Andreotta2019},
	isbn = {1554-3528},
	journal = {Behavior Research Methods},
	number = {4},
	pages = {1766--1781},
	title = {Analyzing social media data: A mixed-methods framework combining computational and qualitative text analysis},
	url = {https://doi.org/10.3758/s13428-019-01202-8},
	volume = {51},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.3758/s13428-019-01202-8}}

@inproceedings{alokaili_2019_re_ranking_words_to_improve_interpretability_of_automatically_generated_topics,
	abstract = {Topics models, such as LDA, are widely used in Natural Language Processing. Making their output interpretable is an important area of research with applications to areas such as the enhancement of exploratory search interfaces and the development of interpretable machine learning models. Conventionally, topics are represented by their n most probable words, however, these representations are often difficult for humans to interpret. This paper explores the re-ranking of topic words to generate more interpretable topic representations. A range of approaches are compared and evaluated in two experiments. The first uses crowdworkers to associate topics represented by different word rankings with related documents. The second experiment is an automatic approach based on a document retrieval task applied on multiple domains. Results in both experiments demonstrate that re-ranking words improves topic interpretability and that the most effective re-ranking schemes were those which combine information about the importance of words both within topics and their relative frequency in the entire corpus. In addition, close correlation between the results of the two evaluation approaches suggests that the automatic method proposed here could be used to evaluate re-ranking methods without the need for human judgements.},
	address = {Gothenburg, Sweden},
	author = {Alokaili, Areej and Aletras, Nikolaos and Stevenson, Mark},
	booktitle = {Proceedings of the 13th International Conference on Computational Semantics - Long Papers},
	date-added = {2022-11-17 18:00:39 +0100},
	date-modified = {2022-11-17 18:00:39 +0100},
	doi = {10.18653/v1/W19-0404},
	month = may,
	pages = {43--54},
	publisher = {Association for Computational Linguistics},
	title = {Re-Ranking Words to Improve Interpretability of Automatically Generated Topics},
	url = {https://aclanthology.org/W19-0404},
	year = {2019},
	bdsk-url-1 = {https://aclanthology.org/W19-0404},
	bdsk-url-2 = {https://doi.org/10.18653/v1/W19-0404}}

@article{aletras_2017_evaluating_topic_representations_for_exploring_document_collections,
	abstract = {Topic models have been shown to be a useful way of representing the content of large document collections, for example, via visualization interfaces topic browsers. These systems enable users to explore collections by way of latent topics. A standard way to represent a topic is using a term list; that is the top-n words with highest conditional probability within the topic. Other topic representations such as textual and image labels also have been proposed. However, there has been no comparison of these alternative representations. In this article, we compare 3 different topic representations in a document retrieval task. Participants were asked to retrieve relevant documents based on predefined queries within a fixed time limit, presenting topics in one of the following modalities: a lists of terms, b textual phrase labels, and c image labels. Results show that textual labels are easier for users to interpret than are term lists and image labels. Moreover, the precision of retrieved documents for textual and image labels is comparable to the precision achieved by representing topics using term lists, demonstrating that labeling methods are an effective alternative topic representation.},
	address = {USA},
	author = {Aletras, Nikolaos and Baldwin, Timothy and Lau, Jey Han and Stevenson, Mark},
	date-added = {2022-11-17 18:00:35 +0100},
	date-modified = {2022-11-17 18:00:35 +0100},
	doi = {aletras_2017_evaluating_topic_representations_for_exploring_document_collections},
	issn = {2330-1635},
	issue_date = {January 2017},
	journal = {J. Assoc. Inf. Sci. Technol.},
	month = {jan},
	number = {1},
	numpages = {14},
	pages = {154--167},
	publisher = {John Wiley &amp; Sons, Inc.},
	title = {Evaluating Topic Representations for Exploring Document Collections},
	url = {https://doi.org/10.1002/asi.23574},
	volume = {68},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1002/asi.23574}}

@article{agrawal_2018_what_is_wrong_with_topic_modeling_and_how_to_fix_it_using_search_based_software_engineering,
	abstract = {Context
Topic modeling finds human-readable structures in unstructured textual data. A widely used topic modeling technique is Latent Dirichlet allocation. When running on different datasets, LDA suffers from ``order effects'', i.e., different topics are generated if the order of training data is shuffled. Such order effects introduce a systematic error for any study. This error can relate to misleading results; specifically, inaccurate topic descriptions and a reduction in the efficacy of text mining classification results.
Objective
To provide a method in which distributions generated by LDA are more stable and can be used for further analysis.
Method
We use LDADE, a search-based software engineering tool which uses Differential Evolution (DE) to tune the LDA's parameters. LDADE is evaluated on data from a programmer information exchange site (Stackoverflow), title and abstract text of thousands of Software Engineering (SE) papers, and software defect reports from NASA. Results were collected across different implementations of LDA (Python+Scikit-Learn, Scala+Spark) across Linux platform and for different kinds of LDAs (VEM, Gibbs sampling). Results were scored via topic stability and text mining classification accuracy.
Results
In all treatments: (i) standard LDA exhibits very large topic instability; (ii) LDADE's tunings dramatically reduce cluster instability; (iii) LDADE also leads to improved performances for supervised as well as unsupervised learning.
Conclusion
Due to topic instability, using standard LDA with its ``off-the-shelf'' settings should now be depreciated. Also, in future, we should require SE papers that use LDA to test and (if needed) mitigate LDA topic instability. Finally, LDADE is a candidate technology for effectively and efficiently reducing that instability.},
	author = {Amritanshu Agrawal and Wei Fu and Tim Menzies},
	date-added = {2022-11-17 17:59:19 +0100},
	date-modified = {2022-11-17 17:59:19 +0100},
	doi = {https://doi.org/10.1016/j.infsof.2018.02.005},
	issn = {0950-5849},
	journal = {Information and Software Technology},
	keywords = {Topic modeling, Stability, LDA, Tuning, Differential evolution},
	pages = {74-88},
	title = {What is wrong with topic modeling? And how to fix it using search-based software engineering},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584917300861},
	volume = {98},
	year = {2018},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0950584917300861},
	bdsk-url-2 = {https://doi.org/10.1016/j.infsof.2018.02.005}}
