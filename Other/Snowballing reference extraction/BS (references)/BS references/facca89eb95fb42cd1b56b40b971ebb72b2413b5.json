{"paperId": "facca89eb95fb42cd1b56b40b971ebb72b2413b5", "title": "Topically Driven Neural Language Model", "references": [{"paperId": "934be2cdd0c06f73b01e704de4d6162dc354e173", "title": "The Sensitivity of Topic Coherence Evaluation to Topic Cardinality"}, {"paperId": "889e57259a1d6017701fb2c2ceece82f9f4eff4c", "title": "Recurrent Memory Networks for Language Modeling"}, {"paperId": null, "title": "Largercontext language modelling with recurrent neural network"}, {"paperId": "e8e76b1062918624e9904e0073e11794d7594593", "title": "Document Context Language Models"}, {"paperId": "a739ae988ba0e3ff232f4507627dfc282ba7b3f4", "title": "Depth-Gated LSTM"}, {"paperId": "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e", "title": "End-To-End Memory Networks"}, {"paperId": "d10b7c5dd80f866cff7280f6516ca5041924d6c0", "title": "A Novel Neural Topic Model and Its Supervised Extension"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "71ae756c75ac89e2d731c9c79649562b5768ff39", "title": "Memory Networks"}, {"paperId": "adfcf065e15fd3bc9badf6145034c84dfb08f204", "title": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling"}, {"paperId": "c3823aacea60bc1f2cabb9283144690a3d015db5", "title": "Neural Turing Machines"}, {"paperId": "f264e8b33c0d49a692a6ce2c4bcb28588aeb7d97", "title": "Recurrent Neural Network Regularization"}, {"paperId": "1eb09fecd75eb27825dce4f964b97f4f5cc399d7", "title": "On the Properties of Neural Machine Translation: Encoder\u2013Decoder Approaches"}, {"paperId": "4987baca7365133a03b8a0849bae337d8bf0c3c4", "title": "Machine Reading Tea Leaves: Automatically Evaluating Topic Coherence and Topic Model Quality"}, {"paperId": "c0b624c46b51920dfec5aa02cc86323c0beb0df5", "title": "Dropout Improves Recurrent Neural Networks for Handwriting Recognition"}, {"paperId": "34f25a8704614163c4095b3ee2fc969b60de4698", "title": "Dropout: a simple way to prevent neural networks from overfitting"}, {"paperId": "bcd1c98f58aa580a628cf4c690efca947f89dbae", "title": "Evaluating Topic Coherence Using Distributional Semantics"}, {"paperId": "d1b78d136e9e6be0aeb814027f0f3fd843606155", "title": "A Neural Autoregressive Topic Model"}, {"paperId": "d94072c75fce4f8984db863c85e78fa4895cdb59", "title": "A Hybrid Neural Network-Latent Topic Model"}, {"paperId": null, "title": "A hybrid neural networklatent topic model Larger - context language modelling with recurrent neural network"}, {"paperId": "ef2d64e448ee5ed2dc26179c8570803ded123a5e", "title": "Optimizing Semantic Coherence in Topic Models"}, {"paperId": "649d03490ef72c5274e3bccd03d7a299d2f8da91", "title": "Learning Word Vectors for Sentiment Analysis"}, {"paperId": "bc1022b031dc6c7019696492e8116598097a8c12", "title": "Natural Language Processing (Almost) from Scratch"}, {"paperId": "8e31f3c7e70e9a5f8afafd86cebc004d5eca8c2b", "title": "Automatic Evaluation of Topic Coherence"}, {"paperId": null, "title": "Visualizing document collections and search results using topic mapping"}, {"paperId": "9819b600a828a57e1cde047bbe710d3446b30da5", "title": "Recurrent neural network based language model"}, {"paperId": "edd0aec78e53c08c90305e7a1234c2644d8f104a", "title": "Reading Tea Leaves: How Humans Interpret Topic Models"}, {"paperId": "b32de117302258dd29919435cd001a8bcdfee3b3", "title": "Replicated Softmax: an Undirected Topic Model"}, {"paperId": "2f041bde7e1968427b09ce428116b21152c7e715", "title": "Evaluation methods for topic models"}, {"paperId": "5f3bcff2f4ce3130df160719c096bfe942b06f58", "title": "Studying the History of Ideas Using Topic Models"}, {"paperId": null, "title": "Griffiths , Mark Steyvers , David M . Blei , and Joshua B . Tenenbaum . 2004 . Integrating topics and syntax"}, {"paperId": "c13aa63ccd5cf972a0a8c6b236c1dfad95b19b4e", "title": "Supervised Topic Models"}, {"paperId": null, "title": "The British National Corpus, version 3 (BNC XML Edition)"}, {"paperId": "97a5bdf0ed22a5688abef32b282e922da362e7b5", "title": "Topics over time: a non-Markov continuous-time model of topical trends"}, {"paperId": "0ecc5ffeae38689dd2fe6ed4c32a6745744d7641", "title": "Integrating Topics and Syntax"}, {"paperId": "e99f196cf21e0781ef1e119d14e6db45cd71bf3b", "title": "Finding scientific topics"}, {"paperId": "a600850ac0120cb09a0b7de7da80bb6a7a76de06", "title": "Accurate Unlexicalized Parsing"}, {"paperId": "f198043a866e9187925a8d8db9a55e3bfdd47f2c", "title": "Latent Dirichlet Allocation"}, {"paperId": "545a4e23bf00ddbc1d3325324b4c61f57cf45081", "title": "Recurrent nets that time and count"}, {"paperId": "44d2abe2175df8153f465f6c39b68b76a0d40ab9", "title": "Long Short-Term Memory"}, {"paperId": null, "title": "Griffiths and Mark Steyvers . 2004 . Finding scientific topics"}]}
